Question ID,Question Title,Question Body,Question Tags,Answer ID,Answer Score,Answer Body
52424976,kubernetes nginx ingress controller expose nginx webserver,"i basically want to access the nginx-hello page externally by url. i've made a (working) a-record for a subdomain to my v-server running kubernetes and nginx ingress: vps.my-domain.com

i installed kubernetes via kubeadm on coreos as a single-node cluster using these tutorials: https://kubernetes.io/docs/setup/independent/install-kubeadm/, https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/, and nginx-ingress using https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal.

i also added the following entry to the /etc/hosts file:

31.214.xxx.xxx vps.my-domain.com


(xxx was replaced with the last three digits of the server ip)

i used the following file to create the deployment, service, and ingress:

apiversion: apps/v1
kind: deployment
metadata:
  name: my-nginx
spec:
  selector:
    matchlabels:
      run: my-nginx
  replicas: 1
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      containers:
      - name: my-nginx
        image: nginx
        ports:
        - name: http
          containerport: 80
          protocol: tcp
---
apiversion: v1
kind: service
metadata:
  name: my-nginx
  labels:
    run: my-nginx
spec:
  type: clusterip
  ports:
  - name: http
    port: 80
    protocol: tcp
    targetport: http
  selector:
    run: my-nginx
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-nginx
  annotations:
    kubernetes.io/ingress.class: ""nginx""
    ingress.kubernetes.io/ssl-redirect: ""false""
spec:
  rules:
  - host: vps.my-domain.com
    http:
      paths:
      - backend:
          servicename: my-nginx
          serviceport: 80


output of describe ing:

core@vps ~/k8 $ kubectl describe ing
name:             my-nginx
namespace:        default
address:
default backend:  default-http-backend:80 (&lt;none&gt;)
rules:
  host                  path  backends
  ----                  ----  --------
  vps.my-domain.com
                           my-nginx:80 (&lt;none&gt;)
annotations:
  kubectl.kubernetes.io/last-applied-configuration:      
{""apiversion"":""extensions/v1beta1"",...}

  kubernetes.io/ingress.class:         nginx
  ingress.kubernetes.io/ssl-redirect:  false
events:
  type    reason  age                from                      message
  ----    ------  ----               ----                      -------
  normal  update  49m (x2 over 56m)  nginx-ingress-controller  ingress default/my-nginx


while i can curl the nginx hello page using the nodeip and port 80 it doesn't work from outside the vm. failed to connect to vps.my-domain.com port 80: connection refused

did i forgot something or is the configuration just wrong? any help or tips would be appreciated! 

thank you

edit:

visiting ""vps.my-domain.com:30519` gives me the nginx welcome page. but in the config i specified port :80.
i got the port from the output of get services:

core@vps ~/k8 $ kubectl get services --all-namespaces | grep ""my-nginx""
default         my-nginx               clusterip   10.107.5.14      &lt;none&gt;        80/tcp                       1h


i also got it to work on port :80 by adding   

externalips:
  - 31.214.xxx.xxx


to the my-nginx service. but this is not how it's supposed to work, right? in the tutorials and examples for kubernetes and ingress-nginx, it worked always without externalips. also the ingress rules doesn't work now (e.g. if i set the path to /test).
",<docker><nginx><kubernetes><kubernetes-ingress><nginx-ingress>,52426654,2,"so apparently i was missing one part: the load balancer. i'm not sure why this wasn't mentioned in those instructions as a requirement. but i followed this tutorial: https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb and now everything works. 

since metallb requires multiple ip addresses, you have to list your single ip-adress with the subnet \32: 31.214.xxx.xxx\32
"
73163375,kubernetes cannot pull a public image,"kubernetes cannot pull a public image. standard images like nginx are downloading successfully, but my pet project is not downloading. i'm using minikube for launch kubernetes-cluster
apiversion: apps/v1
kind: deployment
metadata:
  name: api-gateway-deploumnet
  labels:
    app: api-gateway
spec:
  replicas: 3
  selector:
    matchlabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: creatorsprodhouse/api-gateway:latest
        imagepullpolicy: always
        ports:
        - containerport: 80

when i try to create a deployment i get an error that kubernetes cannot download my public image.
$ kubectl get pods

result:
name                                      ready   status             restarts   age
api-gateway-deploumnet-599c784984-j9mf2   0/1     imagepullbackoff   0          13m
api-gateway-deploumnet-599c784984-qzklt   0/1     imagepullbackoff   0          13m
api-gateway-deploumnet-599c784984-csxln   0/1     imagepullbackoff   0          13m

$ kubectl logs api-gateway-deploumnet-599c784984-csxln 

result
error from server (badrequest): container &quot;api-gateway&quot; in pod &quot;api-gateway-deploumnet-86f6cc5b65-xdx85&quot; is waiting to start: trying and failing to pull image

what could be the problem? the standard images are downloading but my public one is not. any help would be appreciated.
edit 1
$ api-gateway-deploumnet-599c784984-csxln

result:
events:
  type     reason     age                    from               message
  ----     ------     ----                   ----               -------
  normal   scheduled  8m22s                  default-scheduler  successfully assigned default/api-gateway-deploumnet-849899786d-mq4td to minikube
  warning  failed     3m8s                   kubelet            failed to pull image &quot;creatorsprodhouse/api-gateway:latest&quot;: rpc error: code = unknown desc = context deadline exceeded
  warning  failed     3m8s                   kubelet            error: errimagepull
  normal   backoff    3m7s                   kubelet            back-off pulling image &quot;creatorsprodhouse/api-gateway:latest&quot;
  warning  failed     3m7s                   kubelet            error: imagepullbackoff
  normal   pulling    2m53s (x2 over 8m21s)  kubelet            pulling image &quot;creatorsprodhouse/api-gateway:latest&quot;

edit 2
if i try to download a separate docker image, it's fine
$ docker pull creatorsprodhouse/api-gateway:latest

result:
digest: sha256:e664a9dd9025f80a3dd60d157ce1464d4df7d0f8a00538e6a137d44f9f9f12aa
status: downloaded newer image for creatorsprodhouse/api-gateway:latest
docker.io/creatorsprodhouse/api-gateway:latest

edit 3
after advice to restart minikube
$ minikube stop

$ minikube delete --purge

$ minikube start --cni=calico

i started the pods.

events:
  type     reason                  age    from               message
  ----     ------                  ----   ----               -------
  normal   scheduled               4m28s  default-scheduler  successfully assigned default/api-gateway-deploumnet-849899786d-bkr28 to minikube
  warning  failedcreatepodsandbox  4m27s  kubelet            failed to create pod sandbox: rpc error: code = unknown desc = [failed to set up sandbox container &quot;7e112c92e24199f268ec9c6f3a6db69c2572c0751db9fd57a852d1b9b412e0a1&quot; network for pod &quot;api-gateway-deploumnet-849899786d-bkr28&quot;: networkplugin cni failed to set up pod &quot;api-gateway-deploumnet-849899786d-bkr28_default&quot; network: failed to set bridge addr: could not add ip address to &quot;cni0&quot;: permission denied, failed to clean up sandbox container &quot;7e112c92e24199f268ec9c6f3a6db69c2572c0751db9fd57a852d1b9b412e0a1&quot; network for pod &quot;api-gateway-deploumnet-849899786d-bkr28&quot;: networkplugin cni failed to teardown pod &quot;api-gateway-deploumnet-849899786d-bkr28_default&quot; network: running [/usr/sbin/iptables -t nat -d postrouting -s 10.85.0.34 -j cni-57e7da7379b524635074e6d0 -m comment --comment name: &quot;crio&quot; id: &quot;7e112c92e24199f268ec9c6f3a6db69c2572c0751db9fd57a852d1b9b412e0a1&quot; --wait]: exit status 2: iptables v1.8.4 (legacy): couldn't load target `cni-57e7da7379b524635074e6d0':no such file or directory

try `iptables -h' or 'iptables --help' for more information.


",<kubernetes><kubectl><minikube>,73290885,1,"i could not solve the problem in the ways i was suggested. however, it worked when i ran minikube with a different driver
$ minikube start --driver=none

--driver=none means that the cluster will run on your host instead of the standard --driver=docker which runs the cluster in docker.
it is better to run minikube with --driver=docker as it is safer and easier, but it didn't work for me as i could not download my images. for me personally it is ok to use --driver=none although it is a bit dangerous.
in general, if anyone knows what the problem is, please answer my question. in the meantime you can try to run minikube cluster on your host with the command i mentioned above.
in any case, thank you very much for your attention!
"
71889733,"kubernetes ingres.yml unknown field ""service.port.number"" in io.k8s.api.networking.v1","i'm running into issues with my ingress.yml. getting this error:
error: error validating &quot;ingress.yml&quot;: error validating data: [validationerror(ingress.spec.rules[0].http.paths[0].backend): unknown field &quot;service.name&quot; in io.k8s.api.networking.v1.ingressbackend, validationerror(ingress.spec.rules[0].http.paths[0].backend): unknown field &quot;service.port.number&quot; in io.k8s.api.networking.v1.ingressbackend, validationerror(ingress.spec.rules[0].http.paths[1].backend): unknown field &quot;service.name&quot; in io.k8s.api.networking.v1.ingressbackend, validationerror(ingress.spec.rules[0].http.paths[1].backend): unknown field &quot;service.port.number&quot; in io.k8s.api.networking.v1.ingressbackend];
based on this documentation servicename changed to service.name and serviceport changed to service.port and so on. here is the ingress file:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: bitwarden
  namespace: bitwarden
  labels:
    app: bitwarden
  annotations:
    # the name of the nginx-ingress-controller class
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers &quot;request-id: $req_id&quot;;
    nginx.ingress.kubernetes.io/connection-proxy-header: &quot;keep-alive&quot;
    nginx.ingress.kubernetes.io/enable-cors: &quot;true&quot;
    nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
    nginx.ingress.kubernetes.io/limit-connections: &quot;25&quot;
    nginx.ingress.kubernetes.io/limit-rps: &quot;15&quot;
    nginx.ingress.kubernetes.io/proxy-body-size: 1024m
    nginx.ingress.kubernetes.io/proxy-connect-timeout: &quot;10&quot;
    nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;1800&quot;
    nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;1800&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
    cert-manager.io/cluster-issuer: &quot;letsencrypt-prod&quot;
spec:
  tls:
  - hosts:
    - kryskanbit.ddns.net
    secretname: bitwarden-tls
  rules:
  - host: kryskanbit.ddns.net
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service.name: bitwarden
          service.port.number: 80
      - path: /notifications/hub
        pathtype: exact
        backend:
          service.name: bitwarden
          service.port.number: 3012

",<kubernetes><kubernetes-ingress><kubectl>,71891258,1,"kubernetes has a special treatment for yaml format, so basically, you just need to extend the properties individually the service.name and service.port.number:
...
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: bitwarden
                port:
                  number: 80
          - path: /notifications/hub
            pathtype: exact
            backend:
              service:
                name: bitwarden
                port:
                  number: 3012

"
41482485,kubectl behind a proxy,"i have installed a local kubernetes cluster using minikube following the instructions here.

i'm under a corporate proxy. therefore i have set the http_proxy and https_proxy env vars. once the cluster is started after minikube start command i also added the value of minikube ip to the no_proxy env var. however still kubectl cannot connect to the cluster.

ubuntu@ros-2:~$ kubectl -v=7 get pods
i0105 10:31:47.773801   17607 loader.go:354] config loaded from file /home/ubuntu/.kube/config
i0105 10:31:47.775151   17607 round_trippers.go:296] get https://192.168.42.22:8443/api
i0105 10:31:47.778533   17607 round_trippers.go:303] request headers:
i0105 10:31:47.778606   17607 round_trippers.go:306]     accept: application/json, */*
i0105 10:31:47.778676   17607 round_trippers.go:306]     user-agent: kubectl/v1.5.1 (linux/amd64) kubernetes/82450d0
i0105 10:31:47.783069   17607 round_trippers.go:321] response status:  in 4 milliseconds
i0105 10:31:47.783166   17607 helpers.go:221] connection error: get https://192.168.42.22:8443/api: forbidden port
f0105 10:31:47.783181   17607 helpers.go:116] unable to connect to the server: forbidden port


i'm assuming this is because of kubectl not being aware of the no_proxy settings. a simple curl to the cluster goes through fine.

ubuntu@ros-2:~$ curl -v -k https://192.168.42.22:8443/api
* hostname was not found in dns cache
*   trying 192.168.42.22...
* connected to 192.168.42.22 (192.168.42.22) port 8443 (#0)
* successfully set certificate verify locations:
*   cafile: none
  capath: /etc/ssl/certs
* sslv3, tls handshake, client hello (1):
* sslv3, tls handshake, server hello (2):
* sslv3, tls handshake, cert (11):
* sslv3, tls handshake, server key exchange (12):
* sslv3, tls handshake, request cert (13):
* sslv3, tls handshake, server finished (14):
* sslv3, tls handshake, cert (11):
* sslv3, tls handshake, client key exchange (16):
* sslv3, tls change cipher, client hello (1):
* sslv3, tls handshake, finished (20):
* sslv3, tls change cipher, client hello (1):
* sslv3, tls handshake, finished (20):
* ssl connection using ecdhe-rsa-aes128-gcm-sha256
* server certificate:
*        subject: cn=minikube
*        start date: 2017-01-04 16:04:47 gmt
*        expire date: 2018-01-04 16:04:47 gmt
*        issuer: cn=minikubeca
*        ssl certificate verify result: unable to get local issuer certificate (20), continuing anyway.
&gt; get /api http/1.1
&gt; user-agent: curl/7.35.0
&gt; host: 192.168.42.22:8443
&gt; accept: */*
&gt;
&lt; http/1.1 401 unauthorized
&lt; content-type: text/plain; charset=utf-8
&lt; x-content-type-options: nosniff
&lt; date: thu, 05 jan 2017 10:33:45 gmt
&lt; content-length: 13
&lt;
unauthorized
* connection #0 to host 192.168.42.22 left intact


any ideas on how to fix this?
",<proxy><kubernetes><kubectl><minikube>,41482866,55,"fixed this. the fix was to have the no_proxy details in no_proxy as well.

export no_proxy=$no_proxy,$(minikube ip)


relevant thread. hope this will be useful to someone.
"
69577282,pod name resolution for statefulset doesn't work,"i have the following kubernetes yaml with a statefulset i use to deploy a postgresql cluster with patroni. however, the question is relative to how kubernetes registers pod names in coredns.
according to this documentation in the stable network id section if i create a headless service called spilodemo-svc for my pods i can access them using the short hostname (podname.servicename):
spilodemo-0.spilodemo-svc

basically, my code worked properly for a long time on a k8s cluster deployed with kubeadm on virtualbox and vagrant. today i wanted to deploy it on ibm cloud but the hostname above didn't work and the strange thing is that when i repeated my tests on vagrant/virtualbox again i wasn't able to have it working anymore and i do not know why.
now the yaml deploys spilo that is an open-source project developed by zalando that is a docker image with patroni and postgresql. my code comes from their example here.
basically, they create a clusterip service (and not a headless) with no selector. under these conditions, kubernetes doesn't create an endpoint in it. for this reason, we have an endpoint in the yaml with the same name of the service (it seems this is the binding kubernetes expect).
spilo has python code that always keeps updated this endpoint with the ip of the primary node.
the statefulset has the field servicename equal to the name of the service:
servicename: spilodemo-svc

and, according to the documentation, this guarantees that kubernetes creates an entry in coredns for this short hostname (podname.servicename):
spilodemo-0.spilodemo-svc

and it worked for a long time until today and nothing happened in the meanwhile. to be honest i never fully understand how the dns name spilodemo-0.spilodemo-svc worked so far since it uses a clusterip service instead of a headless one.
another strange thing is that the zalando team uses another headless service that i called spilodemo-config and according to a comment in their code, it should avoid that kubernetes delete the endpoint but this doesn't make much sense to me.
however, today i also tried to convert the service into a headless one removing the spilodemo-config one but no luck. kubernetes only create the entry for the service in the coredns:
spilodemo.spilons.svc.cluster.local

but not the one for each pod:
spilodemo-0.spilodemo-svc
spilodemo-1.spilodemo-svc
spilodemo-2.spilodemo-svc

can anyone help me to figure out what's going on with my yaml file and how i can get the three short hostnames above working in coredns?
ps
on stackoverflow i found these discussions:

hostname of pods in the same statefulset can not be resolved
stateful pod hostname doesn't resolve
but they don't address my issue.

",<kubernetes><kubernetes-pod><kubernetes-statefulset><coredns><patroni>,69737368,2,"after almost three days of tests, i found a solution. the solution depends on two things:

how kubernetes works;
how patroni works.

how kubernetes works
when you create a statefulset deployment (but this is true also for deployment), let's say with 3 pods, kubernetes register in coredns three dns names:
ip-with-dashes.&lt;namespace&gt;.pod.cluster.local

however, these names are useless for me because i cannot set them in advance on my yaml files because it depends on the ip kubernetes assigned to pods.
however, for statefulset deployments, according to this documentation in the stable network id section if i create a headless service for my pod i can access them using the short hostname (podname.servicename) of fqdn (...svc.cluster.local).
here is the headless service i needed to create:
---
apiversion: v1
kind: service
metadata:
  name: spilodemo-svc
  labels:
    application: spilo
    spilo-cluster: spilodemo
spec:
  clusterip: none
  selector:
    application: spilo
    spilo-cluster: spilodemo

it's important here to set the selector to bind all three pods. another important thing is to add the following line to your statefulset with a name equal to the headless service:
servicename: spilodemo-svc

this is the kubernetes part. now you can reference your pods with dns names:
spilodemo-0.spilodemo-svc
spilodemo-1.spilodemo-svc
spilodemo-2.spilodemo-svc

or fqdn:
spilodemo-0.spilodemo-svc.&lt;namespace&gt;.svc.cluster.local
spilodemo-1.spilodemo-svc.&lt;namespace&gt;.svc.cluster.local
spilodemo-2.spilodemo-svc.&lt;namespace&gt;.svc.cluster.local

how patroni works
however, using pods' dns name is not meaningful for clients because they need a single point of access. for this reason, the patroni team suggest to create a clusterip service like this:
---
apiversion: v1
kind: service
metadata:
  name: spilodemo
  labels:
    application: spilo
    spilo-cluster: spilodemo
spec:
  type: clusterip
  ports:
  - name: postgresql
    port: 5432
    targetport: 5432

note: there is no selector. this is not an error. when you create a service like this kubernetes creates a clusterip service (then it can be referenced using an ip or hostname) but without an endpoint. this means that you connect to its ip or its dns name: spilodemo.&lt;namespace&gt;.svc.cluster.local, the connection hangs.
for this reason, the patroni team asks you to add in your yaml file the following endpoint having the same name as the clusterip service.
apiversion: v1
kind: endpoints
metadata:
  name: spilodemo
  labels:
    application: spilo
    spilo-cluster: spilodemo
subsets: []

patroni, internally, has a piece of code in python that via kubernetes api updates this endpoint with the master pod ip. patroni is able to determine the endpoint to update using its relative labels above (application, spilo-cluster) that you can even customize.
at this point, patroni cluster clients only need to use this dns name (the clusterip one) or the relative ip:
spilodemo.spilons.svc.cluster.local

the connection is automatically redirected to the pod master node ip.
so far so good. now the confusing part. if you look at the patroni kubernetes sample file in spilo code, you node another headless service was already present.
---
# headless service to avoid deletion of patronidemo-config endpoint
apiversion: v1
kind: service
metadata:
  name: spilodemo-config
  labels:
    application: spilo
    spilo-cluster: spilodemo
spec:
  clusterip: none

what confuse me was the presence of this headless service. i didn't understand its purpose. in the beginning, i thought it was the headless service required to have the pods dns name mentioned above. but i was wrong. the purpose of this service is different. basically, the zalando team doesn't know how the user writes the yaml file to deploy patroni. if the user creates the endpoint but forgot to associate to it a service, kubernetes see it as an orphan and delete it. for this reason, the patroni code itself creates this service on its own. in fact, if you don't define it in the yaml file, patroni will create it for you.
so, if patroni creates it for you why do they add it in the sample yaml above? the reason is permissions. if pod doesn't have permissions cannot create it. this is the reason they added it in the yaml. it's a bit confusing but this is the whole story.
"
48248522,unhealthy load balancer on gce,"i have a couple of services and the loadbalancers work fine. now i keep facing an issue with a service that runs fine, but when a loadbalancer is applied i cannot get it to work, because one service seams to be unhealty, but i cannot figure out why. how can i get that service healthy?



here are my k8s yaml.
deployment:

kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: api-production
spec:
  replicas: 1
  template:
    metadata:
      name: api
      labels:
        app: api
        role: backend
        env: production
    spec:
      containers:
      - name: api
        image: eu.gcr.io/foobar/api:1.0.0
        livenessprobe:
          httpget:
            path: /readinez
            port: 8080
          initialdelayseconds: 45
          periodseconds: 10
        readinessprobe:
          httpget:
            path: /healthz
            port: 8080
        env:
        - name: environment
          value: ""production""
        - name: gin_mode
          value: ""release""
        resources:
          limits:
            memory: ""500mi""
            cpu: ""100m""
        imagepullpolicy: always
        ports:
        - name: api
          containerport: 8080


service.yaml

kind: service
apiversion: v1
metadata:
  name: api
spec:
  selector:
    app: api
    role: backend
  type: nodeport
  ports:
  - name: http
    port: 8080
  - name: external
    port: 80
    targetport: 80


ingress.yaml

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: api
  namespace: production
  annotations:
    kubernetes.io/tls-acme: ""true""
    kubernetes.io/ingress.class: ""gce""
spec:
  tls:
  - hosts:
    - foo.bar.io
    secretname: api-tls
  rules:
  - host: foo.bar.io
    http:
      paths:
      - path: /*
        backend:
          servicename: api
          serviceport: 80

",<kubernetes><google-cloud-platform><google-kubernetes-engine>,48347326,1,"the problem was solved by configuring the ports in the correct way. container, service and lb need (obviously) to be aligned. i also added the initialdelayseconds.

lb:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: api
  namespace: production
  annotations:
    # kubernetes.io/ingress.allow-http: ""false""
    kubernetes.io/tls-acme: ""true""
    kubernetes.io/ingress.class: ""gce""
spec:
  tls:
  - hosts:
    - api.foo.io
    secretname: api-tls
  rules:
  - host: api.foo.io
    http:
      paths:
      - path: /*
        backend:
          servicename: api
          serviceport: 8080 


service:

kind: service
apiversion: v1
metadata:
  name: api
spec:
  selector:
    app: api
    role: backend
  type: nodeport
  ports:
    - protocol: tcp
      port: 8080
      targetport: 8080
      name: http 


deployment:

kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: api-production
spec:
  replicas: 1
  template:
    metadata:
      name: api
      labels:
        app: api
        role: backend
        env: production
    spec:
      containers:
      - name: api
        image: eu.gcr.io/foobarbar/api:1.0.0
        livenessprobe:
          httpget:
            path: /readinez
            port: 8080
          initialdelayseconds: 45
          periodseconds: 10
        readinessprobe:
          httpget:
            path: /healthz
            port: 8080
          initialdelayseconds: 45
        env:
         - name: environment
          value: ""production""
        - name: gin_mode
          value: ""release""
        resources:
          limits:
            memory: ""500mi""
            cpu: ""100m""
        imagepullpolicy: always
        ports:
        - containerport: 8080

"
76493147,mongo command not working after logging into kubernetes pod,"i wanted to check my mongo database, not sure which database my application is putting the data. basically i have configured a very simple tasks application using a python flask api(deployed in gke) which in turn connects to a mongo database in the same gke cluster. the application works fine.
i referred to this link
link
below is my application yaml file
apiversion: apps/v1
kind: deployment
metadata:
  name: tasksapp
  labels:
    app: tasksapp
spec:
  replicas: 1
  selector:
    matchlabels:
      app: tasksapp
  template:
    metadata:
      labels:
        app: tasksapp
    spec:
      containers:
        - name: tasksapp
          image: myimage/1.0
          ports:
            - containerport: 5000
          imagepullpolicy: always

the python code section which connects to the database ---&gt;this does not have username /password. not sure which database it is connecting to(even though in the code it says as 'dev'. this is why i wanted to check the mongo db pod.
from bson.objectid import objectid
import socket
app = flask(__name__)
app.config[&quot;mongo_uri&quot;] = &quot;mongodb://mongo:27017/dev&quot;
mongo = pymongo(app)
db = mongo.db
@app.route(&quot;/&quot;)
def index():
    hostname = socket.gethostname()
    return jsonify(
        message=&quot;welcome to tasks app! i am running inside {} pod!&quot;.format(hostname)
    )

the mongo db deployment yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: mongo
spec:
  selector:
    matchlabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: mongo
          ports:
            - containerport: 27017
          volumemounts:
            - name: storage
              mountpath: /data/db
      volumes:
        - name: storage
          persistentvolumeclaim:
            claimname: mongo-pvc

the issue is that when i log into the pod for mongo, mongo command is not recognized as shown below?
kubectl exec -it mongo-869f6488c8-jnkgp -- /bin/bash
root@mongo-869f6488c8-jnkgp:/# cd home
root@mongo-869f6488c8-jnkgp:/home# ls
root@mongo-869f6488c8-jnkgp:/home# mongo
bash: mongo: command not found

",<python><mongodb><kubernetes><flask><google-kubernetes-engine>,76493913,1,"your deployment does not specify an image tag so will run the latest version of mongo (currently v6).
v6 mongo does not include this legacy mongo shell; it has been replaced with mongosh
docker run -it --entrypoint /bin/bash mongo
root@e920eac138d7:/# mongo
bash: mongo: command not found
root@e920eac138d7:/# mongosh --nodb
current mongosh log id: 648ce23ff5d64ce445218977
using mongosh:          1.10.0

for mongosh info see: https://docs.mongodb.com/mongodb-shell/


to help improve our products, anonymous usage data is collected and sent to mongodb periodically (https://www.mongodb.com/legal/privacy-policy).
you can opt-out by running the disabletelemetry() command.

notwithstanding this, the points that ernani makes are also relevant.
"
65633719,default-http-backend is stopping me to hit the ingress rule created,"am installing nginx-controller to expose the service, after installing the ingress resource am not able to hit the desired port. i get failed saying the below,
[root@k8-m smartrem]# kubectl describe ingress ingress-svc
name:             ingress-svc
namespace:        default
address:
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host          path  backends
  ----          ----  --------
  auditmee.com
                /swagger-ui.html   springboot-service:8080 (192.168.157.76:8080,192.168.157.77:8080,192.168.250.8:8080)
annotations:    &lt;none&gt;
events:         &lt;none&gt;

i see the errors are related to default-http-backend, how to create the default-http-backend service.
any help would be highly appreciated
",<kubernetes><kubernetes-ingress><nginx-ingress>,65770952,2,"there are several parts in this question, i do think need to be addressed:


there are multiple nginx ingress controllers available to use within kubernetes environment. specifying which exact one is used will definitely help in troubleshooting process as there could be slight differences in their inner workings that could affect your workload.

you can read more about this topic (nginx based ingress controllers) by following this thread:

github.com: nginxinc: kubernetes ingress: blob: master: docs: nginx ingress controllers


a side note!
i saw you're using this specific ingress controller as per previous question asked on stackoverflow:

https://github.com/nginxinc/kubernetes-ingress




what is a default-backend?

default-backend in short is a &quot;place&quot; (deployment with a pod and a service) where all the traffic that doesn't match ingress resource is sent (for example unknown path).
your ingress resource is displaying following message:

default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)

as it can't find an endpoint named default-http-backend (with associated service of the same name). to fix that you'll need to provision such resources.
example of such default-backend implementation:

github.com: uswitch: master: deploy: default-backend.yaml



ingress resources and it's path

as for your ingress resource. it's crucial to include yaml manifests for resources you are deploying. it's easier for other community member to see the whole pictures and the potential issues you are facing.
by the part of the: $ kubectl describe ingress ingress-svc it can be seen:
rules:
  host          path  backends
  ----          ----  --------
  auditmee.com
                /swagger-ui.html   springboot-service:8080 (192.168.157.76:8080,...) 

there is a host: host.com that have one really specific path (file to be exact). setup like this will allow your client to have access only to swagger-ui.html. if you had some other files, there wouldn't be available:

curl http://host/swagger-ui.html &lt;-- 200
curl http://host/super-awesome-icon.png &lt;-- 404


a side note!
also please check on which protocol http/https are you serving your resources.

as your workload is unknown to us, you could try to set your path to path: /. this rule would allow all request for resources for host to be passed to your springboot-service.

i encourage you to check available documentation for more resources:

kubernetes.io: docs: concepts: services networking: ingress
github.com: nginxinc: kubernetes ingress:

github.com: nginxinc: kubernetes ingress: examples: complete example



i also found displaying logs of the ingress controller to be highly effective in troubleshooting:

$ kubectl logs -n namespace ingress-pod-name

"
60280485,kubernetes ingress difference of path/backend specification,"what's the difference between these two specs in my ingress resource. do they perform the same thing? when do i use which type?

spec:
  rules:
  - host: {{ .values.subdomain }}{{ .values.domain }}
    http:
      paths:
        - path: /api
          backend:
            servicename: {{ .values.servicename }}
            serviceport: 80


and:

spec:
  rules:
  - host: {{ .values.subdomain }}{{ .values.domain }}
    http:
      paths:
      - backend:
          servicename: {{ .values.servicename }}
          serviceport: 80
        path: /api

",<kubernetes><kubernetes-ingress>,60281647,1,"there is no difference. the paths field is a list of maps(dictionary), where each map consists of path and backend field. within a map, the order of fields doesn't matter which is the case in your two templates.
"
68258172,how to access the keycloak.local ingress host?,"i just installed the keycloak kubernetes operator using the official operatorhub.io guide: https://operatorhub.io/operator/keycloak-operator
afterwards i created an operator deployment by following the official keycloak getting started guide: https://www.keycloak.org/getting-started/getting-started-operator-kubernetes
i can see that everything works out as the needed pods, the service and the ingress are coming up and are running after a small amount of time. what i don't understand is how to access the ingress created by the deployment as the spec does not specify the normal host of my kubernetes cluster, but this instead:
spec:
  rules:
  - host: keycloak.local
    http:
      paths:
      - backend:
          servicename: keycloak
          serviceport: 8443
        path: /
        pathtype: implementationspecific

that guide that i used does not specify this. what das keycloak.local mean and how do i access it?
edit: my keycloak config looks like this:
apiversion: keycloak.org/v1alpha1
kind: keycloak
metadata:
  labels:
    app: mykeycloak
  name: mykeycloak
  namespace: test
spec:
  externalaccess:
    enabled: true
  instances: 1
status:
  credentialsecret: credential-mykeycloak
  externalurl: https://keycloak.local
  internalurl: https://keycloak.test.svc:8443
  message: &quot;&quot;
  phase: reconciling
  ready: true
  secondaryresources:
    configmap:
    - keycloak-probes
    deployment:
    - keycloak-postgresql
    ingress:
    - keycloak
    persistentvolumeclaim:
    - keycloak-postgresql-claim
    secret:
    - credential-mykeycloak
    - keycloak-db-secret
    service:
    - keycloak-postgresql
    - keycloak
    - keycloak-discovery
    statefulset:
    - keycloak
  version: 14.0.0

",<kubernetes><keycloak><kubernetes-ingress>,68258809,1,"you have configured the following in your keycloak crd.
  externalaccess:
    enabled: true

that will create an ingress-object as you have already posted. by default, the keycloak operator is using keycloak.local as value for the host.
https://github.com/keycloak/keycloak-operator/blob/master/deploy/olm-catalog/keycloak-operator/12.0.1/keycloaks.keycloak.org.crd.yaml#l62
so if you would like to change it to keycloak.example.org you have to edit your keycloak definition to something like:
  externalaccess:
    enabled: true
    host: keycloak.example.org

afterwards, your ingress-controller will listen to this path in your request.
this should answer your first question &quot;what das keycloak.local mean&quot;.
your second question, &quot;how do i access it&quot;:
i assume you have an ingress controller deployed on your system. if not, read up on the topic (https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/).
if you have deployed an ingress-controller, you should be able to reach your keycloak with the defined host.
"
52044180,kubernetes using wrong value for restartpolicy,"i'm trying a job deployment in kubernetes with the configuration below but i'm getting this error :

spec.template.spec.restartpolicy: unsupported value: ""always"": supported values: onfailure, never


it's like kubernetes doesn't read my restartpolicy configuration (set to never) or it's overridden somewhere...

the ""funny"" thing is it's working for my cronjob deployment (i'm using the same template for both of them).

kubernetes version : 1.7.7

here is my configuration :

{
  ""apiversion"": ""batch/v1"",
  ""kind"": ""job"",
  ""metadata"": {
    ""name"": ""pipeline-test"",
    ""labels"": {
      ""app"": ""pipeline-test"",
      ""env"": ""test"",
      ""commit"": ""xxxxxxxx""
    },
    ""namespace"": ""pipeline-test""
  },
  ""spec"": {
    ""jobtemplate"": {
      ""spec"": {
        ""template"": {
          ""metadata"": {
            ""labels"": {
              ""app"": ""pipeline-test"",
              ""env"": ""test"",
              ""commit"": ""xxxxxxxx""
            }
          },
          ""spec"": {
            ""restartpolicy"": ""never"",
            ""containers"": [
              {
                ""name"": ""pipeline-test"",
                ""image"": ""us.gcr.io/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
                ""env"": [
                  {
                    ""name"": ""app_env"",
                    ""value"": ""test""
                  },
                  {
                    ""name"": ""max_workers"",
                    ""value"": ""2""
                  },
                  {
                    ""name"": ""type_casting"",
                    ""value"": ""false""
                  },
                  {
                    ""name"": ""env"",
                    ""value"": ""test""
                  },
                  {
                    ""name"": ""project_name"",
                    ""value"": ""null-testing1-v""
                  },
                  {
                    ""name"": ""job_name"",
                    ""value"": ""testjob""
                  },
                  {
                    ""name"": ""subscription_name"",
                    ""value"": ""testsub""
                  },
                  {
                    ""name"": ""cache_invalidator"",
                    ""value"": ""14-1""
                  },
                  {
                    ""name"": ""git_commit"",
                    ""value"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx""
                  },
                  {
                    ""name"": ""app_git_commit"",
                    ""value"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx""
                  },
                  {
                    ""name"": ""app_name"",
                    ""value"": ""pipeline-test""
                  },
                ],
                ""volumemounts"": [

                ],
                ""ports"": [
                  {
                    ""containerport"": 3000
                  }
                ],
                ""resources"": {
                  ""requests"": {
                    ""cpu"": ""100m"",
                    ""memory"": ""512mi""
                  },
                  ""limits"": {
                    ""cpu"": ""1000m"",
                    ""memory"": ""512mi""
                  }
                }
              }
            ],
            ""volumes"": [

            ],
            ""imagepullsecrets"": [
              {
                ""name"": ""image-pull-secret""
              }
            ]
          }
        }
      }
    }
  }
}


thanks

edit : i was able to run it by removing 2 lines :

    ""jobtemplate"": {
      ""spec"": {


and so the restartpolicy was at the wrong level in the json and wasn't read.
",<kubernetes><kubectl>,52046158,2,"i was able to run it by removing 2 lines :

""jobtemplate"": {
  ""spec"": {


and so the restartpolicy was at the wrong level in the json and wasn't read.
"
67985163,kubernetes dashboard not accessible when providing path in ingress,"i have deployed minikube on windows vm and the minikube vm is created on virtualbox with the host-only ip.
i have deployed the kubernetes dashboard with nodeport ip so i can access it from outside the cluster. the svc is as follows:
ps c:\users\xxx\desktop\ingress&gt; kubectl get svc -n kubernetes-dashboard
name                        type        cluster-ip      external-ip   port(s)         age
dashboard-metrics-scraper   clusterip   10.111.167.61   &lt;none&gt;        8000/tcp        5d20h
kubernetes-dashboard        nodeport    10.111.220.57   &lt;none&gt;        443:30613/tcp   5d20h

with the help of the minikube ingress addon, i installed the ingress controller which is of nginx. its svc details are as follows:
ps c:\users\xxx\desktop\ingress&gt; kubectl get svc -n ingress-nginx
name                                 type        cluster-ip    external-ip   port(s)                      age
ingress-nginx-controller             nodeport    10.98.29.41   &lt;none&gt;        80:32628/tcp,443:31194/tcp   5d20h
ingress-nginx-controller-admission   clusterip   10.96.35.36   &lt;none&gt;        443/tcp                      5d20h

then i have created an ingress rule for my dashboard application as follows:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/add-base-url: &quot;true&quot;
    nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;
    nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;
    nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
    ingress.kubernetes.io/configuration-snippet: |
      rewrite ^(/dashboard)$ $1/ permanent;
spec:
  rules:
  - host: k8s.dashboard.com
    http:
      paths:
      - path: /dashboard
        pathtype: prefix
        backend:
          service:
            name: kubernetes-dashboard
            port:
              number: 443

but now when i am trying to access the dashboard with the following url https://k8s.dashboard.com/dashboard then i am facing the error of 404 not found. i also tried multiple url to access the dashboard such as :
https://k8s.dashboard.com:30613/dashboard
http://k8s.dashboard.com:30613/dashboard
https://k8s.dashboard.com/dashboard

but this url is working for me: https://k8s.dashboard.com:30613
i have added the minikube ip to hosts files in the windows machine.
ingress rule describe the output is as follows:
ps c:\users\xxx\desktop\ingress&gt; kubectl describe ingress -n kubernetes-dashboard
name:             dashboard-ingress
namespace:        kubernetes-dashboard
address:          192.168.56.100
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host               path  backends
  ----               ----  --------
  k8s.dashboard.com
                     /dashboard   kubernetes-dashboard:443 (172.17.0.4:8443)
annotations:         ingress.kubernetes.io/configuration-snippet: rewrite ^(/dashboard)$ $1/ permanent;
                     kubernetes.io/ingress.class: nginx
                     nginx.ingress.kubernetes.io/add-base-url: true
                     nginx.ingress.kubernetes.io/backend-protocol: https
                     nginx.ingress.kubernetes.io/force-ssl-redirect: false
                     nginx.ingress.kubernetes.io/rewrite-target: /
                     nginx.ingress.kubernetes.io/secure-backends: true
events:
  type    reason  age                   from                      message
  ----    ------  ----                  ----                      -------
  normal  sync    26m (x16 over 5d20h)  nginx-ingress-controller  scheduled for sync

any help regarding this really helps. thanks
edited
my ingress controller logs are as follows:
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /dashboard http/2.0&quot; 200 746 &quot;-&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 418 0.019 [kubernetes-dashboard-kubernetes-dashboard-443] [] 172.17.0.4:8443 746 0.018 200 1a2793052f70031c6c9fa59b0d4374d1
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /styles.aa1f928b22a88c391404.css http/2.0&quot; 404 548 &quot;https://k8s.dashboard.com/dashboard&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 101 0.002 [upstream-default-backend] [] 127.0.0.1:8181 548 0.002 404 1974258442f8b4c46d8badd1dda3e3f5
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /runtime.2a456dd93bf6c4890676.js http/2.0&quot; 404 548 &quot;https://k8s.dashboard.com/dashboard&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 49 0.008 [upstream-default-backend] [] 127.0.0.1:8181 548 0.007 404 96c17c52e6337f29dd8b2b2b68b088ac
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /polyfills.f4f05ad675be9638106e.js http/2.0&quot; 404 548 &quot;https://k8s.dashboard.com/dashboard&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 40 0.008 [upstream-default-backend] [] 127.0.0.1:8181 548 0.007 404 096ae29cb168523aa9191f27a967e47a
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /scripts.128068f897fc721c4673.js http/2.0&quot; 404 548 &quot;https://k8s.dashboard.com/dashboard&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 38 0.008 [upstream-default-backend] [] 127.0.0.1:8181 548 0.007 404 728f73f75276167b387dc87a69b65a72
192.168.56.1 - - [16/jun/2021:06:57:00 +0000] &quot;get /en.main.09bf52db2dbc808e7279.js http/2.0&quot; 404 548 &quot;https://k8s.dashboard.com/dashboard&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/91.0.4472.77 safari/537.36&quot; 38 0.014 [upstream-default-backend] [] 127.0.0.1:8181 548 0.014 404 b11e5ae324a828508d488816306399c2

and this is dashboard logs
172.17.0.1 - - [16/jun/2021:06:59:46 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
172.17.0.1 - - [16/jun/2021:06:59:56 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
172.17.0.1 - - [16/jun/2021:07:00:00 +0000] &quot;get /healthz http/1.1&quot; 200 13 &quot;&quot; &quot;dashboard/v2.2.0&quot;
172.17.0.1 - - [16/jun/2021:07:00:06 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
172.17.0.1 - - [16/jun/2021:07:00:16 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
172.17.0.1 - - [16/jun/2021:07:00:26 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
172.17.0.1 - - [16/jun/2021:07:00:30 +0000] &quot;get /healthz http/1.1&quot; 200 13 &quot;&quot; &quot;dashboard/v2.2.0&quot;
172.17.0.1 - - [16/jun/2021:07:00:36 +0000] &quot;get / http/1.1&quot; 200 6 &quot;&quot; &quot;kube-probe/1.20&quot;
{&quot;level&quot;:&quot;error&quot;,&quot;msg&quot;:&quot;error scraping node metrics: the server could not find the requested resource (get nodes.metrics.k8s.io)&quot;,&quot;time&quot;:&quot;2021-06-16t07:00:41z&quot;}

",<kubernetes><kubernetes-ingress><minikube>,67999266,5,"according to this issue this is a limitation/bug of the kubernetes dashboard.
they suggest using this config as a workaround:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: kubernetes-dashboard
  labels:
    app.kubernetes.io/name: kubernetes-dashboard  
  annotations:
    kubernetes.io/ingress.class: nginx
    # add https backend protocol support for ingress-nginx
    nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;
    nginx.ingress.kubernetes.io/configuration-snippet: |
      proxy_set_header accept-encoding &quot;&quot;;
      sub_filter '&lt;base href=&quot;/&quot;&gt;' '&lt;base href=&quot;/dashboard/&quot;&gt;';
      sub_filter_once on;
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  rules:
    - host: my.example.com
      http:
        paths:
          - path: /dashboard(/|$)(.*)
            backend:
              servicename: kubernetes-dashboard
              serviceport: 443

"
55614538,error running gcloud scripts in a pipeline in jenkins,"i create an application of jenkins in kubernetes using the marketplace click-to-deploy from the google cloud platform when i want to use the gcloud command after installing the gcloud plugin appears the log message:

this is the pipeline.

def project = 'my-project'
def appname = 'my_app-name'
def zone = 'us-east1-d'
def fesvcname = ""${appname}""
def imagetag = ""gcr.io/${project}/${appname}:${env.branch_name}.${env.build_number}""

pipeline {
  agent  any
    stages {
      stage('test') {
        steps {  
          sh "" echo test is not avalaible""
        }
      }
    stage('build and push image with container builder') {
      steps {
        container('gcloud') {
          sh ""cd ..""
          sh ""pythonunbuffered=1 gcloud builds submit -t ${imagetag} .""
        }
      }
    }
    stage('deploy development') {
      // canary branch
      when { branch 'develop' }
      steps {
        container('kubectl') {
          sh (""echo branch develop is not avalaible"")

        }
      }
    }
    stage('deploy test') {
      // canary branch
      when { branch 'develop' }
      steps {
        container('kubectl') {
          sh (""echo branch develop is not avalaible"")

        }
      }
    }
    stage('deploy production') {
      // production branchh
      when { branch 'master' }
      steps {
        container('kubectl') {
          sh (""echo branch master is not avalaible"")

        }
      }
    }

  }
}


log

 &gt; git rev-parse --is-inside-work-tree # timeout=10
setting origin to https://source.developers.google.com/p/test-jalfonso/r/hello-app
 &gt; git config remote.origin.url https://source.developers.google.com/p/test-jalfonso/r/hello-app # timeout=10
fetching origin...
fetching upstream changes from origin
 &gt; git --version # timeout=10
 &gt; git config --get remote.origin.url # timeout=10
using git_askpass to set credentials test-jalfonso
 &gt; git fetch --tags --progress origin +refs/heads/*:refs/remotes/origin/*
seen branch in repository origin/master
seen branch in repository origin/test
seen 2 remote branches
obtained jenkinsfile from 3e1b0fd042813f25f4761bec13a50646d7a3fccf
running in durability level: max_survivability
[pipeline] start of pipeline
[pipeline] node
running on jenkins in /var/jenkins_home/workspace/test-jalfonso_test@2
[pipeline] {
[pipeline] stage
[pipeline] { (declarative: checkout scm)
[pipeline] checkout
using credential source:test-jalfonso
cloning the remote git repository
cloning with configured refspecs honoured and without tags
cloning repository https://source.developers.google.com/p/test-jalfonso/r/hello-app
 &gt; git init /var/jenkins_home/workspace/test-jalfonso_test@2 # timeout=10
fetching upstream changes from https://source.developers.google.com/p/test-jalfonso/r/hello-app
 &gt; git --version # timeout=10
using git_askpass to set credentials test-jalfonso
 &gt; git fetch --no-tags --progress https://source.developers.google.com/p/test-jalfonso/r/hello-app +refs/heads/*:refs/remotes/origin/*
 &gt; git config remote.origin.url https://source.developers.google.com/p/test-jalfonso/r/hello-app # timeout=10
 &gt; git config --add remote.origin.fetch +refs/heads/*:refs/remotes/origin/* # timeout=10
 &gt; git config remote.origin.url https://source.developers.google.com/p/test-jalfonso/r/hello-app # timeout=10
fetching without tags
fetching upstream changes from https://source.developers.google.com/p/test-jalfonso/r/hello-app
using git_askpass to set credentials test-jalfonso
 &gt; git fetch --no-tags --progress https://source.developers.google.com/p/test-jalfonso/r/hello-app +refs/heads/*:refs/remotes/origin/*
checking out revision 3e1b0fd042813f25f4761bec13a50646d7a3fccf (test)
 &gt; git config core.sparsecheckout # timeout=10
 &gt; git checkout -f 3e1b0fd042813f25f4761bec13a50646d7a3fccf
commit message: ""test""
&gt; git rev-list --no-walk f0d84e4bb46eff9acd4a79f93013f8eca20370c9 # timeout=10
[pipeline] }
[pipeline] // stage
[pipeline] withenv
[pipeline] {
[pipeline] stage
[pipeline] { (test)
[pipeline] sh
+ echo test is not avalaible
test is not avalaible
[pipeline] }
[pipeline] // stage
[pipeline] stage
[pipeline] { (build and push image with container builder)
[pipeline] sh
+ echo not available
not available
[pipeline] sh
+ gcloud builds submit -t gcr.io/my-project/my-app-name:master.23 .
/var/jenkins_home/workspace/test_master@tmp/durable-1d490c65/script.sh: 1: /var/jenkins_home/workspace/test_master@tmp/durable-1d490c65/script.sh: gcloud: not found
[pipeline] }
[pipeline] // stage
[pipeline] stage
[pipeline] { (deploy development)
stage ""deploy development"" skipped due to earlier failure(s)
[pipeline] }
[pipeline] // stage
[pipeline] stage
[pipeline] { (deploy test)
stage ""deploy test"" skipped due to earlier failure(s)
[pipeline] }
[pipeline] // stage
[pipeline] stage
[pipeline] { (deploy production)
stage ""deploy production"" skipped due to earlier failure(s)
[pipeline] }
[pipeline] // stage
[pipeline] }
[pipeline] // withenv
[pipeline] }
[pipeline] // node
[pipeline] end of pipeline
error: script returned exit code 127
finished: failure



i tried to search the folder installation of the sdk of google but i can't found any, i don't know if is an issue of the deploy.
i expected just upload my dockerfile to the source repository but if i use a script with gcloud appears this log, i installed all the plugins for google auth, sdk, kubernetes and i configure the kubernetes in the jenkins config, i export the keys from google cloud.
",<jenkins><kubernetes><jenkins-plugins><google-kubernetes-engine>,55688490,1,"from your pipeline output i can see, that all your stages are running on jenkins master node (where 'gcloud' is not available by default), not like you would expect on dynamically created jenkins-slave pod, on kubernetes cluster.

to fix the problem quickly, just configure your pod template explicitly in jenkins pipeline code, here is an example of pod template including 'gcloud' container:

def label = ""gcloud-command-${uuid.randomuuid().tostring()}""

podtemplate(label: label, yaml: """"""
apiversion: v1
kind: pod
spec:
  containers:
  - name: gcloud
    image: gcr.io/cloud-builders/gcloud
    command:
    - cat
    tty: true
""""""
  ) {

  node(label) {
    stage('test -  execution of gcloud command') {
      container('gcloud') {
        sh ""gcloud compute zones --help""
      }
    }

  }
}


job output:

running on jenkins-slave-33v1t-04zwp in /home/jenkins/workspace/run-jenkins-slave-on-k8s
[pipeline] {
[pipeline] stage
[pipeline] { (test -  execution of gcloud command) (test -  execution of gcloud command)
[pipeline] container
[pipeline] {
[pipeline] sh
+ gcloud compute zones --help
name
    gcloud compute zones - list google compute engine zones

synopsis
    gcloud compute zones command [gcloud_wide_flag ...]

description
    list google compute engine zones.

gcloud wide flags
    these flags are available to all commands: --account, --configuration,
    --flags-file, --flatten, --format, --help, --impersonate-service-account,
    --log-http, --project, --quiet, --trace-token, --user-output-enabled,
    --verbosity. run $ gcloud help for details.

commands
    command is one of the following:

     describe
        describe a google compute engine zone.

     list
        list google compute engine zones.

notes
    these variants are also available:

        $ gcloud alpha compute zones
        $ gcloud beta compute zones

[pipeline] }
[pipeline] // container
[pipeline] }
[pipeline] // stage
[pipeline] }
[pipeline] // node
[pipeline] }
[pipeline] // podtemplate
[pipeline] end of pipeline
finished: success


please verify if you have properly configured jenkins kubernetes plugin, especially part of configuration related to kubernetes pod template as described here. 
"
67096465,how to generate helm template files without the folder `/templates`?,"i create a helm chart directory
helm create mychart
after updating the templates and values i run
helm template .
everything looks as expected. next, i want to output the manifest files into another directory
helm template . --output-dir ./test
wrote ./test/mychart/templates/serviceaccount.yaml
wrote ./test/mychart/templates/service.yaml
wrote ./test/mychart/templates/deployment.yaml
wrote ./test/mychart/templates/tests/test-connection.yaml

is there a way to output just the file manifest without the mychart/templates?
wrote ./test/serviceaccount.yaml
wrote ./test/service.yaml
wrote ./test/deployment.yaml
wrote ./test/test-connection.yaml

",<kubernetes><kubernetes-helm>,67102771,4,"i don't think there is such an option in the helm command itself, but you can always run the following command.
helm template mychart . --output-dir ./test &amp;&amp; mv ./test/mychart/templates/* ./test &amp;&amp; rm -r ./test/mychart

"
75427142,how can i update prometheus-node-exporter when deploying prometheus through helm charts?,"i have used the prometheus helm chart from https://prometheus-community.github.io/helm-charts to setup a prometheus server on eks for me. that involves prometheus-node-exporter too. now what i'm trying to do is modify the prometheus-node-exporter service port to another one from 9100.
i updated the value under prometheus-node-exportes/values.yaml to this :
service:
  type: clusterip
  port: 9400
  targetport: 9400
  nodeport:
  portname: metrics
  listenonallinterfaces: true
  annotations:
    prometheus.io/scrape: &quot;true&quot;

but when i do :
helm upgrade prometheus prometheus-community/prometheus --namespace monitoring
the changes do not take effect at all.
how can i update values of other subcharts like prometheus-node-exporter in my helm chart?
",<kubernetes><prometheus><kubernetes-helm><prometheus-node-exporter>,75427221,3,"the way that your command is running, is pulling the chart from the internet, you are not passing any extra values file.
if the port is all you are changing, use this command to pass the port value:
helm upgrade prometheus prometheus-community/prometheus --namespace monitoring --set prometheus-node-exporter.service.port=&lt;your-port&gt;
otherwise, you can download the promethues values file, then add the mods to it, e.g.:
prometheus-node-exporter:
  ## if false, node-exporter will not be installed
  ##
  enabled: true

  rbac:
    pspenabled: false

  containersecuritycontext:
    allowprivilegeescalation: false

  service:
  port: &lt;your-port&gt;

then, pass the values file to the upgrade command using -f values.yaml
also, check this doc.
"
68106338,kubernetes get secrets got messy after helm upgrade,"when i run kubectl get secrets after doing a helm upgrade --install &lt;release-name&gt; in kubernetes cluster, our secrets got messy.
is there any way to stop having sh.helm.release.v1. whenever i declare kubectl get secrets?

",<kubernetes><kubernetes-helm>,68107109,9,"no, these secrets are where helm stores its state.
when you install or upgrade a release, helm creates a new secret. the secret who’s name ends in .airflow.v29 contains all the information helm has about revision number 29 of the airflow release.
whenever you run commands like helm list, helm history, or helm upgrade, helm reads these secrets to know what it did in the past.
by default, helm keeps up to 10 revisions in its state for each release, so up to 10 secrets per release in your namespace. you can have helm keep a different number of revisions in its state with the --history-max flag.
if you don’t want to keep a history of changes made to your release, you can keep as little as a single revision in helm’s state.
running helm upgrade --history-max=1 will keep the number of secrets helm creates to a minimum.
"
65277688,kubernetes ingress path: allow all exept for /blog/,"i have a service running on kubernetes available on a domain like example.com. i'm trying to add a path which should redirect to a wordpress blog. so i need to add a rule: everithing that goes in /blog/ should redirect to wordpress, otherwise use the main app.
i tried to include a regexp for the main application path to include all except /blog/
  - host: example.com
    http:
      paths:
      - path: /^(?!blog).*$

but i keep getting must be a valid regex or if i remove the slash, it says must be an absolute path. i can't seem to find a way how to do that, it just keeps redirecting to my root app
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: app
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        backend:
          servicename: mainappservice
          serviceport: 3010
      - path: /blog/*
        backend:
          servicename: blogservice
          serviceport: 3020

",<kubernetes><microservices><kubernetes-ingress><nginx-ingress>,65283452,2,"try this -
apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    kubernetes.io/ingress.class: nginx
  name: app
spec:
  rules:
  - host: example.com
    http:
      paths:
      - path: /(.*)
        backend:
          servicename: mainappservice
          serviceport: 3010
      - path: /blog/(.*)
        backend: 
          servicename: blogservice
          serviceport: 3020


i guess, this should work
"
63430959,client pod identity in http request header while internal service call,"i have deployed an application on kubernetes and exposed with istio service mesh. there is 2 components in the application, ui and api. i am trying to setup canary based setup to enable ab testing. so, for these 2 components, there is 2 versions (v1 and v2) has deployed, so (min) 4 pods are running.
assume, v1 is stable and v2 is release version. version v1 will serve real internet traffic and version v2 will serve the request from specific ip address to make sure promotion of version v2 will not impact real production environment. refer the attached image for clarity of traffic flow within application.

testing of ui v2 (release version) is quite easy by filter real client ip address of user using virtualservice-
    - headers:
        x-forwarded-for:
          regex: .*1.2.3.4.*

testing of api v2 (release version) is complex, because it is not exposed to internet and must serve traffic only from  ui v2 (release version) internally but i am unable to do.
    url = &quot;http://service-api&quot;
    hdr = { 'caller_pod' : 'ui_v2_pod_hostname_with_release' }
    req = urllib.request.request(url, headers=hdr)
    response = urllib.request.urlopen(req)

one hacky trick i have applied in application, added custom http request headers &quot;caller_pod&quot; while calling api from ui v2 pod, so that api virtualservice can filter out request based on &quot;caller_pod&quot;. but it looks more complex because it need code refactoring on a broader level and more human manageable in future if any changes come.
is there any way to add ui v2 pod identity (preferable hostname) in http request header while calling api service internally on kubernetes or istio level.
",<kubernetes><google-kubernetes-engine><kubernetes-helm><istio><amazon-eks>,63432439,5,"have you tried using sourcelabels based routing? for example:
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: socks-com
spec:
  hosts:
  - sock.com
  http:
  - match:
    - sourcelabels:
        ui: v2
    - route:
      - destination:
          host: api
          label: v2
  - route:
    - destination:
        host: api
        subset: v1

it would also require destinationrule update with two subsets.
"
70611407,kubernetes ingress tls not being created with headless service,"what i'm trying to achieve
i'm trying to deploy an elixir (phoenix) application in a microk8s cluster namespace with tls using let's encrypt. the cluster is hosted on an aws ec2 instance.
the problem i'm facing

the ingress is created in the namespace
ingress routes to the correct domain
the application is working and displayed on the given domain

the tls secret is not being created in the namespace and a 'default' one is created
the secrets after deploying both phoenix app and httpbin app:
me@me:~/documents/kubernetes-test$ kubectl get secret -n production
name                           type                                  data   age
default-token-jmgrg            kubernetes.io/service-account-token   3      20m
httpbin-tls                    kubernetes.io/tls                     2      81s

the domain is insecure, i.e the tls is not working.
logs from the ingress controller after applying the yml files:
w0106 17:26:36.967036       6 controller.go:1192] error getting ssl certificate &quot;production/phoenix-app-tls&quot;: local ssl certificate production/phoenix-app-tls was not found. using default certificate
w0106 17:26:46.445248       6 controller.go:1192] error getting ssl certificate &quot;production/phoenix-app-tls&quot;: local ssl certificate production/phoenix-app-tls was not found. using default certificate
w0106 17:26:49.779680       6 controller.go:1192] error getting ssl certificate &quot;production/phoenix-app-tls&quot;: local ssl certificate production/phoenix-app-tls was not found. using default certificate
i0106 17:26:56.431925       6 status.go:281] &quot;updating ingress status&quot; namespace=&quot;production&quot; ingress=&quot;phoenix-app-ingress&quot; currentvalue=[] newvalue=[{ip:127.0.0.1 hostname: ports:[]}]
i0106 17:26:56.443405       6 event.go:282] event(v1.objectreference{kind:&quot;ingress&quot;, namespace:&quot;production&quot;, name:&quot;phoenix-app-ingress&quot;, uid:&quot;redacted&quot;, apiversion:&quot;networking.k8s.io/v1beta1&quot;, resourceversion:&quot;1145907&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'sync' scheduled for sync
w0106 17:26:56.443655       6 backend_ssl.go:46] error obtaining x.509 certificate: no object matching key &quot;production/phoenix-app-tls&quot; in local store
w0106 17:26:56.443781       6 controller.go:1192] error getting ssl certificate &quot;production/phoenix-app-tls&quot;: local ssl certificate production/phoenix-app-tls was not found. using default certificate

the description of the created ingress, note that here at the bottom it says successfully created certificate &quot;phoenix-app-tls&quot; but the secret does not exist:
me@me:~/documents/kubernetes-test$ kubectl describe ing phoenix-app-ingress -n production
name:             phoenix-app-ingress
labels:           app=phoenix-app
namespace:        production
address:          127.0.0.1
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  phoenix-app-tls terminates phoenix.sub.mydomain.com
rules:
  host                           path  backends
  ----                           ----  --------
  phoenix.sub.mydomain.com  
                                 /   phoenix-app-service-headless:8000 (redacted_ip:4000,redacted_ip:4000)
annotations:                     cert-manager.io/cluster-issuer: letsencrypt
                                 nginx.ingress.kubernetes.io/cors-allow-credentials: true
                                 nginx.ingress.kubernetes.io/cors-allow-methods: get, post, options
                                 nginx.ingress.kubernetes.io/cors-allow-origin: *
                                 nginx.ingress.kubernetes.io/enable-cors: true
events:
  type    reason             age                  from                      message
  ----    ------             ----                 ----                      -------
  normal  createcertificate  29m                  cert-manager              successfully created certificate &quot;phoenix-app-tls&quot;
  normal  sync               8m43s (x3 over 29m)  nginx-ingress-controller  scheduled for sync

resources
the deployment yml:
apiversion: apps/v1
kind: deployment
metadata:
  name: phoenix-app
  labels:
    app: phoenix-app
spec:
  replicas: 2
  selector:
    matchlabels:
      app: phoenix-app
  strategy:
    rollingupdate:
      maxsurge: 1
      maxunavailable: 1
    type: rollingupdate
  template:
    metadata:
      labels:
        app: phoenix-app
    spec:
      containers:
      - name: phoenix-app
        image: redacted
        imagepullpolicy: always
        command: [&quot;./bin/hello&quot;, &quot;start&quot;]
        lifecycle:
          prestop:
            exec:
              command: [&quot;./bin/hello&quot;, &quot;stop&quot;]
        ports:
        - containerport: 4000
        env:
        - name: pod_ip
          valuefrom:
            fieldref:
              fieldpath: status.podip
        envfrom:
        - configmapref:
            name: phoenix-app-config
        - secretref:
            name: phoenix-app-secrets
      imagepullsecrets:
      - name: gitlab-pull-secret

the service yml:
apiversion: v1
kind: service
metadata:
  name: phoenix-app-service-headless
  labels:
    app: phoenix-app
spec:
  clusterip: none
  selector:
    app: phoenix-app
  ports:
  - name: http
    port: 8000
    targetport: 4000 # the exposed port by the phoenix app

note: i removed my actual domain
the ingress yml:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: phoenix-app-ingress
  labels:
    app: phoenix-app
  annotations:
    nginx.ingress.kubernetes.io/enable-cors: &quot;true&quot;
    nginx.ingress.kubernetes.io/cors-allow-methods: &quot;get, post, options&quot;
    nginx.ingress.kubernetes.io/cors-allow-origin: &quot;*&quot;
    nginx.ingress.kubernetes.io/cors-allow-credentials: &quot;true&quot;
    cert-manager.io/cluster-issuer: &quot;letsencrypt&quot;
spec:
  tls:
  - hosts:
    - &quot;phoenix.sub.mydomain.com&quot;
    secretname: phoenix-app-tls
  rules:
  - host: &quot;phoenix.sub.mydomain.com&quot;
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: phoenix-app-service-headless
            port:
              number: 8000 # same port as in service.yml

tested with different service
i deployed a sample service using httpbin (is not a headless service) and the tls works fine in the same namespace. here are the resources that i used to deploy it:
deplyoment.yml
apiversion: apps/v1
kind: deployment
metadata:
  name: httpbin
  labels:
    app: httpbin
spec:
  replicas: 1
  selector: 
    matchlabels:
      app: httpbin
      version: v1
  template:
    metadata:
      labels:
        app: httpbin
        version: v1
    spec:
      containers:
      - image: docker.io/kennethreitz/httpbin
        imagepullpolicy: always
        name: httpbin
        ports:
        - containerport: 80

the service yml:
apiversion: v1
kind: service
metadata:
  name: httpbin
  labels:
    app: httpbin
spec:
  ports:
  - name: http
    port: 8000
    targetport: 80
  selector:
    app: httpbin

the ingress yml:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: httpbin
  labels:
    app: httpbin
  annotations:
    cert-manager.io/cluster-issuer: &quot;letsencrypt&quot;
spec:
  tls:
  - hosts:
    - &quot;httpbin.sub.mydomain.com&quot;
    secretname: httpbin-tls
  rules:
  - host: &quot;httpbin.sub.mydomain.com&quot; # this is a subdomain we want to route these requests to
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: httpbin
            port:
              number: 8000

my best guess is that it has something to do with the fact that the service is headless, but i have no clue as to how i can resolve the issue.
",<ssl><kubernetes><kubernetes-ingress><lets-encrypt><nginx-ingress>,70613142,2,"i found out that you can actually check for certificates with kubectl:
kubectl get certificate -n production
the status of this certificate was ready = false.
i checked the description:
kubectl describe certificate &lt;certificate_name&gt; -n production
at the bottom it said:
too many certificates have been created in the last 164 hours for this exact domain.
i just changed the domain and voila! it works.
"
56688514,"integration testing deployed services using ""helm test""","i'm using helm charts to deploy several rest services to microsoft azure. 
some of these services communicate with each other and to some databases. after the deployment i want to test if ""everything"" works as expected. to be more precise, i want to send some http requests to one of the services and check if the response makes sense. in automated tests of course.

i saw that it's possible to run basic commands after the deployment using ""helm test"", but this is not exactly what i need.

in some earlier approach i used newman to execute a postman collection in a script after the deployment.
the postman collection defined several requests and the corresponding tests.

now i don't know how to do it in the new environment (azure) and deployment pipeline (helm, k8s).

it would be nice to have something like this again.
but for me it's not clear how to do it, e.g. 


how can i use newman in the ""helm test"" scope?
how can i ensure, that the deployed pods are all ""running"" before starting the test (some wait time? status check?)?


newman run ""test.postman_collection.json"" -e ""azure.postman_environment.json"" --bail
",<java><kubernetes><postman><kubernetes-helm><newman>,56732400,3,"helm test is very flexible, because it runs any kubernetes yaml including any docker image. as an example, you can check tests for the mysql helm chart.

so, coming to your questions:


to use newman, you just need to find a docker image with the newman installed (e.g. the official one postman/newman or build your own). to use your json configuration files, you can either put them as configmap or copy them into the container. check he mysql helm chart for more details.
you're right that you need to wait until your system is ready before running the tests. afaik this is not covered by helm test. so you need to either put sleep into your script or actively check with kubectl until the pods are ready.

"
69686202,kubernetes ingress objects return no response on windows 10 minikube,"i try to test kubernetes ingress on minikube. my os is windows 10. minikube is installed successfully as well as nginx ingress controller.
&gt; minikube addons enable ingress

below is my kubernetes manifest file:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: test-ingress
  namespace: ingress-nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: 'nginx'
    nginx.ingress.kubernetes.io/default-backend: app-nginx-svc
spec:
  rules:
    - host: boot.aaa.com
      http:
        paths:
          - path: /path
            pathtype: prefix
            backend:
              service:
                name: app-nginx-svc
                port:
                  number: 80

---
apiversion: v1
kind: service
metadata:
  name: app-nginx-svc
  namespace: ingress-nginx
spec:
  type: nodeport  
  selector:
    app: test-nginx  
  ports:
  - name: http
    port: 80
    targetport: 80
    nodeport: 30000

---
apiversion: v1
kind: pod
metadata:
  name: app-nginx
  namespace: ingress-nginx  
  labels:
    app: test-nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports: 
    - containerport: 80

kubernetes pod and service are generated on minikube without errors. when i test service with the below commands, the pod shows the right values.
&gt; minikube service -n ingress-nginx app-nginx-svc --url
* app-nginx-svc 서비스의 터널을 시작하는 중
|--------------------|---------------|-------------|------------------------|
|   namespace   |     name     | target port |      url           |
|--------------------|---------------|-------------|------------------------|
|  ingress-nginx  | app-nginx-svc |           | http://127.0.0.1:63623 |
|-------------------|---------------|-------------|------------------------|
http://127.0.0.1:63623

but the problem occurs in the ingress object. the minikube ingress generates the endpoint and host domain.

i type in the domain mapping hostname in windows 10 host file
192.168.49.2       boot.aaa.com

but i can not receive any response from nginx container:
http://boot.aaa.com/path
the above url does not work at all.
",<kubernetes><kubernetes-ingress><nginx-ingress>,69688243,2,"when you try to access http://boot.aaa.com/path - do you provide the port on which it listens? from what i see from the output of:
minikube service -n ingress-nginx app-nginx-svc --url
* app-nginx-svc 서비스의 터널을 시작하는 중
|--------------------|---------------|-------------|------------------------|
|   namespace        |      name     | target port |          url           |
|--------------------|---------------|-------------|------------------------|
|  ingress-nginx     | app-nginx-svc |             | http://127.0.0.1:63623 |
|--------------------|---------------|-------------|------------------------|
==&gt; http://127.0.0.1:63623 &lt;==


i think that you need to make request on: http://boot.aaa.com:63623/path
if you don't want to use hostname in you ingress, just remove it from manifest.
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: test-ingress
  namespace: ingress-nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: 'nginx'
    nginx.ingress.kubernetes.io/default-backend: app-nginx-svc
spec:
  rules:
    - http:
        paths:
          - path: /path
            pathtype: prefix
            backend:
              service:
                name: app-nginx-svc
                port:
                  number: 80

you should be able then to access your pod by only http://{ip}:{port}/path
my additional questions:

are you trying to make request from the same os where the minikube is installed?
is the hostfile edited on the os you are making requests from?
if yes, is the windows firewall turned on?

also, i see that you service expose a nodeport directly to your app on port 30000 (it will not pass through ingress controller).
usually if we are setting up an ingress endpoint to a pod, we do it to avoid exposing it directly by the nodeport. using clusterip service type will do so.
apiversion: v1
kind: service
metadata:
  name: app-nginx-svc
  namespace: ingress-nginx
spec:
  type: clusterip
  selector:
    app: test-nginx  
  ports:
  - name: http
    port: 80
    targetport: 80


"
58159454,ingress controller on minikube not routing correctly flask post request,"i have a simple flask app. it worked fine when i connected to it via port-forwarding to send the http post request directly to the service.

from flask import flask, request
import redis
from rq import queue
from worker import job_worker

upload_folder = './uploads/'

app = flask(__name__)

r = redis.redis()
q = queue(connection = r)

@app.route('/', methods=['post'])
def upload():
    scale = int(request.form['scale'])
    q.enqueue(job_worker, scale)
    return """"

if __name__ == ""__main__"":
    app.run()


i also have a simple index.html file in an nginx container which is served at port 80. it does an ajax post request to ""/upload"". which if you look at the ingress controller, should convert that to a port 5000 request and strip away the ""upload""
the flask app gets served at port 5000

here is the ingress controller:

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: emoji-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - path: /upload
        backend:
          servicename: emoji-backend
          serviceport: 5000
      - path: /
        backend:
          servicename: emoji-frontend
          serviceport: 80


and for completeness, the emoji-backend service:

apiversion: v1
kind: service
metadata:
  name: emoji-backend
  labels:
    app: emoji-backend
    tier: backend
spec:
  type: loadbalancer
  ports:
  - port: 5000
  selector:
    app: emoji-backend
    tier: backend


i get a 502 bad gateway without really any indication except the ingress log does say this:

2019/09/29 21:41:04 [error] 2021#2021: *78651 connect() failed (111: connection refused) while connecting to upstream, client: 192.168.64.1, server: _, 
request: ""post /upload http/2.0"", upstream: ""http://172.17.0.4:5000/"", host: ""192.168.64.5"", referrer: ""https://192.168.64.5/""


""http://172.17.0.4:5000/"" is the correct endpoint and port for the emoji-backend service.
",<flask><kubernetes><minikube><kubernetes-ingress>,58160138,2,"adding the following line fixed it:

app.run(debug=true,host='0.0.0.0',port=5000)


however, it took me a while to figure that out because at first when i tried it my docker image was not updating when i re-deployed.
"
50956741,referring to kubernetes docker registry secrets with namespaces,"what i have

i have used kube secrets for private docker registry authentication in the default namespace. that works as expected. for example:

$ kubectl get secret regsecret
name        type                             data      age
regsecret   kubernetes.io/dockerconfigjson   1         30m


which is referenced in my deployment.yml as shown in the snippet below:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: nginx
spec:
  replicas: 1
  template:
    ...
    spec:
      containers:
      - name:  bootstrap-nginx
        image: quay.io/example/nginx:latest
      ...
      imagepullsecrets:
      - name: regsecret


here's my question

i need to create the regsecret above in a namepsace, for example, myns as shown below:

$ kubectl get secret regsecret --namespace=myns
name        type                             data      age
regsecret   kubernetes.io/dockerconfigjson   1         30m


with this, how do i reference regsecret from myns namespace into my deployment spec? if i use imagepullsecrets as shown above, it fails saying that kubernetes could not pull the image (the secret regsecret could not be found). is there a way to reference ""fully qualified"" secret name in imagepullsecrets?
",<kubernetes><google-kubernetes-engine>,50957911,5,"by design, there is no way to accomplish this. you will need to create the regsecret in the same namespace where your deployment is.


  imagepullsecrets is an optional list of references to secrets in the same
       namespace to use for pulling any of the images used by this podspec. if
       specified, these secrets will be passed to individual puller
       implementations for them to use. for example, in the case of docker, only
       dockerconfig type secrets are honored.


see also:
https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
"
51535654,"kubectl apply command does not work, gives connection refused error","when i am trying to setup pod network using the following

sudo kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml


i get this error, please help

unable to recognize ""https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml"": get http://localhost:8080/api?timeout=32s: dial tcp 127.0.0.1:8080: connect: connection refused
unable to recognize ""https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml"": get http://localhost:8080/api?timeout=32s: dial tcp 127.0.0.1:8080: connect: connection refused


update:
doesn't seem to be a permission issue, unlike other question
",<kubernetes><kubectl>,51537076,23,"found that it's an issue with kubectl not being configured properly.

fixed the issued by using the following commands for calico network(change accordingly for your network addon plugin)

sudo kubeadm init --pod-network-cidr=192.168.0.0/16
mkdir -p $home/.kube
sudo cp -i /etc/kubernetes/admin.conf $home/.kube/config
sudo chown $(id -u):$(id -g) $home/.kube/config


and then run 

sudo kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml


and follow the rest accordingly
"
45518730,kubernetes helm - running helm install in a running pod,"i want to spin up a single installer pod with helm install that once running, will apply some logic and install other applications into my cluster using helm install. 

i'm aware of the helm dependencies, but i want to run some business logic with the installations and i'd rather do it in the installer pod and on the host triggering the whole installation process.

i found suggestions on using the kubernetes rest api when inside a pod, but helm requires kubectl installed and configured.

any ideas?
",<kubernetes><kubernetes-helm>,45525994,2,"you could add kubectl to your installer pod.

""in cluster"" credentials could be provided via service account in ""default-token"" secret: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
"
67862431,"when installing bitnami mongodb-sharded, i got error from pvcs: no persistent volumes available for this claim and no storage class is set","i am trying to install my rancher(rke) kubernetes cluster bitnami/mongodb-shared . but i couldn't create a valid pv for this helm chart.
the error that i am getting:
no persistent volumes available for this claim and no storage class is set
this is the helm chart documentation section about persistencevolume: https://github.com/bitnami/charts/tree/master/bitnami/mongodb-sharded/#persistence
this is the storageclass and persistentvolume yamls that i created for this helm chart pvcs':
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: ssd-nfs-storage
provisioner: nope
parameters:
  archiveondelete: &quot;false&quot;
----------
apiversion: v1
kind: persistentvolume
metadata:
  name: nfs-pv
  labels:
    name: db-nfs
spec:
  storageclassname: ssd-nfs-storage # same storage class as pvc
  capacity:
    storage: 100gi
  accessmodes:
    - readwriteonce
  nfs:
    server: 142.251.33.78 # ip addres of nfs server
    path: &quot;/bitnami/mongodb&quot; # path to directory

this is the pvc yaml that created by the helm chart:
apiversion: v1
kind: persistentvolumeclaim
metadata:
  creationtimestamp: &quot;2021-06-06t17:50:40z&quot;
  finalizers:
  - kubernetes.io/pvc-protection
  labels:
    app.kubernetes.io/component: shardsvr
    app.kubernetes.io/instance: sam-db
    app.kubernetes.io/name: mongodb-sharded
  managedfields:
  - apiversion: v1
    fieldstype: fieldsv1
    fieldsv1:
      f:metadata:
        f:labels:
          .: {}
          f:app.kubernetes.io/component: {}
          f:app.kubernetes.io/instance: {}
          f:app.kubernetes.io/name: {}
      f:spec:
        f:accessmodes: {}
        f:resources:
          f:requests:
            .: {}
            f:storage: {}
        f:volumemode: {}
      f:status:
        f:phase: {}
    manager: kube-controller-manager
    operation: update
    time: &quot;2021-06-06t17:50:40z&quot;
  name: datadir-sam-db-mongodb-sharded-shard1-data-0
  namespace: default
  resourceversion: &quot;960381&quot;
  uid: c4313ed9-cc99-42e9-a64f-82bea8196629
spec:
  accessmodes:
  - readwriteonce
  resources:
    requests:
      storage: 8gi
  volumemode: filesystem
status:
  phase: pending

can you tell me what i am missing?
",<mongodb><kubernetes><kubernetes-helm><bitnami>,67909954,1,"i am giving the bitnami/mongodb-sharded installation instruction with nfs server on rancher(v2.5.8).
i have three centos 8 vm. one nfs server(lets we say 1.1.1.1), two k8s nodes(lets we say 8.8.8.8 and 9.9.9.9) on k8s-cluster, i am using rke(aka rancher k8s engine)

we will create a nfs server
we will bind the nodes to the nfs server
we will add nfs-subdir-external-provisioner helm repository to the rancher chart repositories
we will install nfs-subdir-external-provisioner via rancher charts
we will add bitnami helm repo  to the rancher chart repositories
we will install mongodb-sharded via rancher charts



create a nfs server

# nfs server install
dnf install nfs-utils -y
systemctl start nfs-server.service
systemctl enable nfs-server.service
systemctl status nfs-server.service
# you can verify the version
rpcinfo -p | grep nfs
# nfs deamon config: /etc/nfs.conf
# nfs mount config: /etc/nfsmount.conf
mkdir /mnt/storage
# allows creation from client
# for mongodb-sharded: /mnt/storage
chown -r nobody: /mnt/storage
chmod -r 777 /mnt/storage
# restart service again
systemctl restart nfs-utils.service
# grant access to the client 
vi /etc/exports
/mnt/storage    8.8.8.8(rw,sync,no_all_squash,root_squash)
/mnt/storage    9.9.9.9(rw,sync,no_all_squash,root_squash)
# check exporting
exportfs -arv
exportfs -s
# exporting 8.8.8.8:/mnt/storage
# exporting 9.9.9.9:/mnt/storage



bind the k8s nodes to the nfs server

# nfs client install
dnf install nfs-utils nfs4-acl-tools -y
# see from the client shared folder
showmount -e 1.1.1.1
# create mounting folder for client
mkdir /mnt/cstorage
# mount server folder to the client folder
mount -t nfs 1.1.1.1:/mnt/storage /mnt/cstorage
# check mounted folder vis nfs
mount | grep -i nfs
# mount persistent upon a reboot
vi /etc/fstab
# add following codes
1.1.1.1:/mnt/storage /mnt/cstorage  nfs  defaults  0  0
# all done

bonus: unbind nodes.
# un mount and delete from client
umount -f -l /mnt/cstorage
rm -rf /mnt/cstorage
# delete added volume from fstab
vi /etc/fstab



add nfs-subdir-external-provisioner helm repository

helm repository url: https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/

rancher --&gt;
cluster explorer --&gt;
apps &amp; marketplace
chart repositories --&gt;
create --&gt;
add url like below this ccreenshot --&gt;
save --&gt;



install nfs-subdir-external-provisioner via charts


rancher --&gt;
cluster explorer --&gt;
apps &amp; marketplace
charts --&gt;
find nfs-subdir-external-provisioner chart --&gt;
select --&gt;
give a name(like nfs-pr) --&gt;
select values yaml --&gt;
set path, server ip and storageclass name(we will use this class name later)  --&gt;
install --&gt;



add bitnami helm repo to the rancher chart repositories

bitnami helm url: https://charts.bitnami.com/bitnami

rancher --&gt;
cluster explorer --&gt;
apps &amp; marketplace
chart repositories --&gt;
create --&gt;
add url like step 3's screenshot --&gt;
save --&gt;



install mongodb-sharded via rancher charts


rancher --&gt;

cluster explorer --&gt;

apps &amp; marketplace

charts --&gt;

find mongodb-sharded --&gt;

select --&gt;

give a name(my-db) --&gt;

select values yaml --&gt;

add global.storageclassname: nfs-client(we set this value step 5) --&gt;

install


"
54334917,gcsfuse to mount a bucket in gke and/or python3 boto to stream write?,"i am looking for a way to ""write stream"" some .mp4 video files -- as they are being generated by some python app -- to a google cloud storage bucket. the python app is containerised and deployed in gke and currently executes fine as a web service. but the problem is that all the video files are locally generated and stored in a path (tmp/processed) inside the pod. 

however, i want the video files to be written to files in a google's storage bucket named my_bucket. 

i have read gcsfuse guidelines (https://github.com/maciekrb/gcs-fuse-sample) on how to mount a bucket in kubernetes pods and also read about boto (https://cloud.google.com/storage/docs/boto-plugin#streaming-transfers) that is used to do the stream transfers to storage buckets. 

to mount my_bucket in tmp/processed, i have added the following lines to my app's deployment file (yaml):

        lifecycle:
          poststart:
            exec:
              command:
              - gcsfuse
              - -o
              - nonempty
              - my_bucket
              - tmp/processed
          prestop:
            exec:
              command:
              - fusermount
              - -u
              - tmp/processed/
        securitycontext:
          capabilities:
            add:
            - sys_admin


i haven't used boto yet and thought maybe just mounting would be enough! but, my app gives me input/output error when trying to generate the video file. 

now my question is that do i need to use both gcsfuse and boto, or just mounting the bucket in my gke pod is enough? and am i doing the mounting right?



update: i verified that i did the mount correctly using the following command:

kubectl exec -it [pod_name] bash
",<kubernetes><boto><bucket><google-kubernetes-engine><gcsfuse>,54449396,4,"problem solved!
i only had to mount my bucket within the pod and that was it. the mounting script (as written above in my question) was done correctly. but, the problem that caused the input/output error was due to my gke cluster that had insufficient permissions. basically, the cluster didn't have the permission to read/write to storage and a couple of other permissions were needed by the project. so, i created a new cluster using the following command:

gcloud container clusters create [my_cluster_name] \
  --scopes=https://www.googleapis.com/auth/userinfo.email,cloud-platform,https://www.googleapis.com/auth/devstorage.read_write,storage-rw,trace,https://www.googleapis.com/auth/trace.append,https://www.googleapis.com/auth/servicecontrol,compute-rw,https://www.googleapis.com/auth/compute,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/taskqueue \
  --num-nodes 4 --zone ""us-central1-c""


to be able to read/write from/to a storage bucket the cluster had to have the https://www.googleapis.com/auth/devstorage.read_write permission.

also, that there was no need to use boto and mounting through gcsfuse was enough for me to be able to write stream video files to my_bucket.
"
60627248,http error 413 requesting k8s service which does not have an ingress configuration,"inside my cluster, there is a service that returns 413 when requested via post with a large request client body size, > 10mb. since this service should not be reachable from outside the cluster i am wondering how to increase this setting in order to prevent the above error.

sure, when using an ingress configuration on the service i can stick to the proxy-body-size annotation, but how is it when not using an ingress configuration?
",<kubernetes><kubernetes-ingress><http-status-code-413>,60655743,1,"it seems there is no limitation on request-body-size when a service has not defined an ingress resource.

edit: exemplary, we got two services hosted in our cluster a and b. 
service a will be reachable from outside the cluster which will be achieved by defining an nginx ingress resource which exposes to the url my.service.a.

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: ""0""
  ...
spec:
  rules:
    - host: my.service.a
    http:
      paths:
      ...


please take note of the annotation nginx.ingress.kubernetes.io/proxy-body-size: ""0"" which disables the limitation of client request body size (not recommended!).

service b will only be requested by service a within its internal cluster address my-service-b.svc.cluster.local and therefore no nginx ingress resource has been defined for service b.

my assumption was, that service b has by default a client_request_body_size limitation too. but after testing, it seems that there is no limitation.
"
59004600,terraform: create single node gke cluster,"i am trying to create a gke cluster of node size 1. however, it always create a cluster of 3 nodes. why is that? 

resource ""google_container_cluster"" ""gke-cluster"" {
  name = ""sonarqube""
  location = ""asia-southeast1""
  remove_default_node_pool = true
  initial_node_count = 1
}

resource ""google_container_node_pool"" ""gke-node-pool"" {
  name = ""sonarqube""
  location = ""asia-southeast1""
  cluster = google_container_cluster.gke-cluster.name
  node_count = 1

  node_config {
    machine_type = ""n1-standard-1""
    metadata = {
      disable-legacy-endpoints = ""true""
    }

    labels = {
      app = ""sonarqube""
    }
  }
}



",<kubernetes><google-cloud-platform><terraform><google-kubernetes-engine>,59005212,4,"ok, found i can do so using node_locations: 

resource ""google_container_cluster"" ""gke-cluster"" {
  name = ""sonarqube""
  location = ""asia-southeast1""
  node_locations = [
    ""asia-southeast1-a""
  ]
  remove_default_node_pool = true
  initial_node_count = 1
}


without that, it seems gke will create 1 node per zone. 
"
76251197,not able to add ipv6 type load balancer ip in kubernetes service,"i'm on gke and i'm trying to expose one application using ipv6 address.
this is my service.yaml
apiversion: v1
kind: service
metadata:
  annotations:
    cloud.google.com/neg: '{&quot;ingress&quot;:true}'
  labels:
    run: ubuntu
  name: ubuntu
  namespace: default
spec:
  loadbalancerip: &quot;&lt;ipv6-address&gt;&quot;
  ipfamilies:
  - ipv6
  ipfamilypolicy: singlestack
  ports:
  - nodeport: 30783
    port: 5000
    protocol: tcp
    targetport: 5001
  selector:
    run: ubuntu
  sessionaffinity: none
  type: loadbalancer

this is my gcloud address list
deletable-pzk-reg-ip2-6           &lt;ipv6-address&gt;/96  external                    us-central1  pzksubnet1  reserved

i'm getting this error
  warning  syncloadbalancerfailed  13s (x6 over 2m49s)  service-controller  error syncing load balancer: failed to ensure load balancer: requested ip &quot;&lt;ipv6-address&gt;&quot; is neither static nor assigned to the lb

please help me in debugging this.
",<kubernetes><service><google-kubernetes-engine><ipv6>,76253055,1,"below troubleshooting steps can help you to resolve your issue:

ipv6 is only for http, ssl proxy and tcp proxy and make sure you are using one of them.

the following documentation describes creation of an ingress resource.



using the following reserve a regional external ipv6 address.
- gcloud compute addresses create &lt;your-ipv6-address-name&gt; --global --ip-version=ipv6

specify the global ip address in the yaml file using the annotation:
kubernetes.io/ingress.global-static-ip-name: &lt;your-ipv6-address-name&gt;



if you want to use load balancer check the load balancer parameters, example: after reserving the static ip use it as loadbalancedip in yaml, the load balancer will be created.

apiversion: v1
kind: servicemetadata:
  name: my-lb-service
spec:
  type: loadbalancer
  loadbalancerip: &lt;ip&gt;

attaching a blog http on load balancer and ipv6 authored by john hanley for your reference.
"
59129958,how to clean up after a gke cluster created with gcloud container clusters create?,"i'm creating kubernetes clusters programmatically for end-to-end tests in gitlab ci/cd. i'm using gcloud container clusters create. i'm doing this for half a year and created and deleted a few hundred clusters. the cost went up and down. now, i got an unusually high bill from google and i checked the cost breakdown. i noticed that the cost is >95% for ""storage pd capacity"". i found out that gcloud container clusters delete never deleted the google compute disks created for persistent volume claims in the kubernetes cluster.

how can i delete those programmatically? what else could be left running after deleting the kubernetes cluster and the disks?
",<kubernetes><google-compute-engine><google-kubernetes-engine><gcloud>,59146041,1,"because this part of the answer is lengthy:

gcloud compute disks create disk-a \
--size=10gb \
--zone=us-west1-a \
--labels=something=monday \
--project=${project}

gcloud compute disks create disk-b \
--size=10gb \
--zone=us-west1-b \
--labels=something=else \
--project=${project}


then:

id=$(gcloud compute disks list \
--filter=""name~disk zone~us-west1 labels.something=else"" \
--format=""value(id)"" \
--project=${project}) &amp;&amp; echo ${id}


nb 


the filter and is implicit and omitted
you may remove terms as needed
you should make the filter as specific as possible




and -- when you're certain as deletion is irrecoverable:

gcloud compute disks delete ${id} --project=${project} --region=${region}


if there are multiple matches, you can iterate:

ids=$(gcloud compute disks list ...)
for id in ${ids}
do
  gcloud compute disks delete ${id}
done


if you prefer -- the awesome jq, you'll have a general-purpose way (not gcloud-specific):

gcloud compute disks list \
--project=${project} \
--format=json \
| jq --raw-output '.[] | select(.name | contains(""disk"")) | select(.zone | contains(""us-west1"")) | select(.labels.something==""else"")'
...

"
49861195,"creating persistent volume results in storageclass.storage.k8s.io ""fast"" not found","i installed kubernetes on two centos7 vms using kubeadm.

i am trying to follow the example: deploying cassandra with stateful sets or scalable-cassandra-deployment-on-kubernetes samples.

creating the local volumes works but kubectl get pvc always results in a status of pending. kubectl descrive pvc &lt;*pvc name*&gt; results in the following warning:

events:
type     reason              age                   from                         message
----     ------              ----                  ----                         -------
warning  provisioningfailed  54s (x16854 over 2d)  persistentvolume-controller  storageclass.storage.k8s.io ""fast"" not found


i'm uncertain how to create the ""fast"" storage class to enable the volume to be successfully created and complete the samples.
",<kubernetes><kubeadm><kubernetes-pvc>,49861436,5,"when you create a persistent volume you have to make sure that the corresponding storage class exist.


  a storageclass provides a way for administrators to describe the “classes” of storage they offer. different classes might map to quality-of-service levels, or to backup policies, or to arbitrary policies determined by the cluster administrators. kubernetes itself is unopinionated about what classes represent. this concept is sometimes called “profiles” in other storage systems.


for example in the guide you linked at the bottom of the yaml file you find:

kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: fast
provisioner: k8s.io/minikube-hostpath
parameters:
  type: pd-ssd


this is the definition of the storage class, the api and the provisioner makes sure how it get mapped to the actual storage and depends on the kubernetes implementation and where it is running.

therefore you should double check if you declared the storage class:

$ kubectl get storageclasses --all-namespaces


if you do not have a storage class you should create it specifying the correct provisioner or if it merely a test you can consider to create the volume claim of a storage class you already have.

example

for example running on google kubernetes engine i have by default a standard class. trying to deploy a claim i have as well a pending error message.

deploying the following yaml file(and note that the provisioned changed) i am able to successfully create the persistent volume claim since now kubernetes knows what i mean with type ""fast"":

kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd  
parameters:
  type: pd-ssd
  zones: us-central1-a, us-central1-b

"
71010998,how do i deploy the aws efs csi driver helm chart from https://kubernetes-sigs.github.io/aws-efs-csi-driver/ using pulimi,"i would like to be able to deploy the aws efs csi driver helm chart hosted at aws efs sig repo using pulumi. with source from aws efs csi driver github source.  i would like to avoid having almost everything managed with pulumi except this one part of my infrastructure.
below is the typescript class i created to manage interacting with the k8s.helm.v3.release class:
import * as k8s from '@pulumi/kubernetes';
import * as eks from '@pulumi/eks';

export default class awsefscsidriverhelmrepo extends k8s.helm.v3.release {
  constructor(cluster: eks.cluster) {
    super(`aws-efs-csi-driver`, {
      chart: `aws-efs-csi-driver`,
      version: `1.3.6`,
      repositoryopts: {
        repo: `https://kubernetes-sigs.github.io/aws-efs-csi-driver/`,
      },
      namespace: `kube-system`,
    }, { provider: cluster.provider });
  }
}

i've tried several variations on the above code, chopping of the -driver in the name, removing aws-cfs-csi-driver from the repo property, changing to latest for the version.
when i do a pulumi up i get: failed to pull chart: chart &quot;aws-efs-csi-driver&quot; version &quot;1.3.6&quot; not found in https://kubernetes-sigs.github.io/aws-efs-csi-driver/ repository
$ helm version
version.buildinfo{version:&quot;v3.7.0&quot;, gitcommit:&quot;eeac83883cb4014fe60267ec6373570374ce770b&quot;, gittreestate:&quot;clean&quot;, goversion:&quot;go1.16.8&quot;}

$ pulumi version
v3.24.1

",<kubernetes><amazon-eks><amazon-efs><pulumi>,71011318,1,"you're using the wrong version in your chart invocation.
the version you're selecting is the application version, ie the release version of the underlying application. you need to set the chart version, see here which is defined here
the following works:
const csidrive = new kubernetes.helm.v3.release(&quot;csi&quot;, {
  chart: `aws-efs-csi-driver`,
  version: `2.2.3`,
  repositoryopts: {
    repo: `https://kubernetes-sigs.github.io/aws-efs-csi-driver/`,
  },
  namespace: `kube-system`,
});

if you want to use the existing code you have, try this:
import * as k8s from '@pulumi/kubernetes';
import * as eks from '@pulumi/eks';

export default class awsefscsidriverhelmrepo extends k8s.helm.v3.release {
  constructor(cluster: eks.cluster) {
    super(`aws-efs-csi-driver`, {
      chart: `aws-efs-csi-driver`,
      version: `2.2.3`,
      repositoryopts: {
        repo: `https://kubernetes-sigs.github.io/aws-efs-csi-driver/`,
      },
      namespace: `kube-system`,
    }, { provider: cluster.provider });
  }
}

"
72281094,how to specify kubernetes rbac permissions for scaling a specific deployment,"i'm trying to give a group of users permission to scale a specific set of deployments in kubernetes 1.20
i've tried using the api reference doc here: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#patch-scale-deployment-v1-apps
to set resource names like so:
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: kubeoperator-cr
rules:
... #irrelevant rules omitted
- apigroups: [&quot;apps&quot;]
  resources:
    - /namespaces/my-namespace-name/deployments/my-deployment-name/scale
    - deployments/my-deployment-name/scale
  verbs:
    - update
    - patch

this doesn't work:
$ kubectl scale deployments -n my-namespace-name my-deployment-name --replicas 3
error from server (forbidden): deployments.apps &quot;my-deployment-name&quot; is forbidden: user &quot;kubeoperatorrole&quot; cannot patch resource &quot;deployments/scale&quot; in api group &quot;apps&quot; in the namespace &quot;my-namespace-name&quot;

the only way i can get the scale command to work is to grant the permission for all deployments (which is not what i want) like this:
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: kubeoperator-cr
rules:
... #irrelevant rules omitted
- apigroups: [&quot;apps&quot;]
  resources:
    - deployments/scale
  verbs:
    - update
    - patch

$ kubectl scale deployments -n my-namespace-name my-deployment-name --replicas 3
deployment.apps/my-deployment-name scaled

what is the correct syntax for specifying a specific deployment resource by name, or is this not possible?
the deployments i'm targeting cannot be moved to an isolated namespace.
",<kubernetes><rbac><kubernetes-rbac><k8s-cluster-role>,72282749,1,"resources isn't what you're looking for, it's resourcenames which has to be a specific object name like resourcenames: [my-deployment-name]. in general this isn't a very good approach, the expectation is that you will segment things by namespace and give them permissions in just one namespace (or two or three or whatever it is).
"
75097192,unable to run kubernetespodoperator,"i am using airflow 2.4.3 and running kubernetespodoperator
below is the code and error:-
please help me with creating a kubernetesposoperator in python. i have tried on both gcp and azure.
also adding the kubernetes documentation for reference:-
https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/_api/airflow/providers/cncf/kubernetes/operators/kubernetes_pod/index.html#airflow.providers.cncf.kubernetes.operators.kubernetes_pod.kubernetespodoperator
i can also share any other info if required.

from kubernetes.client import models as k8s

from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import kubernetespodoperator

#custom modules
from spark_api.spark_submit import sparksubmit

#import modules
import json
import datetime
import logging

import airflow_api
import time


airflow_dag_object = airflowdagutilities(&quot;aaa_test_airflow_api&quot;)


def def_func1(**kwargs):
    print(&quot;in func1&quot;)
    
    namespace = &quot;segmentation-pipeline&quot;
    docker_image = &quot;****:v6&quot; # name commented out
    is_delete_operator_pod = true
    
    docker_image_creds =  [k8s.v1localobjectreference(&quot;****&quot;)] # harbor name commented out

    
    submit_command = [&quot;/bin/bash&quot;,&quot;-c&quot;]
    
    max_cores = 60
    driver_memory = &quot;4g&quot;
    executor_memory = &quot;4g&quot;
            
    submit_args = &quot;/usr/local/spark/bin/spark-submit --master local[&quot; + str(max_cores) + &quot;] --driver-memory &quot; + \
                                driver_memory + &quot; --executor-memory &quot; + executor_memory + &quot; &quot;
    
    submit_spark_pipeline_config_conf = &quot;--conf &quot; + '\'' + 'spark.pipelineconfig' + &quot;=&quot; + json.dumps(_infra_config.get_infra_config(),separators=(',',':')) + '\'' + &quot; &quot;
    
    submit_spark_broadcast_timeout = &quot;--conf &quot; + '\&quot;' + &quot;spark.sql.broadcasttimeout&quot; + &quot;=&quot; + str(&quot;36000&quot;) + '\&quot;' + &quot; &quot;
    
    submit_spark_max_result_size = &quot;--conf &quot; + '\&quot;' + &quot;spark.driver.maxresultsize&quot; + &quot;=&quot; + str(&quot;0&quot;) + '\&quot;' + &quot; &quot;

    final_dependency_jars = [&quot;./resources/mysql_connector_java_5.1.45.jar&quot;,\
                            &quot;./resources/commons_httpclient_3.0.1.jar&quot;]
                 
    
    dependency_jars_string = ','.join(list(set(final_dependency_jars)))
    
    submit_spark_dependency_jars = &quot;--conf &quot; + '\&quot;' + &quot;spark.jars&quot; + &quot;=&quot; + dependency_jars_string + '\&quot;' + &quot; &quot;
    extra_conf = []
    extra_conf_final = []
    
    for conf in extra_conf:
        conf_appended_string = &quot;--conf &quot; + '\&quot;' + conf + '\'' + &quot; &quot;
        extra_conf_final.append(conf_appended_string)
            
    
    extra_conf = &quot; &quot;.join(extra_conf_final) + &quot; &quot;
    
    airflow_task_settings = airflow_api.extract_airflow_task_details(kwargs['task_instance'])
    
    submit_spark_airflow_task_details = &quot;--conf &quot; + '\&quot;' + &quot;spark.airflowtaskdetails&quot; + &quot;=&quot; + json.dumps(airflow_task_settings) + '\'' + &quot; &quot;
    
    common_submit_args_beginning = submit_args + submit_spark_broadcast_timeout + submit_spark_max_result_size + submit_spark_dependency_jars + extra_conf + submit_spark_airflow_task_details
    
    application_resource = &quot;/update_scores.py&quot;
    application_arguments = [&quot;test_args&quot;]
    
    string_application_arguments = &quot; &quot;
    for i in range(0,len(application_arguments)):
        string_application_arguments = string_application_arguments + &quot; &quot; + json.dumps(application_arguments[i]) 
    
    
    common_submit_args_end = application_resource + string_application_arguments
            
    platform_utilities = platformutilities(_infra_config)
    
    print(&quot;platform_utilities.get_python_modules_path() -&gt; &quot;,str(platform_utilities.get_python_modules_path()))
    
    submit_spark_python_module_path = &quot;--conf &quot; + '\&quot;' + &quot;spark.modulepath&quot; + &quot;=&quot; + str(platform_utilities.get_python_modules_path()) + '\&quot;' + &quot; &quot;
    
    submit_spark_args = [common_submit_args_beginning + submit_spark_pipeline_config_conf + submit_spark_python_module_path + common_submit_args_end]
    
    print(&quot;submit_spark_args -&gt; &quot;,submit_spark_args)
    
    submit_in_cluster = true
    
       
    submit_spark_pod_affinity = k8s.v1affinity(
    node_affinity=k8s.v1nodeaffinity(k8s.v1nodeselectorterm(
                    match_expressions=[
                        k8s.v1nodeselectorrequirement(key=&quot;****&quot;, operator=&quot;in&quot;, values=[&quot;n2-highmem-8&quot;]),
                        k8s.v1nodeselectorrequirement(key=&quot;deployment&quot;, operator=&quot;in&quot;, values=[&quot;dynamic&quot;]),
                    ]
                )
            )
        )
    
    
    submit_spark_pod_tolerations = [k8s.v1toleration(key=&quot;deployment&quot;, operator=&quot;equal&quot;, value=&quot;dynamic&quot;, effect=&quot;noschedule&quot;)]
    
    application_name = &quot;test_airflow_api_test_task_id&quot;
    
    container_resources = k8s.v1resourcerequirements(
                requests={
                    'memory': str(&quot;10gi&quot;),
                    'cpu': str(&quot;2&quot;)
                },
                limits={
                    'memory': str(&quot;50gi&quot;),
                    'cpu': str(&quot;5&quot;)
                }
            )
    
    submit_startup_timeout_seconds = 600
    
    submit_get_logs = true
    
    kube_submssion = kubernetespodoperator(namespace = namespace,
                    image = docker_image,
                    is_delete_operator_pod = is_delete_operator_pod,
                    image_pull_secrets = docker_image_creds,
                    cmds = submit_command,
                    arguments = submit_spark_args,
                    in_cluster = submit_in_cluster,
                    affinity = submit_spark_pod_affinity,
                    tolerations = submit_spark_pod_tolerations,
                    container_resources = container_resources,
                    name = application_name,
                    task_id = application_name,
                    startup_timeout_seconds = submit_startup_timeout_seconds,
                    get_logs = submit_get_logs
                )
    
    kube_submssion.execute(context = none)
    
  

def def_func2(**kwargs):
    print(&quot;in func2&quot;)

dag_base = airflow_dag_object.get_dag_object()

func1=pythonoperator(
    task_id='func1',
    provide_context=true,
    python_callable=def_func1,
    dag=dag_base
)

func2=pythonoperator(
    task_id='func2',
    provide_context=true,
    python_callable=def_func2,
    dag=dag_base
)

func1 &gt;&gt; func2

output error:-
traceback (most recent call last):
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/cncf/kubernetes/operators/kubernetes_pod.py&quot;, line 419, in execute
    context=context,
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/cncf/kubernetes/operators/kubernetes_pod.py&quot;, line 387, in get_or_create_pod
    pod = self.find_pod(self.namespace or pod_request_obj.metadata.namespace, context=context)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/cncf/kubernetes/operators/kubernetes_pod.py&quot;, line 371, in find_pod
    label_selector=label_selector,
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/api/core_v1_api.py&quot;, line 15697, in list_namespaced_pod
    return self.list_namespaced_pod_with_http_info(namespace, **kwargs)  # noqa: e501
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/api/core_v1_api.py&quot;, line 15826, in list_namespaced_pod_with_http_info
    collection_formats=collection_formats)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/api_client.py&quot;, line 353, in call_api
    _preload_content, _request_timeout, _host)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/api_client.py&quot;, line 184, in __call_api
    _request_timeout=_request_timeout)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/api_client.py&quot;, line 377, in request
    headers=headers)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/rest.py&quot;, line 244, in get
    query_params=query_params)
  file &quot;/home/airflow/.local/lib/python3.7/site-packages/kubernetes/client/rest.py&quot;, line 234, in request
    raise apiexception(http_resp=r)
kubernetes.client.exceptions.apiexception: (400)
reason: bad request
http response headers: httpheaderdict({'audit-id': '6ab39ea1-f955-4481-b3eb-7b3abe747a7c', 'cache-control': 'no-cache, private', 'content-type': 'application/json', 'x-kubernetes-pf-flowschema-uid': '8e487991-120d-49d0-940a-ace0b0e64421', 'x-kubernetes-pf-prioritylevel-uid': '8f6ab0b3-abdf-4782-994c-2f0f247592d2', 'date': 'thu, 12 jan 2023 13:13:20 gmt', 'content-length': '169'})
http response body: {&quot;kind&quot;:&quot;status&quot;,&quot;apiversion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{},&quot;status&quot;:&quot;failure&quot;,&quot;message&quot;:&quot;found ',', expected: !, identifier, or 'end of string'&quot;,&quot;reason&quot;:&quot;badrequest&quot;,&quot;code&quot;:400}

",<python><kubernetes><google-kubernetes-engine><airflow-2.x><kubernetespodoperator>,75105826,2,"in previous version of airflow &lt; 2.3 kubernetespodoperator used to work with none context
as mentioned in your question
kube_submssion = kubernetespodoperator(namespace = namespace,
                    image = docker_image,
                    is_delete_operator_pod = is_delete_operator_pod,
                    image_pull_secrets = docker_image_creds,
                    cmds = submit_command,
                    arguments = submit_spark_args,
                    in_cluster = submit_in_cluster,
                    affinity = submit_spark_pod_affinity,
                    tolerations = submit_spark_pod_tolerations,
                    container_resources = container_resources,
                    name = application_name,
                    task_id = application_name,
                    startup_timeout_seconds = submit_startup_timeout_seconds,
                    get_logs = submit_get_logs
                )
    
kube_submssion.execute(context = none)

the execute method is expecting the context as mentioned in the documentation at followig link
https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/_modules/airflow/providers/cncf/kubernetes/operators/kubernetes_pod.html#kubernetespodoperator.execute
you can pass the context from **kwargs to the execute method. you can try by passing kwargs to execute method
kube_submssion.execute(context = kwargs)

"
48610778,http -> https redirect in google kubernetes engine,"i'm looking to redirect all traffic from 

http://example.com -> https://example.com like how nearly all websites do.

i've looked at this link with no success:
kubernetes https ingress in google container engine

and have tried the following annotations in my ingress.yaml file.

nginx.ingress.kubernetes.io/configuration-snippet: |
  if ($http_x_forwarded_proto != 'https') {
    return 301 https://$host$request_uri;
  }
nginx.ingress.kubernetes.io/force-ssl-redirect: ""true""
nginx.ingress.kubernetes.io/ssl-redirect: ""true""
kubernetes.io/ingress.allow-http: ""false""


all without any success. to be clear, i can access https://example.com and  http://example.com without any errors, i need the http call to redirect to https. 

thanks
",<kubernetes><google-cloud-platform><google-compute-engine><google-kubernetes-engine>,49045549,2,"for what it's worth, i ended up using a reverse proxy in nginx.


you need to create secrets and sync them into your containers
you need to create a configmap in nginx with your nginx config, as well as a default config that references this additional config file.


here is my configuration:

worker_processes  1;

events {
    worker_connections  1024;
}


http {

default_type  application/octet-stream;

# logging configs
log_format  main  '$remote_addr - $remote_user [$time_local] ""$request"" '
                  '$status $body_bytes_sent ""$http_referer"" '
                  '""$http_user_agent"" ""$http_x_forwarded_for""';

access_log  /var/log/nginx/access.log  main;

sendfile        on;
keepalive_timeout  65;

# puntdoctor proxy config
include /path/to/config-file.conf;

# pubsub allows 10mb files. lets allow 11 to give some space
client_max_body_size 11m;

}


then, the config.conf

server {
listen 80;
server_name example.com;
return 301 https://$host$request_uri;
}

server {

listen 443;
server_name example.com;

ssl_certificate           /certs/tls.crt;
ssl_certificate_key       /certs/tls.key;

ssl on;
ssl_session_cache  builtin:1000  shared:ssl:10m;
ssl_protocols tlsv1 tlsv1.1 tlsv1.2;
ssl_ciphers ecdhe-rsa-aes256-gcm-sha384:ecdhe-rsa-aes128-gcm-sha256:ecdhe-rsa-aes128-sha:ecdhe-rsa-rc4-sha:aes128-gcm-sha256:high:!rc4:!md5:!anull:!edh:!camellia;
ssl_prefer_server_ciphers on;

location / {

  proxy_set_header        host $host;
  proxy_set_header        x-real-ip $remote_addr;
  proxy_set_header        x-forwarded-for $proxy_add_x_forwarded_for;
  proxy_set_header        x-forwarded-proto $scheme;
  proxy_set_header        x-forwarded-host $http_host;

  # fix the “it appears that your reverse proxy set up is broken"" error.
  proxy_pass          http://deployment-name:8080/;
  proxy_read_timeout  90;

  proxy_redirect      http://deployment-name:8080/ https://example.com/;
}
}



create a deployment:


here are the .yaml files

---
apiversion: v1
kind: service
metadata:
  name: puntdoctor-lb
spec:
   ports:
    - name: https
      port: 443
      targetport: 443
     - name: http
      port: 80
      targetport: 80
  selector:
    app: puntdoctor-nginx-deployment
  type: loadbalancer
  loadbalancerip: 35.195.214.7
---
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: puntdoctor-nginx-deployment
spec:
   replicas: 2
  template:
    metadata:
      labels:
        app: puntdoctor-nginx-deployment
    spec:
       containers:
       - name: adcelerate-nginx-proxy
        image: nginx:1.13
         volumemounts:
        - name: certs
          mountpath: /certs/
        - name: site-config
          mountpath: /etc/site-config/
        - name: default-config
          mountpath: /etc/nginx/
        ports:
        - containerport: 80
          name: http
        - containerport: 443
          name: https
      volumes:
      - name: certs
        secret:
          secretname: nginxsecret
      - name: site-config
        configmap:
          name: nginx-config
       - name: default-config
        configmap:
         name: default


hope this helps someone solve this issue, thanks for the other 2 answers, they both gave me valuable insight.
"
71262479,fluent bit does not send logs from my eks custom applications,"i am using aws opensearch to retrieve the logs from all my kubernetes applications.
i have the following pods: kube-proxy, fluent-bit, aws-node, aws-load-balancer-controller, and all my apps (around 10).
while fluent-bit successfully send all the logs from kube-proxy, fluent-bit, aws-node and aws-load-balancer-controller, none of the logs from my applications are sent. my applications had debug, info, error logs, and none are sent by fluent bit.
here is my fluent bit configuration:
apiversion: v1
kind: configmap
metadata:
  name: fluent-bit-config
  namespace: my-namespace
  labels:
    k8s-app: fluent-bit
data:
  # configuration files: server, input, filters and output
  # ======================================================
  fluent-bit.conf: |
    [service]
        flush         1
        log_level     info
        daemon        off
        parsers_file  parsers.conf
        http_server   on
        http_listen   0.0.0.0
        http_port     2020

    @include input-kubernetes.conf
    @include filter-kubernetes.conf
    @include output-elasticsearch.conf

  input-kubernetes.conf: |
    [input]
        name              tail
        tag               kube.*
        path              /var/log/containers/*.log
        parser            docker
        db                /var/log/flb_kube.db
        mem_buf_limit     50mb
        skip_long_lines   on
        refresh_interval  10

  filter-kubernetes.conf: |
    [filter]
        name                kubernetes
        match               kube.*
        kube_url            https://kubernetes.default.svc:443
        kube_ca_file        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        kube_token_file     /var/run/secrets/kubernetes.io/serviceaccount/token
        kube_tag_prefix     kube.var.log.containers.
        merge_log           on
        merge_log_key       log_processed
        k8s-logging.parser  on
        k8s-logging.exclude off

  output-elasticsearch.conf: |
    [output]
        name            es
        match           *
        host            my-host.es.amazonaws.com
        port            443
        tls             on
        aws_auth        on
        aws_region      ap-southeast-1
        retry_limit     6

  parsers.conf: |
    [parser]
        name   apache
        format regex
        regex  ^(?&lt;host&gt;[^ ]*) [^ ]* (?&lt;user&gt;[^ ]*) \[(?&lt;time&gt;[^\]]*)\] &quot;(?&lt;method&gt;\s+)(?: +(?&lt;path&gt;[^\&quot;]*?)(?: +\s*)?)?&quot; (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: &quot;(?&lt;referer&gt;[^\&quot;]*)&quot; &quot;(?&lt;agent&gt;[^\&quot;]*)&quot;)?$
        time_key time
        time_format %d/%b/%y:%h:%m:%s %z

    [parser]
        name   apache2
        format regex
        regex  ^(?&lt;host&gt;[^ ]*) [^ ]* (?&lt;user&gt;[^ ]*) \[(?&lt;time&gt;[^\]]*)\] &quot;(?&lt;method&gt;\s+)(?: +(?&lt;path&gt;[^ ]*) +\s*)?&quot; (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: &quot;(?&lt;referer&gt;[^\&quot;]*)&quot; &quot;(?&lt;agent&gt;[^\&quot;]*)&quot;)?$
        time_key time
        time_format %d/%b/%y:%h:%m:%s %z

    [parser]
        name   apache_error
        format regex
        regex  ^\[[^ ]* (?&lt;time&gt;[^\]]*)\] \[(?&lt;level&gt;[^\]]*)\](?: \[pid (?&lt;pid&gt;[^\]]*)\])?( \[client (?&lt;client&gt;[^\]]*)\])? (?&lt;message&gt;.*)$

    [parser]
        name   nginx
        format regex
        regex ^(?&lt;remote&gt;[^ ]*) (?&lt;host&gt;[^ ]*) (?&lt;user&gt;[^ ]*) \[(?&lt;time&gt;[^\]]*)\] &quot;(?&lt;method&gt;\s+)(?: +(?&lt;path&gt;[^\&quot;]*?)(?: +\s*)?)?&quot; (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: &quot;(?&lt;referer&gt;[^\&quot;]*)&quot; &quot;(?&lt;agent&gt;[^\&quot;]*)&quot;)?$
        time_key time
        time_format %d/%b/%y:%h:%m:%s %z

    [parser]
        name   json
        format json
        time_key time
        time_format %d/%b/%y:%h:%m:%s %z

    [parser]
        name        docker
        format      json
        time_key    time
        time_format %y-%m-%dt%h:%m:%s.%l
        time_keep   on

    [parser]
        name        syslog
        format      regex
        regex       ^\&lt;(?&lt;pri&gt;[0-9]+)\&gt;(?&lt;time&gt;[^ ]* {1,2}[^ ]* [^ ]*) (?&lt;host&gt;[^ ]*) (?&lt;ident&gt;[a-za-z0-9_\/\.\-]*)(?:\[(?&lt;pid&gt;[0-9]+)\])?(?:[^\:]*\:)? *(?&lt;message&gt;.*)$
        time_key    time
        time_format %b %d %h:%m:%s

i followed this documentation
thanks a lot for the help.
",<elasticsearch><kubernetes><amazon-eks><fluentd><fluent-bit>,71275575,4,"finally, i did two things that solved my issue:

modified this configuration:

# before
 output-elasticsearch.conf: |
    [output]
        name            es
        match           *
        host            search-blacaz-logs-szzq6vokwwm4y5fkfwyngjwjxq.ap-southeast-1.es.amazonaws.com
        port            443
        tls             on
        aws_auth        on
        aws_region      ap-southeast-1
        retry_limit     6

# after
 output-elasticsearch.conf: |
    [output]
        name            es
        match           *
        host            search-blacaz-logs-szzq6vokwwm4y5fkfwyngjwjxq.ap-southeast-1.es.amazonaws.com
        port            443
        tls             on
        aws_auth        on
        replace_dots    on // added this
        aws_region      ap-southeast-1
        retry_limit     6

then, i had to delete the fluent-bit elastic search index, and re-create it.
indeed, the index was probably not well suited for my java logs at first, and adjusted to it after re-creation.
"
46610180,downgrade kubectl version to match minikube k8s version,"i started minikube with k8s version 1.5.2 and i would like to downgrade my kubectl so that it is also 1.5.2. currently when i run  kubectl version i get:

client version: version.info{major:""1"", minor:""7"", gitversion:""v1.7.5"", gitcommit:""17d7182a7ccbb167074be7a87f0a68bd00d58d97"", gittreestate:""clean"", builddate:""2017-08-31t19:32:12z"", goversion:""go1.9"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""5"", gitversion:""v1.5.2"", gitcommit:""08e099554f3c31f6e6f07b448ab3ed78d0520507"", gittreestate:""clean"", builddate:""1970-01-01t00:00:00z"", goversion:""go1.7"", compiler:""gc"", platform:""linux/amd64""}


i would like to use kubectl to fetch petsets but in later versions this was updated to statefulsets so i cannot use the commands with my current kubectl version 

kubectl get petsets
the server doesn't have a resource type ""petsets""


thanks!
",<kubernetes><kubectl><minikube>,46610263,72,"you can just download the previous version binary and replace the one you have now.

linux:

curl -lo https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl


macos:

curl -lo https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/darwin/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl


windows:

curl -lo https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/windows/amd64/kubectl.exe


and add it to path.

if not follow instructions for other operating systems here: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-via-curl
"
58531740,google cloud platform creating a pipeline with kubernetes and replacing the same container,"i am struggling trying to replace an existing container with a container from my container-register from google cloud platform.

this is my cloudbuild.yaml file.

steps:

  # this steps clone the repository into gcp
  - name: gcr.io/cloud-builders/git
    args: ['clone', 'https:///user/:password@github.com/patrickvibild/scrappercontroller']

  # this step runs the unit tests on the src
  - name: 'docker.io/library/python:3.7'
    id: test
    entrypoint: /bin/sh
    args:
      - -c
      - 'pip install -r requirements.txt &amp;&amp; python -m pytest src/tests/**'

  #this step creates a container and leave it on cloudbuilds repository.
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/abiding-robot-255320/scrappercontroller', '.']

  #adds the container to google container registry as an artefact
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/abiding-robot-255320/scrappercontroller']

  #uses the container and replaces the existing one in kubernetes
  - name: 'gcr.io/cloud-builders/kubectl'
    args: ['set', 'image', 'deployment/scrappercontroller', 'scrappercontroller-sha256=gcr.io/abiding-robot-255320/scrappercontroller:latest']
    env:
      - 'cloudsdk_compute_zone=us-central1-a'
      - 'cloudsdk_container_cluster=scrapper-admin'


i have no issues building my project and i get green on all the steps, i might be missing in the last step but i cant find a way to replace my container in my cluster with a newer version of my code. 

i can create a new workload inside my existing cluster manually using the gui and selecting a container from my container registry, but from there the step to replace that workload container with my new version from the clouds fails.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,58543316,4,"it's a common pitfall. according with the documentation:


  note: a deployment’s rollout is triggered if and only if the deployment’s pod template (that is, .spec.template) is changed, for example if the labels or container images of the template are updated. other updates, such as scaling the deployment, do not trigger a rollout.


your issue come from the tag of your image doesn't change: the :latest is deployed and you ask for deploying :latest. no image name change, no rollout.

for changing this, i propose you to use substitution variables, especially commit_sha or short_sha. you can not this in the documentation:


  only available for triggered builds


this means that this variable is only populated when the build is automatically triggered  and not manually. 

for manual run, you have to specify your own variable, like this

gcloud builds submit --substitutions=commit_sha=&lt;what you want&gt;


and update your build script like this:

  # this steps clone the repository into gcp
  - name: gcr.io/cloud-builders/git
    args: ['clone', 'https:///user/:password@github.com/patrickvibild/scrappercontroller']

  # this step runs the unit tests on the src
  - name: 'docker.io/library/python:3.7'
    id: test
    entrypoint: /bin/sh
    args:
      - -c
      - 'pip install -r requirements.txt &amp;&amp; python -m pytest src/tests/**'

  #this step creates a container and leave it on cloudbuilds repository.
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/abiding-robot-255320/scrappercontroller:$commit_sha', '.']

  #adds the container to google container registry as an artefact
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/abiding-robot-255320/scrappercontroller:$commit_sha']

  #uses the container and replaces the existing one in kubernetes
  - name: 'gcr.io/cloud-builders/kubectl'
    args: ['set', 'image', 'deployment/scrappercontroller', 'scrappercontroller-sha256=gcr.io/abiding-robot-255320/scrappercontroller:commit_sha']
    env:
      - 'cloudsdk_compute_zone=us-central1-a'
      - 'cloudsdk_container_cluster=scrapper-admin'


and during the deployment, you should see this line:

step #2: running: kubectl set image deployment.apps/test-deploy go111=gcr.io/&lt;projectid&gt;/postip:&lt;what you want&gt;
step #2: deployment.apps/test-deploy image updated


if you don't see it, this mean that your rollout has not take into account.
"
59539621,helm 3.0.2 dry-run + stable/prometheus-operator? is this supposed to work?,"with helm v3.0.2 + a new kubernetes v1.14.9 cluster.

fyi, i've already added the stable repo:

helm repo add stable https://kubernetes-charts.storage.googleapis.com/


helm install \
  --namespace prometheus \
  prom-dry-run \
  stable/prometheus-operator \
  --dry-run

manifest_sorter.go:175: info: skipping unknown hook: ""crd-install""
manifest_sorter.go:175: info: skipping unknown hook: ""crd-install""
manifest_sorter.go:175: info: skipping unknown hook: ""crd-install""
manifest_sorter.go:175: info: skipping unknown hook: ""crd-install""
manifest_sorter.go:175: info: skipping unknown hook: ""crd-install""
error: unable to build kubernetes objects from release manifest: [unable to recognize """": no matches for kind ""alertmanager"" in version ""monitoring.coreos.com/v1"", unable to recognize """": no matches for kind ""prometheus"" in version ""monitoring.coreos.com/v1"", unable to recognize """": no matches for kind ""prometheusrule"" in version ""monitoring.coreos.com/v1"", unable to recognize """": no matches for kind ""servicemonitor"" in version ""monitoring.coreos.com/v1""]


i thought helm 3 was backward-compatible with existing charts? is this an exception?

is prometheus-operator not compatible with helm 3? do i have to use helm 2? or is there a backward-compatibility option?
",<kubernetes><kubernetes-helm><prometheus-operator>,60768777,3,"crds were an exception to the helm v3 chart compatibility, sadly.
the problem is that --dry-run can't generate resources using the crds, because the crds aren't installed by the dry run. this is apparently a &quot;documented behaviour&quot; although it was documented in the implementation pull-request, not in the helm documentation.
edit: i forgot to mention the best current workaround is to install the crds by hand. then --dry-run will work. helm v3 ignores crds that are already installed, so you can just leave them there once you're happy with your configuration and do the install for real.
upgrading crds in helm is a whole different (not yet resolved) issue.

stable/prometheus-operator gained support to helm v3 in 8.2.0 in mid-november 2019 so that's not the issue here.
bitnami/prometheus-operator gained support in 0.3.0 only a couple of days earlier.
both appear to be actively maintained at the time of writing (march 2020).

in case anyone comes looking and is confused that the above two chart names are not links: both have been renamed, and one has moved.
they are now prometheus-community/kube-prometheus-stack (replaces stable/prometheus-operator) and bitnami/kube-prometheus respectively.
"
50099515,how to correctly give patterns for pod name in kubernetes?,"i'm using kubernetes for deploying applications, and 

kubect logs


for logs viewing.
redeployments are very often, so it's bit uncomfortable - to copy pod name each time to paste in log command(because end of pod name dinamically changes each time), e.g. below are commands for same application, after 2 deployments

kubectl logs -n=testns --since=1m testapp-2818008534-jx2vv
kubectl logs -n=testns --since=1m testapp-2818008534-xls93


so, i want to use one command, which will correctly ""pick up"" needed pod name each time we'r running the ""kubectl logs"".

but smth like

$kubectl logs -n=testns --since=1h $(kubectl get pods --namespace=testns | grep testapp)


returns an error, that we are not ""giving"" pod name, but that pod exists for sure:

error: expected 'logs (pod | type/name) [container_name]'.
pod or type/name is a required argument for the logs command


so, how to correctly set this command, to use it every time we want to look at logs, without need to re-copypaste full pod name?
",<kubernetes><kubectl>,50099709,1,"when you do:

kubectl get pods --namespace=testns | grep testapp

you get something like:

testapp-54d99599bc-g2gs4           1/1       running   0          56m

so this won't go well with logs command as it has some additional data which can not be understood by kubectl. what you can do is:

kubectl get pods --namespace=testns | grep testapp | cut -d' ' -f1

which will produce only name of the pod and then your log command should work.
"
47638923,migrate from plain kubernetes to helm without downtime,"i have several apps deployed into a kubernetes cluster. i have the receipts and etc as yaml files and i deploy and apply everything with kubectl.

i decided to migrate to helm because of its features and to avoid replicating code between dev and prod (i could use variables and etc).

the problem is: my services are aws elbs, and, as far as i found out, to migrate something already deployed with kubectl to helm, i need to delete it and install it again with helm - which will destroy and re-create my elbs, so i'll need to change dns records, etc. on top of all that, i'll have downtime - which is not really desired.

i thought about renaming the old-things and create the new things with the right name, keeping a common label to use in the service - so i could create the new one, change the dns records, and then delete the old stuff - but apparently renames are not allowed by kubernetes.

another strategy would be to launch a new cluster - which i don't really want to do.

are there any other alternatives?
",<kubernetes><kubernetes-helm>,47639111,1,"a properly designed chart should namespace deployed resources by .release.name. that way you can deploy chart side by side with existing software you have. it's likely that you will be able create large part of your stack in parallel and then update your off-chart services to point to on-chart pods, that way you can have both on-chart and off-chart services defined and working with two distinct elbs and if you want to get rid of off-charts, just edit dns and let it propagate, then, after a day, week or month you can scrap it and be left with chart only.
"
51152439,helm on aws eks,"having my cluster up and running on aws eks, i'm finding trouble running helm init with the following error:

$ helm init --service-account tiller --upgrade
error: error installing: deployments.extensions is forbidden: user ""system:anonymous"" cannot create deployments.extensions in the namespace ""kube-system""


kubectl works properly (object retrieval, creation and cluster administration), authenticating and authorizing correctly by running heptio-authenticator-aws at connection time ( with an exec section in the kubectl config).

in order to prepare the cluster for helm, i created the service account and role binding as specified in the helm docs.

i've heard of people having helm running on eks, and i'm guessing they're skipping the exec section of the kubectl config by hardcoding the token... i'd like to avoid that!

any ideas on how to fix this? my guess is that it is related to helm not being able to execute heptio-authenticator-aws properly
",<amazon-web-services><kubernetes><kubernetes-helm><amazon-eks>,51152692,7,"i was running helm version 2.8.2 when obtaining this error, upgrading to v2.9.1 fixed this!
"
64511653,kubernetes ingress configuration,"i have a working nexus 3 pod, reachable on port 30080 (with nodeport): http://nexus.mydomain:30080/ works perfectly from all hosts (from the cluster or outside).
now i'm trying to make it accessible at the port 80 (for obvious reasons).
following the docs, i've implemented it like that (trivial):
[...]
---

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: nexus-ingress
  namespace: nexus-ns
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$1
spec:
  rules:
    - host: nexus.mydomain
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              servicename: nexus-service
              serviceport: 80

applying it works without errors. but when i try to reach http://nexus.mydomain, i get:

service unavailable

no logs are shown (the webapp is not hit).
what did i miss ?
",<kubernetes><kubernetes-ingress><k3s>,64538549,2,"k3s lightweight kubernetes

k3s is designed to be a single binary of less than 40mb that completely implements the kubernetes api. in order to achieve this, they removed a lot of extra drivers that didn't need to be part of the core and are easily replaced with add-ons.

as i mentioned in comments, k3s as default is using traefik ingress controller.

traefik is an open-source edge router that makes publishing your services a fun and easy experience. it receives requests on behalf of your system and finds out which components are responsible for handling them.

this information can be found in k3s rancher documentation.

traefik is deployed by default when starting the server... to prevent k3s from using or overwriting the modified version, deploy k3s with --no-deploy traefik and store the modified copy in the k3s/server/manifests directory. for more information, refer to the official traefik for helm configuration parameters.
to disable it, start each server with the --disable traefik option.

if you want to deploy nginx ingress controller, you can check guide how to use nginx ingress controller in k3s.
as you are using specific nginx ingress like nginx.ingress.kubernetes.io/rewrite-target: /$1, you have to use nginx ingress.
if you would use more than 2 ingress controllers you will need to force using nginx ingress by annotation.
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;

if mention information won't help, please provide more details like your deployment, service.
"
54074758,kubectl apply --dry-run behaving weirdly,"i am facing a weird behaviour with kubectl and --dry-run.

to simplify let's say that i have the following yaml file:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  labels:
    run: nginx
  name: nginx
spec:
  replicas: 3
  selector:
    matchlabels:
      run: nginx
  strategy:
    rollingupdate:
      maxsurge: 1
      maxunavailable: 1
    type: rollingupdate
  template:
    metadata:
      creationtimestamp: null
      labels:
        run: nginx
    spec:
      containers:
      - image: nginxsdf
        imagepullpolicy: always
        name: nginx


modifying for example the image or the number of replicas:


kubectl apply -f deployment.yaml  -o yaml  --dry-run outputs me the resource having the old specifications
kubectl apply -f deployment.yaml  -o yaml outputs me the resource having new specifications


according to the documentation:


  --dry-run=false: if true, only print the object that would be sent, without sending it.


however the object printed is the old one and not the one that will be sent to the apiserver

tested on minikube, gke v1.10.0

in the meanwhile i opened a new github issue for it:


https://github.com/kubernetes/kubernetes/issues/72644

",<kubernetes><kubectl><minikube><kubernetes-apiserver>,54077812,8,"i got the following answer in the kubernetes issue page:

when updating existing objects, kubectl apply doesn't send an entire object, just a patch. it is not exactly correct to print either the existing object or the new object in dry-run mode... the outcome of the merge is what should be printed.
for kubectl to be able to accurately reflect the result of the apply, it would need to have the server-side apply logic clientside, which is a non-goal.
current efforts are directed at moving apply logic to the server. as part of that, the ability to dry-run server-side has been added. kubectl apply --server-dry-run will do what you want, printing the result of the apply merge, without actually persisting it.
@apelisse we should probably update the flag help for apply and possibly print a warning when using --dry-run when updating an object via apply to document the limitations of --dry-run and direct people to use --server-dry-run

"
68931789,digital ocean kubernetes secrets certificate connect with managed database,"i am trying to connect my kubernetes cluster in digital ocean with a managed database.
i need to add the ca certificate that is a file with extension cer.  is this the right way to add this file/certificate to a secret?
apiversion: v1
kind: secret
metadata:
  name: secret-db-ca
type: kubernetes.io/tls
data:
  .tls.ca: |
        &quot;&lt;base64 encoded ~/.digitalocean-db.cer&gt;&quot;

",<kubernetes><digital-ocean><kubernetes-secrets>,68938640,1,"how to create a secret from certificate

the easiest and fastest way is to create a secret from command line:
kubectl create secret generic secret-db-ca --from-file=.tls.ca=digitalocean-db.cer

please note that type of this secret is generic, not kubernetes.io/tls because tls one requires both keys provided: tls.key and tls.crt
also it's possible to create a key from manifest, however you will need to provide full base64 encoded string to the data field and again use the type opaque in manifest (this is the same as generic from command line).
it will look like:
apiversion: v1
kind: secret
metadata:
  name: secret-db-ca
type: opaque
data:
  .tls.ca: |
     ls0tls1crudjtibdrvj..........

option you tried to use is used for docker config files. please see docker config - secrets

note! i tested the above with cer certificate.
der (distinguished encoding rules) is a binary encoding for x.509 certificates and private keys, they do not contain plain text (extensions .cer and .der). secret was saved in etcd (generally speaking database for kubernetes cluster), however there may be issues with workability of secrets based on this type of secrets.
there is a chance that different type/extension of certificate should be used (digital ocean has a lot of useful and good documentation).

please refer to secrets in kubernetes page.
"
52393264,caculating the global index for two ranges in kubernetes sprig/helm templates?,"in a helm chart i have to following values

datacenters:
  - name: a
    replicas: 3
  - name: b
    replicas: 2


when generating the template i would like my output to be like the following 

server.1 = a-1
server.2 = a-2
server.3 = a-3
server.4 = b-1
server.5 = b-2


i tried this code

{{- $index := 0 -}}
{{ range $dc := .values.cluster.datacenters -}}
{{ range $seq := (int $dc.replicas | until) -}}
{{- $index := (add $index 1) -}}
server.{{ $index }}={{ $dc.name }}-{{ $seq }}
{{ end -}}
{{ end -}}


however in helm templates i don't thing you can reassign the value of the index as my 4th line is attempting and because of that i get out

server.1 = a-1
...
server.1 = b-2


how does one calculates the global index 0 to 4 (1 to 5 in my situation) using the sprig/helm templating language?
",<kubernetes><yaml><kubernetes-helm>,52396152,3,"i have a way to do it that involves some trickery, heavily inspired by functional programming experience.

a go/helm template takes a single parameter, but the sprig library gives you the ability to create lists, and the text/template index function lets you pick things out of a list.  that lets you write a ""function"" template that takes multiple parameters, packed into a list.

say we want to write out a single line of this output.  we need to keep track of which server number we're at (globally), which replica number we're at (within the current data center), the current data center record, and the records we haven't emitted yet.  if we're past the end of the current list, then print the records for the rest of the data centers; otherwise print a single line for the current replica and repeat for the next server/replica index.

{{ define ""emit-dc"" -}}
  {{ $server := index . 0 -}}
  {{ $n := index . 1 -}}
  {{ $dc := index . 2 -}}
  {{ $dcs := index . 3 -}}
  {{ if gt $n (int64 $dc.replicas) -}}
    {{ template ""emit-dcs"" (list $server $dcs) -}}
  {{ else -}}
server.{{ $server }}: {{ $dc.name }}-{{ $n }}
{{ template ""emit-dc"" (list (add1 $server) (add1 $n) $dc $dcs) -}}
  {{ end -}}
{{ end -}}


at the top level, we know the index of the next server number, plus the list of data centers.  if that list is empty, we're done.  otherwise we can start emitting rows from the first data center in the list.

{{ define ""emit-dcs"" -}}
  {{ $server := index . 0 -}}
  {{ $dcs := index . 1 -}}
  {{ if ne 0 (len $dcs) -}}
    {{ template ""emit-dc"" (list $server 1 (first $dcs) (rest $dcs)) -}}
  {{ end -}}
{{ end -}}


then in your actual resource definition (say, your configmap definition) you can invoke this template with the first server number:

{{ template ""emit-dcs"" (list 1 .values.datacenters) -}}


copy this all into a dummy helm chart and you can verify the output:

% helm template .
---
# source: x/templates/test.yaml
server.1: a-1
server.2: a-2
server.3: a-3
server.4: b-1
server.5: b-2


i suspect this trick won't work well if the number of servers goes much above the hundreds (the go templating engine almost certainly isn't tail recursive), and this is somewhat trying to impose standard programming language methods on a templating language that isn't quite designed for it.  but...it works.
"
58988669,eks cannot create persistent volume,"i am deploying prometheus which needs persistent volume(i have also tried with other statefulset), but persistent volume is not created and persistent volume clam shows the flowing error after kubectl describe -n {namespace} {pvc-name}.

type: warning 

reason: provisioningfailed

from: persistentvolume-controller

message: (combined from similar events): failed to provision volume with storageclass ""gp2"": error querying for all zones: error listing aws instances: ""unauthorizedoperation: you are not authorized to perform this operation.\n\tstatus code: 403, request id: d502ce90-8af0-4292-b872-ca04900d41dc""



kubectl get sc
name            provisioner             age
gp2 (default)   kubernetes.io/aws-ebs   7d17h


kubectl describe sc gp2

name:            gp2
isdefaultclass:  yes
annotations:     kubectl.kubernetes.io/last-applied-configuration={""apiversion"":""storage.k8s.io/v1"",""kind"":""storageclass"",""metadata"":{""annotations"":{""storageclass.kubernetes.io/is-default-class"":""true""},""name"":""gp2""},""parameters"":{""fstype"":""ext4"",""type"":""gp2""},""provisioner"":""kubernetes.io/aws-ebs"",""volumebindingmode"":""waitforfirstconsumer""}
,storageclass.kubernetes.io/is-default-class=true
provisioner:           kubernetes.io/aws-ebs
parameters:            fstype=ext4,type=gp2
allowvolumeexpansion:  &lt;unset&gt;
mountoptions:          &lt;none&gt;
reclaimpolicy:         delete
volumebindingmode:     waitforfirstconsumer
events:                &lt;none&gt;


k8s versions(aws eks):

client version: version.info{major:""1"", minor:""16"", gitversion:""v1.16.2"", gitcommit:""c97fe5036ef3df2967d086711e6c0c405941e14b"", gittreestate:""clean"", builddate:""2019-10-15t23:41:55z"", goversion:""go1.12.10"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""14+"", gitversion:""v1.14.8-eks-b7174d"", gitcommit:""b7174db5ee0e30c94a0b9899c20ac980c0850fc8"", gittreestate:""clean"", builddate:""2019-10-18t17:56:01z"", goversion:""go1.12.10"", compiler:""gc"", platform:""linux/amd64""}


helm version

version.buildinfo{version:""v3.0.0"", gitcommit:""e29ce2a54e96cd02ccfce88bee4f58bb6e2a28b6"", gittreestate:""clean"", goversion:""go1.13.4""}

",<kubernetes><amazon-eks><kubernetes-pvc>,58991291,8,"i solved this problem by adding amazoneksclusterpolicy and amazoneksservicepolicy to the eks cluster role.
"
67729910,helm range with 2 variables,"im trying to a loop with a range in helm but using 2 variables, what i have..
values.yaml
master:
  slave1: 
    - slave1value1
    - slave1value2
  slave2: 
    - slave2value1
    - slave2value2

my actual loop.
{{- range  .values.master.slave1 }}
        name: http://slave1-{{ . }}
{{- end }}
{{- range  .values.master.slave2 }}
        name: http://slave2-{{ . }}
{{- end }}


this is actually doing what i need, the output will be like this...
looping on .values.master.slave1
name: http://slave1-slave1value1
name: http://slave1-slave1value2

looping on .values.master.slave2
name: http://slave2-slave1value1
name: http://slave2-slave1value2

this is fully working for now, the question is, can i achieve the same result using just one loop block ? i tried this.
{{ alias := .values.master }}
{{- range  $alias }}
        name: http://{{ . }}-{{ $alias.name }}
{{- end }}

but the output is not what i'm expecting, thanks in advance.
",<kubernetes><kubernetes-helm><go-templates>,67730247,4,"almost...you need a nested loop to do this.  the top-level data structure is a map, where the keys are the worker names and the values are the list of values.  so you can iterate through the top-level map, then for each item iterate through the value list.
{{- $key, $values := range .values.master -}}
{{- $value := range $values -}}
name: http://{{ $key }}-{{ $value }}
{{ end -}}
{{- end -}}

note that we've assigned the values of range to locals to avoid some ambiguity around what exactly . means (inside each range loop it would be the iterator, for the currently-innermost loop).
"
69262538,units for kube_metrics_server_pods_cpu metric in prometheus,"can anyone guide if we monitoring out eks cluster using prometheus
then what would be the units for the metric kube_metrics_server_pods_cpu by default.
",<amazon-web-services><kubernetes><prometheus><monitoring><amazon-eks>,69279551,2,"cpu  is measured in nanocores.
kube_metrics_server_pods_cpu is measured in nanocores.
i agree with @noam-yizraeli
as per the source code of the metrics-server-exporter, there is pod_container_cpu variable.
metrics_pods_cpu.add_sample('kube_metrics_server_pods_cpu', value=int(pod_container_cpu), labels={ 'pod_name': pod_name, 'pod_namespace': pod_namespace, 'pod_container_name': pod_container_name })

pod_container_cpu is declared here
and readme.md says:

kube_metrics_server_nodes_cpu

provides nodes cpu information in nanocores.


memory is measured in kibibites.
as for the memory usage, the same readme.md says:

kube_metrics_server_nodes_mem

provides nodes memory information in kibibytes.


"
60096121,how to curl container deployed on kubernetes?,"
i built my docker image and uploaded it to amazon ecs (image repository). 
i've written a deployment.yaml file and ran kubectl apply -f deployment.yaml. 


worth noting i've used kops to deploy the k8s cluster to aws ec2

i can see the containers are running in kubernetes pods using the kubernetes dashboard. also kubectl get pods -o wide also shows me the pods.

the image i deployed is a simple api that exposes one route. my problem is that i have no idea how to query the container i just deployed.

dockerfile of deployed image:

from node:lts
copy package*.json tsconfig.json ./
run npm ci
copy . .
run npm run build

expose 3000
cmd [""node"", ""dist/index.js""]


deployment.yaml (kubectl apply -f deployment.yaml):  

apiversion: apps/v1
kind: deployment
metadata:
  name: vuekcal
spec:
  selector:
    matchlabels:
      app: vuekcal
  replicas: 2
  template:
    metadata:
      labels:
        app: vuekcal
    spec:
      containers:
        - name: search
          image: [my-repo-id].dkr.ecr.eu-central-1.amazonaws.com/k8s-search
          ports:
            - containerport: 3000


what i tried:


run kubectl get pods -o wide


name                       ready   status    restarts   age   ip           node                                            nominated node   readiness gates
vuekcal-6956589484-7f2kx   1/1     running   0          16m   100.96.2.6   ip-172-20-54-21.eu-central-1.compute.internal   &lt;none&gt;           &lt;none&gt;
vuekcal-6956589484-f4pqf   1/1     running   0          16m   100.96.1.7   ip-172-20-59-29.eu-central-1.compute.internal   &lt;none&gt;           &lt;none&gt;


if get and ip address from the ip column and try to curl it, nothing happens:



i assume this is because those ips are local.


finding the k8s node that is running my k8s pod with my container and trying to curl that node's public ip address




and same thing: no response.


everything is fine if i run the container locally docker run k8s-search.

i have no idea what to do here. how do i query the image that deployment.yaml sets up inside a kubernetes node?
",<docker><kubernetes><kubectl><kops>,60096453,5,"to access the pod from outside the cluster you need to create either nodeport or loadbalancer type service.

kubectl expose deployment vuekcal --type=nodeport --name=example-service


then access it via curl http://&lt;public-node-ip&gt;:&lt;node-port&gt;



!make sure you ran the kubectl expose command above!

public node ip

to get the public node ip, run the following command:

kubectl get nodes -o wide


and look at the ""external-ip"" column. this is the public ip of the node that is running your container. this is where you should try to connect. for example, the extrenal ip of your node could be 133.71.33.7. remember this ip.

nodeport

it's different than the containerport in your deployment.yaml.
to find the nodeport, run this command:

kubectl describe service example-service


replace example-service with whatever you wrote in --name= when running kubectl expose deployment ... (first command in this post)

after you run the command, you'll see something like this:


this is the port you should use when connecting.

putting it together

133.73.133.7:31110
"
70659738,what are the good practices in handling kubectl context in scripts?,"my bash scripts with kubectl sometimes cause trouble when it changes context. after running the script user may accidentally end up make changes in wrong cluster. i would like to probe your wisdom when it comes to handling context in scripts.
is it possible for the script to save old context and when done revert the old context back? (i thought about running kubectl config get-contexts find current context and set it back after script completes. but this may fail if user haven't saved contexts)
other approach i am thinking is to save the value of kubeconfig env var, change it to a temp file, get credentials and restore the value when the script completes.
before i go and reinvent the wheel i like to here how the power users are handling situation like this? can you share your thoughts/ideas?
",<bash><kubernetes><kubectl>,70660001,6,"generally, i think it's problematic to depend implicitly on global state that may be arbitrarily updated by other processes and users.
even with multiple configuration files, there's still opacity as to which cluster, user, namespace, context are being used.
for a single user, kubectl's configuration file provides the convenience of not having to retype flags for every command and i think that should be it's sole purpose.
in scripts, i think it's preferable (clearer|self-documenting) to be explicit and to include either --context or --cluster, --user (and possibly --namespace) every time.
this said, it is also advisable to use variables rather than hard-coded values so there's still room for error.
kubectl delete deployment/primary-service

# vs

kubeconfig=sam-monday-morning-config.yaml \
kubectl delete deplopyment/primary-service

# vs

kubectl delete deployment/primary-service \
--cluster=test-cluster \
--namespace=test-namespace \
--user=test-user

"
53272951,when i create a gke cluster with a route through a nat i am unable to pull a docker image because of permission issues,"i can create a regular gke cluster and pull the docker image i need and get it running. when i create the gke cluster with a routing rule through a nat my user no longer has permission to pull the docker image.

i start the cluster with these settings:

resources:
######## network ############
- name: gke-nat-network
  type: compute.v1.network
   properties: 
    autocreatesubnetworks: false
######### subnets ##########
######### for cluster #########
- name: gke-cluster-subnet 
  type: compute.v1.subnetwork
   properties:
    network: $(ref.gke-nat-network.selflink)
     ipcidrrange: 172.16.0.0/12
     region: us-east1
 ########## nat subnet ##########
 - name: nat-subnet
  type: compute.v1.subnetwork
   properties: 
    network: $(ref.gke-nat-network.selflink)
    ipcidrrange: 10.1.1.0/24
    region: us-east1
########## nat vm ##########
- name: nat-vm
  type: compute.v1.instance 
   properties:
    zone: us-east1-b
    canipforward: true
    tags:
      items:
      - nat-to-internet
    machinetype: https://www.googleapis.com/compute/v1/projects/{{ 
env[""project""] }}/zones/us-east1-b/machinetypes/f1-micro
    disks:
      - devicename: boot
        type: persistent
        boot: true
        autodelete: true
        initializeparams:
          sourceimage: 
https://www.googleapis.com/compute/v1/projects/debian- 
cloud/global/images/debian-7-wheezy-v20150423
     networkinterfaces:
     - network: projects/{{ env[""project""] }}/global/networks/gke-nat- 
 network
      subnetwork: $(ref.nat-subnet.selflink)
       accessconfigs:
       - name: external nat
         type: one_to_one_nat
     metadata:
       items:
       - key: startup-script
        value: |
          #!/bin/sh
          # --
          # ---------------------------
          # install tcp dump
          # start nat; start dump
          # ---------------------------
          apt-get update
          apt-get install -y tcpdump
          apt-get install -y tcpick 
          iptables -t nat -a postrouting -o eth0 -j masquerade
          nohup tcpdump -e -l -i eth0 -w /tmp/nat.pcap &amp;
          nohup tcpdump -e -l -i eth0 &gt; /tmp/nat.txt &amp;
          echo 1 | tee /proc/sys/net/ipv4/ip_forward
 ########## firewall rules for nat vm ##########
 - name: nat-vm-firewall 
   type: compute.v1.firewall
   properties: 
    allowed:
    - ipprotocol : tcp
      ports: []
    sourcetags: 
    - route-through-nat
    network: $(ref.gke-nat-network.selflink)
 - name: nat-vm-ssh
  type: compute.v1.firewall
  properties: 
    allowed:
     - ipprotocol : tcp
       ports: [22]
     sourceranges: 
    - 0.0.0.0/0
    network: $(ref.gke-nat-network.selflink)
 ########## gke cluster creation ##########
 - name: nat-gke-cluster
   type: container.v1.cluster
   metadata: 
   dependson:
   - gke-nat-network 
   - gke-cluster-subnet
   properties: 
    cluster: 
      name: nat-gke-cluster 
      initialnodecount: 1
      network: gke-nat-network
      subnetwork: gke-cluster-subnet
      nodeconfig:
        machinetype: n1-standard-4
        tags:
        - route-through-nat
    zone: us-east1-b
########## gke master route ##########
- name: master-route
  type: compute.v1.route
  properties:
    destrange: $(ref.nat-gke-cluster.endpoint)
    network: $(ref.gke-nat-network.selflink)
    nexthopgateway: projects/{{ env[""project""] 
}}/global/gateways/default-internet-gateway
    priority: 100
    tags:
    - route-through-nat
########## nat route ##########
 - name: gke-cluster-route-through-nat
  metadata: 
    dependson:
    - nat-gke-cluster  
    - gke-nat-network
   type: compute.v1.route
   properties: 
    network: $(ref.gke-nat-network.selflink)
     destrange: 0.0.0.0/0
     description: ""route all other traffic through nat""
     nexthopinstance: $(ref.nat-vm.selflink)
    tags:
    - route-through-nat
    priority: 800


when i try to pull and start a docker image i get:


  imagepullbackoff error google kubernetes engine


when i do kubectl describe pod i get:


  failed to pull image : rpc error: code = unknown desc = unauthorized: authentication required


edit:

i have found out that the gcloud console command has changed since v1.10
https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes

basically certain roles are not allowed by default for these clusters which includes pulling an image from google storage.

i am still having trouble figuring out how assign these roles while using


  gcloud deployment-manager deployments create gke-with-nat --config gke-with-nat-route.yml

",<docker><kubernetes><google-cloud-platform><google-kubernetes-engine>,53396351,1,"so the reason the container images were not pulling is because gcloud clusters have changed how they handle permissions. it used to grant the 'storage-ro' role to new clusters allowing them to pull container images from the container registry. as per https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes .

i had to add scopes to the yml cluster deployment as i create my deployment using


  gcloud deployment-manager deployments create gke-with-nat --config gke-with-nat-route.yml


the new yml included these settings

nodeconfig:
    serviceaccount: thisuser@project-id.iam.gserviceaccount.com
    oauthscopes:
      - https://www.googleapis.com/auth/devstorage.read_only


if you are using cluster create i think you can use


  gcloud container clusters create example-cluster --scopes scope1,scope2


if you are using the website ui i think you can choose to use the legacy setting using a checkbox in the ui. i am not sure how long this will be supported.
"
66053921,traefik v2 in kubernetes. fail to deploy. do not see other services,"i have been trying to run traefik v2.x in minikube to check it and how it routes request to needed service. i am  failing to get access to my services at all. would be good to understand what i am doing wrong.

minikube is running in virtualbox vm
vm box has lab ip address to which i want to send url request
on my localhost i set hosts (mydomain.local and mydomain.com) to ip address of minikube vm


how to reproduce:

create 2 namespaces new-ns and new-who
set namespace to be default for ingress: kubectl config set-context --current --namespace=new-ns

all yaml files can be found in https://github.com/vencrena-lt/traefik

deploy customresourcedefinition
deploy clusterrole , clusterrolebinding and serviceaccount (to new-ns namespace)
deploy daemonset and service (to new-ns namespace)

then would like to deploy 2 apps: in both namespaces (for testing purposes)

deployment, service and ingressroute to new-ns namespace
deployment, service and ingressroute to new-new namespace

dashboard:

routes:

localpod:

some logs from traefik pod:
e0206 08:25:21.798628       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: failed to watch *v1alpha1.tlsstore: failed to list 
*v1alpha1.tlsstore: tlsstores.traefik.containo.us is forbidden: user &quot;system:serviceaccount:new-ns:traefik-ingress-controller&quot; cannot list resource &quot;tlsstores&quot; in api group &quot;traefik.containo.us&quot; at the cluster scope

e0206 08:25:34.653633       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: failed to watch *v1alpha1.serverstransport: failed to list
*v1alpha1.serverstransport: serverstransports.traefik.containo.us is forbidden: user &quot;system:serviceaccount:new-ns:traefik-ingress-controller&quot; cannot list resource &quot;serverstransports&quot; in api group &quot;traefik.containo.us&quot; at the cluster scope

e0206 08:26:02.857094       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: failed to watch *v1alpha1.ingressrouteudp: failed to list
*v1alpha1.ingressrouteudp: ingressrouteudps.traefik.containo.us is forbidden: user &quot;system:serviceaccount:new-ns:traefik-ingress-controller&quot; cannot list resource &quot;ingressrouteudps&quot; in api group &quot;traefik.containo.us&quot; at the cluster scope

any hints what i am doing wrong? why can not access mydomain.local and mydomain.com and see whoami services. why no routes are seen in traefik dashboard
",<kubernetes><kubernetes-ingress><traefik><minikube><traefik-ingress>,66087688,2,"your clusterrole definition is a bit too thin:
https://github.com/vencrena-lt/traefik/blob/main/2_roles.yml
you could try to follow the example here:
https://github.com/sleighzy/k3s-traefik-v2-kubernetes-crd
for the question why no routes are seen:
traefik will pickup from k8s routes when you specify
        - --providers.kubernetescrd
        - --providers.kubernetesingress

also please be aware of the namespace where traefik resides, you will apply ingressroutes on that namespace
"
52711167,kubernetes: readinessprobes failing but the livelinessprobe is succeeding with the same settings,"i have a livelinessprobe configured for my pod which does a http-get on path on the same pod and a particular port. it works perfectly. but, if i use the same settings and configure a readinessprobe it fails with the below error.


  readiness probe failed: wsarecv: read tcp :50578->:80: an existing connection was forcibly closed by the remote host


actually after certain point i even see the liveliness probes failing. not sure why . liveliness probe succeeding should indicate that the kube-dns is working fine and we're able to reach the pod from the node. here's the readinessprobe for my pod's spec

readinessprobe:  
        httpget:  
          path: /&lt;path&gt; # -&gt; this works for livelinessprobe  
          port: 80  
        initialdelayseconds: 30  
        periodseconds: 10  
        timeoutseconds: 10  


does anyone have an idea what might be going on here.
",<kubernetes><kubernetes-helm>,52711952,2,"i don't think it has anything to do with kube-dns or coredns. the most likely cause here is that your pod/container/application is crashing or stop serving requests. 

seems like this timeline:


pod/container comes up.
liveliness probe passes ok.
some time passes.
probably app crash or error.
readiness fails.
liveliness probe fails too.


more information about what that error means here: 
an existing connection was forcibly closed by the remote host
"
69739352,running skaffold fails if configured to work with helm,"i am trying to make skaffold work with helm.
below is my skaffold.yml file:
apiversion: skaffold/v2beta23
kind: config
metadata:
  name: test-app
build:
  artifacts:
  - image: test.common.repositories.cloud.int/manager/k8s
    docker:
      dockerfile: dockerfile
deploy:
  helm:
    releases:
    - name: my-release
      artifactoverrides:
        image: test.common.repositories.cloud.int/manager/k8s
      imagestrategy:
        helm: {}

here is my values.yaml:
image:
  repository: test.common.repositories.cloud.int/manager/k8s
  tag: 1.0.0

running the skaffold command results in:
...
starting deploy...
helm release my-release not installed. installing...
error: installation failed: failed to download &quot;&quot;
deploying &quot;my-release&quot;: install: exit status 1


does anyone have an idea, what is missing here?!
",<kubernetes><deployment><kubernetes-helm><skaffold><google-cloud-code>,69744946,1,"i believe this is happening because you have not specified a chart to use for the helm release. i was able to reproduce your issue by commenting out the chartpath field in the skaffold.yaml file of the helm-deployment example in the skaffold repo.
you can specify a local chart using the deploy.helm.release.chartpath field or a remote chart using the deploy.helm.release.remotechart field.
"
57863647,blue green deployment with helm charts,"we could deploy applications using 'helm charts' with

helm install --name the-release  helm/the-service-helm --namespace myns


and we cold 'rolling upgrade' the deployment using,

helm upgrade --recreate-pods the-release helm/the-service-helm --namespace myns


is there a way to use 'helm charts' to achieve 'blue/green' deployments?
",<kubernetes><kubernetes-helm><blue-green-deployment><canary-deployment>,57866025,21,"let's start from definitions
since there are many deployment strategies, let's start from the definition.
as per martin flower:

the blue-green deployment approach does this by ensuring you have two production environments, as identical as possible. at any time one of them, let's say blue for the example, is live. as you prepare a new release of your software you do your final stage of testing in the green environment. once the software is working in the green environment, you switch the router so that all incoming requests go to the green environment - the blue one is now idle.

blue/green is not recommended in helm. but there are workaround solutions

as per to helm issue #3518, it's not recommended to use helm for blue/green or canary deployment.

there are at least 3 solutions based on top of helm, see below

however there is a helm chart for that case.


helm itself (tl;dr: not recommended)
helm itself is not intended for the case. see their explanation:

direct support for blue / green deployment pattern in helm · issue #3518 · helm/helm


helm works more in the sense of a traditional package manager, upgrading charts from one version to the next in a graceful manner (thanks to pod liveness/readiness probes and deployment update strategies), much like how one expects something like apt upgrade to work. blue/green deployments are a very different beast compared to the package manager style of upgrade workflows; blue/green sits at a level higher in the toolchain because the use cases around these deployments require step-in/step-out policies, gradual traffic migrations and rollbacks. because of that, we decided that blue/green deployments are something out of scope for helm, though a tool that utilizes helm under the covers (or something parallel like istio) could more than likely be able to handle that use case.

other solutions based on helm
there are at least three solution based on top of helm, described and compared here:

shipper
istio
flagger.

shipper by booking.com - deprecated
bookingcom/shipper: kubernetes native multi-cluster canary or blue-green rollouts using helm

it does this by relying on helm, and using helm charts as the unit of configuration deployment. shipper's application object provides an interface for specifying values to a chart just like the helm command line tool.
shipper consumes charts directly from a chart repository like chartmuseum, and installs objects into clusters itself. this has the nice property that regular kubernetes authentication and rbac controls can be used to manage access to shipper apis.

kubernetes native multi-cluster canary or blue-green rollouts using helm
istio
you can try something like this:
kubectl create -f &lt;(istioctl kube-inject -f cowsay-v1.yaml) # deploy v1

kubectl create -f &lt;(istioctl kube-inject -f cowsay-v2.yaml) # deploy v1

flagger.
there is guide written by flagger team: blue/green deployments - flagger
this guide shows you how to automate blue/green deployments with flagger and kubernetes
you might try helm itself
also, as kamol hasan recommended, you can try that chart: puneetsaraswat/helmcharts/blue-green.
blue.yml sample
{{ if .values.blue.enabled }}
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: {{ template &quot;blue-green.fullname&quot; . }}-blue
  labels:
    release: {{ .release.name }}
    chart: {{ .chart.name }}-{{ .chart.version }}
    app: {{ template &quot;blue-green.name&quot; . }}
spec:
  replicas: {{ .values.replicacount }}
  template:
    metadata:
      labels:
        app: {{ template &quot;blue-green.name&quot; . }}
        release: {{ .release.name }}
        slot: blue
    spec:
      containers:
        - name: {{ template &quot;blue-green.name&quot; . }}-blue
          image: nginx:stable
          imagepullpolicy: ifnotpresent
          ports:
            - name: http
              containerport: 80
              protocol: tcp
          # this (and the volumes section below) mount the config map as a volume.
          volumemounts:
            - mountpath: /usr/share/nginx/html
              name: wwwdata-volume
      volumes:
        - name: wwwdata-volume
          configmap:
            name: {{ template &quot;blue-green.fullname&quot; . }}
{{ end }}

medium blog post: blue/green deployments using helm charts
"
56970876,kubectl describe returns 404 for ingresses,"i reinstalled my system today and since than i can not access my ingresses anymore with kubectl describe, get works fine and returns the expected ingresses.

kubectl describe ingresses
error from server (notfound): the server could not find the requested resource


this is the response i get if i run describe with -v 8

get host:443/apis/networking.k8s.io/v1beta1/namespaces/default/ingresses/ingress-rule
request headers:
    authorization: bearer token
    accept: application/json, */*
    user-agent: kubectl/v1.15.0 (linux/amd64) kubernetes/e8462b5
response status: 404 not found in 14 milliseconds
response headers:
    content-type: application/json
    content-length: 174
    date: wed, 10 jul 2019 12:30:05 gmt
response body: {""kind"":""status"",""apiversion"":""v1"",""metadata"":{},""status"":""failure"",""message"":""the server could not find the requested resource"",""reason"":""notfound"",""details"":{},""code"":404}


this is the kubectl version result

client version: version.info{major:""1"", minor:""15"", gitversion:""v1.15.0"", gitcommit:""e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529"", gittreestate:""clean"", builddate:""2019-06-19t16:40:16z"", goversion:""go1.12.5"", compiler:""gc"", platform:""linux/amd64""}
server version: version.info{major:""1"", minor:""12"", gitversion:""v1.12.7"", gitcommit:""6f482974b76db3f1e0f5d24605a9d1d38fad9a2b"", gittreestate:""clean"", builddate:""2019-03-25t02:41:57z"", goversion:""go1.10.8"", compiler:""gc"", platform:""linux/amd64""}

",<kubernetes><kubectl><kubernetes-ingress>,56971487,3,"you have problem with different version of kubectl client and server. you need to downgrade your kubectl client to the 1.12 

in k8s v.15 ingress is part of the group networking.k8s.io before it was in the ""extensions/v1beta1"" group


  ingress resources will no longer be served from extensions/v1beta1 in v1.19. migrate use to the networking.k8s.io/v1beta1 api, available since v1.14. existing persisted data can be retrieved via the networking.k8s.io/v1beta1 api.k8s changelog-1.15.md

"
57658593,what is the recommended alternative to kubectl '--generator' option?,"one of the points in the kubectl best practices section in kubernetes docs state below:


  pin to a specific generator version, such as kubectl run
  --generator=deployment/v1beta1


but then a little down in the doc, we get to learn that except for pod, the use of --generator option is deprecated and that it would be removed in future versions.

why is this being done? doesn't generator make life easier in creating a template file for resource definition of deployment, service, and other resources? what alternative is the kubernetes team suggesting? this isn't there in the docs :(
",<kubernetes><kubectl>,57665097,1,"kubectl create is the recommended alternative if you want to use more than just a pod (like deployment).

https://kubernetes.io/docs/reference/kubectl/conventions/#generators says:


  note: kubectl run --generator except for run-pod/v1 is deprecated in v1.12.


this pull request has the reason why generators (except run-pod/v1) were deprecated:


  the direction is that we want to move away from kubectl run because it's over bloated and complicated for both users and developers. we want to mimic docker run with kubectl run so that it only creates a pod, and if you're interested in other resources kubectl create is the intended replacement.

"
56570319,helm and kubectl context mismatch,"i'm having trouble understanding helm's use of helm --kube-context=microk8s install ... should install into the context microk8s thus into my local microk8s cluster rather than the remote gke cluster which i once connected to.

this however fails due to error: could not get kubernetes config for context ""microk8s"": context ""microk8s"" does not exist if i run e.g. helm --kube-context=microk8s install --name mereet-kafka after successfully running helm init and adding necessary repositories.

the context microk8s is present and enabled according to kubectl config current-context. i can even reproduce this by running helm --kube-context=$(kubectl config current-context) install --name mereet-kafka in order to avoid any typos.

why can't helm use obviously present contexts?
",<kubernetes><kubernetes-helm><kubectl><microk8s>,56580804,15,"this looks like a kubernetes configuration problem more than an issue with helm itself.

there are few things that might help:


check the config file in ~/.kube/config


kubectl config view



is current-context set to: microk8s?


try to use: 


kubectl config get-contexts
kubectl config set-context 
kubectl config use-context



with proper arguments --server --user --cluster


check if you are refering to the config from ~/.kube/config and not your own private config from somewhere else. 
check if you have a kubeconfig environment variable (echo $kubeconfig)


i hope it helps.
"
61157272,what role and rolebinding is kubectl associated to?,"i am trying to understand how kubectl gets permissions to run the commands. 
i understand that all interactions with kubernetes clusters go through the kube-apiserver. so when we run a kubectl command, say kubectl get pods from the master node, the request will go via kube-apiserver. 

the apiserver does the authentication and authorization and provide the results back. 
kubectl like any other user or resource should also be associated with a role and rolebinding to acquire the permissions for accessing the resources on the cluster. how can i check to which role and rolebinding is the kubectl associated to ?

apologies if this is a ridiculous question.
",<kubernetes><kubectl>,61170019,5,"this answer is an extension to the other ones and helps you with scripts when are using client certificates:

get user and group from current-context:

if you are using client certificates, your ~/.kube/config file contains client-certificate-data for the user of the current context. this data is a base64 encoded certificate which can be displayed in text form with openssel. the interesting information for your question is in the subject section. 

this script will print the subject line of the client certificate:

$ kubectl config view --raw -o json \
    | jq "".users[] | select(.name==\""$(kubectl config current-context)\"")"" \
    | jq -r '.user[""client-certificate-data""]' \
    | base64 -d | openssl x509 -text | grep ""subject:""


output on my mac when running kubernetes via docker for mac:

subject: o=system:masters, cn=docker-for-desktop

o is the organization and represents a group in kubernetes.

cn is the common name and is interpreted as user by kubernetes.

find corresponding clusterrole and clusterrolebinding:

now you know which user and group you are using with kubectl at the moment. 
to find out which (cluster)rolebinding you are using, you have to look for the identified group/user:

$ group=""system:masters""
$ kubectl get clusterrolebindings -o json \
    | jq "".items[] | select(.subjects[].name==\""$group\"")""


{
  ""apiversion"": ""rbac.authorization.k8s.io/v1"",
  ""kind"": ""clusterrolebinding"",
  ""metadata"": {
    ""annotations"": {
      ""rbac.authorization.kubernetes.io/autoupdate"": ""true""
    },
    ""creationtimestamp"": ""2020-03-31t14:12:13z"",
    ""labels"": {
      ""kubernetes.io/bootstrapping"": ""rbac-defaults""
    },
    ""name"": ""cluster-admin"",
    ""resourceversion"": ""95"",
    ""selflink"": ""/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin"",
    ""uid"": ""878fa48b-cf30-42e0-8e3c-0f27834dfeed""
  },
  ""roleref"": {
    ""apigroup"": ""rbac.authorization.k8s.io"",
    ""kind"": ""clusterrole"",
    ""name"": ""cluster-admin""
  },
  ""subjects"": [
    {
      ""apigroup"": ""rbac.authorization.k8s.io"",
      ""kind"": ""group"",
      ""name"": ""system:masters""
    }
  ]
}


you can see in the output that this group is associated with the clusterrole cluster-admin. you can take a closer look at this clusterrole to see the permissions in detail:

$ kubectl get clusterrole cluster-admin -o yaml


apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: ""true""
  creationtimestamp: ""2020-03-31t14:12:12z""
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
  resourceversion: ""42""
  selflink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin
  uid: 9201f311-4d07-46c3-af36-2bca9ede098f
rules:
- apigroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonresourceurls:
  - '*'
  verbs:
  - '*'

"
61739296,unable to build kubernetes objects from release manifest on install stable/rabbitmq-ha,"when trying to install &quot;rabbitmq-ha&quot; i have an error:
$ helm install rabbitmq stable/rabbitmq-ha
error: unable to build kubernetes objects from release manifest: unable to recognize &quot;&quot;: no matches for kind &quot;prometheusrule&quot; in version &quot;monitoring.coreos.com/v1&quot;

version of helm and kubernetes:

version of helm : &quot;v3.2.1&quot;
version of kubernetes : &quot;v1.17.5-0&quot;

",<kubernetes><rabbitmq><kubernetes-helm>,61809374,1,"i solved the problem by using this command to install rabbitmq:
helm install --set replicacount=2 \
               --set rabbitmqusername=yourusername \
               --set rabbitmqpassword=yourpassword \
               --set prometheus.operator.enabled=false \
               ha-rabbitmq stable/rabbitmq-ha

but i opened the issue on github for helm-chart and a contributor on the project  say:

confirming the bug too. this is caused by the following pr: #21274
(comment)
the regression was released in rabbitmq-ha chart version 1.44.2.
1.44.1 works ok.

"
62964532,helm not creating the resources,"i have tried to run helm for the first time. i am having deployment.yaml, service.yaml and ingress.yaml files alongwith values.yaml and chart.yaml.
deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: abc
  namespace: xyz
  labels:
    app: abc
    app.kubernetes.io/managed-by: {{ .release.service }}
spec:
  replicas: 3
  template:
    spec:
      containers:
        - name: abc
          image: {{ .values.image.repository }}:{{ .values.image.tag }}
          ports:
            -
              containerport: 8080

service.yaml
apiversion: v1
kind: service
metadata:
  name: abc
  labels:
    app.kubernetes.io/managed-by: {{ .release.service }}
  namespace: xyz
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: {{ .values.service.sslcert }}
spec:
  ports:
    - name: https
      protocol: tcp
      port: 443
      targetport: 8080
    - name: http
      protocol: tcp
      port: 80
      targetport: 8080
  type: clusterip
  selector:
    app: abc

ingress.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: &quot;haproxy-ingress&quot;
  namespace: xyz
  labels:
    app.kubernetes.io/managed-by: {{ .release.service }}
  annotations:
    kubernetes.io/ingress.class: alb

from what i can see i do not think i have missed putting app.kubernetes.io/managed-by but still, i keep getting an error:

rendered manifests contain a resource that already exists. unable to
continue with install: service &quot;abc&quot; in namespace &quot;xyz&quot; exists and
cannot be imported into the current release: invalid ownership
metadata; label validation error: missing key
&quot;app.kubernetes.io/managed-by&quot;: must be set to &quot;helm&quot;; annotation
validation error: missing key &quot;meta.helm.sh/release-name&quot;: must be set
to &quot;abc&quot;; annotation validation error: missing key
&quot;meta.helm.sh/release-namespace&quot;: must be set to &quot;default&quot;


it renders the file locally correctly.
helm list --all --all-namespaces returns nothing.
please help.
",<kubernetes><kubernetes-helm>,62964820,42,"you already have some resources, e.g. service abc in the given namespace, xyz that you're trying to install via a helm chart.
delete those and install them via helm install.
$ kubectl delete service -n &lt;namespace&gt; &lt;service-name&gt;
$ kubectl delete deployment -n &lt;namespace&gt; &lt;deployment-name&gt;
$ kubectl delete ingress -n &lt;namespace&gt; &lt;ingress-name&gt;

once you have these resources deployed via helm, you will be able to perform helm update to change properties.
remove the &quot;app.kubernetes.io/managed-by&quot; label from your yaml's, this will be added by helm.
"
49720308,"kubernetes podsecuritypolicy set to runasnonroot, container has runasnonroot and image has non-numeric user (appuser), cannot verify user is non-root","kubernetes podsecuritypolicy set to runasnonroot, pods are not getting started post that getting error error: container has runasnonroot and image has non-numeric user (appuser), cannot verify user is non-root
we are creating the user (appuser) uid -&gt; 999 and group (appgroup) gid -&gt; 999 in the docker container, and we are starting the container with that user.
but the pod creating is throwing error.
events:
  type     reason                 age                from                           message
  ----     ------                 ----               ----                           -------
  normal   scheduled              53s                default-scheduler              successfully assigned app-578576fdc6-nfvcz to appmagent01
  normal   successfulmountvolume  52s                kubelet, appagent01  mountvolume.setup succeeded for volume &quot;default-token-ksn46&quot;
  warning  dnsconfigforming       11s (x6 over 52s)  kubelet, appagent01  search line limits were exceeded, some search paths have been omitted, the applied search line is: app.svc.cluster.local svc.cluster.local cluster.local 
  normal   pulling                11s (x5 over 51s)  kubelet, appagent01  pulling image &quot;app.dockerrepo.internal.com:5000/app:9f51e3e7ab91bb835d3b85f40cc8e6f31cdc2982&quot;
  normal   pulled                 11s (x5 over 51s)  kubelet, appagent01  successfully pulled image &quot;app.dockerrepo.internal.com:5000/app:9f51e3e7ab91bb835d3b85f40cc8e6f31cdc2982&quot;
  warning  failed                 11s (x5 over 51s)  kubelet, appagent01  error: container has runasnonroot and image has non-numeric user (appuser), cannot verify user is non-root

",<kubernetes><kubernetes-security>,49729786,56,"here is the implementation of the verification:
case uid == nil &amp;&amp; len(username) &gt; 0:
    return fmt.errorf(&quot;container has runasnonroot and image has non-numeric user (%s), cannot verify user is non-root&quot;, username)

and here is the validation call with the comment:
// verify runasnonroot. non-root verification only supports numeric user.
if err := verifyrunasnonroot(pod, container, uid, username); err != nil {
    return nil, cleanupaction, err
}

as you can see, the only reason of that messages in your case is uid == nil. based on the comment in the source code, we need to set a numeric user value.
so, for the user with uid=999 you can do it in your pod definition like that:
securitycontext:
    runasuser: 999

"
76742300,pod is not getting mapped to service if deployed through yaml configuration,"i am trying to deploy the container using yaml.
the pod is getting created but service is not getting mapped to pod. what i am missing here?
be informed i am using trial subscription on google cloud and kubernetes-sdk on my machine.
deployment file
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: udemydocker1
  name: udemydocker
  namespace: default
spec:
  progressdeadlineseconds: 30
  replicas: 1
  selector:
    matchlabels:
      app: udemydocker1
  strategy:
    rollingupdate:
      maxsurge: 25%
      maxunavailable: 25%
    type: rollingupdate
  template:
    metadata:
      creationtimestamp: null
      labels:
        app: udemydocker1
    spec:
      containers:
      - image: lazyav/udemydocker:release.1.0.0
        imagepullpolicy: always
        name: udemydocker
      restartpolicy: always
      
---
apiversion: v1
kind: service
metadata:
  labels:
    app: udemydocker1
  name: udemydocker
  namespace: default
spec:
  ports:
  - port: 8080
    protocol: tcp
    targetport: 8080
  selector:
    app: udemydocker
  sessionaffinity: none
  type: loadbalancer


dashboard screen shot and command line commands


",<kubernetes><google-cloud-platform><google-kubernetes-engine>,76742412,1,"the above issue is due to selector app: udemydocker. the service was unable to find the pod.
changing it to app=udemydocker1 solves the problem
apiversion: v1
kind: service
metadata:
  labels:
    app: udemydocker1
  name: udemydocker
  namespace: default
spec:
  ports:
  - port: 8080
    protocol: tcp
    targetport: 8080
  selector:
    app: udemydocker1
  sessionaffinity: none
  type: loadbalancer

"
58620357,more default named port in kubernetes?,"in kubernetes, i always see the service's definition like this:

---
apiversion: v1
kind: service
metadata:
  name: random-exporter
  labels:
    app: random-exporter
spec:
  type: clusterip
  selector:
    app: random-exporter
  ports:
    - port: 9800
      targetport: http
      name: random-port


whose targetport is http, it's human friendly！ 

and what i'm interested is that is there more named port such as http in kubernetes? maybe https？
",<kubernetes><kubernetes-service>,58621691,3,"usually you refer to target port by its number. 
but you can give a specific name to each pod`s port 
and refer this name in your service specification. 

this will make your service clearer.
here you have example where you named your ports in pod. 

apiversion: v1
kind: pod
metadata:
  name: test
spec:
  containers:
  - name: test
    ports:
    - name: http
      containerport: 8080
    - name: https
      containerport: 8443 


and here you refer to those ports by name in the service yaml. 

apiversion: v1
kind: service
metadata:
  name: test-svc
spec:
  ports:
  - name: http
    port: 80
    targetport: http
  - name: https
    port: 443
    targetport: https 


also from the kubernetes documention you may find this information: 

targetport - number or name of the port to access on the pods targeted by the service. number must be in the range 1 to 65535. name must be an iana_svc_name. 
if this is a string, it will be looked up as a named port in the target pod's container ports. 
"
75161286,using kubernetes secret env var inside another env var,"i have a secret being used as env var in another env var as follows:
- name: &quot;pwd&quot;
  valuefrom:
    secretkeyref:
      name: &quot;credentials&quot;
      key: &quot;password&quot;
- name: host
  value: &quot;xyz.mongodb.net&quot;
- name: mongodb_uri 
  value: &quot;mongodb+srv://user:$(pwd)@$(host)/db_name?&quot;

when i exec into the container and run env command to see the values of env i see -
mongodb+srv://user:password123  
@xyz.mongodb.net/db_name?

the container logs show error as authentication failure.
is this something that is expected to work in kubernetes ? there docs talk about dependent env vars but do not give example using secrets. did not find clear explanation on this after extensive search. only found this one article doing something similar.
some points to note -

the secret is a sealed secret.
this is the final manifest's contents, but all this is templated using helm.
the value is being used inside a spring boot application

is the new line after 123 expected ?
if this evaluation of env from a secret in another env is possible then what am i doing wrong here ?
",<kubernetes><environment-variables><kubernetes-helm><kubernetes-secrets>,75198171,3,"the issue was with the command used to encode the secret - echo &quot;pasword&quot; | base64. the echo adds a newline character at the end of the string. using echo -n &quot;password&quot; | base64 fixed the secret.
closing the issue.
"
71505977,kubernetes stateful sets storage in aws ebm with helm,"i am deploying a stateful set with helm and the pods are complaining about volumes.
what is the proper way of doing this with aws ebs? considering the helm templates.
warning  failedscheduling  30s (x112 over 116m)  default-scheduler  0/9 nodes are available: 9 pod has unbound immediate persistentvolumeclaims.

deployment.yaml
volumeclaimtemplates:
  - metadata:
      name: {{ .values.storage.name }}
      labels:
        app: {{ template &quot;etcd.name&quot; . }}
        chart: {{ .chart.name }}-{{ .chart.version }}
        release: {{ .release.name }}
        heritage: {{ .release.service }}
    spec:
      storageclassname: {{ .values.storage.class | default .values.global.storage.class }}
      accessmodes:
        - {{ .values.storage.accessmode }}
      resources:
        requests:
          storage: {{ .values.storage.size }}

values.yaml
storage:
  name: etcd-data
  mountpath: /somepath/etcd
  class: &quot;default&quot;
  size: 1gi
  accessmode: readwriteonce

",<amazon-web-services><kubernetes><kubernetes-helm><amazon-eks>,71506269,1,"try change the class name to the default name on eks:
...
spec:
  storageclassname: {{ .values.storage.class | default &quot;gp2&quot; | quote }}
  accessmodes:
  - ...


storage:
  ...
  class: &quot;gp2&quot;
  ...

"
52745577,"if i have a public load balancer, how does direct service-to-service communication get load balanced?","                                  |--&gt; service1:8081 --&gt; pod1-a, pod1-b, pod1-c
   ui -&gt; load balancer -&gt; ingress (mydomain.com)
                                  |--&gt; service2:8082 --&gt; pod2-a, pod2-b, pod2-c


so from service1, i could call service2 directly with http://service2:8082, but since this is not being done through the ui -> load balancer, how does this get load balanced? should i not call service2 directly, and call it through mydomain.com/service2 instead so it would have to go through the flow?
",<kubernetes><kubernetes-ingress>,52746404,1,"if you are by-passing the ingress, meaning directly calling http://service2:8082 from service1, kubernetes would pick a random backend based on the default proxy-mode: iptables.

you can tweak this a bit more if you are using something like ipvs. for example, set up round robin.

you can also use the old proxy-mode: userspace if you'd like round robin only.

all these options are configurable using the -proxy-mode proxymode flag on the kube-proxy.
"
74498508,how to create kubernetes secret with multiple values for one key?,"this is how i'm trying to create a secret for my kubernetes mongodb, which gets deployed using the bitnami mongodb helm chart:
apiversion: v1
kind: secret
metadata:
  name: mongodb-secret
  namespace: mongodb
  labels:
    app.kubernetes.io/component: mongodb
type: opaque
data: 
  mongodb-root-password: 'encoded value'
  mongodb-passwords: '???'
  mongodb-metrics-password: 'encoded value'
  mongodb-replica-set-key: 'encoded value'

the helm chart values.yaml says:
auth:
  ## mongodb(&amp;reg;) custom users and databases
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mongodb#creating-a-user-and-database-on-first-run
  ## @param auth.usernames list of custom users to be created during the initialization
  ## @param auth.passwords list of passwords for the custom users set at `auth.usernames`
  ## @param auth.databases list of custom databases to be created during the initialization
  ##
  usernames: []
  passwords: []
  databases: []
  ## @param auth.existingsecret existing secret with mongodb(&amp;reg;) credentials (keys: `mongodb-passwords`, `mongodb-root-password`, `mongodb-metrics-password`, ` mongodb-replica-set-key`)
  ## note: when it's set the previous parameters are ignored.
  ##
  existingsecret: &quot;&quot;

so passwords is an array of strings for each username and each database.
how do i have to implement these multiple passwords in my secret?
the helm template should give me a hint, but i don't understand it: secret.yaml
or is it a simple string with all passwords separated by , and encoded?
",<mongodb><kubernetes><kubernetes-helm><kubernetes-secrets>,74505280,2,"should be something like:
auth:
  usernames: [&quot;bob&quot;, &quot;alice&quot;]
  passwords: [&quot;bobpass&quot;, &quot;alicepass&quot;]
  databases: [&quot;bobdb&quot;, &quot;alicedb&quot;]

if you want to pass those on the cli --set flag instead, you should be able to use curly braces as per this comment: https://github.com/helm/helm/issues/1987#issuecomment-280497496 - like:
--set auth.usernames={bob,alice},auth.passwords={bobpass,alicepass},auth.databases={bobdb,alicedb}

this would produce a secret like following - which you can check with helm template command:
---
# source: mongodb/templates/secrets.yaml
apiversion: v1
kind: secret
metadata:
  name: release-name-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.4.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/component: mongodb
type: opaque
data:
  mongodb-root-password: &quot;uk1tzthhyznfzg==&quot;
  mongodb-passwords: &quot;ym9icgfzcyxhbgljzxbhc3m=&quot;
---

you can decode mongodb-passwords, using:
echo -n ym9icgfzcyxhbgljzxbhc3m= | base64 -d

and notice that it looks as following: bobpass,alicepass
also note that there seems to be an option to have mongodb.createsecret flag set to false and creating that secret manually (which may be more secure depending on the exact workflow).
"
57492145,error when creating a mongodb replicaset - shows unrecognized option '--smallfiles',"i am creating the below mongodb statefulset which creates 3 replicas but when i run the code i get the below error and all pods are in crashloopbackoff state.

this is the error which i get when i try kubectl create -f 

error parsing command line: unrecognised option '--smallfiles' 


apiversion: apps/v1beta1
kind: statefulset
metadata:
 name: mongo
 namespace: microservice1
spec:
 servicename: ""mongo""
 replicas: 3
 template:
   metadata:
     labels:
       role: mongo
       environment: test
   spec:
     terminationgraceperiodseconds: 10
     containers:
       - name: mongo
         image: mongo
         command:
           - mongod
           - ""--replset""
           - rs0
           - ""--smallfiles""
           - ""--noprealloc""
         ports:
           - containerport: 27017
         volumemounts:
           - name: mongo-persistent-storage
             mountpath: /data/db
       - name: mongo-sidecar
         image: cvallance/mongo-k8s-sidecar
         env:
           - name: mongo_sidecar_pod_labels
             value: ""role=mongo,environment=test""
     volumes:
      - name: mongo-persistent-storage
        flexvolume:
          driver: rook.io/rook
          fstype: ceph
          options:
            fsname: myfs # name of the filesystem specified in the filesystem crd.
            clusternamespace: rook # namespace where the rook cluster is deployed
            clustername: rook


",<mongodb><kubernetes><kubernetes-statefulset>,57492633,16,"--smallfiles is not supported in newest mongo (4.2) you can check it in doc, you are not specifying image tag so newest latest is pull in this case mongo 4.2. 

if you set image: mongo:4.0 your configuration should be correct.
"
47568030,how to expose 2 port in one deployement and service,"i want to expose 2 ports on one service:

apiversion: apps/v1beta1
kind: deployment
metadata:
  name: etools
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: etools
    spec:
      containers:
      - name: etools
        image: eregistry.azurecr.io/etools:latest
        ports:
        - containerport: 8080
        - containerport: 3100
---
apiversion: v1
kind: service
metadata:
  name: etools
spec:
  ports:
  - port: 8080
  selector:
    app: etools
  ports:
  - port: 3100
  selector:
    app: etools


how can i achieve it?
",<kubernetes><kubectl>,47568401,1,"your service is very close, but in the ports: array, the ports need to be named if there is more than one (they ideally would always have names), and the selector: is just once per service, not per-port:

spec:
  selector:
    app: etools
  ports:
  - name: web
    port: 8080
    targetport: 8080
  - name: other-port-something
    port: 3100
    targetport: 3100


be aware that while you will often see port: and targetport: equal to the same number, they don't have to be. so your container could listen on 8080, because docker image says it will, but your service could expose that to other members of your cluster as port: 80 to be closer to what one would expect.

it's also possible to name the ports in your podspec with natural language names, and then point the service at that value:

ports:
- name: http
  port: 80
  targetport: http-in-my-pod


which i recommend because it decouples your service from having to change just because the containerport changed in your podspec, but at your discretion.

i'm a little surprised that kubectl didn't offer helpful feedback when you provided it that malformed yaml, but either way, i believe the snippet above is correct. as the docs specify, the names must be both unique within the service, and also ""dns-compatible"" names, so no underscores, spaces, crazy characters
"
53950918,unable to get a websocket app work through kubernetes ingress-nginx in a non-root context path,"here is a sample websocket app that i'm trying to get it to work from a kubernetes ingress-nginx controller.

kubernetes yaml:

echo ""
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: ws-example
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: wseg
    spec:
      containers:
      - name: websocketexample
        image: nicksardo/websocketexample
        imagepullpolicy: always
        ports:
        - name: http
          containerport: 8080
        env:
        - name: podname
          valuefrom:
            fieldref:
              fieldpath: metadata.name
---
apiversion: v1
kind: service
metadata:
  name: ws-example-svc
  labels:
    app: wseg
spec:
  type: nodeport
  ports:
  - port: 80
    targetport: 8080
    protocol: tcp
  selector:
    app: wseg
---

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ws-example-svc
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: myhostname.com
    http:
      paths:
      - backend:
          servicename: ws-example-svc
          serviceport: 80
        path: /somecontext

"" | kubectl create -f -


i get this error:

websocket connection to 'ws://myhostname.com/somecontext/ws?encoding=text' failed: error during websocket handshake: unexpected response code: 400


when i try to connect using a websocket client web page like this http://www.websocket.org/echo.html

the version of ingress-nginx is 0.14.0.  this version supports websockets.



update, i'm able to directly access the websocket running pod, when i port-forward from my localhost to pod's port.

[rpalaniappan@sdgl15280a331:~/git/zalenium] $ kubectl get pods -l app=wseg
name                          ready     status    restarts   age
ws-example-5dddb98cfb-vmdt5   1/1       running   0          5h
[rpalaniappan@sdgl15280a331:~/git/zalenium] $ kubectl port-forward ws-example-5dddb98cfb-vmdt5 8080:8080
forwarding from 127.0.0.1:8080 -&gt; 8080
forwarding from [::1]:8080 -&gt; 8080
handling connection for 8080




[rpalaniappan@sdgl15280a331:~/git/zalenium] $ wscat -c ws://localhost:8080/ws
connected (press ctrl+c to quit)
&lt; connected to ws-example-5dddb98cfb-vmdt5
&gt; hi
&lt; hi
&lt; ws-example-5dddb98cfb-vmdt5 reports time: 2018-12-28 01:19:00.788098266 +0000 utc

",<nginx><websocket><kubernetes><kubernetes-ingress><nginx-ingress>,53962137,3,"https://kubernetes.github.io/ingress-nginx/user-guide/miscellaneous/#websockets


  if the nginx ingress controller is exposed with a service
  type=loadbalancer make sure the protocol between the loadbalancer and
  nginx is tcp.


sample aws l4 service https://github.com/kubernetes/ingress-nginx/blob/master/deploy/provider/aws/service-l4.yaml#l11

# enable proxy protocol
service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: ""*""

"
64289478,minikube: are there any ways for driver=none to use ingress,"i am using minikube on my laptop with &quot;driver=none&quot; option. when i try to enable ingress, i got the following error:
$ minikube addons enable ingress

❌  exiting due to mk_usage: due to networking limitations of driver none, ingress addon is not supported. try using a different driver.

after some googling, i found that ingress addon stopped to work with 'none' vm driver starting from minikube v1.12.x, and i am using v1.13.1. (please refer to: https://github.com/kubernetes/minikube/issues/9322)
i wonder whether there are other ways to install &quot;native&quot; ingress on minikube with the &quot;driver=none&quot; option?
",<kubernetes><kubernetes-ingress><minikube>,64315071,3,"this is a community wiki answer. feel free to expand it.
unfortunately, as you already found out, this addon is not supported with with vm-driver=none.
if you use the none driver, some kubernetes components run as privileged containers that have side effects outside of the minikube environment. those side effects mean that the none driver is not recommended for personal workstations.
also, according to the official docs:

most users of this driver should consider the newer docker
driver, as it is significantly easier to configure and does not
require root access. the ‘none’ driver is recommended for advanced
users only.

so basically you have two options here:

downgrade to minikube v1.11 (not recommended)

use a supported driver (strongly recommended)


remember that these changes are made for a reason and going against them is usually a bad idea. it would be better to follow the official recommendation.
"
55873614,how to deploy multiple pods with same a helm chart?,"i want to deploy multiple ml models in different pods within the same namespace. but whenever i pull a new image from aws ecr and deploy it using helm it terminates the current running pod and makes a new one. so i am unable to deploy multiple models. every time it kills the previous one and makes a new pod.

helm upgrade --install tf-serving ./charts/tf-serving/ --namespace mlhub


or 

helm upgrade --recreate-pods --install tf-serving ./charts/tf-serving/ --namespace mlhub



tf-serving-8559fb87d-2twwl        1/1     running       0          37s  
tf-serving-8559fb87d-m6hgs        0/1     terminating   0          45s



it kills the previous one and makes a new, but the images of both models are different with different tags also.
",<kubernetes><kubernetes-helm>,55878132,20,"you can use one helm chart to create multiple releases. for example to deploy first model:
helm install ./charts/tf-serving/ --name tf-serving --namespace mlhub

and if you later want to add another one:
helm install ./charts/tf-serving/ --name tf-serving2 --namespace mlhub

now when you run helm list you will be able to see both tf-serving and tf-serving2.
be aware that you can not have multiple kubernetes resources of the same kind with the same name, so i would recommend using {{ .release.name }} value in your chart, as a prefix for all deployed resources.
edit:
since helm v3, --name flag does not exist anymore. instead, you can run: helm install  tf-serving ./charts/tf-serving/ --namespace mlhub.
credit to pieber
"
72557676,kubernetes service account to access aws s3 for different users in the container,"i have an eks deployment with a service account with policy and role that enable access to s3.
this works well for root account in the container. the container can execute aws s3 cp ... with no issue.
the problem is that another user cannot. it gets accessdenied from the s3 service, meaning it does not have the correct credentials.
so my question is: how to give rights to another user in the container (which is linux based) in this case?
(i don't think it's specific to eks as service accounts are generic to kubernetes.)
",<amazon-web-services><kubernetes><amazon-s3><amazon-eks><k8s-serviceaccount>,72557805,1,"you can check out the reference for how iam roles for service accounts work in k8s here.
in short, in order to allow another user to use the iam role the same environment variables have to be configured for that user, and it needs to be able to access the path specified in the aws_web_identity_token_file variable.
once both of these prerequisites are met, the user should be able to use the same identity as the root user.
"
64019915,how do i pass multiple arguments to a shell script into `kubectl exec`?,"consider the following shell script, where pod is set to the name of a k8 pod.
kubectl exec -it $pod -c messenger -- bash -c &quot;echo '$@'&quot;

when i run this script with one argument, it works fine.
hq6:bot hqin$ ./test.sh  x
x

when i run it with two arguments, it blows up.
hq6:bot hqin$ ./test.sh  x y
y': -c: line 0: unexpected eof while looking for matching `''
y': -c: line 1: syntax error: unexpected end of file

i suspect that something is wrong with how the arguments are passed.
how might i fix this so that arguments are expanded literally by my shell and then passed in as literals to the bash running in kubectl exec?
note that removing the single quotes results in an output of x only.
note also that i need the bash -c so i can eventually pass in file redirection: https://stackoverflow.com/a/49189635/391161.
",<bash><kubernetes><kubectl><positional-parameter>,64020445,1,"you're going to want something like this:
kubectl exec pod -c container -- sh -c 'echo &quot;$@&quot;' -- &quot;$@&quot;

with this syntax, the command we're running inside the container is echo &quot;$@&quot;. we then take the local value of &quot;$@&quot; and pass that as parameters to the remote shell, thus setting $@ in the remote shell.
on my local system:
bash-5.0$ ./test.sh hello
hello
bash-5.0$ ./test.sh hello world
hello world

"
54466647,how can i use kubectl --server-dry-run to output the final response body of an apply?,"kubectl supports --server-dry-run so that modifications are not persisted but changes from admission controllers etc. are applied. the default output looks something like the following:

$ kubectl apply --server-dry-run -f deployment.yaml
deployment.apps/nginx-deployment created (server dry run)


however, adding -v=8 shows me the response body with the actual json content that will be persisted to etcd. is there any way to ask kubectl to print that in a nicer format without some crazy grepping etc.?
",<kubernetes><kubectl>,54471923,1,"you can get the appropriate json by using following command:

kubectl apply --server-dry-run - f deployment.yaml -o json

"
69022858,"tearing down a gke cluster to ""brand new"" state without deleting it?","i am playing with kubernetes really for the first time, and have a brand new (empty) gke cluster up on gcp.
i am going to play around with yaml kustomize files and try to get a few services deployed there, but what i'm really looking for is a command (or set of kubectl/gcloud commands) to restore the gke cluster to a totally &quot;new&quot; slate. this is because it's probably going to take several dozen (or more!) attempts at configuring and tweaking my yaml files until i get the configs and behavior down just right, and each time i mess up i want to start over with a completely &quot;clean&quot;/new gke cluster. for reasons outside the scope of this question, deleting and recreating the gke cluster really isn't a viable option.
my kustomize files and deploment scripts will create kubernetes operators, namespaces, persistent volumes (and claims), various services and all sorts of other resources. but i need to be able to drop/delete them all and bring the cluster back to the brand new state.
is this possible, and if so, whats the process/command(s) involved? fwiw i have cluster admin permissions.
",<kubernetes><google-kubernetes-engine>,69047383,1,"as mentioned by @dany l, kubernetes namespace will be the perfect option for deleting the resources. create a custom namespace by using the command
kubectl create namespace custom-name 

and deploy all the resources(deployment,replicaset,services etc.,) into the namespace.
to work with namespace, you need to add --namespace flag to k8s commands.
for example:
kubectl create -f deployment.yaml --namespace=custom-namespace

if you want to delete all of these resources, you just need to delete the custom namespace. by deleting the custom namespace, all the other resources would be deleted. without it, replicaset might create new pods when existing pods are deleted. run the following command for deleting the namespace.
kubectl delete namespace custom-name

to list down all the resources associated to a specific namespace, you can run the following command
kubectl api-resources --verbs=list --namespaced -o name  | xargs -n 1 kubectl get --show-kind --ignore-not-found -n &lt;namespace&gt;

the kubectl api-resources enumerates the resource types available in your cluster. so we can use it by combining it with kubectl get to list every instance of every resource type in a kubernetes namespace.
refer to this link to list all the resources in a namespace.
"
53987459,websockets on gke with istio gives 'no healthy upstream' and 'crashloopbackoff',"i am on gke using istio version 1.0.3 . i try to get my express.js with socket.io (and uws engine) backend working with websockets and had this backend running before on a 'non kubernetes server' with websockets without problems. 

when i simply enter the external_gke_ip as url i get my backend html page, so http works. but when my client-app makes socketio authentication calls from my client-app i get 503 errors in the browser console:

websocket connection to 'ws://external_gke_ip/socket.io/?eio=3&amp;transport=websocket' failed: error during websocket handshake: unexpected response code: 503


and when i enter the external_gke_ip as url while socket calls are made i get: no healthy upstream in the browser. and the pod gives: crashloopbackoff.

i find somewhere: 'in node.js land, socket.io typically does a few non-websocket handshakes to the server before eventually upgrading to websockets. if you don't have sticky-sessions, the upgrade never works.' so maybe i need sticky sessions? or not... as i just have one replica of my app? it seems to be done by setting sessionaffinity: clientip, but with istio i do not know how to do this and in the gui i can edit some values of the loadbalancers, but session affinity shows 'none' and i can not edit it.

other settings that might be relevant and that i am not sure of (how to set using istio) are:


externaltrafficpolicy=local 
ttl


my manifest config file:

apiversion: v1
kind: service
metadata:
  name: myapp
  labels:
    app: myapp
spec:
  selector:
    app: myapp
  ports:
  - port: 8089
    targetport: 8089
    protocol: tcp
    name: http
---
apiversion: apps/v1
kind: deployment
metadata:
  name: myapp
  labels:
    app: myapp
spec:
  selector:
    matchlabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: app
          image: gcr.io/myproject/firstapp:v1
          imagepullpolicy: always
          ports:
          - containerport: 8089
          env:
          - name: postgres_db_host
            value: 127.0.0.1:5432
          - name: postgres_db_user
            valuefrom:
              secretkeyref:
                name: mysecret
                key: username
          - name: postgres_db_password
            valuefrom:
              secretkeyref:
                name: mysecret
                key: password
          readinessprobe:
            httpget:
              path: /healthz
              scheme: http
              port: 8089
            initialdelayseconds: 10
            timeoutseconds: 5
        - name: cloudsql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:1.11
          command: [""/cloud_sql_proxy"",
                    ""-instances=myproject:europe-west4:osm=tcp:5432"",
                    ""-credential_file=/secrets/cloudsql/credentials.json""]
          securitycontext:
            runasuser: 2
            allowprivilegeescalation: false
          volumemounts:
            - name: cloudsql-instance-credentials
              mountpath: /secrets/cloudsql
              readonly: true
      volumes:
        - name: cloudsql-instance-credentials
          secret:
            secretname: cloudsql-instance-credentials
---
apiversion: networking.istio.io/v1alpha3
kind: gateway
metadata:
  name: myapp-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
      - ""*""
---
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: myapp
spec:
  hosts:
  - ""*""
  gateways:
  - myapp-gateway
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: myapp
      weight: 100
    websocketupgrade: true
---
apiversion: networking.istio.io/v1alpha3
kind: serviceentry
metadata:
  name: google-apis
spec:
  hosts:
    - ""*.googleapis.com""
  ports:
    - number: 443
      name: https
      protocol: https
  location: mesh_external
---
apiversion: networking.istio.io/v1alpha3
kind: serviceentry
metadata:
  name: cloud-sql-instance
spec:
  hosts:
  - 35.204.xxx.xx # ip of cloudsql database
  ports:
  - name: tcp
    number: 3307
    protocol: tcp
  location: mesh_external


various output (while making socket calls, when i stop these the deployment restarts and ready returns to 3/3):

kubectl get pods
name                    ready   status             restarts   age
myapp-8888  2/3     crashloopbackoff   11         1h


$ kubectl describe pod/myapp-8888 gives:

name:           myapp-8888
namespace:      default
node:           gke-standard-cluster-1-default-pool-888888-9vtk/10.164.0.36
start time:     sat, 19 jan 2019 14:33:11 +0100
labels:         app=myapp
  pod-template-hash=207157
annotations:
kubernetes.io/limit-ranger:
limitranger plugin set: cpu request for container app; cpu request for container cloudsql-proxy
sidecar.istio.io/status:
{""version"":""3c9617ff82c9962a58890e4fa987c69ca62487fda71c23f3a2aad1d7bb46c748"",""initcontainers"":[""istio-init""],""containers"":[""istio-proxy""]...
status:         running
ip:             10.44.0.5
controlled by:  replicaset/myapp-64c59c94dc
init containers:
  istio-init:
    container id:  docker://a417695f99509707d0f4bfa45d7d491501228031996b603c22aaf398551d1e45
    image:         gcr.io/gke-release/istio/proxy_init:1.0.2-gke.0
    image id:      docker-pullable://gcr.io/gke-release/istio/proxy_init@sha256:e30d47d2f269347a973523d0c5d7540dbf7f87d24aca2737ebc09dbe5be53134
    port:          &lt;none&gt;
    host port:     &lt;none&gt;
    args:
      -p
      15001
      -u
      1337
      -m
      redirect
      -i
      *
      -x

      -b
      8089,
  -d

state:          terminated
  reason:       completed
  exit code:    0
  started:      sat, 19 jan 2019 14:33:19 +0100
finished:     sat, 19 jan 2019 14:33:19 +0100
ready:          true
  restart count:  0
  environment:    &lt;none&gt;
  mounts:         &lt;none&gt;
containers:
  app:
    container id:   docker://888888888888888888888888
    image:          gcr.io/myproject/firstapp:v1
    image id:       docker-pullable://gcr.io/myproject/firstapp@sha256:8888888888888888888888888
    port:           8089/tcp
    host port:      0/tcp
    state:          terminated
      reason:       completed
      exit code:    0
      started:      sat, 19 jan 2019 14:40:14 +0100
finished:     sat, 19 jan 2019 14:40:37 +0100
last state:     terminated
  reason:       completed
  exit code:    0
  started:      sat, 19 jan 2019 14:39:28 +0100
finished:     sat, 19 jan 2019 14:39:46 +0100
ready:          false
  restart count:  3
  requests:
    cpu:      100m
  readiness:  http-get http://:8089/healthz delay=10s timeout=5s period=10s #success=1 #failure=3
  environment:
    postgres_db_host:      127.0.0.1:5432
    postgres_db_user:      &lt;set to the key 'username' in secret 'mysecret'&gt;  optional: false
    postgres_db_password:  &lt;set to the key 'password' in secret 'mysecret'&gt;  optional: false
  mounts:
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-rclsf (ro)
  cloudsql-proxy:
    container id:  docker://788888888888888888888888888
    image:         gcr.io/cloudsql-docker/gce-proxy:1.11
    image id:      docker-pullable://gcr.io/cloudsql-docker/gce-proxy@sha256:5c690349ad8041e8b21eaa63cb078cf13188568e0bfac3b5a914da3483079e2b
    port:          &lt;none&gt;
    host port:     &lt;none&gt;
    command:
      /cloud_sql_proxy
      -instances=myproject:europe-west4:osm=tcp:5432
      -credential_file=/secrets/cloudsql/credentials.json
    state:          running
      started:      sat, 19 jan 2019 14:33:40 +0100
ready:          true
  restart count:  0
  requests:
    cpu:        100m
  environment:  &lt;none&gt;
  mounts:
    /secrets/cloudsql from cloudsql-instance-credentials (ro)
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-rclsf (ro)
  istio-proxy:
    container id:  docker://f3873d0f69afde23e85d6d6f85b1f
    image:         gcr.io/gke-release/istio/proxyv2:1.0.2-gke.0
    image id:      docker-pullable://gcr.io/gke-release/istio/proxyv2@sha256:826ef4469e4f1d4cabd0dc846
    port:          &lt;none&gt;
    host port:     &lt;none&gt;
    args:
      proxy
      sidecar
      --configpath
      /etc/istio/proxy
      --binarypath
      /usr/local/bin/envoy
      --servicecluster
      myapp
      --drainduration
      45s
      --parentshutdownduration
      1m0s
      --discoveryaddress
      istio-pilot.istio-system:15007
      --discoveryrefreshdelay
      1s
      --zipkinaddress
      zipkin.istio-system:9411
      --connecttimeout
      10s
      --statsdudpaddress
      istio-statsd-prom-bridge.istio-system:9125
      --proxyadminport
      15000
      --controlplaneauthpolicy
      none
    state:          running
      started:      sat, 19 jan 2019 14:33:54 +0100
ready:          true
  restart count:  0
  requests:
    cpu:  10m
  environment:
    pod_name:                      myapp-64c59c94dc-8888 (v1:metadata.name)
    pod_namespace:                 default (v1:metadata.namespace)
    instance_ip:                    (v1:status.podip)
    istio_meta_pod_name:           myapp-64c59c94dc-8888 (v1:metadata.name)
    istio_meta_interception_mode:  redirect
  mounts:
    /etc/certs/ from istio-certs (ro)
    /etc/istio/proxy from istio-envoy (rw)
conditions:
  type           status
  initialized    true
  ready          false
  podscheduled   true
volumes:
  cloudsql-instance-credentials:
    type:        secret (a volume populated by a secret)
    secretname:  cloudsql-instance-credentials
    optional:    false
  default-token-rclsf:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-rclsf
    optional:    false
  istio-envoy:
    type:    emptydir (a temporary directory that shares a pod's lifetime)
    medium:  memory
  istio-certs:
    type:        secret (a volume populated by a secret)
    secretname:  istio.default
    optional:    true
qos class:       burstable
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
  node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason                 age                   from                                                        message
  ----     ------                 ----                  ----                                                        -------
  normal   scheduled              7m31s                 default-scheduler                                           successfully assigned myapp-64c59c94dc-tdb9c to gke-standard-cluster-1-default-pool-65b9e650-9vtk
  normal   successfulmountvolume  7m31s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  mountvolume.setup succeeded for volume ""istio-envoy""
  normal   successfulmountvolume  7m31s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  mountvolume.setup succeeded for volume ""cloudsql-instance-credentials""
  normal   successfulmountvolume  7m31s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  mountvolume.setup succeeded for volume ""default-token-rclsf""
  normal   successfulmountvolume  7m31s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  mountvolume.setup succeeded for volume ""istio-certs""
  normal   pulling                7m30s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  pulling image ""gcr.io/gke-release/istio/proxy_init:1.0.2-gke.0""
  normal   pulled                 7m25s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  successfully pulled image ""gcr.io/gke-release/istio/proxy_init:1.0.2-gke.0""
  normal   created                7m24s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  created container
  normal   started                7m23s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  started container
  normal   pulling                7m4s                  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  pulling image ""gcr.io/cloudsql-docker/gce-proxy:1.11""
  normal   pulled                 7m3s                  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  successfully pulled image ""gcr.io/cloudsql-docker/gce-proxy:1.11""
  normal   started                7m2s                  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  started container
  normal   pulling                7m2s                  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  pulling image ""gcr.io/gke-release/istio/proxyv2:1.0.2-gke.0""
  normal   created                7m2s                  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  created container
  normal   pulled                 6m54s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  successfully pulled image ""gcr.io/gke-release/istio/proxyv2:1.0.2-gke.0""
  normal   created                6m51s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  created container
  normal   started                6m48s                 kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  started container
  normal   pulling                111s (x2 over 7m22s)  kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  pulling image ""gcr.io/myproject/firstapp:v3""
  normal   created                110s (x2 over 7m4s)   kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  created container
  normal   started                110s (x2 over 7m4s)   kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  started container
  normal   pulled                 110s (x2 over 7m7s)   kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  successfully pulled image ""gcr.io/myproject/firstapp:v3""
  warning  unhealthy              99s                   kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  readiness probe failed: http probe failed with statuscode: 503
  warning  backoff                85s                   kubelet, gke-standard-cluster-1-default-pool-65b9e650-9vtk  back-off restarting failed container


and:

$ kubectl logs myapp-8888 myapp

&gt; api_server@0.0.0 start /usr/src/app
&gt; node src/

info: feathers application started on http://localhost:8089


and the database logs (which looks ok, as some 'startup script entries' from app can be retrieved using psql):

    $ kubectl logs myapp-8888 cloudsql-proxy
  2019/01/19 13:33:40 using credential file for authentication; email=proxy-user@myproject.iam.gserviceaccount.com
    2019/01/19 13:33:40 listening on 127.0.0.1:5432 for myproject:europe-west4:osm
    2019/01/19 13:33:40 ready for new connections
    2019/01/19 13:33:54 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:33:55 couldn't connect to ""myproject:europe-west4:osm"": post https://www.googleapis.com/sql/v1beta4/projects/myproject/instances/osm/createephemeral?alt=json: oauth2: cannot fetch token: post https://oauth2.googleapis.com/token: dial tcp 74.125.143.95:443: getsockopt: connection refused
    2019/01/19 13:39:06 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:39:06 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:39:06 client closed local connection on 127.0.0.1:5432
    2019/01/19 13:39:13 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:39:14 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:39:14 new connection for ""myproject:europe-west4:osm""
    2019/01/19 13:39:14 new connection for ""myproject:europe-west4:osm""


edit:
here is the serverside log of the 503 of websocket calls to my app:

{
  insertid:  ""465nu9g3xcn5hf""
    jsonpayload: {
      apiclaims:  """"
        apikey:  """"
        clienttraceid:  """"
        connection_security_policy:  ""unknown""
        destinationapp:  ""myapp""
        destinationip:  ""10.44.xx.xx""
        destinationname:  ""myapp-888888-88888""
        destinationnamespace:  ""default""
        destinationowner:  ""kubernetes://apis/extensions/v1beta1/namespaces/default/deployments/myapp""
        destinationprincipal:  """"
        destinationservicehost:  ""myapp.default.svc.cluster.local""
        destinationworkload:  ""myapp""
        httpauthority:  ""35.204.xxx.xxx""
        instance:  ""accesslog.logentry.istio-system""
        latency:  ""1.508885ms""
        level:  ""info""
        method:  ""get""
        protocol:  ""http""
        receivedbytes:  787
        referer:  """"
        reporter:  ""source""
        requestid:  ""bb31d922-8f5d-946b-95c9-83e4c022d955""
        requestsize:  0
        requestedservername:  """"
        responsecode:  503
        responsesize:  57
        responsetimestamp:  ""2019-01-18t20:53:03.966513z""
        sentbytes:  164
        sourceapp:  ""istio-ingressgateway""
        sourceip:  ""10.44.x.x""
        sourcename:  ""istio-ingressgateway-8888888-88888""
        sourcenamespace:  ""istio-system""
        sourceowner:  ""kubernetes://apis/extensions/v1beta1/namespaces/istio-system/deployments/istio-ingressgateway""
        sourceprincipal:  """"
        sourceworkload:  ""istio-ingressgateway""
        url:  ""/socket.io/?eio=3&amp;transport=websocket""
        useragent:  ""mozilla/5.0 (iphone; cpu iphone os 10_3_1 like mac os x) applewebkit/603.1.30 (khtml, like gecko) version/10.0 mobile/14e304 safari/602.1""
        xforwardedfor:  ""10.44.x.x""
    }
    logname:  ""projects/myproject/logs/stdout""
    metadata: {
      systemlabels: {
        container_image:  ""gcr.io/gke-release/istio/mixer:1.0.2-gke.0""
          container_image_id:  ""docker-pullable://gcr.io/gke-release/istio/mixer@sha256:888888888888888888888888888888""
          name:  ""mixer""
          node_name:  ""gke-standard-cluster-1-default-pool-88888888888-8887""
          provider_instance_id:  ""888888888888""
          provider_resource_type:  ""gce_instance""
          provider_zone:  ""europe-west4-a""
          service_name: [
            0:  ""istio-telemetry""
          ]
          top_level_controller_name:  ""istio-telemetry""
          top_level_controller_type:  ""deployment""
      }
        userlabels: {
          app:  ""telemetry""
            istio:  ""mixer""
            istio-mixer-type:  ""telemetry""
            pod-template-hash:  ""88888888888""
        }
    }
    receivetimestamp:  ""2019-01-18t20:53:08.135805255z""
    resource: {
      labels: {
        cluster_name:  ""standard-cluster-1""
          container_name:  ""mixer""
          location:  ""europe-west4-a""
          namespace_name:  ""istio-system""
          pod_name:  ""istio-telemetry-8888888-8888888""
          project_id:  ""myproject""
      }
        type:  ""k8s_container""
    }
    severity:  ""info""
    timestamp:  ""2019-01-18t20:53:03.965100z""
}


in the browser at first it properly seems to switch protocol but then causes a repeated 503 response and subsequent health issues cause a repeating restart. the protocol switch websocket call:

general:

request url: ws://localhost:8080/sockjs-node/842/s4888/websocket
request method: get
status code: 101 switching protocols [green]


response headers:

connection: upgrade
sec-websocket-accept: ns8888888888888888888
upgrade: websocket


request headers:

accept-encoding: gzip, deflate, br
accept-language: nl-nl,nl;q=0.9,en-us;q=0.8,en;q=0.7
cache-control: no-cache
connection: upgrade
cookie: _ga=ga1.1.1118102238.18888888; hblid=nsnq2ms8888888888888; olfsk=ol8888888888
host: localhost:8080
origin: http://localhost:8080
pragma: no-cache
sec-websocket-extensions: permessage-deflate; client_max_window_bits
sec-websocket-key: b8zkvaxleyshasckd4auiw==
sec-websocket-version: 13
upgrade: websocket
user-agent: mozilla/5.0 (iphone; cpu iphone os 10_3_1 like mac os x) applewebkit/603.1.30 (khtml, like gecko) version/10.0 mobile/14e304 safari/602.1


its frames:


following the above i get multiple of these:

chrome output regarding websocket call:

general:

request url: ws://35.204.210.134/socket.io/?eio=3&amp;transport=websocket
request method: get
status code: 503 service unavailable


response headers:

connection: close
content-length: 19
content-type: text/plain
date: sat, 19 jan 2019 14:06:39 gmt
server: envoy


request headers:

accept-encoding: gzip, deflate
accept-language: nl-nl,nl;q=0.9,en-us;q=0.8,en;q=0.7
cache-control: no-cache
connection: upgrade
host: 35.204.210.134
origin: http://localhost:8080
pragma: no-cache
sec-websocket-extensions: permessage-deflate; client_max_window_bits
sec-websocket-key: vtks5xkf+gz4u3ugih2fig==
sec-websocket-version: 13
upgrade: websocket
user-agent: mozilla/5.0 (iphone; cpu iphone os 10_3_1 like mac os x) applewebkit/603.1.30 (khtml, like gecko) version/10.0 mobile/14e304 safari/602.1


the frames:

data: (opcode -1)
length: 63
time: 15:06:44.412

",<socket.io><kubernetes><google-cloud-platform><google-kubernetes-engine><uwebsockets>,54303000,3,"using uws (uwebsockets) as websocket engine causes these errors. when i swap in my backend app this code:

app.configure(socketio({
  wsengine: 'uws',
  timeout: 120000,
  reconnect: true
}))


for this:

app.configure(socketio())


everything works as expected. 

edit: now it also works with uws. i used alpine docker container which is based on node 10, which does not work with uws. after switching to container based on node 8 it works.
"
63167757,gcp - logging k8s: error while sending request to stackdriver googleapi: error 400: one or more timeseries could not be written,"i've recently added the logging for my gke instances on the gcp instances. nowadays the following error occurs three times a second and therefore a massive amount of errors will be generated. unfortunately all important errors will be lost, cause of the massive amount of errors in the logs. the following json is one of these errors:
{
  &quot;insertid&quot;: &quot;42&quot;,
  &quot;jsonpayload&quot;: {
    &quot;pid&quot;: &quot;1&quot;,
    &quot;source&quot;: &quot;stackdriver.go:60&quot;,
    &quot;message&quot;: &quot;error while sending request to stackdriver googleapi: error 400: one or more timeseries could not be written: unknown metric:
kubernetes.io/internal/addons/workload_identity/go_gc_duration_seconds_count: timeseries[31]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_gc_duration_seconds_sum: timeseries[4]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_goroutines: timeseries[0]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_info: timeseries[47]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_alloc_bytes: timeseries[55]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_alloc_bytes_total: timeseries[40]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_buck_hash_sys_bytes: timeseries[13]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_frees_total: timeseries[2]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_gc_cpu_fraction: timeseries[56]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_gc_sys_bytes: timeseries[19]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_alloc_bytes: timeseries[46]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_idle_bytes: timeseries[32]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_inuse_bytes: timeseries[42]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_objects: timeseries[1]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_released_bytes: timeseries[8]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_heap_sys_bytes: timeseries[43]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_last_gc_time_seconds: timeseries[33]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_lookups_total: timeseries[34]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_mallocs_total: timeseries[3]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_mcache_inuse_bytes: timeseries[18]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_mcache_sys_bytes: timeseries[11]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_mspan_inuse_bytes: timeseries[38]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_mspan_sys_bytes: timeseries[23]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_next_gc_bytes: timeseries[10]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_other_sys_bytes: timeseries[16]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_stack_inuse_bytes: timeseries[17]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_stack_sys_bytes: timeseries[12]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_memstats_sys_bytes: timeseries[21]; unknown metric: kubernetes.io/internal/addons/workload_identity/go_threads: timeseries[41]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_cpu_seconds_total: timeseries[20]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_max_fds: timeseries[22]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_open_fds: timeseries[9]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_resident_memory_bytes: timeseries[39]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_start_time_seconds: timeseries[45]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_virtual_memory_bytes: timeseries[30]; unknown metric: kubernetes.io/internal/addons/workload_identity/process_virtual_memory_max_bytes: timeseries[44]; unknown metric: kubernetes.io/internal/addons/workload_identity/promhttp_metric_handler_requests_in_flight: timeseries[7]; unknown metric: kubernetes.io/internal/addons/workload_identity/promhttp_metric_handler_requests_total: timeseries[35-37]; value type for metric kubernetes.io/internal/addons/workload_identity/metadata_server_build_info must be double, but is int64.: timeseries[48], badrequest&quot;
  },
  &quot;resource&quot;: {
    &quot;type&quot;: &quot;k8s_container&quot;,
    &quot;labels&quot;: {
      &quot;cluster_name&quot;: &quot;cluster-a&quot;,
      &quot;location&quot;: &quot;europe-west3&quot;,
      &quot;pod_name&quot;: &quot;prometheus-to-sd-jcmwn&quot;,
      &quot;project_id&quot;: &quot;my-nice-project-id&quot;,
      &quot;container_name&quot;: &quot;prometheus-to-sd-new-model&quot;,
      &quot;namespace_name&quot;: &quot;kube-system&quot;
    }
  },
  &quot;timestamp&quot;: &quot;2020-07-30t06:26:01.784963z&quot;,
  &quot;severity&quot;: &quot;error&quot;,
  &quot;labels&quot;: {
    &quot;k8s-pod/pod-template-generation&quot;: &quot;1&quot;,
    &quot;k8s-pod/controller-revision-hash&quot;: &quot;7984bf4f95&quot;,
    &quot;k8s-pod/k8s-app&quot;: &quot;prometheus-to-sd&quot;
  },
  &quot;logname&quot;: &quot;projects/my-nice-project-id/logs/stderr&quot;,
  &quot;sourcelocation&quot;: {
    &quot;file&quot;: &quot;stackdriver.go&quot;,
    &quot;line&quot;: &quot;60&quot;
  },
  &quot;receivetimestamp&quot;: &quot;2020-07-30t06:26:03.411798926z&quot;
}

what is the problem of this behaviour and how i can fix it?
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,63206876,1,"it looks like a bug in gke clusters with the workload identity feature enabled.
the bug reproduced for me in 1.14.10-gke.42 with workload identity, but works as expected with gke cluster deployed with version 1.15.12-gke.2.
there is an open issue in github. if you can't upgrade your cluster version, i suggest you to contact google cloud support and ask them for their recommended mitigation (although they probably will instruct you to upgrade your cluster version as well).
"
73174987,production setting for keycloak 18 from bitnami helm chart on kubernetes,"i'm trying to run keycloak 18.0.1 as a statefulset with the bitnami helm chart on my azure aks kubernetes cluster. traefik 2.7 is the ingress controller and an external postgres database is used. keycloak is in &quot;proxy&quot;-mode &quot;edge&quot; and doesn't need to handle ssl, because it's handled by traefik, cert-manager &amp; let's encrypt.
i'm trying to switch it to production mode:
2022-07-29 22:43:21,460 info  [io.quarkus] (main) installed features: [agroal, cdi, hibernate-orm, jdbc-h2, jdbc-mariadb, jdbc-mssql, jdbc-mysql, jdbc-oracle, jdbc-postgresql, keycloak, narayana-jta, reactive-routes, resteasy, resteasy-jackson, smallrye-context-propagation, smallrye-health, smallrye-metrics, vault, vertx]
2022-07-29 22:43:21,466 warn  [org.keycloak.quarkus.runtime.keycloakmain] (main) running the server in development mode. do not use this configuration in production.

therefore i tried using the following values during helm chart installation:

cache:
  enabled: true

auth:
  adminuser: ****
  adminpassword: ****
  managementuser: ****
  managementpassword: ****

proxy: edge

postgresql:
  enabled: false

externaldatabase:
  host: ****
  port: 5432
  user: ****
  password: ****
  database: keycloak

resources:
  requests:
    cpu: 0.5
    memory: 512mi
  limits:
    cpu: 1
    memory: 1gi

extraenvvars:
  - name: keycloak_production
    value: &quot;true&quot;
  - name: kc_hostname
    value: &quot;&lt;external host name&gt;&quot;
  - name: kc_hostname_strict_https
    value: &quot;false&quot;

as soon as i add the env vars for production, i'm getting the following error:
at org.h2.jdbcx.jdbcdatasource.getxaconnection(jdbcdatasource.java:352)
 at io.agroal.pool.connectionfactory.createconnection(connectionfactory.java:216)
 at io.agroal.pool.connectionpool$createconnectiontask.call(connectionpool.java:513)
 at io.agroal.pool.connectionpool$createconnectiontask.call(connectionpool.java:494)
 at java.base/java.util.concurrent.futuretask.run(futuretask.java:264)
 at io.agroal.pool.util.priorityscheduledexecutor.beforeexecute(priorityscheduledexecutor.java:75)
 at java.base/java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1126)
 at java.base/java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:628)
 at java.base/java.lang.thread.run(thread.java:829)
2022-07-29 18:27:20,885 warn  [io.agroal.pool] (agroal-11) datasource '&lt;default&gt;': no suitable driver found for jdbc:postgresql://***********:5432/keycloak?currentschema=public

it seems that the chart wants to go back to the integrated h2 database?
the second problem is the infinispan cache:
[org.infinispan.config] (keycloak-cache-init) ispn000569: unable to persist infinispan internal caches as no global state enabled
how can i enable this cache to make the chart work with multiple replicas?
any help is appreciated!
thanks,
pascal
",<kubernetes><keycloak><kubernetes-helm>,73183975,1,"found the solution to enable production mode:
  - name: keycloak_extra_args
    value: &quot;--auto-build&quot;

the error:
[org.infinispan.config] (keycloak-cache-init) ispn000569: unable to persist infinispan internal caches as no global state enabled

however still remains.
"
60130992,airflow scheduler fails to start with kubernetes executor,"i am using using  https://github.com/helm/charts/tree/master/stable/airflow helm chart and building  v1.10.8 puckle/docker-airflow image with kubernetes installed on it and using that image in the helm chart,
but i keep getting

  file ""/usr/local/bin/airflow"", line 37, in &lt;module&gt;
    args.func(args)
  file ""/usr/local/lib/python3.7/site-packages/airflow/bin/cli.py"", line 1140, in initdb
    db.initdb(settings.rbac)
  file ""/usr/local/lib/python3.7/site-packages/airflow/utils/db.py"", line 332, in initdb
    dagbag = models.dagbag()
  file ""/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py"", line 95, in __init__
    executor = get_default_executor()
  file ""/usr/local/lib/python3.7/site-packages/airflow/executors/__init__.py"", line 48, in get_default_executor
    default_executor = _get_executor(executor_name)
  file ""/usr/local/lib/python3.7/site-packages/airflow/executors/__init__.py"", line 87, in _get_executor
    return kubernetesexecutor()
  file ""/usr/local/lib/python3.7/site-packages/airflow/contrib/executors/kubernetes_executor.py"", line 702, in __init__
    self.kube_config = kubeconfig()
  file ""/usr/local/lib/python3.7/site-packages/airflow/contrib/executors/kubernetes_executor.py"", line 283, in __init__
    self.kube_client_request_args = json.loads(kube_client_request_args)
  file ""/usr/local/lib/python3.7/json/__init__.py"", line 348, in loads
    return _default_decoder.decode(s)
  file ""/usr/local/lib/python3.7/json/decoder.py"", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  file ""/usr/local/lib/python3.7/json/decoder.py"", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.jsondecodeerror: expecting property name enclosed in double quotes: line 1 column 2 (char 1)


in my scheduler,  also as various sources advise,
i tried setting :

airflow__kubernetes__kube_client_request_args: {""_request_timeout"" : [60,60] }

in my helm values. that also didn't work any one have any ideas what am i missing?

here's my values.yaml


airflow:
  image:
     repository: airflow-docker-local
     tag: 1.10.8
  executor: kubernetes
  service:
    type: loadbalancer
  config:
    airflow__kubernetes__worker_container_repository: airflow-docker-local
    airflow__kubernetes__worker_container_tag: 1.10.8
    airflow__kubernetes__worker_container_image_pull_policy: never

    airflow__kubernetes__worker_service_account_name: airflow
    airflow__kubernetes__dags_volume_claim: airflow
    airflow__kubernetes__namespace: airflow
    airflow__kubernetes__kube_client_request_args: {""_request_timeout"" : [60,60] }

    airflow__core__sql_alchemy_conn: postgresql+psycopg2://postgres:airflow@airflow-postgresql:5432/airflow

persistence:
  enabled: true
  existingclaim: ''

workers:
  enabled: false

postgresql:
  enabled: true

redis:
  enabled: false


edit : 

various attempts to set environment variable in helm values.yaml didn't work, after that i added (pay attention to double and single quotes)

env airflow__kubernetes__kube_client_request_args='{""_request_timeout"" : [60,60] }'


to dockerfile here : https://github.com/puckel/docker-airflow/blob/1.10.9/dockerfile#l19
after that my airflow-scheduler pod starts but then i keep getting following error on my scheduler pod.

process kubernetesjobwatcher-9: traceback (most recent call last): 
    file ""/usr/local/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py"", line 313, 
    in recv_into return self.connection.recv_into(*args, **kwargs) file ""/usr/local/lib/python3.7/site-packages/openssl/ssl.py"", 
    line 1840, in recv_into self._raise_ssl_error(self._ssl, result) file ""/usr/local/lib/python3.7/site-packages/openssl/ssl.py"", 
    line 1646, in _raise_ssl_error raise wantreaderror() openssl.ssl.wantreaderror

",<kubernetes><airflow><kubernetes-helm><airflow-scheduler>,60429089,4,"for the helm value, the template uses a loop that places the airflow.config map into double quotes "". this means any "" in a value needs to be escaped for the output templated yaml to be valid.

airflow:
  config:
    airflow__kubernetes__kube_client_request_args: '{\""_request_timeout\"":60}'


that deploys and runs (but i haven't completed an end to end test)

according to this github issue, the python scheduler ssl timeout may not be a problem as the watcher starts again after the 60 second connection timeout.
"
54482596,access denied when pulling private registry image using helm with gitlab runner helm chart and ci job,"i have a kubernetes cluster with 1 master and 2 workers. all nodes have their ip address. let's call them like this:


master-0
worker-0
worker-1


the network pod policy and all my nodes communication are setting up correctly, all works perfectly. if i specify this infrastructure, it's just to be more specific about my case.

using helm i have created a chart which deploy a basic nginx. it's a docker image that i build on my private gitlab registry.

with the gitlab ci, i have created a job which used two functions:

# init helm client on k8s cluster for using helm with gitlab runner
function init_helm() {
  docker login -u ""$ci_registry_user"" -p ""$ci_registry_password"" ""$ci_registry""
  mkdir -p /etc/deploy
  echo ${kube_config} | base64 -d &gt; ${kubeconfig}
  kubectl config use-context ${k8s_current_context}
  helm init --client-only
  helm repo add stable https://kubernetes-charts.storage.googleapis.com/
  helm repo add incubator https://kubernetes-charts-incubator.storage.googleapis.com/
  helm repo update
}

# deploy latest tagged image on k8s cluster
function deploy_k8s_cluster() {
  echo ""create and apply secret for docker gitlab runner access to gitlab private registry ...""
  kubectl create secret -n ""$kubernetes_namespace_overwrite"" \
    docker-registry gitlab-registry \
    --docker-server=""https://registry.gitlab.com/v2/"" \
    --docker-username=""${ci_deploy_user:-$ci_registry_user}"" \
    --docker-password=""${ci_deploy_password:-$ci_registry_password}"" \
    --docker-email=""$gitlab_user_email"" \
    -o yaml --dry-run | kubectl replace -n ""$kubernetes_namespace_overwrite"" --force -f -
  echo ""build helm dependancies in $chart_template""
  cd $chart_template/
  helm dep build
  export deploys=""$(helm ls | grep $project_name | wc -l)""
  if [[ ${deploys}  -eq 0 ]]; then
    echo ""creating the new chart ...""
    helm install --name ${project_name} --namespace=${kubernetes_namespace_overwrite} . -f values.yaml
  else
  echo ""updating the chart ...""
    helm upgrade ${project_name} --namespace=${kubernetes_namespace_overwrite} . -f values.yaml
  fi
} 


the first function allow the gitlabrunner to login with docker, init helm and kubectl. the second to deploy on the cluster my image.

all the process works well, e-g my jobs are passed on the gitlab ci, no error occurred except for the deployment of the pod.

indeed i have this error:

failed to pull image ""registry.gitlab.com/path/to/repo/project/image:tag_number"": rpc error: code
= unknown desc = error response from daemon: get https://registry.gitlab.com/v2/path/to/repo/project/image/manifests/image:tag_number: denied: access forbidden


to be more specific, i am using gitlab-runner helm chart and this the config of the chart:

## gitlab runner image
##
## by default it's using gitlab/gitlab-runner:alpine-v{version}
## where {version} is taken from chart.yaml from appversion field
##
## ref: https://hub.docker.com/r/gitlab/gitlab-runner/tags/
##
# image: gitlab/gitlab-runner:alpine-v11.6.0

## specify a imagepullpolicy
## 'always' if imagetag is 'latest', else set to 'ifnotpresent'
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
##
imagepullpolicy: ifnotpresent

## the gitlab server url (with protocol) that want to register the runner against
## ref: https://docs.gitlab.com/runner/commands/readme.html#gitlab-runner-register
##
gitlaburl: https://gitlab.com/

## the registration token for adding new runners to the gitlab server. this must
## be retrieved from your gitlab instance.
## ref: https://docs.gitlab.com/ce/ci/runners/readme.html#creating-and-registering-a-runner
##
runnerregistrationtoken: ""&lt;token&gt;""

## the runner token for adding new runners to the gitlab server. this must
## be retrieved from your gitlab instance. it is token of already registered runner.
## ref: (we don't yet have docs for that, but we want to use existing token)
##
# runnertoken: """"
#
## unregister all runners before termination
##
## updating the runner's chart version or configuration will cause the runner container
## to be terminated and created again. this may cause your gitlab instance to reference
## non-existant runners. un-registering the runner before termination mitigates this issue.
## ref: https://docs.gitlab.com/runner/commands/readme.html#gitlab-runner-unregister
##
unregisterrunners: true

## set the certssecretname in order to pass custom certficates for gitlab runner to use
## provide resource name for a kubernetes secret object in the same namespace,
## this is used to populate the /etc/gitlab-runner/certs directory
## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates
##
# certssecretname:

## configure the maximum number of concurrent jobs
## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section
##
concurrent: 10

## defines in seconds how often to check gitlab for a new builds
## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section
##
checkinterval: 30

## configure gitlab runner's logging level. available values are: debug, info, warn, error, fatal, panic
## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section
##
# loglevel:

## for rbac support:
rbac:
  create: true

  ## run the gitlab-bastion container with the ability to deploy/manage containers of jobs
  ## cluster-wide or only within namespace
  clusterwideaccess: true

  ## use the following kubernetes service account name if rbac is disabled in this helm chart (see rbac.create)
  ##
  serviceaccountname: default

## configure integrated prometheus metrics exporter
## ref: https://docs.gitlab.com/runner/monitoring/#configuration-of-the-metrics-http-server
metrics:
  enabled: true

## configuration for the pods that that the runner launches for each new job
##
runners:
  ## default container image to use for builds when none is specified
  ##
  image: ubuntu:16.04

  ## specify one or more imagepullsecrets
  ##
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  imagepullsecrets: [""namespace-1"", ""namespace-2"", ""default""]

  ## specify the image pull policy: never, if-not-present, always. the cluster default will be used if not set.
  ##
  # imagepullpolicy: """"

  ## specify whether the runner should be locked to a specific project: true, false. defaults to true.
  ##
  # locked: true

  ## specify the tags associated with the runner. comma-separated list of tags.
  ##
  ## ref: https://docs.gitlab.com/ce/ci/runners/#using-tags
  ##
  tags: my-tag-1, my-tag-2""

  ## run all containers with the privileged flag enabled
  ## this will allow the docker:dind image to run if you need to run docker
  ## commands. please read the docs before turning this on:
  ## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind
  ##
  privileged: true

  ## the name of the secret containing runner-token and runner-registration-token
  # secret: gitlab-runner

  ## namespace to run kubernetes jobs in (defaults to the same namespace of this release)
  ##
  # namespace:

  # regular expression to validate the contents of the namespace overwrite environment variable (documented following).
  # when empty, it disables the namespace overwrite feature
  namespace_overwrite_allowed: overrided-namespace-*

  ## distributed runners caching
  ## ref: https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/configuration/autoscale.md#distributed-runners-caching
  ##
  ## if you want to use s3 based distributing caching:
  ## first of all you need to uncomment general settings and s3 settings sections.
  ##
  ## create a secret 's3access' containing 'accesskey' &amp; 'secretkey'
  ## ref: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/
  ##
  ## $ kubectl create secret generic s3access \
  ##   --from-literal=accesskey=""youraccesskey"" \
  ##   --from-literal=secretkey=""yoursecretkey""
  ## ref: https://kubernetes.io/docs/concepts/configuration/secret/
  ##
  ## if you want to use gcs based distributing caching:
  ## first of all you need to uncomment general settings and gcs settings sections.
  ##
  ## access using credentials file:
  ## create a secret 'google-application-credentials' containing your application credentials file.
  ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section
  ## you could configure
  ## $ kubectl create secret generic google-application-credentials \
  ##   --from-file=gcs-applicaton-credentials-file=./path-to-your-google-application-credentials-file.json
  ## ref: https://kubernetes.io/docs/concepts/configuration/secret/
  ##
  ## access using access-id and private-key:
  ## create a secret 'gcsaccess' containing 'gcs-access-id' &amp; 'gcs-private-key'.
  ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section
  ## you could configure
  ## $ kubectl create secret generic gcsaccess \
  ##   --from-literal=gcs-access-id=""youraccessid"" \
  ##   --from-literal=gcs-private-key=""yourprivatekey""
  ## ref: https://kubernetes.io/docs/concepts/configuration/secret/
  cache: {}
    ## general settings
    # cachetype: s3
    # cachepath: ""cache""
    # cacheshared: true

    ## s3 settings
    # s3serveraddress: s3.amazonaws.com
    # s3bucketname:
    # s3bucketlocation:
    # s3cacheinsecure: false
    # secretname: s3access

    ## gcs settings
    # gcsbucketname:
    ## use this line for access using access-id and private-key
    # secretname: gcsaccess
    ## use this line for access using google-application-credentials file
    # secretname: google-application-credential

  ## build container specific configuration
  ##
  builds:
    # cpulimit: 200m
    # memorylimit: 256mi
    cpurequests: 100m
    memoryrequests: 128mi

  ## service container specific configuration
  ##
  services:
    # cpulimit: 200m
    # memorylimit: 256mi
    cpurequests: 100m
    memoryrequests: 128mi

  ## helper container specific configuration
  ##
  helpers:
    # cpulimit: 200m
    # memorylimit: 256mi
    cpurequests: 100m
    memoryrequests: 128mi
    image: gitlab/gitlab-runner-helper:x86_64-latest

  ## service account to be used for runners
  ##
  # serviceaccountname:

  ## if gitlab is not reachable through $ci_server_url
  ##
  # cloneurl:

  ## specify node labels for ci job pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  ##
  nodeselector: {}
    # gitlab: true

## configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  # limits:
  #   memory: 256mi
  #   cpu: 200m
  requests:
    memory: 128mi
    cpu: 100m

## affinity for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## node labels for pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeselector: {}
  # example: the gitlab runner manager should not run on spot instances so you can assign
  # them to the regular worker nodes only.
  # node-role.kubernetes.io/worker: ""true""

## list of node taints to tolerate (requires kubernetes &gt;= 1.6)
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []
  # example: regular worker nodes may have a taint, thus you need to tolerate the taint
  # when you assign the gitlab runner manager with nodeselector or affinity to the nodes.
  # - key: ""node-role.kubernetes.io/worker""
  #   operator: ""exists""

## configure environment variables that will be present when the registration command runs
## this provides further control over the registration process and the config.toml file
## ref: `gitlab-runner register --help`
## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html
##
envvars:
  - name: runner_executor
    value: kubernetes


as you can see, i created a secret on my ci job, no error occurred here too. in my chart, i declare this same secret (by his name) in values.yaml file, which allow deployment.yaml to use it.

so i do not understand where i am wrong. why i get this error ?
",<kubernetes><gitlab-ci><gitlab-ci-runner><kubernetes-helm>,54668066,1,"extending my last comment, i suppose that tag_number variable is somewhere in your ci gitlab job. however, you are not able to be authorized with the assigned variables in --docker-username and --docker-password docker flags. have you checked the credentials used for the connection to docker-registry? or it might be the option to manage secret within a gitlab runner helm chart template.
"
62371926,how to add a loadbalancer to a cluster on digitalocean,"i created a cluster on digitalocean using kubeadm and 3 droplets. since this is not a managed kubernetes cluster from digital ocean, how do i manually setup a loadbalancer ?

i've tried adding an external load balancer by adding the following lines to a deployment config file

...
replicacount: 1

image:
  repository: turfff/node-replicas
  tag: latest
  pullpolicy: ifnotpresent
...
service:
  type: loadbalancer
  port: 80
  targetport: 8080
...


however, when i run the configuration and check for created svc

kubectl get svc

name                              type           cluster-ip      external-ip   port(s)        age
kubernetes                        clusterip      10.96.0.1       &lt;none&gt;        443/tcp        13d
mongo-mongodb-replicaset          clusterip      none            &lt;none&gt;        27017/tcp      3h15m
mongo-mongodb-replicaset-client   clusterip      none            &lt;none&gt;        27017/tcp      3h15m
nodejs-nodeapp                    loadbalancer   10.109.213.98   &lt;pending&gt;     80:31769/tcp   61m

kubectl describe svc nodejs-nodeapp

name:                     nodejs-nodeapp
namespace:                default
labels:                   app.kubernetes.io/instance=nodejs
                          app.kubernetes.io/managed-by=tiller
                          app.kubernetes.io/name=nodeapp
                          app.kubernetes.io/version=1.0
                          helm.sh/chart=nodeapp-0.1.0
annotations:              &lt;none&gt;
selector:                 app.kubernetes.io/instance=nodejs,app.kubernetes.io/name=nodeapp
type:                     loadbalancer
ip:                       10.109.213.98
port:                     http  80/tcp
targetport:               http/tcp
nodeport:                 http  31769/tcp
endpoints:                10.244.2.19:8080
session affinity:         none
external traffic policy:  cluster
events:                   &lt;none&gt;

kubectl get pods

name                              ready   status    restarts   age
mongo-mongodb-replicaset-0        1/1     running   0          3h18m
mongo-mongodb-replicaset-1        1/1     running   0          3h17m
mongo-mongodb-replicaset-2        1/1     running   0          3h16m
nodejs-nodeapp-7b89db8888-sjcbq   1/1     running   0          65m

kubectl describe pod nodejs-nodeapp

name:               nodejs-nodeapp-7b89db8888-sjcbq
namespace:          default
priority:           0
priorityclassname:  &lt;none&gt;
node:               worker-02/206.81.3.65
start time:         sun, 14 jun 2020 11:21:07 +0100
labels:             app.kubernetes.io/instance=nodejs
                    app.kubernetes.io/name=nodeapp
                    pod-template-hash=7b89db8888
annotations:        &lt;none&gt;
status:             running
ip:                 10.244.2.19
controlled by:      replicaset/nodejs-nodeapp-7b89db8888
containers:
  nodeapp:
    container id:   docker://f0d4d01f....
    image:          turfff/node-replicas:latest
    image id:       docker-pullable://turfff/node-replicas@sha256:34d...
    port:           8080/tcp
    host port:      0/tcp
    state:          running
      started:      sun, 14 jun 2020 11:21:08 +0100
    ready:          true
    restart count:  0
    liveness:       http-get http://:http/sharks delay=0s timeout=1s period=10s #success=1 #failure=3
    readiness:      http-get http://:http/sharks delay=0s timeout=1s period=10s #success=1 #failure=3
    environment:
      mongo_username:    &lt;set to the key 'mongo_username' in secret 'nodejs-auth'&gt;          optional: false
      mongo_password:    &lt;set to the key 'mongo_password' in secret 'nodejs-auth'&gt;          optional: false
      mongo_hostname:    &lt;set to the key 'mongo_hostname' of config map 'nodejs-config'&gt;    optional: false
      mongo_port:        &lt;set to the key 'mongo_port' of config map 'nodejs-config'&gt;        optional: false
      mongo_db:          &lt;set to the key 'mongo_db' of config map 'nodejs-config'&gt;          optional: false
      mongo_replicaset:  &lt;set to the key 'mongo_replicaset' of config map 'nodejs-config'&gt;  optional: false
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from nodejs-nodeapp-token-4wxvd (ro)
conditions:
  type              status
  initialized       true
  ready             true
  containersready   true
  podscheduled      true
volumes:
  nodejs-nodeapp-token-4wxvd:
    type:        secret (a volume populated by a secret)
    secretname:  nodejs-nodeapp-token-4wxvd
    optional:    false
qos class:       besteffort
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:          &lt;none&gt;


it fails to create a loadbalancer. how do i manually setup the loadbalancer ?
",<kubernetes><digital-ocean><kubernetes-helm>,62371972,2,"i would not recommend configuring loadbalancers manually. you can automate this if you install digital ocean cloud controller manager which is the kubernetes cloud controller manager implementation for digitalocean. read more about cloud controller managers here.

digitalocean cloud controller manager runs service controller, which is responsible for watching services of type loadbalancer and creating do loadbalancers to satisfy its requirements. here are example of how it's used.

here is a yaml file that you can use to deploy this on your kubernetes cluster. this needs a digital ocean api token to be placed in access-token: section of the manifest.
"
48376819,find dockerfile build for `k8s.gcr.io/kubernetes-zookeeper:1.0-3.4.10`,"i've followed the tutorial here
https://kubernetes.io/docs/tutorials/stateful-application/zookeeper/

which references image k8s.gcr.io/kubernetes-zookeeper:1.0-3.4.10. i can go to 

http://k8s.gcr.io/kubernetes-zookeeper
which redirects to
https://console.cloud.google.com/gcr/images/google-containers/global/kubernetes-zookeeper?gcrimagelistsize=50

and i can see the built docker image and the manifest.

how can i find the dockerfile and the source used to build the image. most other hubs link to the source. i presume the source to this is on github or some similar public repo?
",<docker><kubernetes><google-kubernetes-engine>,48392947,4,"i believe the github repo with the right dockerfile and build environment is
https://github.com/kow3ns/kubernetes-zookeeper/tree/master/docker

the makefile look like it lines up with the image k8s.gcr.io/kubernetes-zookeeper:1.0-3.4.10
"
57218140,dns kubernetes external ips for new service does not update,"i would like to create new mongo service for kubernetes which is outside kubernetes cluster.

mongo deployment and service are working fine in cluster but when i create new mongo service which external ips , then delete all apps kubectl delete and mongo and create again kubectl apply with new mongo service. 

but dns kubernetes does not update: 

kubectl exec -it python-guestbook-backend-8544c67965-pxlj5 ping python-guestbook-mongodb
ping python-guestbook-mongodb.default.svc.cluster.local (172.20.74.79) 56(84) bytes of data.


still got old ip address.

name                                         ready   status    restarts   age
python-guestbook-backend-8544c67965-pxlj5    1/1     running   0          28m
python-guestbook-frontend-55677f6fd7-sjrf5   1/1     running   0          28m
python-guestbook-mongodb-567654b76f-zxd6t    1/1     running   0          5h53m


mongo-service.yaml 

kind: service
metadata:
  name: python-guestbook-mongodb
#  name: python-guestbook-mongodb
  labels:
    app: python-guestbook
    tier: db
spec:
  ports:
  - name: python-guestbook
    protocol: tcp
    port: 27017
    targetport: 27017
  selector:
    app: python-guestbook
    tier: db
  externalips:
  - 18.139.115.128

",<mongodb><docker><kubernetes><dns><amazon-eks>,57229063,1,"actually, i missed endpoint for this service: 

apiversion: v1
metadata:
 name: python-guestbook-mongodb
spec:
 ports:
 - port: 27017
   targetport: 27017
---
kind: endpoints
apiversion: v1
metadata:
 name: python-guestbook-mongodb
subsets:
 - addresses:
     - ip: x.x.x.x
   ports:
     - port: 27017

"
74549554,how to have pod to pod communication in kubernetes using service?,"hi i am working in kubernetes. i have two pods running. i want to call another pod from one pod. i am trying as below
httpclient req = new httpclient();
            var content = await req.getasync(&quot;https://cepserviceone.cep-dev.svc.cluster.local/api/values&quot;);
            string response = await content.content.readasstringasync();
            return response;

i have exposed both services as cluster ip as below.
apiversion: v1
kind: service
metadata:
  name: cep #### insert your application service name here ####
  namespace: cep-dev #### insert your application's namespace. omit this line to use default namespace. ####
  labels:
    app: cep #### insert your application service name here ####
spec:
  # use one of clusterip, loadbalancer or nodeport. see https://kubernetes.io/docs/concepts/services-networking/service/
  type: clusterip
  selector:
    app: cep   #### insert your application deployment name here. this must match the deployment name specified in the deployment manifest ####
    instance: app
  ports:
    - port: 8080 #### replace with appropriate port
      targetport: 80 #### replace with the port name defined in deployment

this is another service
apiversion: v1
kind: service
metadata:
  name: cepserviceone #### insert your application service name here ####
  namespace: cep-dev #### insert your application's namespace. omit this line to use default namespace. ####
  labels:
    app: cepserviceone #### insert your application service name here ####
spec:
  # use one of clusterip, loadbalancer or nodeport. see https://kubernetes.io/docs/concepts/services-networking/service/
  type: clusterip
  selector:
    app: cepservice   #### insert your application deployment name here. this must match the deployment name specified in the deployment manifest ####
    instance: app
  ports:
    - port: 8080 #### replace with appropriate port
      targetport: 80 #### replace with the port name defined in deployment

i have ingress which routes requests accordingly. when i try to access serviceone application i get below error
an invalid request uri was provided. either the request uri must be an absolute uri or baseaddress must be set.

may i know what wrong i am doing here? any help would be greatly appreciated. thanks
",<kubernetes><kubernetes-ingress><kubernetes-service>,74555294,2,"use your service port 8080:
var content = await req.getasync(&quot;https://cepserviceone.cep-dev.svc.cluster.local:8080/api/values&quot;);
"
39003890,how to disable http traffic and force https with kubernetes ingress on gcloud,"hi i tried the new annotation for ingress explained here 

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ssl-iagree-ingress
  annotations:
   kubernetes.io/ingress.allowhttp: ""false""
spec:
  tls:
  - secretname: secret-cert-myown
  backend:
    servicename: modcluster
    serviceport: 80


but i can still access it trough http, this is my setup on gcloud ingress--apache:80
",<kubernetes><gcloud><google-kubernetes-engine>,39022396,13,"well i was able to resolve the issue, thanks to mr danny, from this pull request here, there was a typo in

kubernetes.io/ingress.allowhttp: ""false""


change it to 

kubernetes.io/ingress.allow-http: ""false""


and it works fine now.

ps: only for master version 1.3.5
"
75175985,"502 / 503 / 404 http error : gke ingress-nginx serving traffic to the wrong services, from other namespaces","i have this kind of routing in each namespace :
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    janitor/expires: ${expiry_date}
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot; # set to true once ssl is set up.
spec:
  ingressclassname: nginx
  rules:
    - host: api.${kube_deploy_host}
      http:
        paths:
        - pathtype: prefix
          path: /
          backend:
            service:
              name: api-js
              port:
                number: 111

served by ingress-nginx (!= nginx-ingress) 1.2.1 (same issue with 1.5.1) with kube 1.22 (or 1.23), one deployment in the ingress-nginx namespace, two replicas in the deployment.
when i check my logs i see that sometimes, i think especially when i deploy new ingress rules in new namespaces (during and after the ingress-nginx reload event) i get 502 / 503 / 404 http error responses from the ingress-nginx controller.
when i look into the detailed log, i see :
ip - - [time] &quot;get api_route http/1.1&quot; 503 592 &quot;master.frontend.url&quot; ua 449 0.000 [development-branch-api] [] - - - - id

which makes me think the request goes wrong because the master frontend is being served a development api response by the ingress-nginx controller, sometimes when the new api service is not even ready.
when i check the ingress from gke's view it looks like it is serving 3 pods, corresponding to 3 namespaces that should not overlap / mix requests, instead of the one api pod in the namespace corresponding to the ingress :

so the error is seen here, all the ingresses for each 3 namespsace serve 3 pods instead of one pod, which means it is all mixed up, right.
i am sure there is one pod per deployment in my namespaces :

so if i understand correctly, it seems that the situation is ingress a, ingress b and ingress c, all three of them, serve api a and api b and api c instead of serving just the one api pod from their namespace (a, b, c).
but what i don't know is how is it possible that the ingress matches pods from other namespaces, when i am not using externalname, it is the opposite of what an ingress does by default.
i believe the issue is at the ingress level and not at the service level, as when i look into each service, i see that it just serve the one pod corresponding to its namespace and not 3.
the controller is the default ingress-nginx installation edited to use 2 replicas instead of one.
example service and deployment (issue happens for all of them) :
apiversion: v1
kind: service
metadata:
  name: api-js
  labels:
    component: api-js
    role: api-js
  annotations:
    janitor/expires: ${expiry_date}
spec:
  type: clusterip
  selector:
    role: perfmaker-api-js
  ports:
    - name: httpapi
      port: 111
      targetport: 111
---
apiversion: apps/v1
kind: deployment
metadata:
  name: api-js
  annotations:
    janitor/expires: ${expiry_date}
spec:
  replicas: 1
  strategy:
    type: recreate
  selector:
    matchlabels:
      app: api-js
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: &quot;false&quot;
      labels:
        app: api-js
        role: api-js
    spec:
      containers:
        - name: api-js
          image: registry/api

when i change the api name / selectors on one branch, it &quot;untangles&quot; the situation and each branch / namespace's ingress only serves the pod it should serve.
but the errors happen during and after 'reload' event on the ingress-controller, not all the time, an event which is fired when ingress resources are added / removed / updated. in my case it is when there is a new branch in the ci/cd which makes a new namespace and deployment + ingress, or when a finished pipeline triggers a namespace deletion.
",<kubernetes><nginx><google-cloud-platform><google-kubernetes-engine>,75285729,1,"alas i must admit i just discovered the error does not originate from the kubernetes / ingress-nginx part of the setup but from the testing system, which includes a collision between services at deploy time, because of bad separation in the ci / cd job. sorry for your time !
so in fact the logs from ingress nginx that stunned me :
ip - - [time] &quot;get api_route http/1.1&quot; 503 592 &quot;master.frontend.url&quot; ua 449 0.000 [development-branch-api] [] - - - - id

shows that a service i deploy is overwritten by another environment deployment with different variables, which makes it start to make request to another namespace. the ingress routing is correct.
"
58702818,gke load balancer connection refused,"i am trying to set up my app on gke and use an internal load balancer for public access. i am able to deploy the cluster / load balancer service without any issues, but when i try to access the external ip address of the load balancer, i get connection refused and i am not sure what is wrong / how to debug this.

these are the steps i did:

i applied my deployment yaml file via kubectl apply -f file.yaml then after, i applied my load balancer service yaml file with kubectl apply -f service.yaml. after both were deployed, i did kubectl get service to fetch the external ip address from the load balancer.

here is my deployment.yaml file:

apiversion: apps/v1
kind: deployment
metadata:
  name: my-app
spec:
  replicas: 1
  selector:
    matchlabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-api
          image: gcr.io/...
          ports:
            - containerport: 8000
          resources:
            requests:
              memory: ""250m""
              cpu: ""250m""
            limits:
              memory: ""1g""
              cpu: ""500m""
        - name: my-app
          image: gcr.io/...
          ports:
            - containerport: 3000
          resources:
            requests:
              memory: ""250m""
              cpu: ""250m""
            limits:
              memory: ""1g""
              cpu: ""500m""


and here is my service.yaml file:

apiversion: v1
kind: service
metadata:
  name: my-app-ilb
  annotations:
    cloud.google.com/load-balancer-type: ""internal""
  labels:
    app: my-app-ilb
spec:
  type: loadbalancer
  selector:
    app: my-app
  ports:
  - port: 3000
    targetport: 3000
    protocol: tcp



my deployment file has two containers; a backend api and a frontend. what i want to happen is that i should be able to go on [external ip address]:3000 and see my web app.

i hope this is enough information; please let me know if there is anything else i may be missing / can add.

thank you all!
",<network-programming><kubernetes><google-cloud-platform><load-balancing><google-kubernetes-engine>,58702886,4,"you need to allow traffic to flow into your cluster by creating firewall rule.

gcloud compute firewall-rules create my-rule --allow=tcp:3000




remove this annotation : 

  annotations:
    cloud.google.com/load-balancer-type: ""internal""


you need external load balancer.
"
62442679,could not get apiversions from kubernetes: unable to retrieve the complete list of server apis,"while trying to deploy an application got an error as below:
error: upgrade failed: could not get apiversions from kubernetes: unable to retrieve the complete list of server apis: metrics.k8s.io/v1beta1: the server is currently unable to handle the request

output of kubectl api-resources consists some resources along with the same error in the end.
environment: azure cloud, aks service
",<azure><kubernetes><azure-devops><kubectl><azure-aks>,62464015,27,"solution:

the steps i followed are:


kubectl get apiservices : if metric-server service is down with the error crashloopbackoff try to follow the step 2 otherwise just try to restart the metric-server service using kubectl delete apiservice/""service_name"". for me it was v1beta1.metrics.k8s.io .
kubectl get pods -n kube-system and found out that pods like metrics-server, kubernetes-dashboard are down because of the main coredns pod was down.




for me it was: 

name                          ready   status             restarts   age
pod/coredns-85577b65b-zj2x2   0/1     crashloopbackoff   7          13m



use kubectl describe pod/""pod_name"" to check the error in coredns pod and if it is down because of /etc/coredns/corefile:10 - error during parsing: unknown directive proxy, then we need to use forward instead of proxy in the yaml file where coredns config is there. because coredns version 1.5x used by the image does not support the proxy keyword anymore.

"
55036464,how to delete(uninstall) helm chart on specific resource,"i have installed redis. the default given name to me is plinking-narwhal. now i would like to install a service with my assigned name. but first i want to remove the existing one. i had tried deleting them without success.

$ kubectl get all
name                                               ready     status    restarts   age
pod/plinking-narwhal-redis-master-0                1/1       running   0          12m
pod/plinking-narwhal-redis-slave-9b645b597-2vh82   1/1       running   7          12m

name                                    type        cluster-ip       external-ip   port(s)    age
service/kubernetes                      clusterip   10.96.0.1        &lt;none&gt;        443/tcp    15m
service/plinking-narwhal-redis-master   clusterip   10.109.186.189   &lt;none&gt;        6379/tcp   12m
service/plinking-narwhal-redis-slave    clusterip   10.99.122.12     &lt;none&gt;        6379/tcp   12m

name                                           desired   current   up-to-date   available   age
deployment.apps/plinking-narwhal-redis-slave   1         1         1            1           12m

name                                                     desired   current   ready     age
replicaset.apps/plinking-narwhal-redis-slave-9b645b597   1         1         1         12m

name                                             desired   current   age
statefulset.apps/plinking-narwhal-redis-master   1         1         12m
master $ helm delete stable/redis
error: invalid release name, must match regex ^(([a-za-z0-9][-a-za-z0-9_.]*)?[a-za-z0-9])+$ and the length must not longer than 53
master $ helm delete --name plinking-narwhal stable/redis
error: unknown flag: --name

",<redis><kubernetes><kubernetes-helm>,55037460,44,"you probably need:

$ helm delete redis


or if you completely want to remove the release:

$ helm delete redis --purge


stable/redis is not allowed as an expression because of the slash(/)

if you'd like to see the name of the releases you can simply run:

$ helm list -aq

"
57107143,deploying application with terraform doesn't find my service account secret,"is it actually possible to use a kubernates secret in a terraform-deployed application. i am seeing some odd behaviour.

i define a cluster with appropriate node pool, a config map and a secret. the secret contains the service account key json data.
i can then deploy my application using kubectl apply -f myapp-deploy.yaml and it works fine. that tells me the cluster is all good, including the secret and config.
however, when i try to deploy with terraform i get an error in what looks like the service account fetch:

2019-07-19 06:20:45.497  info [myapp,,,] 1 --- [main] b.c.propertysourcebootstrapconfiguration : located property source: secretspropertysource {name='secrets.myapp.null'} 
2019-07-19 06:20:45.665  warn [myapp,,,] 1 --- [main] io.fabric8.kubernetes.client.config      : error reading service account token from: [/var/run/secrets/kubernetes.io/serviceaccount/token]. ignoring.
2019-07-19 06:20:45.677  info [myapp,,,] 1 --- [main] n.c.m.s.myappapplication          : the following profiles are active: test-dev


the middle line is the interesting one, it seems to be trying to read the service account from the wrong place.

i've walked the relevant settings from my yaml file over to my tf file but maybe i missed something. here's what the yaml file looks like:

...
          env:
          - name: google_application_credentials
            value: ""/var/run/secret/cloud.google.com/myapp-sa.json""
          volumemounts:
            - name: ""service-account""
              mountpath: ""/var/run/secret/cloud.google.com""
          ports:
            - containerport: 8080
      volumes:
        - name: ""service-account""
          secret:
            secretname: ""myapp""
...


and this yaml basically just works fine.
now the equivalent in my tf file looks like:

...
          env {
            name  = ""google_application_credentials""
            value = ""/var/run/secret/cloud.google.com/myapp-sa.json""
          }
          volume_mount {
            name       = ""myapp-sa""
            mount_path = ""/var/run/secret/cloud.google.com""
            sub_path = """"
          }
        }
        volume {
          name = ""myapp-sa""
          secret {
            secret_name = ""myapp""
          }
        }
...


and this gives the above error. it seems to decide to look in /var/run/secrets/kubernetes.io/serviceaccount/token for the service account token instead of where i told it to. but only when deployed by terraform. i'm deploying the same image, and into the same cluster with the same configmap. there's something wrong with my tf somewhere. i've tried importing from the yaml deploy but i couldn't see anything important that i missed.

fwiw this is a spring boot application running on gke.

hopefully someone knows the answer.

thanks for any help.

more info: i turned on debugging for io.fabric8.kubernetes and reran both scenarios ie terraform and yaml file. here are the relevant log snippets:

terraform:

2019-07-23 23:03:39.189 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client from kubernetes config...
2019-07-23 23:03:39.268 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : did not find kubernetes config at: [/root/.kube/config]. ignoring.
2019-07-23 23:03:39.274 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client from service account...
2019-07-23 23:03:39.274 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account host and port: 10.44.0.1:443
2019-07-23 23:03:39.282 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : did not find service account ca cert at: [/var/run/secrets/kubernetes.io/serviceaccount/ca.crt].
2019-07-23 23:03:39.285  warn [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : error reading service account token from: [/var/run/secrets/kubernetes.io/serviceaccount/token]. ignoring.
2019-07-23 23:03:39.291 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client namespace from kubernetes service account namespace path...
2019-07-23 23:03:39.295 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : did not find service account namespace at: [/var/run/secrets/kubernetes.io/serviceaccount/namespace]. ignoring.


yaml:

2019-07-23 23:14:53.374 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client namespace from kubernetes service account namespace path...
2019-07-23 23:14:53.375 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account namespace at: [/var/run/secrets/kubernetes.io/serviceaccount/namespace].
2019-07-23 23:14:53.376 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client from kubernetes config...
2019-07-23 23:14:53.377 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : did not find kubernetes config at: [/root/.kube/config]. ignoring.
2019-07-23 23:14:53.378 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client from service account...
2019-07-23 23:14:53.378 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account host and port: 10.44.0.1:443
2019-07-23 23:14:53.383 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account ca cert at: [/var/run/secrets/kubernetes.io/serviceaccount/ca.crt].
2019-07-23 23:14:53.384 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account token at: [/var/run/secrets/kubernetes.io/serviceaccount/token].
2019-07-23 23:14:53.384 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : trying to configure client namespace from kubernetes service account namespace path...
2019-07-23 23:14:53.384 debug [snakecharmer,,,] 1 --- [           main] io.fabric8.kubernetes.client.config      : found service account namespace at: [/var/run/secrets/kubernetes.io/serviceaccount/namespace].


it looks like the yaml deploy finds what it needs at /var/run/secrets/kubernetes.io/serviceaccount/ca.crt etc and the terraform deploy doesn't. as if there is a phantom volume mount in there that is missing in ** terraform**
",<kubernetes><terraform><google-kubernetes-engine>,57173551,3,"i found the fix. the terraform deploy adds a automount_service_account_token = false but the yaml default is for true and that makes all the difference.

the switch is in the template.spec section of the kubernetes_deployment in my tf file and that now looks like this snippet:

...
      spec {
        restart_policy = ""always""
        automount_service_account_token = true
        container {
          port {
            container_port = 8080
            protocol       = ""tcp""
          }
...


setting the automount_service_account_token = true is the fix and it comes up fine with that in place.
"
72481655,creating a kubernetes dashboard token,"i'm trying to follow the instructions at https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md to create a kubernetes dashboard token.  however, when i run the specified command, i get an error
% kubectl -n kubernetes-dashboard create token admin-user
error: must specify one of -f and -k

error: unknown command &quot;token admin-user&quot;
see 'kubectl create -h' for help and examples

if i jump back in the doc history, i see a different, more verbose command that i can run
% kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=&quot;{.secrets[0].name}&quot;) -o go-template=&quot;{{.data.token | base64decode}}&quot;

this seems to work ok and pr for the doc change mentions &quot;version 1.24&quot; but doesn't mention what piece of software version 1.24 refers to (kubectl? the dashboard? kuberenetes itself? kind? something else?)
so what's going on with that first command?  why doesn't it work?
",<kubernetes><kubectl><kubernetes-dashboard>,72481774,9,"this is a new feature in kubernetes 1.24, your cluster and kubectl must be running &lt;1.24 version of kubernetes, causing the issue. see the change log below:

kubectl create token can now be used to request a service account
token, and permission to request service account tokens is added to
the edit and admin rbac roles (#107880, @liggitt)

another snippet showing more relevant info:

kubectl changes:
adds a command to kubectl to request a bound service account token.
this will help ease the transition from scraping generated service
account tokens with commands like kubectl get secret &quot;$(kubectl get
serviceaccount default -o jsonpath='{.secrets[0].name}')&quot;

both server and client must be running 1.24 or newer, something like below:
kubectl version --output=json
{
  &quot;clientversion&quot;: {
    &quot;major&quot;: &quot;1&quot;,
    &quot;minor&quot;: &quot;24&quot;,
    &quot;gitversion&quot;: &quot;v1.24.0&quot;,
    &quot;gitcommit&quot;: &quot;4ce5a8954017644c5420bae81d72b09b735c21f0&quot;,
    &quot;gittreestate&quot;: &quot;clean&quot;,
    &quot;builddate&quot;: &quot;2022-05-03t13:46:05z&quot;,
    &quot;goversion&quot;: &quot;go1.18.1&quot;,
    &quot;compiler&quot;: &quot;gc&quot;,
    &quot;platform&quot;: &quot;linux/amd64&quot;
  },
  &quot;kustomizeversion&quot;: &quot;v4.5.4&quot;,
  &quot;serverversion&quot;: {
    &quot;major&quot;: &quot;1&quot;,
    &quot;minor&quot;: &quot;24&quot;,
    &quot;gitversion&quot;: &quot;v1.24.2&quot;,
    &quot;gitcommit&quot;: &quot;f66044f4361b9f1f96f0053dd46cb7dce5e990a8&quot;,
    &quot;gittreestate&quot;: &quot;clean&quot;,
    &quot;builddate&quot;: &quot;2022-06-15t14:15:38z&quot;,
    &quot;goversion&quot;: &quot;go1.18.3&quot;,
    &quot;compiler&quot;: &quot;gc&quot;,
    &quot;platform&quot;: &quot;linux/amd64&quot;
  }
}

check this for more info: https://github.com/kubernetes/kubernetes/pull/107880
"
67372801,externalize / reuse helm _helpers,"i have several apps of different shapes and purposes, each with their own templates/ folder as generated by helm create chart.  the templates within each app are sufficiently different to justify having them as one-offs.  however, the _helpers.tpl is identical for all of them.  i'd like to externalize/reuse this _helpers.tpl template so that i don't need a copy of it in every app.
what i have currently looks something like this:
app1
|--app (random source code crap, irrelevant)
|--chart
|---templates
|------_helpers.tpl
|------ deployment.yaml
|------ other unique templates

app2
|--app (random source code crap, irrelevant)
|--chart
|---templates
|------_helpers.tpl
|------ deployment.yaml
|------ other unique templates

i'd like to centralize this _helpers.tpl so that i don't need to maintain n versions of it.  i'm imagining something like this, but i'm open to whatever:
common
|--chart
|----templates
|------ _helpers.tpl (i live here now and was removed from the 2 apps below)

app1
|-- app (random source code crap, irrelevant)
|-- chart
|--- templates
|------ deployment.yaml
|------ other unique templates

app2
|-- app (random source code crap, irrelevant)
|-- chart
|--- templates
|------ deployment.yaml
|------ other unique templates

i have tried doing this with a symlink pointing appn/chart/templates/_helper.tpl to common/chart/templates/_helper.tpl but that's clearly bad and i imagine there's a built-in way to do this that i'm just not finding.
even if appn/chart/templates/_helpers.tpl needs to exist only to read ../../_helpers.tpl, that's good enough but i'm not sure how to approach that given the yaml-y/go-y syntax.
",<kubernetes><kubernetes-helm>,67374918,1,"i wound up solving this by inverting my file structure into something like:
parent app
|--chart.yaml // new
|--values.yaml // new
|--templates // new
|----_helpers.tpl // automagically gets referenced in charts/*/templates
|--apps (source code stuff, irrelevant)
|--charts
|----app1
|------chart.yaml
|------values.yaml
|------templates
|--------deployment.yaml (and others)
|----app2
|------chart.yaml
|------values.yaml
|------templates
|--------deployment.yaml (and others)

which follows the &quot;subchart&quot; pattern outlined here more closely:  https://helm.sh/docs/chart_template_guide/subcharts_and_globals/
even though these are independent charts, not dependencies on some parent chart like this structure would indicate, this is good enough for me.
"
74456951,helm: expanding environment variables in values.yaml with helm install or upgrade,"in our jenkins pipeline, i'm using a bash script to call the helm install command. we have a values.yaml containing most of the values to be passed to helm. however, few values are based upon environment variables and have to be passed using the --set argument. here is the snippet:
helm install $release_name shared/phoenixmsp-app -f value.yaml \
    --set global.env.production=$production \
    --set global.cluster.hosts=${config[${cluster_name}]} \
    --set nameoverride=$release_name \
    --set fullnameoverride=$release_name \
    --set image.repository=myhelm.hub.mycloud.io/myrepo/mainservice \
    --set-string image.tag=$docker_tag \
    --wait --timeout 180s --namespace $app_namespace&quot;

we want to move these --set parameters to values.yaml. the goal is to get rid of --set and simply pass the values.yaml.
question: is it possible to expand environment variables in values.yaml while calling with helm install or helm upgrade?
",<bash><kubernetes><environment-variables><kubernetes-helm>,74457316,2,"the only way i think you can do that, if you really want to use a single yaml is to have a template values.yaml and either sed the values into it or use a templating language like jinja or mustache, then feed the resulting output into helm.
"
46618383,how to config simple login/pass authentication for kubernetes desktop ui,"i'm pretty new in kubernetes, i just install kubernetes via kubeadm and run dashboard ui but can't config access to it. following docs i add line --basic-auth-file=/etc/kubernetes/auth.csv to /etc/kubernetes/manifests/kube-apiserver.yaml, create file and put in one string like pass,admin,admin. but after that api server crashed and back to normal after deleting this string and reboot the server. how i can pass this parametr to api server without api server crashing, and maybe something else need add or remove from this file? here is my 

kube-apiserver.yaml

apiversion: v1
kind: pod
metadata:
  annotations:
    scheduler.alpha.kubernetes.io/critical-pod: """"
  creationtimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --admission-control=initializers,namespacelifecycle,limitranger,serviceaccount,persistentvolumelabel,defaultstorageclass,defaulttolerationseconds,noderestriction,resourcequota
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    - --secure-port=6443
    - --kubelet-preferred-address-types=internalip,externalip,hostname
    - --requestheader-allowed-names=front-proxy-client
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-bootstrap-token-auth=true
    - --allow-privileged=true
    - --requestheader-username-headers=x-remote-user
    - --advertise-address=236.273.51.124
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --insecure-port=0
    - --requestheader-group-headers=x-remote-group
    - --requestheader-extra-headers-prefix=x-remote-extra-
    - --service-cluster-ip-range=10.96.0.0/12
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --authorization-mode=node,rbac
    - --etcd-servers=http://127.0.0.1:2379
    image: gcr.io/google_containers/kube-apiserver-amd64:v1.8.0
    livenessprobe:
      failurethreshold: 8
      httpget:
        host: 127.0.0.1
        path: /healthz
        port: 6443
        scheme: https
      initialdelayseconds: 15
      timeoutseconds: 15
    name: kube-apiserver
    resources:
      requests:
        cpu: 250m
    volumemounts:
    - mountpath: /etc/kubernetes/pki
      name: k8s-certs
      readonly: true
    - mountpath: /etc/ssl/certs
      name: ca-certs
      readonly: true
    - mountpath: /etc/pki
      name: ca-certs-etc-pki

",<docker><kubernetes><kubectl><kubeadm>,46633641,10,"your file for basic authentication /etc/kubernetes/auth.csv is not available inside kube-apiserver pod's container. it should be mounted to pod's container as well as certificate folders. just add it to volumes and volumemounts sections:

    volumemounts:
    - mountpath: /etc/kubernetes/auth.csv
      name: kubernetes-dashboard
      readonly: true
  volumes:
  - hostpath:
      path: /etc/kubernetes/auth.csv
    name: kubernetes-dashboard

"
62932874,deploy helm on master node with taints labels,"hi i am trying to initialize helm tiller on master node.
master node is:
name:               ip-10-3-196-251.ec2.internal
roles:              master
labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/instance-type=m4.xlarge
                    beta.kubernetes.io/os=linux
                    failure-domain.beta.kubernetes.io/region=us-east-1
                    failure-domain.beta.kubernetes.io/zone=us-east-1a
                    kubernetes.io/role=master
annotations:        node.alpha.kubernetes.io/ttl=0
                    scheduler.alpha.kubernetes.io/taints=[{&quot;key&quot;:&quot;dedicated&quot;,&quot;value&quot;:&quot;master&quot;,&quot;effect&quot;:&quot;noschedule&quot;}]
                    volumes.kubernetes.io/controller-managed-attach-detach=true
creationtimestamp:  mon, 01 jun 2020 12:50:53 +0200
taints:             node-role.kubernetes.io/master=true:noschedule
unschedulable:      false

...
...
...


i am running this:
helm init \
    --history-max=1000 \
    --service-account tiller \
    --node-selectors &quot;kubernetes.io/role=master&quot; \
    --override spec.template.spec.tolerations[0].key=node-role.kubernetes.io/master \
    --override spec.template.spec.tolerations[0].effect=noschedule \
    --skip-refresh \
    --upgrade

but when i describe the pod i am getting still
events:
  type     reason             age                from                message
  ----     ------             ----               ----                -------
  normal   nottriggerscaleup  1m (x86 over 16m)  cluster-autoscaler  pod didn't trigger scale-up (it wouldn't fit if a new node is added): 9 node(s) didn't match node selector
  warning  failedscheduling   1m (x57 over 17m)  default-scheduler   0/11 nodes are available: 1 insufficient cpu, 3 podtoleratesnodetaints, 8 matchnodeselector.e

do you know what is wrong?
",<kubernetes><devops><release><kubernetes-helm>,62934113,4,"master node has taint node-role.kubernetes.io/master=true:noschedule but you have given node-role.kubernetes.io/master:noschedule in the command.
use below command
helm init \
    --history-max=1000 \
    --service-account tiller \
    --node-selectors &quot;kubernetes.io/role=master&quot; \
    --override spec.template.spec.tolerations[0].key=node-role.kubernetes.io/master \
    --override spec.template.spec.tolerations[0].operator=equal \
    --override spec.template.spec.tolerations[0].value=true \
    --override spec.template.spec.tolerations[0].effect=noschedule \
    --skip-refresh \
    --upgrade

"
69047475,helm release with existing resources,"previously we only use helm template to generate the manifest and apply to the cluster, recently we start planning to use helm install to manage our deployment, but running into following problems:
our deployment is a simple backend api which contains &quot;ingress&quot;, &quot;service&quot;, and &quot;deployment&quot;, when there is a new commit, the pipeline will be triggered to deploy.
we plan to use the short commit sha as the image tag and helm release name. here is the command
helm upgrade --install releasename repo/chartname -f value.yaml --set image.tag=sha
this runs perfectly fine for the first time, but when i create another release it fails with following error message
rendered manifests contain a resource that already exists. unable to continue with install: service &quot;app-svc&quot; in namespace &quot;ns&quot; exists and cannot be imported into the current release: invalid ownership metadata; annotation validation error: key &quot;meta.helm.sh/release-name&quot; must equal &quot;rel-124&quot;: current value is &quot;rel-123&quot;

the error message is pretty clear on what the issue is, but i am just wondering what's &quot;correct&quot; way of using helm in this case?
it is not practical that i uninstall everything for a new release, and i also dont want to keep using the same release.
",<kubernetes><kubernetes-helm>,69047544,1,"you are already doing it &quot;right&quot; way, just don't change release-name. that's key for helm to identify resources. it seems that you previously used different name for release (rel-123) then you are using now (rel-124).
to fix your immediate problem, you should be able to proceed by updating value of annotation meta.helm.sh/release-name on problematic resource. something like this should do it:
kubectl annotate --overwrite service app-svc meta.helm.sh/release-name=rel-124

"
51751462,nginx ingress jenkins path rewrite configuration not working,"i have deployed jenkins on kubernetes and am trying to configure the nginx ingress for it. 

assume i want it to be available at https://myip/jenkins

this is my initial ingress configuration:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: jenkins-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: ""true""
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/add-base-url: ""true""
spec:
  rules:
  - http:
      paths:
      - path: /jenkins
        backend:
          servicename: jenkins
          serviceport: 8080


with this when i access https://myip/jenkins i am redirected to http://myip/login?from=%2f.

when accessing https://myip/jenkins/login?from=%2f it stays on that page but none of the static resources are found since they are looked for at https://myip/static...
",<nginx><jenkins><kubernetes><kubernetes-ingress>,51756313,7,"this is how i solved it configuring the jenkins image context path without the need to use the ingress rewrite annotations:

kind: deployment
metadata:
  creationtimestamp: null
  labels:
    app: jenkins
  name: jenkins
spec:
  replicas: 1
  selector:
    matchlabels:
      app: jenkins
  strategy: {}
  template:
    metadata:
      creationtimestamp: null
      labels:
        app: jenkins
    spec:
      securitycontext:
        fsgroup: 2000
        runasuser: 1000
        runasnonroot: true
      volumes:
      - name: jenkins-storage
        persistentvolumeclaim:
          claimname: jenkins
      containers:
      - image: jenkins/jenkins:lts
        name: jenkins
        ports:
        - containerport: 8080
          name: ""http-server""
        - containerport: 50000
          name: ""jnlp""
        resources: {}
        env:
        - name: jenkins_opts
          value: --prefix=/jenkins
        volumemounts:
        - mountpath: ""/var/jenkins_home""
          name: jenkins-storage
status: {}


ingress:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: prfl-apps-devops-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/add-base-url: ""true""
spec:
  rules:
  - http:
      paths:
      - path: /jenkins
        backend:
          servicename: jenkins
          serviceport: 8080

"
71011270,how can i access mariadb outside from helm installation,"i have a rke2 kube installation, 3 nodes, i install mariadb from bitnami repository:
- name: mariadb
  repository: https://charts.bitnami.com/bitnami
  version: 10.3.2

it boots up correctly in my kube installation, but i need to access it from outside the cluster, let's say with my navicat client as example.
this is my values.yaml:
mariadb:
  clusterdomain: a4b-kube.local
  auth:
    rootpassword: &quot;password&quot;
    replicationpassword: &quot;password&quot;
  architecture: replication
  primary:
    service:
      type: loadbalancer
      loadbalancerip: mariadb.acme.com
  secondary:
    replicacount: 2

listing the services i see:
name                         type           cluster-ip     external-ip   port(s)          age
a4b-test-mariadb-primary     loadbalancer   10.43.171.45   &lt;pending&gt;     3306:31379/tcp   48m

and the external ip never gets updated, i also try specifing an ip instead of dns, in my case was 192.168.113.120 but i got same result. what am i missing?
",<kubernetes><mariadb><kubernetes-helm><rke>,71012920,3,"you might consider using nodeport
mariadb:
  clusterdomain: a4b-kube.local
  auth:
    rootpassword: &quot;password&quot;
    replicationpassword: &quot;password&quot;
  architecture: replication
  primary:
    service:
      type: nodeport
      nodeport: 32036
  secondary:
    replicacount: 2

nodeport: 32036 you can choose in range 30000 - 32767 (default)
then, you can access via nodeip:nodeport
"
69032400,"difference between kubernetes recreate update strategy vs simply uninstall, install","when deciding on update strategy for a kubernetes application, there is an option to use recreate strategy.
how would this be different from just uninstalling and installing the app?
",<kubernetes><kubernetes-deployment>,69047145,2,"i assume that by &quot;just uninstalling and installing the app&quot; you mean complete deletion of your deployment e.g.:
kubectl delete deployment nginx-deployment

and creating it again:
kubectl apply -f nginx-deployment.yaml

note that when using recreate strategy there is no complete deletion of the deployment so there is fundamental difference here. by choosing this strategy you only inform kubernetes that all the pods managed by your deployment should be deleted and recreated when you update them (e.g. you update the image version of the container) rather than deleting and recreating their new versions one at a time what takes place when using rollingupdate strategy. this way you make sure that certain number of pods serving an old version of the application are still available when the update occurs and pods with a new version of the image appear.
when you delete your deployment and create a new one, your new deployment has nothing to do with the old one. in other words, completely new deployment resource is created and no history of the changes you made is preserved.
i believe the best way of explaining things is always an example. so let's move on to the following one.
let's say you've created a new nginx deployment based on your yaml manifest:
kubectl apply -f nginx-deployment.yaml

and then you decided to update the image version, either by editing nginx-deployment.yaml manifest and re-applying it or this way:
kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.161 --record=true

in either case you will be able to check rollout history by running:
kubectl rollout history deployment nginx-deployment

and you should see something like this:
$ kubectl rollout history deployment nginx-deployment 
deployment.apps/nginx-deployment
revision  change-cause
1         kubectl apply --filename=nginx-deployment.yaml --record=true
2         kubectl set image deployment nginx-deployment nginx=nginx:1.16.1 --record=true

when you have rollout history you're able to undo your latest change and go back to the previous revision:
kubectl rollout undo deployment.v1.apps/nginx-deployment

now your rollout history for this deployment may look like this:
$ kubectl rollout history deployment nginx-deployment
deployment.apps/nginx-deployment
revision  change-cause
2         kubectl set image deployment nginx-deployment nginx=nginx:1.16.1 --record=true
3         kubectl apply --filename=nginx-deployment.yaml --record=true

when you simply delete your deployment and recreate it again you will have nothing in rollout history for newly created deployment and you won't be able  to roll it back to some older revision in such an easy way.
"
62533900,trying to install kong using the helm chart,"trying to install kong using the helm chart using the following command using this post
&gt;helm install --version 0.26.1 --name kong stable/kong --namespace kong --set ingresscontroller.enabled=true --set image.tag=1.4 --set admin.usetls=false

but getting the following error
error: unknown flag: --name
solution i tried
removed  -- name then i am getting the following error
error: failed to download &quot;stable/kong&quot; (hint: running helm repo update may help)
can anyone please help me with this?
",<kubernetes><kubernetes-helm><kong-ingress>,62533994,3,"in helm version 3 --name flag is removed.  you can give a name without --name flag as shown below
helm repo add kong https://charts.konghq.com

helm repo update

helm install --version 1.7.0 kong kong/kong  --namespace kong --set ingresscontroller.enabled=true --set image.tag=1.4 --set admin.usetls=false

find more details here
"
49844769,access an application running on kubernetes from the internet,"i'm pretty sure that this is a basic use case when running apps on kubernetes, but till now i wasn't able to find a tutorial, nor understand from the documentation, how to make it work.

i have an application, which is listening on a port 9000. so when run on my localhost, i can access it through a web browser on a localhost:9000. when run in a docker container, which is running on my vps, it's also accessible on myvpsaddress:9000. now the question is, how to deploy it on kubernetes running on the very same virtual private server and expose the application to be visible as well, as when deployed on docker. i can access the application from within the vps on the address of the cluster, but not on the ip address of the server itself. can somebody show me some basic dockerfile with a description what is it doing or show me some idiot-proof way, how to make it work? thanks
",<kubernetes><cluster-computing><kubernetes-service>,49845107,1,"while one would think that this is a very basic use-case, that is not the case for people running their own kubernetes clusters on bare metal servers. (the way you are on your vps).

the recommended way of exposing an application to ""the world"" is to use kubernetes services, see this piece of documentation about exposing services. you define a kubernetes service, either of the type nodeport or of type loadbalancer *.

here is what a dead simple service looks like (hint: it's of the default type nodeport):

kind: service
apiversion: v1
metadata:
  name: my-service
spec:
  selector:
    app: myapp
  ports:
  - protocol: tcp
    port: 9000
    targetport: 9376


this will expose your service with label name: my-service (interally running on port 9000)  on all nodes in your vps cluster at port 9376.

assuming your nodes have a public ip (which from your question i assume they do), you can safely do curl localhost:9376.

because this is usually not ideal ux/ui to expose to users, people use services of type loadbalancer. this service type provides a unique ip to each of your services instead of a port.

these services are first class citizens on cloud managed clusters, such as google's gke, but if you run your own kubernetes cluster (setup using say kubeadm), then you need to deploy your loadbalancer service provider. i've used the excellent metallb and it works flawlessly once it's been setup, but you need to set it up yourself. if you want dns names for you services as well, you should also look at externaldns.



* caveat here is that you can also use a service of type externalip if you can somehow make that ip routable, but unless the network is in your control, this is usually not a feasible approach, and i'd recommend looking at an lb provider instead.
"
65911114,unable to attach or mount volumes: unmounted volumes,"i deplyed my application on kubernetes but have been getting this error:
**mountvolume.setup failed for volume &quot;airflow-volume&quot; : mount failed: mount failed: exit status 32 mounting command: systemd-run mounting arguments: --description=kubernetes transient mount for /var/lib/kubelet/pods/4a3c3d0b-b7e8-49bc-8a78-5a8bdc932eca/volumes/kubernetes.io~glusterfs/airflow-volume --scope -- mount -t glusterfs -o auto_unmount,backup-volfile-servers=10.0.2.107:10.0.2.24,log-file=/var/lib/kubelet/plugins/kubernetes.io/glusterfs/airflow-volume/worker-844c9db787-vprt8-glusterfs.log,log-level=error 10.0.2.107:/airflow /var/lib/kubelet/pods/4a3c3d0b-b7e8-49bc-8a78-5a8bdc932eca/volumes/kubernetes.io~glusterfs/airflow-volume output: running scope as unit run-22059.scope. mount: /var/lib/kubelet/pods/4a3c3d0b-b7e8-49bc-8a78-5a8bdc932eca/volumes/kubernetes.io~glusterfs/airflow-volume: unknown filesystem type 'glusterfs'. , the following error information was pulled from the glusterfs log to help diagnose this issue: could not open log file for pod worker-844c9db787-vprt8**

and
**unable to attach or mount volumes: unmounted volumes=[airflow-volume], unattached volumes=[airflow-volume default-token-s6pvd]: timed out waiting for the condition**

any suggestions?
---
apiversion: apps/v1
kind: deployment
metadata:
  name: web
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchlabels:
      tier: web
  template:
    metadata:
      labels:
        app: airflow
        tier: web
    spec:
      imagepullsecrets:
        - name: peeriqregistrykey
      restartpolicy: always
      containers:
        # airflow webserver container
        - name: web
          image: peeriq/data_availability_service:airflow-metadata-cutover
          volumemounts:
            - mountpath: /usr/local/airflow
              name: airflow-volume
          envfrom:
            - configmapref:
                name: airflow-config
          env:
            - name: vault_addr
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_addr
            - name: vault_token
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_token
            - name: django_auth_user
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_user
            - name: django_auth_pass
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_pass
            - name: fernet_key
              valuefrom:
                secretkeyref:
                  name: airflow-secrets
                  key: fernet_key
            - name: postgres_service_host
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_service_host
            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_password
          ports:
            - name: web
              containerport: 8080
          args: [&quot;webserver&quot;]
        # airflow scheduler container
        - name: scheduler
          image: peeriq/data_availability_service:airflow-metadata-cutover
          volumemounts:
            - mountpath: /usr/local/airflow
              name: airflow-volume
          envfrom:
            - configmapref:
                name: airflow-config
          env:
            - name: aws_default_region
              value: us-east-1
            - name: etl_aws_account_number
              valuefrom:
                secretkeyref:
                  name: aws-creds
                  key: etl_aws_account_number
            - name: vault_addr
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_addr
            - name: vault_token
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_token
            - name: django_auth_user
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_user
            - name: django_auth_pass
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_pass
            - name: fernet_key
              valuefrom:
                secretkeyref:
                  name: airflow-secrets
                  key: fernet_key
            - name: postgres_service_host
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_service_host
            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_password
          args: [&quot;scheduler&quot;]
      volumes:
        - name: airflow-volume
          # this glusterfs volume must already exist.
          glusterfs:
            endpoints: glusterfs-cluster
            path: /airflow
            readonly: false
---
apiversion: apps/v1
kind: deployment
metadata:
  name: flower
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchlabels:
      tier: flower
  template:
    metadata:
      labels:
        app: airflow
        tier: flower
    spec:
      imagepullsecrets:
        - name: peeriqregistrykey
      restartpolicy: always
      containers:
        - name: flower
          image: peeriq/data_availability_service:airflow-metadata-cutover
          volumemounts:
            - mountpath: /usr/local/airflow
              name: airflow-volume
          envfrom:
            - configmapref:
                name: airflow-config
          env:
            # to prevent the error: valueerror: invalid literal for int() with base 10: 'tcp://10.0.0.83:5555'
            - name: flower_port
              value: &quot;5555&quot;
            - name: django_auth_user
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_user
            - name: django_auth_pass
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_pass
            - name: postgres_service_host
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_service_host
            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_password
          ports:
            - name: flower
              containerport: 5555
          args: [&quot;flower&quot;]
      volumes:
        - name: airflow-volume
          # this glusterfs volume must already exist.
          glusterfs:
            endpoints: glusterfs-cluster
            path: /airflow
            readonly: false
---
apiversion: apps/v1
kind: deployment
metadata:
  name: worker
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchlabels:
      tier: worker
  template:
    metadata:
      labels:
        app: airflow
        tier: worker
    spec:
      imagepullsecrets:
        - name: peeriqregistrykey
      restartpolicy: always
      containers:
        - name: worker
          image: peeriq/data_availability_service:airflow-metadata-cutover
          volumemounts:
            - mountpath: /usr/local/airflow
              name: airflow-volume
          envfrom:
            - configmapref:
                name: airflow-config
          env:
            - name: aws_default_region
              value: us-east-1
            - name: etl_aws_account_number
              valuefrom:
                secretkeyref:
                  name: aws-creds
                  key: etl_aws_account_number
            - name: vault_addr
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_addr
            - name: vault_token
              valuefrom:
                secretkeyref:
                  name: vault-credentials
                  key: vault_token
            - name: django_auth_user
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_user
            - name: django_auth_pass
              valuefrom:
                secretkeyref:
                  name: django-auth
                  key: django_auth_pass
            - name: fernet_key
              valuefrom:
                secretkeyref:
                  name: airflow-secrets
                  key: fernet_key
            - name: postgres_service_host
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_service_host
            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: rds-postgres
                  key: postgres_password
          args: [&quot;worker&quot;]
      volumes:
        - name: airflow-volume
          # this glusterfs volume must already exist.
          glusterfs:
            endpoints: glusterfs-cluster
            path: /airflow
            readonly: false

",<kubernetes><amazon-eks>,65914515,3,"you must install package glusterfs-fuse on your kubernetes nodes, otherwise it won't be able to mount glusterfs volumes.
"
67609396,kubectl - how to get the list of all pods that have been restarted at least once,"kubectl get pods --all-namespaces provides the list of all pods. the column restarts shows the number of restarts that a pod has had. how to get the list of all the pods that have had at least one restart? thanks
",<kubernetes><kubectl><kubernetes-pod>,67609686,20,"kubectl get pods --all-namespaces | awk '$5&gt;0'

or simply just
kubectl get po -a | awk '$5&gt;0'

use awk to print if column 5 (restarts) &gt; 0
or with the use of an alias
alias k='kubectl'
k get po -a | awk '$5&gt;0'

"
75523889,select specific cluster from 'kubectl config view',"i am trying to select a specific server url from kubectl config view
kubectl config view -o jsonpath='{.clusters[?(@.name == 'dev')].cluster. server}'

however, this fails with:
 error: error executing jsonpath &quot;{.clusters[?(@.name == dev)].cluster.server}&quot;: error executing template: unrecognized identifier dev. printing more information for debugging the template:
            template was:
                    {.clusters[?(@.name == dev)].cluster. server}

i tested this with jsonpath.com and it's apparently valid.
what am i doing wrong?

",<kubernetes><kubectl><jsonpath>,75524186,3,"change the single quotes around dev to double quotes:
kubectl config view -o jsonpath='{.clusters[?(@.name == &quot;dev&quot;)].cluster.server}'

you can see an example here.
"
59829054,is there a command to list all the kubernetes cluster's configuration files,"i have a kubernetes cluster using istio and i need to debug an issue. i need to see all the configuration files that are being used. i would like to delete certain configurations from my cluster, but i am not sure what is running. 

so for example, i can deploy a configuration
kubectl apply -f config1.yaml

i need a list of all of the deployed configuration like ""config1"". is there is a command that exists and can someone please provide it. 
",<kubernetes><google-cloud-platform><google-kubernetes-engine><istio>,59838409,4,"in the context of istio, and applied to routing/networking, there are 6 objects:

# kubectl api-resources | grep networking.istio
destinationrules                  dr           networking.istio.io            true         destinationrule
envoyfilters                                   networking.istio.io            true         envoyfilter
gateways                          gw           networking.istio.io            true         gateway
serviceentries                    se           networking.istio.io            true         serviceentry
sidecars                                       networking.istio.io            true         sidecar
virtualservices                   vs           networking.istio.io            true         virtualservice


so, to get all istio objects, you can do:

kubectl get dr,envoyfilters,gw,se,sidecars,vs -oyaml -n namespace

or --all-namespaces
"
59491324,is there a way to kubectl apply all the files in a directory?,"i am writing an ansible playbook right now that deploys a dockerized application in kubernetes.  however, for molecularity purposes i would rather not hard code the files that need to be apply after doing kompose convert -f docker-compose.yaml --volumes hostpath  is there a way to apply all the files in a directory?
",<kubernetes><kubectl>,59493623,175,"you can apply all files in a folder with

kubectl apply -f &lt;folder&gt; 


you may also be interested in parameterization of your manifest files using kustomize e.g. use more replicas in a prod-namespace than in a test-namespace. you can apply parameterized manifest files with

kubectl apply -k &lt;folder&gt;

"
62835605,if clause in helm chart,"how can i check if a variable is a boolean value &quot;true&quot; in helm chart?
i have in values.yaml a parameter set as:
myparameter: true

i don't understand well difference between:
{{- if .values.service.myparameter }}

and
{{- if eq .values.service.myparameter &quot;true&quot; }}

i want that flow goes in if clause if the parameter is set as boolean &quot;true&quot;
",<if-statement><kubernetes><kubernetes-helm>,62835936,15,"you can use the following snipped for checking the boolean value
      {{if (default .values.selinux true)}}
      securitycontext:
        selinuxoptions:
          user: system_u
      {{ end }}

then the values file will have following snippet
selinux: true

please let me know if this helps.
"
76707751,helm variable substitution in an appsettings file,"i am trying to use helm to define some variables (including secrets which have been defined in gcp) and use them in an appsettings.json file. none are pulling through. my helm chart defines the vars as below. some 'secrets' are pulling from the helm chart and some will be from gcp secrets):
  - name: aspnetcore_environment
    value: qa-k8
  - name: auth__apiscopesecret
    value: foo
  - name: discovery__uri
    value: bar


envfrom:
  - secretref:
      name: blah-secrets

gcpsecrets:
  enabled: true
  secretsfrom:
    - blah-secrets

and my appsettings.json file is configured as per the below example. when i check the container, none of the variables within the helm chart have translated and the values are blank. what am i missing? i understand that the double underscores are required to locate the variables in the correct locations and probably aren't required in the appsettings file.
  &quot;auth&quot;: {
    &quot;apiscopesecret&quot;: &quot;${auth__apiscopesecret}&quot;
  },
  &quot;discovery&quot;: {
    &quot;uri&quot;: &quot;${discovery__uri}&quot;

",<asp.net><kubernetes><google-cloud-platform><kubernetes-helm>,76707973,3,"that is also the expected behaviour. usually you create the appsettings file with the helm values as a cm or secret that are replaced during the deployment and then you mount it into your container. in your case i dont see that you mount something into the container you just provide it as an env.
you should specify a secret or configmap with your helm values that provide the appsettings file.
apiversion: v1
kind: configmap
metadata:
  name: appsettings
data:
  appsettings.dev.json: |-
    {
      &quot;logging&quot;: {
        &quot;loglevel&quot;: {
          &quot;default&quot;: {{my__helmvalue}},
        }
      }
    }


in your pod you should specify the volumes and in your container the volumemounts to specify in wich location the appsetting file should get mounted into.
apiversion: v1
kind: pod
metadata:
   name: examplepod
spec:
   containers:
     - name: test-container
       image: myimage
       volumemounts:
       - name: config-volume
         mountpath: /app ## specify your path to overwrite the appsettingsfile!
   volumes:
     - name: config-volume
       configmap:
         name: appsettings
   restartpolicy: never

"
68573550,use kubernetes to deploy a single app to multiple servers,"i'd like to deploy a single app to multiple servers in one time.
i'm using kubernetes and k3s to easily deploy containers.
basically, i have a master server that i run and multiple servers that are localed in my customers facilities.
master server was initialized with the following command:
k3sup install \
    --ip $master_ip \
    --user ubuntu \
    --cluster --k3s-channel latest \
    --k3s-extra-args &quot;--node-label ols.role=master&quot;

customer's servers were launched with:
k3sup join \
    --ip $worker01_ip \
    --user ubuntu \
    --server-ip $master_ip \
    --server-user ubuntu \
    --k3s-channel latest \
    --k3s-extra-args &quot;--node-label ols.role=worker&quot;

when i want to deploy a new web service on each customer's server, i've tried the following code:
helm install node-red k8s-at-home/node-red --set nodeselector.&quot;ols\.role&quot;=worker

problem: only one single pod is deployed.
what i'd like is to deploy a single pod on each server and make it independent.
is there a way to do that ?
",<kubernetes><kubernetes-helm><k3s><k3sup>,68573999,1,"here there are two different things that we need to consider.
if the requirement is just to run more number of replicas of the application a change to the deployment template in the helm chart or through values you can pass number of minimum replicas need to be working in the cluster.
reference documentation for deployments
coming to next thing, if the requirements is just to run application across all the nodes existing in the cluster, daemonsets is the workload which gives the capability to run across all the existing nodes.
reference documentation for daemonsets
again if you are using helm to deploy, appropriate templates for either daemonsets or deployments need to be added or modified based on the existing contents of the helm chart.
there are also different workloads k8s supports so based on requirements they can be picked appropriately.
"
69401495,folder deleted/not created inside the common dir mounted with emptydir{} type on eks fargate pod,"we are facing strange issue with eks fargate pods. we want to push logs to cloudwatch with sidecar fluent-bit container and for that we are mounting the separately created /logs/boot and /logs/access folders on both the containers with emptydir: {} type. but somehow the access folder is getting deleted. when we tested this setup in local docker it produced desired results and things were working fine but not when deployed in the eks fargate. below is our manifest files
dockerfile
from anapsix/alpine-java:8u201b09_server-jre_nashorn

arg log_dir=/logs

# install base packages
run apk update
run apk upgrade
# run apk add ca-certificates &amp;&amp; update-ca-certificates

# dynamically set the java_home path
run export java_home=&quot;$(dirname $(dirname $(readlink -f $(which java))))&quot; &amp;&amp; echo $java_home

# add curl
run apk --no-cache add curl

run mkdir -p $log_dir/boot $log_dir/access
run chmod -r 0777 $log_dir/*

# add metadata to the image to describe which port the container is listening on at runtime.

# change timezone
run apk add --update tzdata
env tz=&quot;asia/kolkata&quot;

# clean apk cache
run rm -rf /var/cache/apk/*

# setting java home
env java_home=/opt/jdk

# copy all files and folders
copy . .
run rm -rf /opt/jdk/jre/lib/security/cacerts
copy cacerts /opt/jdk/jre/lib/security/cacerts
copy standalone.xml /jboss-eap-6.4-integration/standalone/configuration/

# set the working directory.
workdir /jboss-eap-6.4-integration/bin

expose 8177

cmd [&quot;./erctl&quot;]

deployment
apiversion: apps/v1
kind: deployment
metadata:
  name: vinintegrator
  namespace: eretail
  labels:
    app: vinintegrator
    pod: fargate
spec:
  selector:
    matchlabels:
      app: vinintegrator
      pod: fargate
  replicas: 2
  template:
    metadata:
      labels:
        app: vinintegrator
        pod: fargate
    spec:
      securitycontext:
        fsgroup: 0
      serviceaccount: eretail
      containers:
      - name: vinintegrator
        imagepullpolicy: ifnotpresent
        image: 653580443710.dkr.ecr.ap-southeast-1.amazonaws.com/vinintegrator-service:latest
        resources:
          limits:
            memory: &quot;7629mi&quot;
            cpu: &quot;1.5&quot;
          requests:
            memory: &quot;5435mi&quot;
            cpu: &quot;750m&quot;
        ports:
        - containerport: 8177
          protocol: tcp
        # securitycontext:
          # runasuser: 506
          # runasgroup: 506
        volumemounts:
          - mountpath: /jboss-eap-6.4-integration/bin
            name: bin
          - mountpath: /logs
            name: logs
      - name: fluent-bit
        image: 657281243710.dkr.ecr.ap-southeast-1.amazonaws.com/fluent-bit:latest
        imagepullpolicy: ifnotpresent
        env:
          - name: host_name
            valuefrom:
              fieldref:
                fieldpath: spec.nodename
          - name: pod_name
            valuefrom:
              fieldref:
                fieldpath: metadata.name
          - name: pod_namespace
            valuefrom:
              fieldref:
                fieldpath: metadata.namespace
        resources:
          limits:
            memory: 200mi
          requests:
            cpu: 200m
            memory: 100mi
        volumemounts:
        - name: fluent-bit-config
          mountpath: /fluent-bit/etc/
        - name: logs
          mountpath: /logs
          readonly: true
      volumes:
        - name: fluent-bit-config
          configmap:
            name: fluent-bit-config
        - name: logs
          emptydir: {}
        - name: bin
          persistentvolumeclaim:
            claimname: vinintegrator-pvc

below is the /logs folder ownership and permission. please notice the 's' in drwxrwsrwx
drwxrwsrwx    3 root     root          4096 oct  1 11:50 logs

below is the content inside logs folder. please notice the access folder is not created or deleted.
/logs # ls -lrt
total 4
drwxr-sr-x    2 root     root          4096 oct  1 11:50 boot
/logs #

below is the configmap of fluent-bit
apiversion: v1
kind: configmap
metadata:
  name: fluent-bit-config
  namespace: eretail
  labels:
    k8s-app: fluent-bit
data:
  fluent-bit.conf: |
    [service]
        flush                     5
        log_level                 info
        daemon                    off
        parsers_file              parsers.conf
        http_server               on
        http_listen               0.0.0.0
        http_port                 2020
        
    @include application-log.conf
  
  application-log.conf: |
    [input]
        name                tail
        path                /logs/boot/*.log
        tag                 boot
        
    [input]
        name                tail
        path                /logs/access/*.log
        tag                 access
        
    [output]
        name                cloudwatch_logs
        match               *boot*
        region              ap-southeast-1
        log_group_name      eks-fluent-bit
        log_stream_prefix   boot-log-
        auto_create_group   on
        
    [output]
        name                cloudwatch_logs
        match               *access*
        region              ap-southeast-1
        log_group_name      eks-fluent-bit
        log_stream_prefix   access-log-
        auto_create_group   on
        
  parsers.conf: |
    [parser]
        name                docker
        format              json
        time_key            time
        time_format         %y-%m-%dt%h:%m:%s.%lz

below is error log of fluent-bit container
aws for fluent bit container image version 2.14.0
fluent bit v1.7.4
* copyright (c) 2019-2021 the fluent bit authors
* copyright (c) 2015-2018 treasure data
* fluent bit is a cncf sub-project under the umbrella of fluentd
* https://fluentbit.io

[2021/10/01 06:20:33] [ info] [engine] started (pid=1)
[2021/10/01 06:20:33] [ info] [storage] version=1.1.1, initializing...
[2021/10/01 06:20:33] [ info] [storage] in-memory
[2021/10/01 06:20:33] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2021/10/01 06:20:33] [error] [input:tail:tail.1] read error, check permissions: /logs/access/*.log
[2021/10/01 06:20:33] [ warn] [input:tail:tail.1] error scanning path: /logs/access/*.log
[2021/10/01 06:20:38] [error] [net] connection #33 timeout after 5 seconds to: 169.254.169.254:80
[2021/10/01 06:20:38] [error] [net] socket #33 could not connect to 169.254.169.254:80

",<docker><kubernetes><amazon-eks><aws-fargate><fluent-bit>,69402891,2,"suggest remove the following from your dockerfile:
run mkdir -p $log_dir/boot $log_dir/access
run chmod -r 0777 $log_dir/*

use the following method to setup the log directories and permissions:
apiversion: v1  
kind: pod    # deployment
metadata:
  name: busy
  labels:
    app: busy
spec:
  volumes:
  - name: logs  # shared folder with ephemeral storage
    emptydir: {}

  initcontainers:    # setup your log directory here
  - name: setup
    image: busybox
    command: [&quot;bin/ash&quot;, &quot;-c&quot;]
    args:
    - &gt;
      mkdir -p /logs/boot /logs/access;
      chmod -r 777 /logs
    volumemounts:
    - name: logs
      mountpath: /logs

  containers:
  - name: app    # run your application and logs to the directories
    image: busybox
    command: [&quot;bin/ash&quot;,&quot;-c&quot;]
    args:
    - &gt;
      while :; do echo &quot;$(date): $(uname -r)&quot; | tee -a /logs/boot/boot.log /logs/access/access.log; sleep 1; done
    volumemounts:
    - name: logs
      mountpath: /logs

  - name: logger    # any logger that you like
    image: busybox
    command: [&quot;bin/ash&quot;,&quot;-c&quot;]
    args:           # tail the app logs, forward to cw etc...
    - &gt;
      sleep 5;
      tail -f /logs/boot/boot.log /logs/access/access.log
    volumemounts:
    - name: logs
      mountpath: /logs

the snippet runs on fargate as well, run kubectl logs -f busy -c logger to see the tailing. in real world, the &quot;app&quot; is your java app, &quot;logger&quot; is any log agent you desired. note fargate has native logging capability using aws fluent-bit, you do not need to run aws fluent-bit as sidecar.
"
69405454,bitnami odoo addons over init container not work,"i use the helm chart from bitnami https://bitnami.com/stack/odoo/helm for the odoo installation.
the chart works without problems. but what i do not manage is that i can download addons using git and an init container.
i have tried the following.
my init container
initcontainers:
  - name: git-hr-attendance
    image: bitnami/odoo
    command: [&quot;/bin/sh&quot;,&quot;-c&quot;
    args: ['apt-get -y update &amp;&amp; apt-get -y install git &amp;&amp; git clone https://github.com/oca/hr-attendance /bitnami/odoo']
    volumemounts:
      - name: odoo-data
        mountpath: /bitnami/odoo
        #subpath: addons

output logs
fatal: destination path '/bitnami/odoo' already exists and is not an empty directory.

what i also tried is to load the git repo into the /tmp folder but this has another effect the data is not copied from the /tmp folder to the /bitnami/odoo/addons folder.
but the folder /bitnami/odoo will be displayed in /tmp.
after that i adjusted the init container.
init container
initcontainers:
  - name: git-hr-attendance
    image: bitnami/odoo
    command: [&quot;/bin/sh&quot;,&quot;-c&quot;
    args: ['apt-get -y update &amp;&amp; apt-get -y install git &amp;&amp; git clone https://github.com/oca/hr-attendance /bitnami/odoo/addons']
    volumemounts:
      - name: odoo-data
        mountpath: /bitnami/odoo
        subpath: addons

output logs
cloning into '/bitnami/odoo/addons'...

the data is now copied but after that the config file is no longer available.
odoo 11:45:27.24 

odoo 11:45:27.24 welcome to the bitnami odoo container

odoo 11:45:27.24 subscribe to project updates by watching https://github.com/bitnami/bitnami-docker-odoo

odoo 11:45:27.24 submit issues and feature requests at https://github.com/bitnami/bitnami-docker-odoo/issues

odoo 11:45:27.24 

odoo 11:45:27.26 info  ==&gt; validating settings in postgresql_client_* env vars

odoo 11:45:27.32 info  ==&gt; restoring persisted odoo installation

odoo 11:45:27.36 info  ==&gt; trying to connect to the database server

grep: /opt/bitnami/odoo/conf/odoo.conf: no such file or directory

does anyone have an idea or experience with odoo what to do about this. so that i can download my addons via git per init container.
",<kubernetes><kubernetes-helm><bitnami><odoo-14>,69463991,1,"the problem you are seeing is related to the way the odoo image verifies if it should initialize the app or instead restore an old installation at the setup stage. if it finds that the /bitnami/odoo/ directory is not empty it will do the latter (link), and so the
grep: /opt/bitnami/odoo/conf/odoo.conf: no such file or directory

is displayed because it tries to find files that should have being created from a previous installation (there are symlinks between some folders in /opt/bitnami/odoo and /bitnami/odoo).
you can modify the image at this point to add your custom logic.
"
68021355,how to specify serviceaccountname for pods in gke deployment.yaml,"i've configured my cluster and node pools for workload identity (https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) but in order to get it to work, i need to also make my pods use the kubernetes service account i created for the workload identity.
i see i can specify the serviceaccountname in a pod's yaml, but how can i do this using google ci/cd which uses deployment.yaml?  or can i somehow reference a pod's yaml for use as a spec template within my deployment.yaml?  sorry, i am new to k8s!
ref. https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
essentially, i am just trying to get workload identity to work with my application so the google_application_credentials is set by google for use within my app!
i've tried the following in my deployment.yaml but i get the error unknown field &quot;serviceaccountname&quot; in io.k8s.api.core.v1.container;:
spec:
  replicas: 3
  selector:
    matchlabels:
      app: my-application
  strategy:
    rollingupdate:
      maxsurge: 25%
      maxunavailable: 25%
    type: rollingupdate
  template:
    metadata:
      labels:
        app: my-application
    spec:
      containers:
        - image: &gt;-
            gcr.io/my-project/github.com/my-org/my-repo
          imagepullpolicy: ifnotpresent
          name: my-application
          serviceaccountname: my-k8s-svc-acct

",<kubernetes><google-kubernetes-engine><workload-identity>,68022016,11,"serviceaccountname is a property of the pod spec object, not the container. so, it should be:
spec:
  replicas: 3
  selector:
    matchlabels:
      app: my-application
  strategy:
    rollingupdate:
      maxsurge: 25%
      maxunavailable: 25%
    type: rollingupdate
  template:
    metadata:
      labels:
        app: my-application
    spec:
      serviceaccountname: my-k8s-svc-acct
      containers:
        - image: &gt;-
            gcr.io/my-project/github.com/my-org/my-repo
          imagepullpolicy: ifnotpresent
          name: my-application
      

"
55831507,aws alb unhealthy target after rolling update of deployment,"i have a eks cluster with the aws-alb-ingress-controller controlling the setup of the aws alb pointing to the eks cluster. 

after a rolling update of one of the deployments, the application failed, causing the pod to never start (the pod is stuck in status crashloopbackoff). however the previous version of the pod is still running. but it seems like the status of the service is still unhealthy:



this means now all traffic is redirected to the default backend, a different service. in this case in kubernetes the related service for the deployment is of type nodeport:

type:                     nodeport
ip:                       172.20.186.130
port:                     http-service  80/tcp
targetport:               5000/tcp
nodeport:                 http-service  31692/tcp
endpoints:                10.0.3.55:5000


what is causing the endpoint to become unhealthy? i expected it to just redirect traffic to the old version of the pod that is still running. is there any way were i can ensure that the endpoint remains healthy?
",<kubernetes><kubernetes-ingress><amazon-eks><amazon-alb>,55849536,2,"the problem was that while in kubernetes the application was healthy, the alb load-balancer performed it's own health check. this health check was configured by default to expect a 200 response from the / endpoint, however for this specific application it did not return a 200 response on that endpoint. 

since the alb is controlled by the alb-ingress-controller, i added an annotation on my ingress to configure the correct path: alb.ingress.kubernetes.io/healthcheck-path:  /health. since we are working with spring microservices this endpoint works for all our applications.
"
65326097,"kubernetes - for scale, pod is pending when attached the persistent volumes while scaling the pod (gke)","i have created a deployment in the xyz-namespace namespace, it has pvc. i can create the deployment and able to access it. it is working properly but while scale the deployment from the kubernetes console then the pod is pending state only.
persistent_claim:
  apiversion: v1
  kind: persistentvolumeclaim
  metadata:
    name: jenkins
  spec:
    accessmodes:
    - readwriteonce
    storageclassname: standard
    resources:
      requests:
        storage: 5gi
namespace: xyz-namespace

and deployment object is like below.
apiversion: apps/v1
kind: deployment
metadata:
  name: db-service
  labels:
    k8s-app: db-service
    name:db-service
    servicename: db-service
spec:
  selector:
    matchlabels:
      tier: data
      name: db-service
      servicename: db-service
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: jenkins
        tier: data
        name: db-service
        servicename: db-service
    spec:
      hostname: jenkins
      initcontainers:
      - command:
        - &quot;/bin/sh&quot;
        - &quot;-c&quot;
        - chown -r 1000:1000 /var/jenkins_home
        image: busybox
        imagepullpolicy: always
        name: jenkins-init
        volumemounts:
        - name: jenkinsvol
          mountpath: &quot;/var/jenkins_home&quot;
      containers:
      - image: jenkins/jenkins:lts
        name: jenkins
        ports:
        - containerport: 8080
          name: jenkins1
        - containerport: 8080
          name: jenkins2
        volumemounts:
        - name: jenkinsvol
          mountpath: &quot;/var/jenkins_home&quot;
      volumes:
      - name: jenkinsvol
        persistentvolumeclaim:
          claimname: jenkins
      nodeselector:
        nodegroup: xyz-testing
namespace: xyz-namespace
replicas: 1

deployment is created fine and working as well but
when i am trying to scale the deployment from console then the pod is getting stuck and it's pending state only.
if i removed the persistent volume and then scaled it then it is working fine, but with persistent volume, it is not working.
",<kubernetes><google-kubernetes-engine><persistent-volumes>,65347675,1,"when using standard storage class i assume you are using the default gcepersisentdisk volume plugin. in this case you cannot set them at all as they are already set by the storage provider (gcp in your case, as you are using gce perisistent disks), these disks only support readwriteonce(rwo) and readonlymany (rox) access modes. if you try to create a readwritemany(rwx) pv that will never come in a success state (your case when set the pvc with accessmodes: readwritemany).
also if any pod tries to attach a readwriteonce volume on some other node, you’ll get following error:
failedmount failed to attach volume &quot;pv0001&quot; on node &quot;xyz&quot; with: googleapi: error 400: the disk resource 'abc' is already being used by 'xyz'

references from above on this article
as mentioned here and here, nfs is the easiest way to get readwritemany as all nodes need to be able to readwritemany to the storage device you are using for your pods.
then i would suggest you to use an nfs storage option. in case you want to test it, here is a good guide by google using its filestore solution which are fully managed nfs file servers.
"
42170380,how to add users to kubernetes (kubectl)?,"i've created a kubernetes cluster on aws with kops and can successfully administer it via kubectl from my local machine.

i can view the current config with kubectl config view as well as directly access the stored state at ~/.kube/config, such as:

apiversion: v1
clusters:
- cluster:
    certificate-authority-data: redacted
    server: https://api.{cluster_name}
  name: {cluster_name}
contexts:
- context:
    cluster: {cluster_name}
    user: {cluster_name}
  name: {cluster_name}
current-context: {cluster_name}
kind: config
preferences: {}
users:
- name: {cluster_name}
  user:
    client-certificate-data: redacted
    client-key-data: redacted
    password: redacted
    username: admin
- name: {cluster_name}-basic-auth
  user:
    password: redacted
    username: admin


i need to enable other users to also administer. this user guide describes how to define these on another users machine, but doesn't describe how to actually create the user's credentials within the cluster itself. how do you do this?

also, is it safe to just share the cluster.certificate-authority-data?
",<kubernetes><kubectl><kops>,42186135,111,"for a full overview on authentication, refer to the official kubernetes docs on authentication and authorization
for users, ideally you use an identity provider for kubernetes (openid connect).
if you are on gke / acs you integrate with respective identity and access management frameworks
if you self-host kubernetes (which is the case when you use kops), you may use coreos/dex to integrate with ldap / oauth2 identity providers - a good reference is this detailed 2 part sso for kubernetes article.
kops (1.10+) now has built-in authentication support which eases the integration with aws iam as identity provider if you're on aws.
for dex there are a few open source cli clients as follows:

nordstrom/kubelogin
pusher/k8s-auth-example

if you are looking for a quick and easy (not most secure and easy to manage in the long run) way to get started, you may abuse serviceaccounts - with 2 options for specialised policies to control access. (see below)
note since 1.6  role based access control is strongly recommended! this answer does not cover rbac setup
edit: great, but outdated (2017-2018), guide by bitnami on user setup with rbac is also available.
steps to enable service account access are (depending on if your cluster configuration includes rbac or abac policies, these accounts may have full admin rights!):
edit: here is a bash script to automate service account creation - see below steps

create service account for user alice
kubectl create sa alice


get related secret
secret=$(kubectl get sa alice -o json | jq -r .secrets[].name)


get ca.crt from secret (using osx base64 with -d flag for decode)
kubectl get secret $secret -o json | jq -r '.data[&quot;ca.crt&quot;]' | base64 -d &gt; ca.crt


get service account token from secret
user_token=$(kubectl get secret $secret -o json | jq -r '.data[&quot;token&quot;]' | base64 -d)


get information from your kubectl config (current-context, server..)
# get current context
c=$(kubectl config current-context)

# get cluster name of context
name=$(kubectl config get-contexts $c | awk '{print $3}' | tail -n 1)

# get endpoint of current context 
endpoint=$(kubectl config view -o jsonpath=&quot;{.clusters[?(@.name == \&quot;$name\&quot;)].cluster.server}&quot;)


on a fresh machine, follow these steps (given the ca.cert and $endpoint information retrieved above:

install kubectl
 brew install kubectl


set cluster (run in directory where ca.crt is stored)
 kubectl config set-cluster cluster-staging \
   --embed-certs=true \
   --server=$endpoint \
   --certificate-authority=./ca.crt


set user credentials
 kubectl config set-credentials alice-staging --token=$user_token


define the combination of alice user with the staging cluster
 kubectl config set-context alice-staging \
   --cluster=cluster-staging \
   --user=alice-staging \
   --namespace=alice


switch current-context to alice-staging for the user
 kubectl config use-context alice-staging





to control user access with policies (using abac), you need to create a policy file (for example):
{
  &quot;apiversion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;,
  &quot;kind&quot;: &quot;policy&quot;,
  &quot;spec&quot;: {
    &quot;user&quot;: &quot;system:serviceaccount:default:alice&quot;,
    &quot;namespace&quot;: &quot;default&quot;,
    &quot;resource&quot;: &quot;*&quot;,
    &quot;readonly&quot;: true
  }
}

provision this policy.json on every master node and add --authorization-mode=abac --authorization-policy-file=/path/to/policy.json flags to api servers
this would allow alice (through her service account) read only rights to all resources in default namespace only.
"
66038882,gke regional disk for pvc and storageclass failover,"i have one pod which requires a persistent disk. i have 1 pod running on us-central1-a and if that zone goes down i want to migrate to another zone without data loss to another zone (us-central1-*).
is it possible to migrate a pod to another zone(where i know the disks exists) and use the regional disk for the pod in the new zone?
approach 1
using the below storageclass my pod is always unable to claim any of these and my pod never starts. i had the understanding this regional disk with all zones configured would make the disk available to all zones in case of zone failure. i do not understand why i cannot claim any of these.
kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: regionalpd-storageclass
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard
  replication-type: regional-pd
volumebindingmode: waitforfirstconsumer
allowedtopologies:
- matchlabelexpressions:
  - key: topology.kubernetes.io/zone
    values:
    - us-central1-a
    - us-central1-b
    - us-central1-c
    - us-central1-f

error: my pvc status is always pending
  normal   nottriggerscaleup  106s                cluster-autoscaler  pod didn't trigger scale-up (it wouldn't fit if a new node is added):
      warning  failedscheduling   62s (x2 over 108s)  default-scheduler   0/8 nodes are available: 8 node(s) didn't find available persistent volumes to bind.

attempt 2
this storage config will allow me to run my pod in 2/4 zones with 1 zone being the initial zone and 1 being random. when i intentionally reduce and move out of my initial pods zone i will get the below error unless i'm lucky enough to have chosen the other randomly provisioned zone. is this functionality intentional because google assumes a very low chance of 2 zone failures? if one does fail wouldn't i have to provision another disk in another zone just in case?
kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: regionalpd-storageclass
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard
  replication-type: regional-pd
volumebindingmode: waitforfirstconsumer

errors:
normal   nottriggerscaleup  4m49s                  cluster-autoscaler  pod didn't trigger scale-up (it wouldn't fit if a new node is added):
  warning  failedscheduling   103s (x13 over 4m51s)  default-scheduler   0/4 nodes are available: 2 node(s) had volume node affinity conflict, 2 node(s) were unschedulable.
  warning  failedscheduling   43s (x2 over 43s)      default-scheduler   0/3 nodes are available: 1 node(s) were unschedulable, 2 node(s) had volume node affinity conflict.
  warning  failedscheduling   18s (x3 over 41s)      default-scheduler   0/2 nodes are available: 2 node(s) had volume node affinity conflict.

my pvc
kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: my-pvc
  namespace: mynamespace
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 200gi
  storageclassname: regionalpd-storageclass

my pod volume
volumes:
  - name: console-persistent-volume
    persistentvolumeclaim:
      claimname: my-pvc

",<kubernetes><google-cloud-platform><google-kubernetes-engine><persistent-volumes><gce-persistent-disk>,66039078,3,"a regional persistent disk on google cloud is only available in two zones, so you must change your storageclass to only two zones.
see example storageclass on using kubernetes engine to deploy apps with regional persistent disks
and more details on gke: provisioning regional persistent disks
"
58251866,connect pods via service name in gcp k8's,"i have a number of services running against pods hosted within a cluster on google cloud k8's.

service 1 is an ingress - basic-ingress

service 2 is a nodejs api gateway w/ 2 pods - security-gateway-svc

service 3 is a nodejs api w/ 2 pods - some-random-api-svc

and so on service 4 / 5 / 6 etc....

my ingress allows me to access exposed services via a sub domain however i would like to move my external api's behind my gateway so i can handle auth etc in the gateway.

what i'd like to do is allow security-gateway-svc to connect to some-random-api-svc without having to go via dns or outside of my cluster.

i figured i could update my ingress so all sub domains use the same service entry and allow the gateway to figure out where the traffic should go.

i can configure this just fine locally as everything runs on localhost and i specify a port so it's fairly straight forward.

is it possible however to expose pods to other pods within a cluster via the service name instead of an actual domain / dns look up?
",<kubernetes><google-cloud-platform><kubernetes-ingress><kubernetes-pod>,58252025,1,"you service should be accessible within your cluster via the service name.

point your gateway entry for each api to the service name.

something like http://some-random-api-svc should work. 
"
53016760,taint a node in kubernetes live cluster,"how can i achieve the same command with a yaml file such that i can do a kubectl apply -f? the command below works and it taints but i can't figure out how to use it via a manifest file.

$ kubectl taint nodes \
          172.4.5.2-3a1d4eeb \
          kops.k8s.io/instancegroup=loadbalancer \
          noschedule

",<kubernetes><kubectl>,53016994,2,"use the -o yaml option and save the resulting yaml file and make sure to remove the status and some extra stuff, this will apply the taint , but provide you the yaml that you can later use to do kubectl apply -f , and save it to version control ( even if you create the resource from command line and later get the yaml and apply it , it will not re-create the resource , so it is perfectly fine )

note: most of the commands support --dry-run , that will just generate the yaml and not create the resource , but in this case , i could not make it work with --dry-run , may be this command does not support that flag.

c02w84xmhtd5:~ iahmad$ kubectl taint node minikube dedicated=foo:prefernoschedule -o yaml
apiversion: v1
kind: node
metadata:
  annotations:
    node.alpha.kubernetes.io/ttl: ""0""
    volumes.kubernetes.io/controller-managed-attach-detach: ""true""
  creationtimestamp: 2018-10-16t21:44:03z
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/os: linux
    kubernetes.io/hostname: minikube
    node-role.kubernetes.io/master: """"
  name: minikube
  resourceversion: ""291136""
  selflink: /api/v1/nodes/minikube
  uid: 99a1a304-d18c-11e8-9334-f2cf3c1f0864
spec:
  externalid: minikube
  taints:
  - effect: prefernoschedule
    key: dedicated
    value: foo


then use the yaml with kubectl apply:

apiversion: v1
kind: node
metadata:
  name: minikube
spec:
  taints:
  - effect: prefernoschedule
    key: dedicated
    value: foo

"
60907090,"""kubeadm upgrade apply v1.18.0-00"" does not seem to upgrade the master node","i'm quite confused here on this kubeadm upgrade.

as you can see from my screenclips below, my serverversion is stuck at v1.17.2 when displaying kubectl version -o json from my mac.  

when i'm on my master node, i issued the kubeadm upgrade plan and the system displays the kubeadm upgrade apply v1.18.0 to upgrade.

but, after the upgrade, my current version is still showing v1.17.2.

you can see from the 3rd screenclip with kubectl get nodes -o wide that the nodes are all showing v1.18.0.  

but, kubectl version -o json, still shows the serverversion at v1.17.2.

also, my k9s continues to show my k8s rev: v1.17.2

adding to the question.

why on the master node, when entering kubectl version would the client &amp; server versions be different?  which is shown in the 2nd to last screen clip below.

isn't the kubectl on the master node both the client &amp; server? i mean if i am ssh'd into the master node, and i use kubectl, am i not issuing a client request on the server itself? so, how can the client &amp; server versions be different?

can someone tell me what i am doing wrong?

thanks in advance.






",<kubernetes><upgrade><kubectl><kubeadm>,60952088,1,"the problem was that emacs had created its normal backup files in the /etc/kubernetes/manifests files, and this was creating the problem. i'm not sure why kubectl had an issue with these backup files, but after i removed these backups from the directory, you can see my kubectl version for the client &amp; server versions match.





thanks nick!
"
56045506,allow traffic to rabbitmq service from istio,"i've setup a k8s-cluster in gke and installed rabbitmq (from the marketplace) and istio (via helm). i can access rabbitmq from pods until i enable the envoy proxy to be injected into these pods, but after that the traffic will not reach rabbitmq, and i can't figure out how to enable traffic to the rabbitmq service.

there is a service rabbitmq-rabbitmq-svc (in the rabbitmq namespace) that is of type loadbalancer.
i've tried a simple busybox when i don't have envoy running and then i have no trouble telneting to rabbitmq (port 5672), but as soon as i try with automatic envoy injection envoy prevents the traffic.
i tried unsuccessfully to add a destinationrule. (i've added a rule but it makes no difference)

apiversion: networking.istio.io/v1alpha3
kind: destinationrule
metadata:
  name: rabbitmq-rabbitmq-svc
spec:
  host: rabbitmq.rabbitmq.svc.cluster.local
  trafficpolicy:
    loadbalancer:
      simple: least_conn


it seems like it should be a simple solution, but i can't figure it out... :/

update
turns out it was a simple error in the hostname, ended up using this and it works:

apiversion: networking.istio.io/v1alpha3
kind: destinationrule
metadata:
  name: rabbitmq-rabbitmq-svc
spec:
  host: rabbitmq-rabbitmq-svc.rabbitmq.svc.cluster.local

",<kubernetes><rabbitmq><google-kubernetes-engine><istio><envoyproxy>,56106626,2,"turns out it was a simple error in the hostname, the correct one was rabbitmq-rabbitmq-svc.rabbitmq.svc.cluster.local
"
74367496,terminationgraceperiodseconds in kind pod vs kind deployment,"i'm trying to set a grace shutdown period for my pods. i found out you can add a field called terminationgraceperiodseconds to the helm charts to set the period. i then looked for example and crossed upon these:
https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace
in the above link they define the value in a kind: pod template.
https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html
in the above link they define the value in a kind: deployment template.
is there a difference between the 2 kinds in regard to where i define this value?
",<kubernetes><kubernetes-helm>,74367912,3,"
is there a difference between the 2 kinds in regard to where i define this value?

a deployment has a field template: and that is actually a podtemplate (most structure of a pod) that includes the terminationgraceperiodseconds property.
a good way to check documentations for fields is to use kubectl explain.
e.g.
kubectl explain deployment.spec.template.spec

and
kubectl explain pod.spec

"
60375691,how to make kubernetes cronjob to identify ssh key from a folder,"i have create cron job in kubernetes and i have ssh key in one of  pod directory. when i am executing from command line its working fine, but when i am manually triggered , cron job is not recognizing .ssh folder .

scp -i  /srv/batch/source/.ssh/id_rsa   user@server:/home/data/openings.csv  /srv/batch/source



",<kubernetes><scp><kubernetes-cronjob>,60378586,1,"when you log into a remote host from your container, the remote host key is  unknown to your ssh client inside the container

usually, you're asked to confirm its fingerprint:

the authenticity of host ***** can't be established.
rsa key fingerprint is *****.
are you sure you want to continue connecting (yes/no)?


but as there is no interactive shell, the ssh client fails.

two solutions:


add the host key in the file ~/.ssh/known_hosts in the container
disable host key check (dangerous as no remote host authentication is performed)

ssh -o ""stricthostkeychecking=no"" user@host

"
37987390,"can not start multiple containers in a pod-error syncing pod, skipping","my kubectl version

client version: version.info{major:""1"", minor:""2"", gitversion:""v1.2.4"", gitcommit:""3eed1e3be6848b877ff80a93da3785d9034d0a4f"", gittreestate:""clean""}
server version: version.info{major:""1"", minor:""2"", gitversion:""v1.2.4"", gitcommit:""3eed1e3be6848b877ff80a93da3785d9034d0a4f"", gittreestate:""clean""}


i followed creating multi-container pods

after launching the pod, one container is up but not other.

kubectl get pods

name                    ready     status             restarts   age
redis-django            1/2       crashloopbackoff   9          22m


then i did kubectl describe redis-django. at the bottom i saw error syncing pod, skipping error

  31m   &lt;invalid&gt;       150     {kubelet 172.25.30.21}  spec.containers{frontend}       warning backoff         back-off restarting failed docker container
  25m   &lt;invalid&gt;       121     {kubelet 172.25.30.21}                                  warning failedsync      error syncing pod, skipping: failed to ""startcontainer"" for ""frontend"" with crashloopbackoff: ""back-off 5m0s restarting failed container=frontend pod=redis-django_default(9f35ffcd-391e-11e6-b160-0022195df673)""


how can i reslove this error? any help!

thanks!

os: ubuntu 14

update

previsoly i used below yaml file which was found at creating multi-container pods

apiversion: v1
kind: pod
metadata:
  name: redis-django
  labels:
    app: web
spec:
  containers:
    - name: key-value-store
      image: redis
      ports:
        - containerport: 6379
    - name: frontend
      image: django
      ports:
        - containerport: 8000


frontend container was not started. then i changed the yaml file to two redis containers with different names and ports. but, the result is same(getting error syncing pod, skipping)

later i have changed yaml file to, only one django container. this pod status crashloopbackoff and the error syncing pod, skipping

update-2

i tail -f /var/log/upstart/kublet.log, which is giving same error. kubelet is continously trying to start the container, but it is not!

i0623 12:15:13.943046     445 manager.go:2050] back-off 5m0s restarting failed container=key-value-store pod=redis-django_default(94683d3c-392e-11e6-b160-0022195df673)
e0623 12:15:13.943100     445 pod_workers.go:138] error syncing pod 94683d3c-392e-11e6-b160-0022195df673, skipping: failed to ""startcontainer"" for ""key-value-store"" with crashloopbackoff: ""back-off 5m0s restarting failed container=key-value-store pod=redis-django_default(94683d3c-392e-11e6-b160-0022195df673)""


update-3

root@vm1:~/kubernetes/cluster/ubuntu/binaries# kubectl describe pod redis-django
name:           redis-django
namespace:      default
node:           192.168.1.10/192.168.1.10
start time:     thu, 23 jun 2016 22:58:03 -0700
labels:         app=web
status:         running
ip:             172.16.20.2
controllers:    &lt;none&gt;
containers:
  key-value-store:
    container id:       docker://8dbdd6826c354243964f0306427082223d3da49bf2aaf30e15961ea00362fe42
    image:              redis
    image id:           docker://sha256:4465e4bcad80b5b43cef0bace96a8ef0a55c0050be439c1fb0ecd64bc0b8cce4
    port:               6379/tcp
    qos tier:
      cpu:              besteffort
      memory:           besteffort
    state:              running
      started:          thu, 23 jun 2016 22:58:10 -0700
    ready:              true
    restart count:      0
    environment variables:
  frontend:
    container id:       docker://9c89602739abe7331b3beb3a79e92a7cc42e2a7e40e11618413c8bcfd0afbc16
    image:              django
    image id:           docker://sha256:0cb63b45e2b9a8de5763fc9c98b79c38b6217df718238251a21c8c4176fb3d68
    port:               8000/tcp
    qos tier:
      cpu:              besteffort
      memory:           besteffort
    state:              terminated
      reason:           completed
      exit code:        0
      started:          thu, 23 jun 2016 22:58:41 -0700
      finished:         thu, 23 jun 2016 22:58:41 -0700
    last state:         terminated
      reason:           completed
      exit code:        0
      started:          thu, 23 jun 2016 22:58:22 -0700
      finished:         thu, 23 jun 2016 22:58:22 -0700
    ready:              false
    restart count:      2
    environment variables:
conditions:
  type          status
  ready         false 
volumes:
  default-token-0oq7p:
    type:       secret (a volume populated by a secret)
    secretname: default-token-0oq7p
events:
  firstseen     lastseen        count   from                    subobjectpath                           type            reason           message
  ---------     --------        -----   ----                    -------------                           --------        ------           -------
  49s           49s             1       {default-scheduler }                                            normal          scheduled        successfully assigned redis-django to 192.168.1.10
  48s           48s             1       {kubelet 192.168.1.10}  spec.containers{key-value-store}        normal          pulling          pulling image ""redis""
  43s           43s             1       {kubelet 192.168.1.10}  spec.containers{key-value-store}        normal          pulled           successfully pulled image ""redis""
  43s           43s             1       {kubelet 192.168.1.10}  spec.containers{key-value-store}        normal          created          created container with docker id 8dbdd6826c35
  42s           42s             1       {kubelet 192.168.1.10}  spec.containers{key-value-store}        normal          started          started container with docker id 8dbdd6826c35
  37s           37s             1       {kubelet 192.168.1.10}  spec.containers{frontend}               normal          started          started container with docker id 3872ceae75d4
  37s           37s             1       {kubelet 192.168.1.10}  spec.containers{frontend}               normal          created          created container with docker id 3872ceae75d4
  30s           30s             1       {kubelet 192.168.1.10}  spec.containers{frontend}               normal          created          created container with docker id d97b99b6780c
  30s           30s             1       {kubelet 192.168.1.10}  spec.containers{frontend}               normal          started          started container with docker id d97b99b6780c
  29s           29s             1       {kubelet 192.168.1.10}                                          warning         failedsync       error syncing pod, skipping: failed to ""startcontainer"" for ""frontend"" with crashloopbackoff: ""back-off 10s restarting failed container=frontend pod=redis-django_default(9d0a966a-39d0-11e6-9027-000c293d51ab)""

  42s   16s     3       {kubelet 192.168.1.10}  spec.containers{frontend}       normal  pulling         pulling image ""django""
  11s   11s     1       {kubelet 192.168.1.10}  spec.containers{frontend}       normal  started         started container with docker id 9c89602739ab
  38s   11s     3       {kubelet 192.168.1.10}  spec.containers{frontend}       normal  pulled          successfully pulled image ""django""
  11s   11s     1       {kubelet 192.168.1.10}  spec.containers{frontend}       normal  created         created container with docker id 9c89602739ab
  29s   10s     2       {kubelet 192.168.1.10}  spec.containers{frontend}       warning backoff         back-off restarting failed docker container
  10s   10s     1       {kubelet 192.168.1.10}                                  warning failedsync      error syncing pod, skipping: failed to ""startcontainer"" for ""frontend"" with crashloopbackoff: ""back-off 20s restarting failed container=frontend pod=redis-django_default(9d0a966a-39d0-11e6-9027-000c293d51ab)""


for container frontend: not showing any logs messages

root@vm1:~/kubernetes/cluster/ubuntu/binaries# kubectl logs redis-django -p -c frontend
root@vm1:~/kubernetes/cluster/ubuntu/binaries# kubectl logs redis-django -p -c key-value-store
error from server: previous terminated container ""key-value-store"" in pod ""redis-django"" not found
root@vm1:~/kubernetes/cluster/ubuntu/binaries# docker ps
container id        image                                command                  created             status              ports               names
8dbdd6826c35        redis                                ""docker-entrypoint.sh""   2 minutes ago       up 2 minutes                            k8s_key-value-store.f572c2d_redis-django_default_9d0a966a-39d0-11e6-9027-000c293d51ab_11101aea
8995bbf9f4f4        gcr.io/google_containers/pause:2.0   ""/pause""                 2 minutes ago       up 2 minutes                            k8s_pod.48e5231f_redis-django_default_9d0a966a-39d0-11e6-9027-000c293d51ab_c00025b0
root@vm1:~/kubernetes/cluster/ubuntu/binaries#

",<kubernetes><kubernetes-pod>,38020091,2,"ah...your django container exited voluntarily without any error message, right after it was started, and that's expected. 

the django image comes with a default command of python3. without overriding the command/args in the pod yaml file, the container will exit immediately.

the doc you followed was simply trying to show how to create multiple containers in a pod, but the example is not realistic and doesn't set up a working application. feel free to file a github issue against https://github.com/kubernetes/kubernetes.github.io
"
76685608,deployment failed: http probe failed with statuscode: 500,"i am having two cluster cluster-1 and cluster-2.
in cluster-1 deployed service-1 in the namespace test-namespace-1. it got deployed successfully and running.
in cluster-2 deployed service-1 in the namespace test-namespace-1. deployment status showing error as http probe failed with statuscode: 500
when i checked the details, it has two conditions

processing status as true
available status as false and reason is minimumreplicaunavailable

i checked both namespaces quota details.

limits.cpu - used:43 hard:90
limits.memory - used:65000mi hard:96gi
persistencevolumeclaims - used:8 hard:10
pods - used:35 hard:65

other details like request's storage, cpu etc have almost 40% available but in one clsuetr's namespace it is showing success and running and in another cluaster's namespace failed.
",<kubernetes><kubernetes-deployment>,76705108,1,"it got fixed, actual issue is due to deployment.yml file, liveness and readyness probes are mapped to 8090 but start probe was mapped to 8080 by the team. due to this deployment got failed.
"
69189695,k8s groundnuty/k8s-wait-for image failing to start as init container (with helm),"i'm facing a problem with the image groundnuty/k8s-wait-for. project at github and repo at dockerhub.
i'm pretty sure that error is in command arguments, as the init container fails with init:crashloopbackoff.
about image:
this image is used for init containers, which need to postpone a pod deployment. the script that is in the image waits for the pod or job to complete, after it completes it lets the main container and all replicas start deploying.
in my example, it should wait for a job named {{ .release.name }}-os-server-migration-{{ .release.revision }} to finish, and after it detects it is finished it should let main containers start. helm templates are used.
by my understanding, the job name is {{ .release.name }}-os-server-migration-{{ .release.revision }} and the second command argument at the init container in deployment.yml needs to be the same so the init container can depend on the named job. any other opinions or experiences with this approach?
there are templates attached.
deployment.yml:
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ .release.name }}-os-{{ .release.revision }}
  namespace: {{ .values.namespace }}
  labels:
    app: {{ .values.fullname }}
spec:
  replicas: {{ .values.replicacount }}
  selector:
    matchlabels:
      app: {{ .values.fullname }}
  template:
    metadata:
      labels:
        app: {{ .values.fullname }}
    spec:
      {{- with .values.imagepullsecrets }}
      imagepullsecrets:
        {{- toyaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: {{ .chart.name }}
          image: &quot;{{ .values.image.repository }}:{{ .values.image.tag }}&quot;
          imagepullpolicy: {{ .values.image.pullpolicy }}
          ports:
            - name: http
              containerport: 8080
          resources:
            {{- toyaml .values.resources | nindent 12 }}
      initcontainers:
        - name: &quot;{{ .chart.name }}-init&quot;
          image: &quot;groundnuty/k8s-wait-for:v1.3&quot;
          imagepullpolicy: &quot;{{ .values.init.pullpolicy }}&quot;
          args:
            - &quot;job&quot;
            - &quot;{{ .release.name }}-os-server-migration-{{ .release.revision }}&quot;

job.yml:
apiversion: batch/v1
kind: job
metadata:
  name: {{ .release.name }}-os-server-migration-{{ .release.revision }}
  namespace: {{ .values.migration.namespace }}
spec:
  backofflimit: {{ .values.migration.backofflimit }}
  template:
    spec:
      {{- with .values.migration.imagepullsecrets }}
      imagepullsecrets:
        {{- toyaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: {{ .values.migration.fullname }}
          image: &quot;{{ .values.migration.image.repository }}:{{ .values.migration.image.tag }}&quot;
          imagepullpolicy: {{ .values.migration.image.pullpolicy }}
          command:
            - sh
            - /app/migration-entrypoint.sh
      restartpolicy: {{ .values.migration.restartpolicy }}

logs:
  normal   scheduled  46s                default-scheduler  successfully assigned development/octopus-dev-release-os-1-68cb9549c8-7jggh to minikube
  normal   pulled     41s                kubelet            successfully pulled image &quot;groundnuty/k8s-wait-for:v1.3&quot; in 4.277517553s
  normal   pulled     36s                kubelet            successfully pulled image &quot;groundnuty/k8s-wait-for:v1.3&quot; in 3.083126925s
  normal   pulling    20s (x3 over 45s)  kubelet            pulling image &quot;groundnuty/k8s-wait-for:v1.3&quot;
  normal   created    18s (x3 over 41s)  kubelet            created container os-init
  normal   started    18s (x3 over 40s)  kubelet            started container os-init
  normal   pulled     18s                kubelet            successfully pulled image &quot;groundnuty/k8s-wait-for:v1.3&quot; in 1.827195139s
  warning  backoff    4s (x4 over 33s)   kubelet            back-off restarting failed container

kubectl get all -n development
name                                                        ready   status                  restarts   age
pod/octopus-dev-release-os-1-68cb9549c8-7jggh   0/1     init:crashloopbackoff   2          44s
pod/octopus-dev-release-os-1-68cb9549c8-9qbdv   0/1     init:crashloopbackoff   2          44s
pod/octopus-dev-release-os-1-68cb9549c8-c8h5k   0/1     init:error              2          44s
pod/octopus-dev-release-os-migration-1-9wq76    0/1     completed               0          44s
......
......
name                                                       completions   duration   age
job.batch/octopus-dev-release-os-migration-1   1/1           26s        44s


",<kubernetes><kubernetes-helm>,69343497,2,"for anyone facing the same issue, i will explain my fix.
problem was that the containers inside deployment.yaml had no permissions to use kube api. so, groundnuty/k8s-wait-for:v1.3 container could not check has the job {{ .release.name }}-os-server-migration-{{ .release.revision }} completed or not. that's why init containers instantly failed with crashlooperror.
after adding service account, role, and role binding everything worked great, and groundnuty/k8s-wait-for:v1.3 successfully waited for the job(migration) to finish, in order to let the main container run.
here are the examples of the code for the service account, role, and role binding that solved the issue.
sa.yaml
apiversion: v1
kind: serviceaccount
metadata:
  name: sa-migration
  namespace: development

role.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  name: migration-reader
rules:
  - apigroups: [&quot;batch&quot;,&quot;extensions&quot;]
    resources: [&quot;jobs&quot;]
    verbs: [&quot;get&quot;,&quot;watch&quot;,&quot;list&quot;]

role-binding.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: migration-reader
subjects:
- kind: serviceaccount
  name: sa-migration
roleref:
  kind: role
  name: migration-reader
  apigroup: rbac.authorization.k8s.io

"
65918338,how to read value from yaml file which are in dictionary and need to use in helm,"this is my string in values.yaml:
selectorlabels: { app.kubernetes.io/name: tinyurl }
yaml file looks like below:
name: test-dj-service
environment: prod
namespace: test-service
labels: { app.kubernetes.io/name: test-dj-service, environment: prod }
replicacount: 1
selectorlabels: { app.kubernetes.io/name: tinyurl } &lt;---


i need to use tinyurl in the below code under values.
note:- tinyurl is variable, it will keep changing with other names.

{‌{ - if .values.affinity.podantiaffinity.preferred == true }}
        podantiaffinity:
          preferredduringschedulingignoredduringexecution:
          - weight: 100
            podaffinityterm:
              labelselector:
                 matchexpressions:
                 - key: app.kubernetes.io/name
                   operator: in
                   values: {‌{ ---------- }} # need to pull the selectorlabels values here.
              topologykey: &quot;kubernetes.io/hostname&quot;
{‌{- end }}

so how i can pull this variable into values.
",<json><kubernetes><yaml><kubernetes-helm>,65922553,1,"in addition to @shashankv's answer, you should also be able to construct your label selector using a range expression (in case you want to support arbitrary label selectors, with multiple labels that are read from your values file):
labelselector:
  matchexpressions:
  {{- range $key, $value := .values.selectorlabels }}
  - key: {{ $key | quote }}
    operator: in
    values: {‌{ $value | quote }}
  {{- end }}

"
73036176,why am i getting `0/1 nodes are available` when running docker desktop?,"i'm running docker desktop with kubernetes.
i can ssh to the node and i have other pods running on the node.
however, when i apply a statefulset to the cluster i get:
0/1 nodes are available: 1 pod has unbound immediate persistentvolumeclaims. preemption: 0/1 nodes are available: 1 preemption is not helpful for scheduling.

the stateful set is here:
https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#components
kubectl get no
name             status   roles           age    version
docker-desktop   ready    control-plane   6d2h   v1.24.1

",<docker><kubernetes><kubernetes-statefulset>,73040151,7,"if you are applying the manifest defined here as it is, the problem is in the below snippet, particularly with the storageclassname.  likely, your cluster does not have a storage class called my-storage-class.
 volumeclaimtemplates:
  - metadata:
      name: www
    spec:
      accessmodes: [ &quot;readwriteonce&quot; ]
      storageclassname: &quot;my-storage-class&quot;
      resources:
        requests:
          storage: 1gi

to get the definitive error statement, you can run the following command:
kubectl describe  pvc www-web-0

you will notice something like:
storageclass.storage.k8s.io &quot;my-storage-class&quot; not found

solution:
you can run the following command to get your cluster's available storage class and replace it in yaml file.
kubectl get sc

alternatively, you can delete the storageclassname and let the default storage class do the magic. however, for this to work, you must have a default sc present in your cluster.
if you have no storage class present, you need to create one. check this out.
"
63968881,unable to connect internet from pod after applying egress network policy in gke,"i have a pod (kubectl run app1 --image tomcat:7.0-slim) in gke after applying the egress network policy apt-get update command unable to connect internet.
before applying policy:

after applying policy:

this is the policy applied:
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: app2-np
  namespace: default
spec:
  podselector:
    matchlabels:
      name: app2
  policytypes:
  - egress
  - ingress
  ingress:
  - {}
  egress:
  - to:
    - podselector:
        matchlabels:
          name: app3
    ports:
    - port: 8080

  - ports:
    - port: 80
    - port: 53
    - port: 443

the here am able to connect 8080 port of app3 pod in same namespace. please help in correcting my netpol.
",<kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-ingress><gke-networking>,63990014,1,"it happens because you are defining the egress rule only for app3 on port 8080, and it will block all internet connect attempts.
if you need to use access internet from some of your pods, you can tag them and create a networkpolicy to permit the internet access.
in the example below, the pods with the tag networking/allow-internet-egress: &quot;true&quot; will be able to reach the internet:
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: internet-egress
spec:
  podselector:
    matchlabels:
      networking/allow-internet-egress: &quot;true&quot;
  egress:
  - {}
  policytypes:
  - egress

another option is allow by ip blocks, in the example below, a rule will allow the internet access (0.0.0.0) except for the ipblocks 10.0.0.0/8
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: allow-internet-only
spec:
  podselector: {}
  policytypes:
    - egress
  egress:
    - to:
      - ipblock:
        cidr: 0.0.0.0/0
          except:
            - 10.0.0.0/8

finally, in this site you can visualize your networkpolices in a good way to understand what is the exact behaviour.
references:
https://www.stackrox.com/post/2020/01/kubernetes-egress-network-policies/
kubernets networkpolicy allow external traffic to internet only
"
58356084,restart pods in deployment a when deployment b changes,"stuck deploying a legacy application i don't control to k8s that requires a list of ip addresses on the command line, those ips being the pods in deployment b, eg.:

./legacy_app -s 10.1.0.1 10.1.0.2 10.2.0.2 - call this app deployment a

(the ip addresses are gathered by querying the .../pods endpoint of the k8s api during pod launch)

when deployment b changes (scales out / in, pods restart, etc), the list of ips changes, and i need the pods in deployment a to restart, in order to re-query the api for the correct list of ips. 

how can i cleanly achieve this, ideally using standard k8s primitives?

what i've tried so far:


an app that calls watch on deployment b, and on detecting a modified event, updates a label on deployment a, forcing a restart. this kinda works, but requires the watcher to pause for a few seconds before restarting deploy a - without the pause, the list of ips is often not up to date by the time deploy a restarts, resulting in an incomplete list. however, the longer it pauses, the more data i'm losing. this adds a bit more operational complexity than i like. 


what i'm going to try next:


replacing pid 1 on deployment a with a monitoring loop that (re-) starts the legacy app with the new list of ips when the list changes. 
can i update a configmap or a label on deployment a pods containing the list of ips, and somehow use that to signal when a restart is needed?


is there a better way? coming into k8s i expected there to be some kind of hook / watch i could subscribe to, and run a ""restart all pods in deployment"" type command, but that feature doesn't appear to exist. 

i'm clearly new to k8s, any input much appreciated. 

k8s 1.14 on aws eks
",<kubernetes><kubernetes-pod>,58379390,1,"i ended up solving this using a bash entry script in front of deployment a, p much this pseudo code:

#!/bin/bash

get_deployment_b_ips() {
    echo $(curl https://$k8s_api/api/v1/namespaces/my_namespace/pods/ | \
           jq -r '[.items[] | select(.metadata.labels.app==""deployment-b"") | select(.status.phase==""running"")] | map(.status.podip + "":9125"") |  join("" "")')
}

while true; do
current_list=$(get_deployment_b_ips)

  if [[ ""$ip_list"" == ""$current_list"" ]]; then
    sleep 5
  else
   # restart the process with new ip list
  fi
done


this works great for now, but going forward i'm going to read about implementation details of k8s operators, and see if they can provide a cleaner fix than this. 

marking this as the answer to my question, unless a better solution comes along. 
"
62157943,rancher - how to expose my services publicly?,"i have a running rancher setup as the following:


host machine (running rancher/rancher container) on a public ip;
nodes in an exclusive network (10.1.1.0/24) not accessible from the internet.


my goal is to serve a web application using the rancher load balancing or whatever similar stuff.
for that, i've perfomed the following steps:


deploy workload using the ""rancher/hello-world"" image on 3 pods mapping port 80/tcp as a nodeport (listening port is random) named ""web-app"";
add ingress named ""hello"" in same namespace selecting ""automatically generate a .xip.io hostname"" and adding route ""/"" to the ""web-app"" on port 80.


this works on the local network, since i get an address like http://hello.gabriel-milan.10.1.1.14.xip.io/ that would resolve to 10.1.1.14, which is local.

i wanted to expose this service for one of my public ips. how can i do that?
",<kubernetes><load-balancing><kubernetes-ingress><rancher><rke>,62162112,9,"
edit 2021-09-27: xip.io is gone, but i'm leaving those references in my response because the op asked about xip.io. alternatives are sslip.io and nip.io, which both function the same way. you can replace xip.io in my response with either of those to achieve the same results.

there are a couple ways of doing this. based on your use of a private network that is not accessible from the internet, the nodes don't have public ips, and therefore kubernetes doesn't know anything about whatever public ip is mapped to them. this is how it works in ec2, or anywhere that has a nat happening off the nodes.
if those nodes are a custom cluster (where you install docker and then use the docker run command from rancher to install rke and join the cluster to rancher), then before you install, you can click the advanced options link in the bottom right corner and set the public and private ips for each node.
when you do this, the nodes receive a label that holds the public ip, and that address will be used with your xip.io hostname that you generate when setting up the ingress.
without that label, the xip.io hostname picks up the primary ip of the node, which in this case is on the private network.
if you do this, though, your traffic will only go to one node on the cluster, even if your ingress controller is listening on multiple nodes.
instead, when running a multi-node cluster, i recommend that you put a layer 4 load balancer in front of all worker nodes (or the nodes where the ingress controller is listening if it's not listening on every node). punch through 80 and 443, and then use that as the target for your domain.
domain.com -&gt; load balancer -&gt; ingress controller (on all nodes) -&gt; service -&gt; pods
your ingress controller is listening on 80/443 for http traffic, which also means that your service doesn't have to be nodeport. it can be clusterip because traffic goes through the ingress controller and then is routed inside the cluster.
nodeport services are used when you have an external load balancer and you need to direct traffic to a specific service. in that scenario, the external load balancer replaces the ingress controller. you create nodeport services for each of your apps, and then you tell the load balancer to send traffic for app a to each node on port 30547 or whatever the nodeport is for that service.
incidentally, if you're in a cloud provider, you can combine these into a loadbalancer service. that will create a nodeport service on the nodes and then reach out to the cloud provider's api and deploy a cloud load balancer and then program it with the nodes, the port for the service, and maintain that configuration for the life of the service.
to recap:

your nodes don't know their public ip, so the xip.io hostname can't know it either
put a layer 4 load balancer in front of your nodes and send traffic to 80/443 on all nodes
change your service to be clusterip
send traffic to the load balancer

also, as a workaround if you don't want to deploy a load balancer, you can delete the ingress and recreate it, but instead of creating an xip.io hostname automatically, choose &quot;set a hostname&quot; and create it manually. if one node's public ip is 1.2.3.4, then you can set it to any.thing.you.want.1.2.3.4.xip.io and it'll return 1.2.3.4 to dns queries.
you just can't edit an existing xip.io ingress and change it to a different manual xip.io hostname. you have to recreate it.
in this workaround traffic is still coming in to the ingress controller, so you can still change your service from nodeport to clusterip.
disclosure: i work for rancher.
"
59976777,helm range get values outside of loop,"i was looking at the helm range example they have on their docs.

yaml

favorite:
  drink: coffee
  food: pizza
pizzatoppings:
  - mushrooms
  - cheese
  - peppers
  - onions


helm

apiversion: v1
kind: configmap
metadata:
  name: {{ .release.name }}-configmap
data:
  myvalue: ""hello world""
  {{- with .values.favorite }}
  drink: {{ .drink | default ""tea"" | quote }}
  food: {{ .food | upper | quote }}
  {{- end }}
  toppings: |-
    {{- range .values.pizzatoppings }}
    - {{ . | title | quote }}
    - {{ .values.favorite.drink }}
    {{- end }}


i updated it to have this line - {{ .values.favorite.drink }} but when i run helm template i get the error 

can't evaluate field values 


is there anyway to access the top level .values from within the range function and escape the loop?
",<kubernetes><kubernetes-helm>,59978477,13,"you can also use a global variable $ that points to the root context

apiversion: v1
kind: configmap
metadata:
  name: {{ .release.name }}-configmap
data:
  myvalue: ""hello world""
  {{- with .values.favorite }}
  drink: {{ .drink | default ""tea"" | quote }}
  food: {{ .food | upper | quote }}
  {{- end }}
  toppings: |-
    {{- range $.values.pizzatoppings }}
    - {{ . | title | quote }}
    - {{ $.values.favorite.drink }}
    {{- end }}

"
44714823,kubernetes: getting the ip addresses of other pods on the network,"what's the best way to get the ip addresses of the other kubernetes pods on a local network?

currently, i'm using the following command and parsing the output: kubectl describe pods.

unfortunately, the command above often takes many seconds to complete (at least 3, and often 30+ seconds) and if a number of requests happen nearly simultaneously, i get 503 style errors. i've built a caching system around this command to cache the ip addresses on the local pod, but when a 10 or so pods wake up and need to create this cache, there is a large delay and often many errors. i feel like i'm doing something wrong. getting the ip addresses of other pods on a network seems like it should be a straightforward process. so what's the best way to get them?

for added details, i'm using google's kubernetes system on their container engine. running a standard ubuntu image. 



context: to add context, i'm trying to put together a shared memcached between the pods on the cluster. to do that, they all need to know eachother's ip address. if there's an easier way to link pods/instances for the purposes of memcached, that would also be helpful.
",<docker><kubernetes><google-cloud-platform><memcached><google-kubernetes-engine>,46739161,3,"for your described use case you should be using services. a headless service would allow you to reference them with my-svc.my-namespace.svc.cluster.local. this assumes you don't need to know individual nodes, only how to reach one of them, as it will round robin between them.

if you do need to have fixed network identities in your cluster attached to the pods you can setup a statefulset and reference them with: app-0.my-svc.my-namespace.svc.cluster.local, app-1.my-svc.my-namespace.svc.cluster.local and so on.

you should never need to contact specific pod ip's in other ways, specially since they can be rescheduled at any time and have their ips changed.

for your use case specifically, it might be easier to just use the memcache helm chart, which supports a cluster in a statefulset: https://github.com/kubernetes/charts/tree/master/stable/memcached
"
63530511,how to correctly update apiversion of manifests prior to cluster upgrade?,"so i did update the manifest and replaced apiversion: extensions/v1beta1 to apiversion: apps/v1
apiversion: apps/v1
kind: deployment
metadata:
  name: secretmanager
  namespace: kube-system
spec:
  selector:
    matchlabels:
      app: secretmanager
  template:
    metadata:
      labels:
        app: secretmanager
    spec:
    ...

i then applied the change
k apply -f deployment.yaml

warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
deployment.apps/secretmanager configured

i also tried
k replace --force -f deployment.yaml

that recreated the pod (downtime :( ) but still if you try to output the yaml config of the deployment i see the old value
k get deployments -n kube-system secretmanager -o yaml 

apiversion: extensions/v1beta1
kind: deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: &quot;1&quot;
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiversion&quot;:&quot;apps/v1&quot;,&quot;kind&quot;:&quot;deployment&quot;,
      &quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;secretmanager&quot;,&quot;namespace&quot;:&quot;kube-system&quot;}....}
  creationtimestamp: &quot;2020-08-21t21:43:21z&quot;
  generation: 2
  name: secretmanager
  namespace: kube-system
  resourceversion: &quot;99352965&quot;
  selflink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/secretmanager
  uid: 3d49aeb5-08a0-47c8-aac8-78da98d4c342
spec:


so i still see this apiversion: extensions/v1beta1
what i am doing wrong?
i am preparing eks kubernetes v1.15 to be migrated over to v1.16
",<kubernetes><amazon-eks><kubectl>,63530595,4,"the deployment exists in multiple apigroups, so it is ambiguous. try to specify e.g. apps/v1 with:
kubectl get deployments.v1.apps

and you should see your deployment but with apps/v1 apigroup.
"
72897454,bitnami/kubectl container unable to create files - permission denied,"i have used &quot;bitnami/kubectl:latest&quot; image to my test container which runs inside a test pod. i just login to that container and i wanted to create a file inside that container. but ended up with below error.
i have no name!@test:/$ touch test
touch: cannot touch 'test': permission denied
i have no name!@test:/$ mkdir test
mkdir: cannot create directory 'test': permission denied

can someone help me to understand why this problem occurs and how to fix this? i am aware that mounting the file as configmap might help me but just i need to understand this issue. thanks in advance!
",<kubernetes><kubectl><bitnami>,72897949,1,"the issue here is that the docker image which you are using is configured to run its final instruction using a non-root user (user 1001 in this case).
have a look at the dockerfile instruction:
https://github.com/bitnami/bitnami-docker-kubectl/blob/master/1.24/debian-11/dockerfile#l24
so you can either

create files in a non-root user owned directory like /tmp or
create your own docker image after removing that user 1001 instruction from the dockerfile and host it in your own repository which can then be pulled into your cluster.

whatever works for you.
hope this helps!
"
70451278,shell script to pass argument to input file,"i have shell script which takes some input from user and pass that input to the file which i am using inside my shell script
shell script myscript.sh
kubectl create -f de_pod.yaml


here is de_pod.yaml
apiversion: v1
kind: pod
metadata:
    name: test
spec:
    restartpolicy: never

    containers:
    -   name: run-esp
        image: myimage:1
        command: [&quot;python&quot;, &quot;/script.py&quot;, &quot;$input1&quot;, &quot;$input2&quot;]
        imagepullpolicy: always
        stdin: true
        tty: true



this is how i am running the script
sh myscript.sh my1stinput my2ndinput

if you look at de_pod.yaml at line command: [&quot;python&quot;, &quot;/script.py&quot;, &quot;$input1&quot;, &quot;$input2&quot;] here i am using the user input after running my myscript.sh. but both $input1 and $input2 is not populating my value
what i am doing wrong?
",<linux><bash><shell><kubernetes><kubectl>,70451705,1,"what i suspect you want is something like this.
myscript.sh:
#!/bin/bash
[[ &quot;${#}&quot; -ne 2 ]] &amp;&amp; {
    echo &quot;usage: ${0} &lt;something_something&gt; &lt;something_else&gt;&quot; 1&gt;&amp;2;
    exit 1;
};
template=&quot;/path/to/de_pod.yaml&quot;;
my1stinput=&quot;&quot;; printf -v my1stinput '%q' &quot;${1}&quot;;
my2ndinput=&quot;&quot;; printf -v my2ndinput '%q' &quot;${2}&quot;;
sed -e &quot;s/\$input1/${my1stinput}/g&quot; -e &quot;s/\$input2/${my2ndinput}/g&quot; &quot;${template}&quot; | kubectl create -f - ;

if the values in the 2 arguments are complex values though, then some extra thought should be given to making sure they're properly escaped in the sed patterns.
"
64681254,errors form my k8s cornjob: pod errors: error with exit code 127,"i have backend service deployed on a private gke cluster, and i want to execute this corn job but everytime i get the following error: pod errors: error with exit code 127
   apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: call-callendar-api-demo
spec:
  
  schedule: &quot;*/15 * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          nodeselector:
            env: demo
          containers:
          - name: call-callendar-api-demo
            image: busybox
            command: [&quot;/bin/sh&quot;]
            args: [&quot;-c&quot;, 'curl -x post &quot;curl -x post &quot;https://x.x.x/api/v1/cal/add_link&quot; -h  &quot;accept: application/json&quot; -d &quot;&quot; &gt;/dev/null 2&gt;&amp;1&quot; -h  &quot;accept: application/json&quot; -d &quot;&quot; &gt;/dev/null 2&gt;&amp;1']
          restartpolicy: never

any suggestions why this  cornjob that is deployed on the same namespace with my backend service is giving me this error? also there is no logs in the container :(  btw i have basic auth, could that be a reason?
edit: logs from the pod after removing &gt;/dev/null/:
textpayload: &quot;curl: (3) url using bad/illegal format or missing url  

textpayload: &quot;
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) could not resolve host: application
&quot;

",<docker><kubernetes><google-kubernetes-engine>,64693818,1,"the command is wrong, and i changed the picture with one that implements curl it suppose to look like this.
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: demo
spec:
  
  schedule: &quot;*/15 * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          nodeselector:
            env: demo
          containers:
          - name: -demo
            image: curlimages/curl #changed the picture 
            command: [&quot;/bin/sh&quot;]
            args: [&quot;-c&quot;, 'curl -x post &quot;https://x.x.x/api/v1/cal/addy_link&quot; -h  &quot;accept: application/json&quot; -d &quot;&quot; &gt;/dev/null 2&gt;&amp;1']
          restartpolicy: never

it solved my problem.
"
58871130,why does data read from a yaml file via set-file of helm contains extra characters?,"i have a configmap inside a helm chart:

---
apiversion: v1
kind: configmap
metadata:
 name: card-template
data:
  card.tmpl: |-
{{- if .values.custommessagecardtemplate }}
{{ toyaml .values.custommessagecardtemplate | indent 4 }}
{{- else }}
{{ .files.get ""card.tmpl"" | indent 4 }}
{{- end }}


this configmap reads data from .values.custommessagecardtemplate value.

i have a file custom-card.tmpl whose content should be set as the value of custommessagecardtemplate during the installation of the chart.

the data inside custom-card.tmpl is :

{{ define ""teams.card"" }}
{
  ""@type"": ""messagecard"",
  ""@context"": ""http://schema.org/extensions"",
  ""themecolor"": ""{{- if eq .status ""resolved"" -}}2dc72d
                 {{- else if eq .status ""firing"" -}}
                    {{- if eq .commonlabels.severity ""critical"" -}}8c1a1a
                    {{- else if eq .commonlabels.severity ""warning"" -}}ffa500
                    {{- else -}}808080{{- end -}}
                 {{- else -}}808080{{- end -}}"",
  ""summary"": ""{{- if eq .commonannotations.summary """" -}}
                  {{- if eq .commonannotations.message """" -}}
                    {{- .commonlabels.alertname -}}-hai
                  {{- else -}}
                    {{- .commonannotations.message -}}
                  {{- end -}}
              {{- else -}}
                  {{- .commonannotations.summary -}}
              {{- end -}}"",
  ""title"": ""prometheus alert ({{ .status }})"",
  ""sections"": [ {{$externalurl := .externalurl}}
  {{- range $index, $alert := .alerts }}{{- if $index }},{{- end }}
    {
      ""activitytitle"": ""[{{ $alert.annotations.description }}]({{ $externalurl }})"",
      ""facts"": [
        {{- range $key, $value := $alert.annotations }}
        {
          ""name"": ""{{ rereplaceall ""_"" "" "" $key }}"",
          ""value"": ""{{ rereplaceall ""_"" "" "" $value }}""
        },
        {{- end -}}
        {{$c := counter}}{{ range $key, $value := $alert.labels }}{{if call $c}},{{ end }}
        {
          ""name"": ""{{ rereplaceall ""_"" "" "" $key }}"",
          ""value"": ""{{ rereplaceall ""_"" "" "" $value }}""
        }
        {{- end }}
      ],
      ""markdown"": true
    }
    {{- end }}
  ]
}
{{ end }}


when running the install command with set-file flag:

helm install --name my-rel --dry-run --debug --set-file custommessagecardtemplate=custom-card.tmpl ./my-chart


helm inserts some extra characters into the data it reads from the file:

# source: my-chart/templates/configmaptemplate.yaml
apiversion: v1
kind: configmap
metadata:
 name: card-template
data:
  card.tmpl: |-
    ""{{ define \""teams.card\"" }}\r\n{\r\n  \""@type\"": \""messagecard\"",\r\n  \""@context\"":
      \""http://schema.org/extensions\"",\r\n  \""themecolor\"": \""{{- if eq .status \""resolved\""
      -}}2dc72d\r\n                 {{- else if eq .status \""firing\"" -}}\r\n                    {{-
      if eq .commonlabels.severity \""critical\"" -}}8c1a1a\r\n                    {{- else
      if eq .commonlabels.severity \""warning\"" -}}ffa500\r\n                    {{- else
      -}}808080{{- end -}}\r\n                 {{- else -}}808080{{- end -}}\"",\r\n  \""summary\"":
      \""{{- if eq .commonannotations.summary \""\"" -}}\r\n                  {{- if eq .commonannotations.message
      \""\"" -}}\r\n                    {{- .commonlabels.alertname -}}-hai\r\n                  {{-
      else -}}\r\n                    {{- .commonannotations.message -}}\r\n                  {{-
      end -}}\r\n              {{- else -}}\r\n                  {{- .commonannotations.summary
      -}}\r\n              {{- end -}}\"",\r\n  \""title\"": \""prometheus alert ({{ .status
      }})\"",\r\n  \""sections\"": [ {{$externalurl := .externalurl}}\r\n  {{- range $index,
      $alert := .alerts }}{{- if $index }},{{- end }}\r\n    {\r\n      \""activitytitle\"":
      \""[{{ $alert.annotations.description }}]({{ $externalurl }})\"",\r\n      \""facts\"":
      [\r\n        {{- range $key, $value := $alert.annotations }}\r\n        {\r\n          \""name\"":
      \""{{ rereplaceall \""_\"" \"" \"" $key }}\"",\r\n          \""value\"": \""{{ rereplaceall
      \""_\"" \"" \"" $value }}\""\r\n        },\r\n        {{- end -}}\r\n        {{$c :=
      counter}}{{ range $key, $value := $alert.labels }}{{if call $c}},{{ end }}\r\n        {\r\n
      \         \""name\"": \""{{ rereplaceall \""_\"" \"" \"" $key }}\"",\r\n          \""value\"":
      \""{{ rereplaceall \""_\"" \"" \"" $value }}\""\r\n        }\r\n        {{- end }}\r\n
      \     ],\r\n      \""markdown\"": true\r\n    }\r\n    {{- end }}\r\n  ]\r\n}\r\n{{
      end }}\r\n""


why does this happen? when i encode the original data and the read data using base-64, both seem different. 

how to solve this issue?

note:

i cannot set the data using an extravalues.yaml as:

custommessagecardtemplate:
  {{ define ""teams.card"" }}
  {
    .
    .
    .
  }
  {{ end }}


it gives an error:

error: failed to parse extravalues.yaml: error converting yaml to json: yaml: line 2: did not find expected key


but this error doesn't appear if the values file is like:

custommessagecardtemplate:
  card.tmpl: |-
    {{ define ""teams.card"" }}
    {
      .
      .
    }
    {{ end }}

",<kubernetes><yaml><kubernetes-helm>,58872764,2,"it just does exactly what you tell it to. custommessagecardtemplate contains a string, so toyaml encodes it as double-quoted yaml string. while doing so, it replaces special characters such as line endings and double quotes with escape sequences.

since you're pasting into a block scalar, you don't need the escaping. just drop the toyaml and you should be fine.
"
57799684,how do i get the pod id in kubernetes?,"i am using stackdriver monitoring api to get the metrics related to the containers. the json object returned from the api has the following details of the container.

example:

{
      ""metric"": {
        ""type"": ""container.googleapis.com/container/cpu/utilization""
      },
      ""resource"": {
        ""type"": ""gke_container"",
        ""labels"": {
          ""zone"": ""us-central1-a"",
          ""pod_id"": ""1138528c-c36e-11e9-a1a7-42010a800198"",
          ""project_id"": ""auto-scaling-springboot"",
          ""cluster_name"": ""load-test"",
          ""container_name"": """",
          ""namespace_id"": ""f0965889-c36d-11e9-9e00-42010a800198"",
          ""instance_id"": ""3962380509873542383""
        }
      },
      ""metrickind"": ""gauge"",
      ""valuetype"": ""double"",
      ""points"": [
        {
          ""interval"": {
            ""starttime"": ""2019-09-04t04:00:00z"",
            ""endtime"": ""2019-09-04t04:00:00z""
          },
          ""value"": {
            ""doublevalue"": 0.050707947222229495
          }
        }
     ]
}


when i execute kubectl describe pod [pod name], i get none of these information unique to a container. therefore i am unable to identify the results corresponding to a container.

therfore, how to i get the pod id so that i'll be able to identify it?
",<kubernetes><monitoring><google-kubernetes-engine><stackdriver>,57800010,44,"use kubectl jsonpath

to get a specific pod's uid:

$ kubectl get pods -n &lt;namespace&gt; &lt;pod-name&gt; -o jsonpath='{.metadata.uid}'


$ kubectl get pods -n kube-system kubedb-66f78 -o jsonpath='{.metadata.uid}'
275ecb36-5aa8-4c2a-9c47-d8bb681b9aff⏎


use kubectl custom-columns

list all podname along with its uid of a namespace:

$ kubectl get pods -n &lt;namespace&gt; -o custom-columns=podname:.metadata.name,poduid:.metadata.uid


$ kubectl get pods -n kube-system -o custom-columns=podname:.metadata.name,poduid:.metadata.uid
podname                                      poduid
coredns-6955765f44-8kp9t                     0ae5c03d-5fb3-4eb9-9de8-2bd4b51606ba
coredns-6955765f44-ccqgg                     6aaa09a1-241a-4013-b706-fe80ae371206
etcd-kind-control-plane                      c7304563-95a8-4428-881e-422ce3e073e7
kindnet-jgb95                                f906a249-ab9d-4180-9afa-4075e2058ac7
kube-apiserver-kind-control-plane            971165e8-6c2e-4f99-8368-7802c1e55e60
kube-controller-manager-kind-control-plane   a0dce3a7-a734-485d-bfee-8ac3de6bb486
kube-proxy-27wgd                             d900c0b2-dc21-46b5-a97e-f30e830aa9be
kube-scheduler-kind-control-plane            9c6f2399-4986-4259-9cd7-875eff1d7198


use unix/linux command grep

you can use kubectl get pods along with grep.

$ kubectl get pods -n &lt;namespace&gt; &lt;pod-name&gt; -o yaml | grep uid
uid: bcfbdfb5-ce0f-11e9-b83e-080027d4916d

"
51768988,how to save content of a configmap to a file with kubectl and jsonpath?,"i'm trying to save the contents of a configmap to a file on my local hard drive. kubectl supports selecting with jsonpath but i can't find the expression i need to select just the file contents.

the configmap was created using the command

kubectl create configmap my-configmap --from-file=my.configmap.json=my.file.json


when i run 

kubectl describe configmap my-configmap


i see the following output:

name:         my-configmap 
namespace:    default 
labels:       &lt;none&gt; 
annotations:  &lt;none&gt;

data
==== 
my.file.json:
---- 
{
    ""key"": ""value"" 
} 
events:  &lt;none&gt;


the furthest i've gotten so selecting only the file contents is this:

 kubectl get configmap my-configmap -o jsonpath=""{.data}""


which outputs

map[my.file.json:{
    ""key"": ""value""
}]


the output that i want is 

{
  ""key"": ""value""
}


what is the last piece of the jsonpath puzzle?
",<kubernetes><jsonpath><kubectl><configmap>,51769868,42,"there’s an open issue at the kubernetes github repo with a list of things that needs to be fixed in regards to kubectl (and jsonpath), one of them are issue 16707 jsonpath template output should be json. 

edit:

how about this:

kubectl get cm my-configmap -o jsonpath='{.data.my\.file\.json}'


i just realized i had answered another question related (kind of) to this one. the above command should output what you had in mind!
"
73944083,how to delete ingress from default namespace,"how to delete below given ingress from default namespace?
# kubectl get ingress
warning: extensions/v1beta1 ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 ingress
name              class    hosts             address      ports   age
abc-ingress       &lt;none&gt;   app.company.com                80      24h

kubectl describe ingress jenkins-ingress
warning: extensions/v1beta1 ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 ingress
name:             abc-ingress
namespace:        default
address:
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host             path  backends
  ----             ----  --------
  abc.company.com
                   /   app-svc:80 (&lt;error: endpoints &quot;app-svc&quot; not found&gt;)
annotations:       &lt;none&gt;
events:            &lt;none&gt;

tried to delete using below command, but it doesn't work.please suggest to delete it.
# kubectl delete abc-ingress -n default
error: the server doesn't have a resource type &quot;abc-ingress&quot;

",<kubernetes><kubernetes-ingress>,73944645,3,"while ali rezvani's answer is correct, i'd like to extend upon it.
kubectl commands are structured as follows:
kubectl action resource name [ -n namepace ]

where action can be get, delete, describe, etc.
resource can be deployments, service, pods, ingress or one of its short forms: deploy, svc, po, or ing
name is the name of the resource(s) you want to apply the action on.
so if you wanted to delete the ingress named abc-ingress in the namespace default, you would use:
kubectl delete ingress abc-ingress -n default

(side note: generally, normally you can omit -n default as the default namespace is normally, as the name suggests, the default namespace)
"
65048877,configuring tls on openshift using helm,"i am trying to configure tls using edge termination on openshift, am passing the tls certificates and private key in values.yaml and referring it in route.yaml file, when i execute the helm chart the creation of the route fails due to improper indentation and newlines introduced while copying the certificate from values.yaml to the route.yaml file.
below are the values.yaml file from which am referring the certificate in the route.yaml file. what is the better way to do this? how can i pass the tls cert and private key from values.yaml with proper indentation.
values.yaml
route:
  enabled: true
  annotations:
    haproxy.router.openshift.io/cookie_name: session_xld
    haproxy.router.openshift.io/disable_cookies: &quot;false&quot;
    haproxy.router.openshift.io/rewrite-target: /
  path: /
  hosts:
    - www.example.com
  tls:
    key:
      -----begin certificate-----
      [...]
      -----end certificate-----
    certificate:
      -----begin certificate-----
      [...]
      -----end certificate-----
    cacertificate:
      -----begin certificate-----
      [...]
      -----end certificate-----
    insecureedgeterminationpolicy: redirect

route.yaml
{{- if $.values.route.tls }}
  tls:
    termination: edge
  {{- with $.values.route.tls }}
    key: |
      {{ .key }}
    certificate: |
      {{ .certificate }}
    cacertificate: |
      {{ .cacertificate }}
    insecureedgeterminationpolicy: {{ .insecureedgeterminationpolicy }}
  {{- end }}
{{- end }}

",<kubernetes><openshift><kubernetes-helm>,65051689,1,"how about try to pass the each certificate to route.yaml with | for preserving the indentation in values.yaml either as follows ?
  tls:
    key: | &lt;--- add
      -----begin certificate-----
      [...]
      -----end certificate-----
    certificate: | &lt;--- add
      -----begin certificate-----
      [...]
      -----end certificate-----
    cacertificate: | &lt;--- add
      -----begin certificate-----
      [...]
      -----end certificate-----

"
46840020,how to get image name in google cloud platform kubernetes pod,"how do you get the digest of a container image running on a pod in kubernetes?

based on the screen-shot below, i would like to be able to retrieve d976aea36eb5 from the pod (logs, yaml etc. whatever is the way to get it)

what i can get from yaml://deployment/spec/template/spec/containers/image is mysolution.host which is the common name of the image.


",<docker><kubernetes><google-cloud-platform><google-kubernetes-engine><google-container-registry>,46840986,3,"if this isn't possible via the kubernetes api, you can do it through the docker registry api.

what you're looking for is the image's digest, which is the sha256 hash of its manifest. the ""name"" column in the screenshot of gcr's ui is the truncated digest of the image.

the string us.gcr.io/my-project-37111/mysolution.host represents a repository, which is just a collection of images. these images can be referenced by their digest or by a tag.

you can list all the tags in your repository using gcloud:

$ gcloud container images list-tags us.gcr.io/my-project-37111/mysolution.host


that will show you the truncated digest as well. for the full digest, you can use the --format=json flag:

$ gcloud container images list-tags --format=json us.gcr.io/my-project-37111/mysolution.host


if you happen to know the tag (0.0.5-linux for the highlighted image), you can call the registry api directly:

$ curl \
  -h ""accept: *"" \
  -h ""authorization: bearer $(gcloud auth print-access-token)"" \
  -i https://us.gcr.io/v2/my-project-37111/mysolution.host/manifests/0.0.5-linux |
  grep ""digest""

"
56750895,can i add initcontainers to a kubernetes-cronjob?,"i want to have an initcontainer that runs prior to the container my kubernetes cronjob is running. it's used to install kubectl. is there a way of doing this? 

i tried to add the initcontainer-parameter to the cronjob.yaml file but it threw an error.

the code of my containerinit is the following:

initcontainers:
- name: install-kubectl
  image: allanlei/kubectl
  volumemounts:
  - name: kubectl
    mountpath: /data
  command: [""cp"", ""/usr/local/bin/kubectl"", ""/data/kubectl""]


my cronjob needs to be able to access kubectl. that is the reason i'm trying to do this. i'm grateful for any suggestions how i could solve this problem.
",<kubernetes><google-kubernetes-engine><kubernetes-cronjob>,56756048,17,"yes, you can use initcontainers in a cronjob template.
like this:
apiversion: batch/v1
kind: cronjob
metadata:
  name: example
  namespace: default
spec:
  schedule: '*/1 * * * *'
  jobtemplate:
    spec:
      template:
        spec:
          initcontainers:
            - name: busybox
              image: busybox
              command:
                - echo
                - initialized
          containers:
            - name: pi
              image: perl
              command:
                - perl
                - '-mbignum=bpi'
                - '-wle'
                - print bpi(2000)
          restartpolicy: onfailure

"
54992723,allow access to all resources on kubernetes cluster except get nodes,"team, i have below cluster role on kubernetes that allows access to everything but i wan't to restrict node level commands and allow all rest.
what to modify below?
basically, user should be able to run
kubectl get all --all-namespaces

but not nodes info should not display
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin-test
rules:
  - apigroups:
      - '*'
    resources:
      - '*'
    verbs:
      - '*'
  - nonresourceurls:
      - '*'
    verbs:
      - '*'

",<kubernetes><kubectl><rbac>,54999647,7,"rules are purely additive, means that you cannot restrict rules.

thus, you will need to list all accessible resources, but ""nodes"" with appropriate operations

for example:

apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: ""true""
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
rules: 
- apigroups: [""""] 
  resources: [""pods"",""services"",""namespaces"",""deployments"",""jobs""] 
  verbs: [""get"", ""watch"", ""list""]


also, it is highly not recommended to change cluster-admin role.
it is worth to create a new role and assign users to it.
"
47269602,how do i avoid unschedulable pods when running an autoscale-enabled google container/kubernetes engine cluster?,"i'm running into an issue where i seem to max out my container engine (kubernetes engine) cluster at 9 nodes (or 9 vcpus). for context, i'm trying to run around 50 or so web scrapers as kubernetes cron jobs. here is the gcloud command i am using to create the cluster in the us-east1-c zone:

gcloud beta container clusters create my-example-cluster \
  --cluster-version=1.8.1-gke.1 \
  --machine-type=f1-micro \
  --enable-autoscaling \
  --min-nodes=1 \
  --max-nodes=60


when i checked out iam &amp; admin > quotas, it looked like i was possibly maxing out on in-use ip addresses (max=8).

after launching all the scrapers, i'm ending up around 35 pods that are unschedulable (seemingly because i can't exceed 9 nodes?).

has anyone run into a similar situation and come up with a solution? is there a way, perhaps via kubernetes config, to not count against ip address usage since these nodes do not need to be accessible externally (if that's even the issue)? also open to other setups if anyone has recommendations.

thanks for all the help!

p.s. i do have billing enabled
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,47298958,9,"i received some help on this issue from the google cloud platform community slack. it turns out i was hitting the in-use ip addresses quota; however, i didn't realize you could request increased quotas.

i was able to increase quotas by:


navigating to menu > iam &amp; admin > quotas in the google cloud platform console for my project
selecting/checking the services in the region i was using (e.g., in-use ip addresses in us-west1)
click edit quotas button above the table of services
input/verify contact information
comply with gcp support when they reach out to you


so, basically an oversight on my end but maybe it will help somebody else who didn't notice or wasn't aware of that option.
"
76033732,"flink, kubernetes, and linkerd","i am deploying some flink jobs which require access to some services under a service mesh implemented via linkerd and i'm running into this error:
java.lang.noclassdeffounderror: could not initialize class foo.bar.job 

i can confirm that the jar file contains the class that cannot be found apparently, so it's not a problem with the jar itself, but seems to be related to linkerd. in particular, i'm using the following pod annotations for both the jobmanager and the taskmanager pods (taken from my helm chart values file):
podannotations:
  linkerd.io/inject: enabled
  config.linkerd.io/skip-outbound-ports: 6123,6124
  config.linkerd.io/proxy-await: enabled

for what it's worth, i'm using the ververica platform (community edition) for deploying my jobs to kubernetes, although i don't think the issue is vvp-specific:
{{- define &quot;vvp.deployment&quot; }}
kind: deployment
apiversion: v1
metadata:
  name: my-job
spec:
  template:
    spec:
      artifact:
        kind: jar
        flinkimageregistry: {{ .values.flink.imageregistry }}
        flinkversion: &quot;1.15.1&quot;
        flinkimagetag: 1.15.1-stream1-scala_2.12-java11-linkerd
        entryclass: foo.bar.job
      kubernetes:
        jobmanagerpodtemplate:
          metadata:
            {{- with .values.flink.podannotations }}
            annotations:
              {{- toyaml . | nindent 14 }}
            {{- end }}
          spec:
            containers:
              - name: flink-jobmanager
                command:
                  - linkerd-entrypoint.sh
        taskmanagerpodtemplate:
          metadata:
            {{- with .values.flink.podannotations }}
            annotations:
              {{- toyaml . | nindent 14 }}
            {{- end }}
{{- end }}

where the contents of linkerd-entrypoint.sh are:
#!/bin/bash
set -e
exec linkerd-await --shutdown -- &quot;$@&quot;

for extra context, the vvp and the flink jobs are deployed into different namespaces. also, for the vvp pods, i'm not using any linkerd annotations whatsoever.
has anyone encountered similar problems? the closest troubleshooting resource/guide that i've found so far is this one, which targets istio instead of linkerd.
",<kubernetes><apache-flink><kubernetes-helm><linkerd>,76320230,2,"answering to myself after having determined the root cause of the issue.
regarding linkerd, everything was correctly setup. the main precaution that one needs to take is adding the linkerd-await binary to the flink image and making sure to override the entrypoint for the jobmanager since otherwise you will run into issues when upgrading your jobs. the jobmanager won't kill the linkerd proxy, and because of that it will hang around with notready status. again, that is easily solved by wrapping the main cmd in a linkerd-await call. so, first add the linkerd-await binary to your docker image:
# add linkerd-await and linkerd-entrypoint.sh
user root
run apt-get update &amp;&amp; apt-get install -y wget
run wget https://github.com/linkerd/linkerd-await/releases/download/release%2fv0.2.7/linkerd-await-v0.2.7-amd64 -o ./linkerd-await &amp;&amp; chmod +x ./linkerd-await
copy scripts/flink/linkerd-entrypoint.sh ./linkerd-entrypoint.sh

then, for the jobmanager only, override the entrypoint like this:
spec:
  containers:
    - name: flink-jobmanager
      command:
       - linkerd-entrypoint.sh # defined above

alternatively one could use the linkerd_disabled or linkerd_await_disabled env vars for bypassing the linkerd-await wrapper. for more info on using jobs &amp; linkerd consult the following resources:

https://itnext.io/three-ways-to-use-linkerd-with-kubernetes-jobs-c12ccc6d4c7c (solution #3 is the one explained here)
https://github.com/linkerd/linkerd-await

also, regarding the annotation
config.linkerd.io/proxy-await: enabled

, it does only the waiting but not the shutdown part, so if we are going to manually run linkerd-await --shutdown -- &quot;$@&quot; anyway, that annotation can be safely removed since it's redundant:

https://github.com/linkerd/linkerd2/issues/8006

finally, regarding:
java.lang.noclassdeffounderror: could not initialize class foo.bar.job 

let me clarify that this had nothing to do with linkerd. this was mostly a config error along the lines of:

java.lang.noclassdeffounderror: could not initialize class xxx

essentially (the specific details are irrelevant), there were some env vars missing in the taskmanager pods. note that the exception message says &quot;could not initialize class foo.bar.job&quot; which is different from &quot;could not find class...&quot;.
sorry for the confusion!
"
50248525,is there a way to put kubernetes secret value in args field of yaml file,"i have a kubernetes yaml deployment file which accepts db username and password as arguments as shown below. 

args:
        - ""-db_host=postgres""
        - ""-db_port=5432""
        - ""-db_username=postgres""
        - ""-db_password=postgres""


to hide the values of db_username and db_password i thought of using kubernetes secret kind. but to achieve that i have to make db_username and db_password as environment variables so that i can use it something like as shown below:

args:
        - ""-db_host=postgres""
        - ""-db_port=5432""
env:
        - name: db_username
          valuefrom:
            secretkeyref:
              name: db-secret
              key: db-user
        - name: db_password
          valuefrom:
            secretkeyref:
              name: db-secret
              key: db-pass


is there any way we can use secret in args itself so that i don't have to do the 2nd approach. 
",<kubernetes><kubernetes-security><kubernetes-secrets>,50248608,43,"once you have an environment variable you can embed its value into the arguments:

env:
- name: message
  value: ""hello world""
command: [""/bin/echo""]
args: [""$(message)""]


or in your case:

args:
        - ""-db_host=postgres""
        - ""-db_port=5432""
        - ""-db_username=$(db_username)""
        - ""-db_password=$(db_password)""
env:
        - name: db_username
          valuefrom:
            secretkeyref:
              name: db-secret
              key: db-user
        - name: db_password
          valuefrom:
            secretkeyref:
              name: db-secret
              key: db-pass


the reference can be found here
"
59748762,jenkins and kubernetes integration using with helm,"i would like to integrate our jenkins and kubernetes clusters which works different servers.i have 2 cluster per stage and production. i already create a 2 name spaces on stage cluster to divide development and stage. i divide my values.yaml such as below. 


valeus.dev.yaml
values.stage.yaml
values.prod.yaml


so according to the git_branch value; i would like to set namespace variable and deploy via helm install command. at this circumstances,

my question is, what is the best way to connect 2 cluster in jenkinsfile for this condition cause for dev and test namespace i need to one cluster , for production i need to deploy another cluster.

 stage('deploy') {
   steps {
      script {
        if (env.git_branch == ""origin/master"") {
            def namepsace=""dev""
            sh ""helm upgrade --install -f values.dev.yaml --namespace ${namespace}""
        } else if (env.git_branch ==""origin/test""){
            def namepsace=""stage""
            sh ""helm upgrade --install -f values.stage.yaml --namespace ${namespace}""

        } else { 
            def namepsace=""prod""
            sh ""helm upgrade --install -f values.prod.yaml --namespace ${namespace}""
        }

",<jenkins><kubernetes><jenkins-pipeline><kubernetes-helm>,59771066,4,"you will need to create the jenkins secrets to add both kubeconfig files for your k8s clusters, and in the if statement you load the kubeconfig for your environment

for example using your code above

stage('deploy') {
  steps {
    script {
      if (env.git_branch == ""origin/master"") {
        def namepsace=""dev""
        withcredentials([file(credentialsid: 'kubeconfig-dev', variable: 'config')]) {
          sh """"""
          export kubeconfig=\${config}
          helm upgrade --install -f values.dev.yaml --namespace ${namespace}""
          """"""
        }
      } else if (env.git_branch ==""origin/test""){
        def namepsace=""stage""
        withcredentials([file(credentialsid: 'kubeconfig-stage', variable: 'config')]) {
          sh """"""
          export kubeconfig=\${config}
          helm upgrade --install -f values.dev.yaml --namespace ${namespace}""
          """"""
        }
      } else {
        def namepsace=""prod""
        withcredentials([file(credentialsid: 'kubeconfig-prod', variable: 'config')]) {
          sh """"""
          export kubeconfig=\${config}
          helm upgrade --install -f values.dev.yaml --namespace ${namespace}""
          """"""
        }
      }
    }
  }
}

"
62674323,helm unable to retrieve search results,"i have stable repo configured
▶ helm repo list
name        url
stable      https://kubernetes-charts.storage.googleapis.com

and i know i can perform
helm install stable/jenkins

then why isn’t the following command retrieving any results?
▶ helm search repo stable/jenkins
no results found
~
▶ helm search repo jenkins
no results found

using
▶ helm version --tls
client: &amp;version.version{semver:&quot;v2.9.1&quot;, gitcommit:&quot;20adb27c7c5868466912eebdf6664e7390ebe710&quot;, gittreestate:&quot;clean&quot;}
server: &amp;version.version{semver:&quot;v2.16.8&quot;, gitcommit:&quot;145206680c1d5c28e3fcf30d6f596f0ba84fcb47&quot;, gittreestate:&quot;clean&quot;}

edit: even after an update
▶ helm repo update
hang tight while we grab the latest from your chart repositories...
...successfully got an update from the &quot;flagger&quot; chart repository
...successfully got an update from the &quot;incubator&quot; chart repository
...successfully got an update from the &quot;stakater&quot; chart repository
...successfully got an update from the &quot;stable&quot; chart repository
...successfully got an update from the &quot;bitnami&quot; chart repository
update complete. ⎈ happy helming!⎈

~/                                                                                                                                                                                                                     40m
▶ helm search repo stable/jenkins
no results found

i even tried to remove and add back again the stable repo; same result.
",<kubernetes><kubernetes-helm>,62677844,2,"you are running helm search repo stable/jenkins and this is helm 3 syntax.
have a look at this help for helm3:
$ helm search --help

search provides the ability to search for helm charts in the various places
they can be stored including the helm hub and repositories you have added. use
search subcommands to search different locations for charts.

usage:
  helm search [command]

available commands:
  hub         search for charts in the helm hub or an instance of monocular
  repo        search repositories for a keyword in charts

but in you question you wrote:

helm version --tls 
client: &amp;version.version{semver:&quot;v2.9.1 ...

this means that you are using helm 2. now lets have a look at helm 2 help command:
$ helm search --help
...
to look for charts with a particular name (such as stable/mysql), try
searching using vertical tabs (\v). vertical tabs are used as the delimiter
between search fields. for example:

    helm search --regexp '\vstable/mysql\v'

to search for charts using common keywords (such as &quot;database&quot; or
&quot;key-value store&quot;), use
    helm search database
or
    helm search key-value store

usage:
  helm search [keyword] [flags]

tldr: use:
helm search stable/jenkins

let me know if you have any further questions. i'd be happy to help.
"
44173832,get kubernetes credentials from azure,"
i have created a azure container service  


orchestratortype : kubernetes
group-name : mygrp
dns : mydns


now i have to install kubectl on m/c and service , pods too
for this i logged into my account from azure cli
i need azure kubernetes credentials for kubectl and command for taht is 


az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt;


from above info , i know cluster-resource-group is mygrp (or i am wrong ?) but what will be cluster-name ? 


or their is something i have configure for this  ?


",<azure><kubernetes><azure-virtual-machine><kubectl>,44174073,1,"we can find the --name via azure portal:


"
69887357,how to block all traffic to pods matching a label using a networkpolicy,"afaik, the k8s networkpolicy can only allow pods matching a label to do something. i do not want to:

deny all traffic
allow traffic for all pods except the ones matching my label

but instead:

allow all traffic
deny traffic for pods matching my label

how do i do that?
from kubectl explain networkpolicy.spec.ingress.from:
description:
     list of sources which should be able to access the pods selected for this
     rule. items in this list are combined using a logical or operation. if this
     field is empty or missing, this rule matches all sources (traffic not
     restricted by source). if this field is present and contains at least one
     item, this rule allows traffic only if the traffic matches at least one
     item in the from list.

as far as i understand this, we can only allow, not deny.
",<security><kubernetes><kubernetes-networkpolicy>,69899258,1,"as you mentioned in the comments, you are using the kind tool for running kubernetes. instead of kindnet cni plugin (default cni plugin for kind) which does not support kubernetes network policies, you can use calico cni plugin which support kubernetes network policies + it has its own, similar solution called calico network policies.

example - i will create cluster with disabled default kind cni plugin + enabled nodeport for testing (assuming that you have kind + kubectl tools already installed):
kind-cluster-config.yaml file:
kind: cluster
apiversion: kind.x-k8s.io/v1alpha4
networking:
  disabledefaultcni: true # disable kindnet
  podsubnet: 192.168.0.0/16 # set to calico's default subnet
nodes:
- role: control-plane
  extraportmappings:
  - containerport: 30000
    hostport: 30000
    listenaddress: &quot;0.0.0.0&quot; # optional, defaults to &quot;0.0.0.0&quot;
    protocol: tcp # optional, defaults to tcp

time for create a cluster using above config:
kind create cluster --config kind-cluster-config.yaml

when cluster is ready, i will install calico cni plugin:
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

i will wait until all calico pods are ready (kubectl get pods -n kube-system command to check). then, i will create sample nginx deployment + service type nodeport for accessing:
nginx-deploy-service.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchlabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerport: 80
---
apiversion: v1
kind: service
metadata:
  name: nginx-service
spec:
  type: nodeport
  selector:
    app: nginx
  ports:
    - protocol: tcp
      port: 80
      targetport: 80
      nodeport: 30000

let's apply it: kubectl apply -f nginx-deploy-service.yaml
so far so good. now i will try to access nginx-service using node ip (kubectl get nodes -o wide command to check node ip address):
curl 172.18.0.2:30000
&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;welcome to nginx!&lt;/title&gt;
...

okay, it's working.
now time to install calicoctl and apply some example policy - based on this tutorial - to block ingress traffic only for pods with label app with value nginx:
calico-rule.yaml:
apiversion: projectcalico.org/v3
kind: globalnetworkpolicy
metadata:
  name: default-deny
spec:
  selector: app == &quot;nginx&quot;
  types:
  - ingress

apply it:
calicoctl apply -f calico-rule.yaml 
successfully applied 1 'globalnetworkpolicy' resource(s)

now i can't reach the address 172.18.0.2:30000 which was working previously. the policy is working fine!
read more about calico policies:

get started with calico network policy
calico policy tutorial

also check this github topic for more information about networkpolicy support in kind.
edit:
seems like calico plugin supports as well kubernetes networkpolicy, so you can just install calico cni plugin and apply the following policy:
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: default-deny
spec:
  podselector:
    matchlabels:
      app: nginx
  policytypes:
  - ingress

i tested it and seems it's working fine as well.
"
66533872,difference between '-- /bin/sh -c ls' vs 'ls' when setting a command in kubectl?,"i am bit confused with commands in kubectl. i am not sure when i can use the commands directly like
command: [&quot;command&quot;] or -- some_command
vs
command: [/bin/sh, -c, &quot;command&quot;] or -- /bin/sh -c some_command
",<kubernetes><command><sh><kubectl>,66539524,1,"at a low level, every (unix/linux) command is invoked as a series of &quot;words&quot;.  if you type a command into your shell, the shell does some preprocessing and then creates the &quot;words&quot; and runs the command.  in kubernetes command: (and args:) there isn't a shell involved, unless you explicitly supply one.
i would default to using the list form unless you specifically need shell features.
command: # overrides docker entrypoint
  - the_command
  - --an-argument
  - --another
  - value

if you use list form, you must explicitly list out each word.  you may use either yaml block list syntax as above or flow list syntax [command, arg1, arg2].  if there are embedded spaces in a single item [command, --option value] then those spaces are included in a single command-line option as if you quoted it, which frequently confuses programs.
you can explicitly invoke a shell if you need to:
command:
  - sh
  - -c
  - the_command --an-argument --another value

this command is in exactly three words, sh, the option -c, and the shell command.  the shell will process this command in the usual way and execute it.
you need the shell form only if you're doing something more complicated than running a simple command with fixed arguments.  running multiple sequential commands c1 &amp;&amp; c2 or environment variable expansion c1 &quot;$option&quot; are probably the most common ones, but any standard bourne shell syntax would be acceptable here (redirects, pipelines, ...).
"
63667242,not able to fetch ip address of pods using kubectl and jsonpath,"i'm trying to get the ip address of pods with particular label using jsonpath with the following command:
kubectl get pods -l app=validate -n {namespace_name} -o jsonpath={.status.podip}
but this doesn't result into anything, even though the namespace and label names are correct. on the other hand, if i try to do:
kubectl get pod/pod_name -n {namespace_name} -o jsonpath={.status.podip}
i'm able to get the pod ip address after that. but the problem is, since i'm trying to query all the pods created for a particular deployment, i want to fetch ip addresses for all the pods under that particular label. i'm not sure what is wrong with the command.
",<kubernetes><kubectl><jsonpath>,63667450,11,"if you have multiple pods with the same label, you get a list of pods. you have to adjust your jsonpath to  -o jsonpath=&quot;{.items[*].status.podip}&quot; to get all the podips.
"
55138427,how can we restart the kubernetes pod if its readiness fail,"a quick question. i know if the kubernetes liveness probe fails, kubernetes will help restart the pod and try again. but how about the readiness probe fails? how can i also ask kubernetes to restart the pod?

api-group-0                     0/1       running     0          6h35m

restart this pod can make it works. thanks all!
",<kubernetes><kubernetes-pod>,55260522,11,"there's no way to trigger pod restart within a readiness probe.
as it was recommended in the comments, you should rely on liveness probe instead.
    livenessprobe:
      exec:
        command:
        - /opt/fissile/readiness-probe.sh
      initialdelayseconds: 20
      periodseconds: 10
      failurethreshold: 3

if you have concerns about readiness-probe.sh fails periodically and shouldn't trigger restart straight after the first failure, consider failurethreshold setting. it will give this many tries before pod restart.
"
73164466,how to create a secret for service account using kubernetes version 1.24,"i am using kubernetes version 1.24, i have created a secret for my service account manually, but when i run kubectl get serviceaccounts, it is showing that i do not have any secrets for that service account?
",<kubernetes><kubernetes-ingress><kubectl>,73165621,7,"if you are on k8s version 1.24
the serviceaccount won't create the secret automatically.
you have to create it manually.
kubectl create sa &lt;serviceaccount-name&gt;

example :
apiversion: v1
kind: secret
type: kubernetes.io/service-account-token
metadata:
  name: token-secret
  annotations:
    kubernetes.io/service-account.name: &quot;&lt;sa name&gt;&quot;

if you just want to create the token you can use the : kubectl create token &lt;name&gt;
read more about it : https://medium.com/@harsh.manvar111/k8s-v1-24-is-unable-to-create-a-serviceaccount-secret-798f8454e6e7
"
60686447,elastic kubernetes service aws deployment process to avoid down time,"its been a month i have started working on eks aws and up till now successfully deployed by code.
the steps which i follow for deployment are given below:


create image from docker terminal.
tag and push to ecr aws.
create the deployment ""project.json"" and service file ""project-svc.json"".
save the above file in ""kubectl/bin"" path and deploy it with following commands below.
""kubectl apply -f projectname.json"" and ""kubectl apply -f projectname-svc.json"".
so if i want to deployment the same project again with change, i push the new image on ecr and delete the existing deployment by using ""kubectl delete -f projectname.json"" without deleting the existing service and deploy it again using command ""kubectl apply -f projectname.json"" again.


now, i'm in confusing that after i delete the existing deployment there is a downtime until i apply or create the deployment again. so, how to avoid this ? because i don't want the downtime actually that is the reason why i started to use the eks. 
and one more thing is the process of deployment is a bit long too. i know i'm missing something can anybody guide me properly please?

the project is on .net core and if there is any simplified way to do deployment using visual studio please guide me for that also.

thank you in advance!
",<amazon-web-services><docker><kubernetes><amazon-eks>,60689342,1,"you only need to use the delete/apply if you are changing (and if you have) the configmap attached to the deployment.
is the only change you do is the ""image"" of the deployment - you must use the ""set-image"" command.

kubectl let you change the actual deployment image and it does the rolling updates all by itself and with 3+ pods you have the minimum chance for downtime.
even more, if you use the --record flag, you can ""rollback"" to your previous image with no effort because it keep track of the changes.

you also have the possibility to specify the ""context"" too, with no need to jump from contexts.

you can go like this:


  kubectl set image deployment deployment_name deployment_name=image_name --record -n namespace


or specifying the cluster


  kubectl set image deployment deployemtn_name deployemtn_name=image_name_ecr -n namespace --cluster eks_cluster_nprod --user eks_cluster --record


as an eg:

kubectl set image deployment nginx-dep nginx-dep=ecr12345/nginx:latest -n nginx --cluster eu-central-123-prod --user eu-central-123-prod --record


the --record is what let you track all the changes, if you want to rollback just do:

kubectl rollout undo deployment.v1.apps/nginx-dep


more documentations about it here:

updating a deployment
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment

roll back deployment
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-back-a-deployment
"
72855183,k3s agent node not getting connected to master node on aws instance,"
environmental info:
k3s version:
v1.23.8+k3s1 (53f2d4e7)
node(s) cpu architecture: os, and version:
linux ip-172-31-88-240 5.15.0-1011-aws #14-ubuntu smp wed jun 1 20:54:22 utc 2022 x86_64 x86_64 x86_64 gnu/linux
cluster configuration:
1 master and 2 agent nodes
description  the bug:
agent node not joining master node when i type command kubectl get nodes.
steps to reproduce:

installed k3s on the master node

$ master_ip=3.93.220.207 (ipv4 public ip: 3.93.220.207)



$curl -sfl https://get.k3s.io | install_k3s_exec=&quot;--write-kubeconfig-mode 644 --no-deploy traefik --disable traefik --tls-san &quot;$master_ip&quot; --node-external-ip &quot;$master_ip&quot; --disable servicelb&quot; sh -s -

generated token by  sudo cat /var/lib/rancher/k3s/server/node-token
on each agent
master_ip=3.93.220.207
export token=your_master_token 
curl -sfl https://get.k3s.io | sh -s - agent --server https://$master_ip :6443 --token ${token} 

expected behavior:
kubectl get nodes command should show agent nodes, but agent nodes are not attached ...

actual behavior:
kubectl get nodes does not show agent nodes ....
please help me to resolve this issue ..... i have done all steps correctly and also exposed the public ip ....i am feeling frustated ... i have been trying this from many days.i even tried implementing this on a virtual box as well but every time i get disappointment.
extra information
(failed to get ca certs)
systemctl status k3s-agent command gives shows 
",<kubernetes><amazon-eks><rancher><k3s>,74182726,1,"from your master node setup command, since you did not supply k3s_token so the token is generated, so make sure your your_master_token value is correct, it can be retrieved by running sudo cat /var/lib/rancher/k3s/server/token in the master node.
the command you run in k3s agent doesn't look right, it is seems that you are mixing the command of joining cluster as agent and as master, make sure you know the difference between a ha cluster and non-ha cluster.
to add k3s agent to the cluster, just run
export url=&quot;https://&lt;&lt;master ip address&gt;&gt;:6443&quot;
export token=&quot;&lt;&lt;token&gt;&gt;&quot;
curl -sfl https://get.k3s.io | k3s_url=$url k3s_token=$token sh -

finally, as you are running it in aws, make sure your vpc settings correct, it includes the right security group settings to allow communication to/from ip range and port range between your master and agent node. also, the nacl of your subnets.
if you are doing it for poc purpose, just put all the instance in the same public subnet will save your time.
"
71523839,"2-node cluster, master goes down, worker fails","we have a 2 node k3s cluster with one master and one worker node and would like &quot;reasonable availability&quot; in that, if one or the other nodes goes down the cluster still works i.e. ingress reaches the services and pods which we have replicated across both nodes. we have an external load balancer (f5) which does active health checks on each node and only sends traffic to up nodes.
unfortunately, if the master goes down the worker will not serve any traffic (ingress).
this is strange because all the service pods (which ingress feeds) on the worker node are running.
we suspect the reason is that key services such as the traefik ingress controller and coredns are only running on the master.
indeed when we simulated a master failure, restoring it from a backup, none of the pods on the worker could do any dns resolution. only a reboot of the worker solved this.
we've tried to increase the number of replicas of the traefik and coredns deployment which helps a bit but:

this gets lost on the next reboot
the worker still functions when the master is down but every 2nd ingress request fails

it seems the worker still blindly (round-robin) sends traffic to a non-existant master



we would appreciate some advice and explanation:

should not key services such as traefik and coredns be daemonsets by default?
how can we change the service description (e.g. replica count) in a persistent way that does not get lost
how can we get intelligent traffic routing with ingress to only &quot;up&quot; nodes
would it make sense to make this a 2-master cluster?

update: ingress description:
kubectl describe ingress -n msa
name:             msa-ingress
namespace:        msa
address:          10.3.229.111,10.3.229.112
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  tls-secret terminates service.ourdomain.com,node1.ourdomain.com,node2.ourdomain.com
rules:
  host                           path  backends
  ----                           ----  --------
  service.ourdomain.com
                                /   gateway:8443 (10.42.0.100:8443,10.42.1.115:8443)
  node1.ourdomain.com
                                /   gateway:8443 (10.42.0.100:8443,10.42.1.115:8443)
  node2.ourdomain.com
                                /   gateway:8443 (10.42.0.100:8443,10.42.1.115:8443)
annotations:                     kubernetes.io/ingress.class: traefik
                                traefik.ingress.kubernetes.io/router.middlewares: msa-middleware@kubernetescrd
events:                          &lt;none&gt;

",<kubernetes><kubernetes-ingress><k3s><traefik-ingress>,71649713,1,"your goals seems can be achievable with a few k8s internal features (not specific to traffic):

assure you have 1 replica of ingress controller's pod on each node =&gt; use daemon set as a installation method

to fix the error from ingress description set the correct load balancer ip of ingress controller's service.

use external traffic policy to &quot;local&quot; - this assures that traffic is routed to local endpoints only (controller pads running on node accepting traffic from load balancer)



externaltrafficpolicy - denotes if this service desires to route external traffic to node-local or cluster-wide endpoints. there are two available options: cluster (default) and local. cluster obscures the client source ip and may cause a second hop to another node, but should have good overall load-spreading. local preserves the client source ip and avoids a second hop for loadbalancer and nodeport type services, but risks potentially imbalanced traffic spreading.

apiversion: v1
kind: service
metadata:
  name: example-service
spec:
  selector:
    app: example
  ports:
    - port: 8765
      targetport: 9376
  externaltrafficpolicy: local
  type: loadbalancer


service name of ingress backend should use external traffic policy externaltrafficpolicy: local too.

"
69607239,kubectl - how to retrieve values of default labels in kubernetes?,"as mentioned here: &quot;currently namespace, pod are default labels provided in the metrics.&quot;

kubectl -n mynamespace get pods --show-labels show the label values that are defined in deployment yaml for kubernetes

goal is to use default label(namespace &amp; pod provided by kubernetes) values through grafana dashboard's promql, that prometheus monitor.
sum(container_memory_working_set_bytes{namespace=&quot;mynamespace&quot;,pod=~&quot;unknown&quot;}) by (pod)


how to view the values of default label pod using kubectl?
",<kubernetes><prometheus><grafana><kubectl><kubernetes-pod>,69622758,1,"according to the link that you shared, {namespace} and {pod} are default labels provided in the metrics, they are referring to the exposed metrics included in the kube-state-metrics (ksm) service.
kube-state-metrics (ksm) is a simple service that listens to the kubernetes api server and generates metrics about the state of the objects.
the exposed metrics are detailed in this document.
in the following links, you can find the related metric for pods and namespace.
speaking about the default labels for pods, you need to create a pod label controller or indicate the label in the pod template.
if you don't explicitly specify labels for the controller, kubernetes will use the pod template label as the default label for the controller itself. the pod selector will also default to pod template labels if unspecified.
if you want to know more about best practices for labels, please follow this link.
if you want to know more about labels and selector, follow this link.
more about pod template here.
"
69160344,how to get all the default user groups of a kubernetes cluster,"such as system:masters、system:anonymous、system:unauthenticated.
is there a way to have all system groups that do not contain external creation, just the system，kubectl command or a list?
i searched the kubernetes documentation but didn't find a list or a way to get it.
",<kubernetes><kubectl>,69175759,4,"there is no build-in command to list all the default user groups from the kubernetes cluster.
however you can try to workaround in several options:

you can create your custom script (i.e. in bash) based on kubectl get clusterrole command.
you can try install some plugins. plugin rakkess could help you:


have you ever wondered what access rights you have on a provided kubernetes cluster? for single resources you can use kubectl auth can-i list deployments, but maybe you are looking for a complete overview? this is what rakkess is for. it lists access rights for the current user and all server resources, similar to kubectl auth can-i --list.

see also more information about:

kubelet authentication / authorization
anonymous requests

"
51372578,no kafka metrics in grafana/prometheus,"i successfully deployed helm chart prometheus operator,  kube-prometheus and kafka (tried both image danielqsj/kafka_exporter v1.0.1 and  v1.2.0). 

install with default value mostly, rbac are enabled. 

i can see 3 up nodes in kafka target list in prometheus, but when go in grafana, i can's see any kafka metric with kafka overview

anything i missed or what i can check to fix this issue?

i can see metrics start with java_, kafka_, but no jvm_ and only few jmx_ metrics.



i found someone reported similar issue (https://groups.google.com/forum/#!searchin/prometheus-users/jvm_%7csort:date/prometheus-users/otym7qgmbva/dz4vifwlagaj), so i deployed with old version of jmx exporter from 0.6 to 0.9, still no jvm_ metrics.

are there anything i missed?

env:

kuberentes: aws eks (kubernetes version is 1.10.x)

public grafana dashboard: kafka overview
",<apache-kafka><kubernetes><kubernetes-helm><amazon-eks>,51391633,2,"just realised the owner of jmx-exporter mentioned in readme:


  this exporter is intended to be run as a java agent, exposing a http server and serving metrics of the local jvm. it can be also run as an independent http server and scrape remote jmx targets, but this has various disadvantages, such as being harder to configure and being unable to expose process metrics (e.g., memory and cpu usage). running the exporter as a java agent is thus strongly encouraged.


not really understood what's that meaning, until i saw this comment: 

https://github.com/prometheus/jmx_exporter/issues/111#issuecomment-341983150


  @brian-brazil can you add some sort of tip to the readme that jvm_* metrics are only exposed when using the java agent? it took me an hour or two of troubleshooting and searching old issues to figure this out, after playing only with the http server version. thanks!


so jmx-exporter has to be run with java agent to get jvm_ metric. jmx_prometheus_httpserver doesn't support, but it is the default setting in kafka helm chart.

https://github.com/kubernetes/charts/blob/master/incubator/kafka/templates/statefulset.yaml#l82

command:
- sh
- -exc
- |
  trap ""exit 0"" term; \
  while :; do \
  java \
  -xx:+unlockexperimentalvmoptions \
  -xx:+usecgroupmemorylimitforheap \
  -xx:maxramfraction=1 \
  -xshowsettings:vm \
  -jar \
  jmx_prometheus_httpserver.jar \              # &lt;&lt;&lt; here
  {{ .values.prometheus.jmx.port | quote }} \
  /etc/jmx-kafka/jmx-kafka-prometheus.yml &amp; \
  wait $! || sleep 3; \
  done

"
74161348,kubernetes ingress not accepting the self signed ssl,"my kubernetes ingress is not accepting the self signed certificate and instead when opening the url on firefox the kubernetes ingress controller fake certificate is added.

all the things done locally on pc with minikube in kali linus. kali
linus is running in a virtual machine by vmware software.the doc which
i am referring is -
https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-multi-ssl

the ingress yaml file.
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: first-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
spec:
  tls:
  - hosts:
      - example.com
    secretname: myssl
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: first-service
            port:
              number: 8080

the &quot;192.168.49.2&quot; is the ingress ip address. so https://192.68.49.2 opens my app on the browser.
the certificate is generated with openssl with the following commands:
openssl genrsa -out s.key 2048
openssl req -new -key s.key -out s.csr -subj &quot;/cn=example.com&quot;
openssl x509 -req -days 365 -in s.csr -signkey s.key -out s.crt

the certificate is added to k8s secret.
kubectl create secret tls myssl --cert s.crt --key s.key

the curl -kv https://192.168.49.2 command output is:
* trying 192.168.49.2:443...
* connected to 192.168.49.2 (192.168.49.2) port 443 (#0)
* alpn: offers h2
* alpn: offers http/1.1
* tlsv1.0 (out), tls header, certificate status (22):
* tlsv1.3 (out), tls handshake, client hello (1):
* tlsv1.2 (in), tls header, certificate status (22):
* tlsv1.3 (in), tls handshake, server hello (2):
* tlsv1.2 (in), tls header, finished (20):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, encrypted extensions (8):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, certificate (11):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, cert verify (15):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, finished (20):
* tlsv1.2 (out), tls header, finished (20):
* tlsv1.3 (out), tls change cipher, change cipher spec (1):
* tlsv1.2 (out), tls header, supplemental data (23):
* tlsv1.3 (out), tls handshake, finished (20):
* ssl connection using tlsv1.3 / tls_aes_256_gcm_sha384
* alpn: server accepted h2
* server certificate:
*  subject: o=acme co; cn=kubernetes ingress controller fake certificate
*  start date: oct 22 09:57:19 2022 gmt
*  expire date: oct 22 09:57:19 2023 gmt
*  issuer: o=acme co; cn=kubernetes ingress controller fake certificate
*  ssl certificate verify result: self-signed certificate (18), continuing anyway.
* using http2, server supports multiplexing
* copying http/2 data in stream buffer to connection buffer after upgrade: len=0
* tlsv1.2 (out), tls header, supplemental data (23):
* tlsv1.2 (out), tls header, supplemental data (23):
* tlsv1.2 (out), tls header, supplemental data (23):
* h2h3 [:method: get]
* h2h3 [:path: /]
* h2h3 [:scheme: https]
* h2h3 [:authority: 192.168.49.2]
* h2h3 [user-agent: curl/7.85.0]
* h2h3 [accept: */*]
* using stream id: 1 (easy handle 0x561c242ff950)
* tlsv1.2 (out), tls header, supplemental data (23):
&gt; get / http/2
&gt; host: 192.168.49.2
&gt; user-agent: curl/7.85.0
&gt; accept: */*
&gt; 
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, newsession ticket (4):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.3 (in), tls handshake, newsession ticket (4):
* old ssl session id is stale, removing
* tlsv1.2 (in), tls header, supplemental data (23):
* connection state changed (max_concurrent_streams == 128)!
* tlsv1.2 (out), tls header, supplemental data (23):
* tlsv1.2 (in), tls header, supplemental data (23):
* tlsv1.2 (in), tls header, supplemental data (23):
&lt; http/2 200 
&lt; date: sat, 22 oct 2022 10:05:50 gmt
&lt; content-type: text/html; charset=utf-8
 ..... html of the page
* tlsv1.2 (in), tls header, supplemental data (23):
* connection #0 to host 192.168.49.2 left intact

kindly help.
update 2 days later:
i debugged and found i have installed nginx ingress with the command:
minikube addons enable ingress

it installs the ingress in ingress-nginx namespace while my secret is in default namespace. can this be the problem, if so what is the solution?
",<kubernetes><ssl><kubernetes-ingress>,74163839,3,"you have an error in your ingress manifest, here:
rules:
- host: example.com
- http:
    paths:

you have created two rules, the first matches host: example.com but defines no paths or backends; the second matches path / but doesn't set a host. you want:
rules:
- host: example.com
  http:
    paths:



it installs the ingress in ingress-nginx namespace while my secret is in default namespace. can this be the problem, if so what is the solution?

this is not a problem: it is the expected configuration. your ssl secrets should be installed in the same namespace as your application and ingress.

i've been playing with this a bit over the past couple of days, and i'm not sure you can get this to operate the way you want without using a hostname. fortunately, setting up a hostname to use during local development is relatively straightforward.
in most cases you can edit your /etc/hosts file. for example, if your application is hosted on 192.168.49.2, then you would add an entry like this to /etc/hosts to access your application at https://example.com:
192.168.49.2    example.com

you can add multiple hostname aliases, which allows you to use multiple hostname-based ingress resources on your cluster:
192.168.49.2    example.com myapp.internal anotherapp.dev

when you're testing with curl, you can use the --resolve option to accomplish the same thing:
curl --resolve example.com:443:192.168.49.2 -kv https://example.com

so for example, if i deploy the following ingress on my local cluster:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: whoami
spec:
  tls:
    - secretname: myssl
      hosts:
        - example.com
  rules:
    - host: example.com
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: whoami
                port:
                  name: http

with the following entry in /etc/hosts:
$ grep example.com /etc/hosts
193.168.1.200 example.com

running curl -skv https://example.com shows that the ingress is using my custom certificate rather than the default ingress certificate:
[...]
* server certificate:
*  subject: cn=example.com
*  start date: oct 23 12:52:45 2022 gmt
*  expire date: oct 23 12:52:45 2023 gmt
*  issuer: cn=example.com
[...]

"
76107126,ingress endpoint on k8s v1.26.3,"getting below error while trying to create an ingress endpoint on k8s v1.26.3. i have created a k8s cluster using kops.
error from server

(badrequest): error when creating &quot;ingress.yaml&quot;: ingress in version
&quot;v1&quot; cannot be handled as a ingress: strict decoding error: unknown
field &quot;spec.rules[0].http.paths[0].backend.servicename&quot;, unknown field
&quot;spec.rules[0].http.paths[0].backend.serviceport&quot;

apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  labels:
    env: prod
    app: demo-ms
    layer: frontend
  name: prod-demo-ingress
  namespace: prod
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: demo.abc.in
      http:
        paths:
          - backend:
              servicename: prod-demo-service
              serviceport: 8080
            path: /
~~~

",<kubernetes><kubernetes-ingress>,76107276,6,"apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: prod-demo-ingress
  namespace: prod
  labels:
    env: prod
    app: demo-ms
    layer: frontend
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: demo.abc.in
      http:
        paths:
          - pathtype: prefix
            path: &quot;/&quot;
            backend:
              service:
                name: prod-demo-service
                port:
                  number: 8080

"
61490287,connection to mongodb replicaset on kubernetes,"i have deployed mongodb replicaset on kubernetes using helm and the chart stable/mongodb-replicaset

on kubernetes, i can connect to mongodb using the connection string which is something of the sort

mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?replicaset=myrepl


in the event i change the number of replicas, the connection string would change as well, which also means that every application connecting to the database would need to be updated.

is there a workaround to this?

i thought of creating a service, so that only this would need to be changed, however the connection string does not pass regex validation.

any help on this is appreciated.
",<mongodb><kubernetes><kubernetes-helm><replicaset>,61514163,4,"the helm chart stable/mongodb-replicaset deploys also 2 headless services:


&lt;release name&gt;-mongodb-replicaset
&lt;release name&gt;-mongodb-replicaset-client


the dns record of &lt;release name&gt;-mongodb-replicaset returns the address of all the replicas, so, in order to connect to the replicaset, the connection string is

""mongodb+srv://&lt;release name&gt;-mongodb-replicaset.namespace.svc.cluster.local/?tls=false&amp;ssl=false""

note that tls and ssl have been set to false for testing as they were enabled by default.
"
51808297,kubenetes: change hpa min-replica,"i have kubernetes cluster hosted in google cloud. i created a deployment and defined a hpa rule for it:

kubectl autoscale deployment my_deployment --min 6 --max 30 --cpu-percent 80


i want to run a command that editing the --min value, without remove and re-create a new hpa rule. something like: 

$ kubectl autoscale deployment my_deployment --min 1 --max 30
error from server (alreadyexists): horizontalpodautoscalers.autoscaling ""my_deployment"" already exists


is this possible to edit hpa (min, max, cpu-percent, ...) on command line?
",<kubernetes><google-cloud-platform><kubectl>,51812017,28,"
  is this possible to edit hpa (min, max, cpu-percent, ...) on command line?


they are editable just as any other resource is, though either kubectl edit hpa $the_hpa_name for an interactive edit, or kubectl patch hpa $the_hpa_name -p '{""spec"":{""minreplicas"": 1}}' for doing so in a ""batch"" setting.

if you don't know the $the_hpa_name, you can get a list of them like any other resource: kubectl get hpa, and similarly you can view the current settings and status with kubectl get -o yaml hpa $the_hpa_name (or even omit $the_hpa_name to see them all, but that might be a lot of text, depending on your cluster setup).
"
72990748,"kuberbetes: dns server, ingress controller and metal lb communucations","i'm unable to wrap my head around the concepts of interconnectivity among dns, ingress controller, metallb and kubeproxy.
i know what these resources/tools/services are for and get the concepts of them individually but unable to form a picture of them working in tandem.
for example, in a bare metal setup, a client accesses my site - https://mytestsite.com, still having doubts , how effectively it lands to the right pod and where the above mentioned services/resources/tools comes into picture &amp; at what stage ?
ex. how dns talks to my metallb, if the client accesses my metallb hosting my application and how lb inturn speaks to ingresscontroller and finally where does kube-proxy comes into play here.
i went thru the k8s official documentation and few others as well but still kind of stumped here. following article is really good but i'm unable to stitch the pieces together.
https://www.disasterproject.com/kubernetes-with-external-dns/
kindly redirect me to the correct forum, if it is not the right place, thanks.
",<kubernetes><dns><kubernetes-ingress>,72999310,4,"the ingress-controller creates a service of type loadbalancer that serves as the entry point into the cluster. in a public cloud environment, a loadbalancer like elb on aws would create the counter part and set the externalip of that service to it's ip. it is like a service of type nodeport but it also has an externalip, which corresponds to the actual ip of the counterpart, a load balancer like elb on aws.
in a bare metal environment, no external load balancer will be created, so the external ip would stay in &lt;pending&gt; state forever. here for example the service of the istio ingress controller:
$ kubectl get svc istio-ingressgateway -n istio-system
name                   type           cluster-ip       external-ip      port(s)
istio-ingressgateway   loadbalancer   192.12.129.119   &lt;pending&gt;   [...],80:32123/tcp,443:30994/tcp,[...]

in that state you would need to call http://&lt;node-ip&gt;:32123 to reach the http port 80 of the ingress controller service, which would be then forwarded to your pod (more on that in a bit).
when you're using metallb, it will update the service with an external ip so you can call http://&lt;ip&gt; instead. metallb will also announce that ip, e.g. via bgp, so other know where to send traffic to, when someone would call the ip.
i havn't used external dns and only scanned the article but i guess that you can use that to also have a dns record to be created so someone can call your service by it's domain, not only by it's ip. so you can call http://example.com instead.
this is basically why you run metallb and how it interacts with your ingress controller. the ingress controller creates an entry point into the cluster and metallb configures it and attracts traffic.
until now the call to http://example.com can reach your cluster, but it needs to also reach the actual application, running in a pod inside the cluster. that's kube-proxy's job.
you read a lot about service of different types and all this kind of stuff, but in the end it all boils down to iptables rules. kube-proxy will create a bunch of those rules, that form a chain.
ssh into any kubernetes worker, run iptables-save | less command and search for the external ip configured on your ingress-controller's service by metallb. you'll find a chain with the destination of you external ip, that basically leads from the external ip over the service ip with a load balancer configuration to a pod ip.
in the end the whole chain would look something like this:
http://example.com  
  -&gt; http://&lt;some-ip&gt; (domain translated to ip)
    -&gt; http://&lt;node-ip&gt;:&lt;node-port&gt; (ingress-controller service)
---
      -&gt; http://&lt;cluster-internal-ip&gt;:&lt;some-port&gt; (service of your application)
        -&gt; http://&lt;other-cluster-internal-ip&gt;:&lt;some-port&gt; (ip of one of n pods)

where the --- line shows the switch from cluster external to cluster internal traffic. the cluster-internal-ip will be from the configured service-cdir and the other-cluster-internal-ip will be from the configured pod-cidr.
note that there are different ways to configure cluster internal traffic routing, how to run kube-proxy and some parts might even be a bit simplified, but this should give you a good enough understanding of the overall concept.
also see this answer on the question 'what is a kubernetes loadbalancer on-prem', that might provide additional input.
"
67415637,kubectl port forward reliably in a shell script,"i am using kubectl port-forward in a shell script but i find it is not reliable, or doesn't come up in time:
kubectl port-forward ${volt_node} ${volt_cluster_admin_port}:${volt_cluster_admin_port} -n ${namespace} &amp;
if [ $? -ne 0 ]; then
    echo &quot;unable to start port forwarding to node ${volt_node} on port ${volt_cluster_admin_port}&quot;
    exit 1
fi
port_forward_pid=$!

sleep 10

often after i sleep for 10 seconds, the port isn't open or forwarding hasn't happened. is there any way to wait for this to be ready. something like kubectl wait would be ideal, but open to shell options also.
",<kubernetes><kubectl>,68824178,22,"i took @akinozer's comment and turned it into this example where i port-forward a postgresql database's port so i can make a pg_dump of the database:
#!/bin/bash

set -e

localport=54320
typename=service/pvm-devel-kcpostgresql
remoteport=5432

# this would show that the port is closed
# nmap -st -p $localport localhost || true

kubectl port-forward $typename $localport:$remoteport &gt; /dev/null 2&gt;&amp;1 &amp;

pid=$!
# echo pid: $pid

# kill the port-forward regardless of how this script exits
trap '{
    # echo killing $pid
    kill $pid
}' exit

# wait for $localport to become available
while ! nc -vz localhost $localport &gt; /dev/null 2&gt;&amp;1 ; do
    # echo sleeping
    sleep 0.1
done

# this would show that the port is open
# nmap -st -p $localport localhost

# actually use that port for something useful - here making a backup of the
# keycloak database
pgpassword=keycloak pg_dump --host=localhost --port=54320 --username=keycloak -fc --file keycloak.dump keycloak

# the 'trap ... exit' above will take care of kill $pid

"
58689157,"can not apply service as ""type: clusterip"" in my gke cluster","i want to deploy my service as a clusterip but am not able to apply it for the given error message:

[xetra11@x11-work coopr-infrastructure]$ kubectl apply -f teamcity-deployment.yaml 
deployment.apps/teamcity unchanged
ingress.extensions/teamcity unchanged
the service ""teamcity"" is invalid: spec.ports[0].nodeport: forbidden: may not be used when `type` is 'clusterip'


this here is my .yaml file:

---
apiversion: apps/v1
kind: deployment
metadata:
  name: teamcity
  labels:
    app: teamcity
spec:
  replicas: 1
  selector:
    matchlabels:
      app: teamcity
  template:
    metadata:
      labels:
        app: teamcity
    spec:
      containers:
      - name: teamcity-server
        image: jetbrains/teamcity-server:latest
        ports:
        - containerport: 8111
---
apiversion: v1
kind: service
metadata:
  name: teamcity
  labels:
    app: teamcity
spec:
  type: clusterip
  ports:
  - port: 8111
    targetport: 8111
    protocol: tcp
  selector:
    app: teamcity
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: teamcity
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  backend:
    servicename: teamcity
    serviceport: 8111

",<kubernetes><google-kubernetes-engine><kubernetes-ingress><kubernetes-service>,58712008,6,"apply a configuration to the resource by filename:

kubectl apply -f [.yaml file] --force


this resource will be created if it doesn't exist yet. to use 'apply', always create the resource initially with either 'apply' or 'create --save-config'.

2) if the first one fails, you can force replace, delete and then re-create the resource:

kubectl replace -f grav-deployment.yml


this command is only used when grace-period=0. if true, immediately remove resources from api and bypass graceful deletion. note that immediate deletion of some resources may result in inconsistency or data loss and requires confirmation.
"
69367327,too many redirects on ingress-controller,"i am trying to setup an ingress controller based upon:
https://kubernetes.github.io/ingress-nginx/deploy/#aws
it works fine for elb, but for some reason, if i set the following in nlb:
nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;

then i am getting a too many redirects error.
if i set the above to false then i can access both http and https separately but there is no redirection.
in my service annotations for nlb i have:
apiversion: v1
kind: service
metadata:
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: &quot;443&quot;
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: '3600'
    service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: &quot;*&quot;
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:eu-west-1:12345:certificate/xyz
    service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy: elbsecuritypolicy-fs-1-2-2019-08
...
spec:
  type: loadbalancer
  externaltrafficpolicy: local
  ports:
    - name: http
      port: 80
      protocol: tcp
      targetport: http
      appprotocol: http
    - name: https
      port: 443
      protocol: tcp
      targetport: http
      appprotocol: https

for elb where it works ok i have:
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: '60'
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:eu-west-1:12345:certificate/xyz
    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: https
    service.beta.kubernetes.io/aws-load-balancer-type: elb
...
spec:
  type: loadbalancer
  externaltrafficpolicy: local
  ports:
    - name: http
      port: 80
      protocol: tcp
      targetport: tohttps
      appprotocol: http
    - name: https
      port: 443
      protocol: tcp
      targetport: http
      appprotocol: https

i've tried many combinations but i can't get nlb to act in the same way like with elb.
",<kubernetes><kubernetes-ingress>,69375115,1,"if backend protocol set to &quot;ssl&quot; everything works fine, except the fact that we're doing double tls offloading for no reason (on nlb first, then on ingress). if backend protocol set to &quot;tcp&quot;, we'll get &quot;plain http request sent to tls port&quot; error. if we map https to http port to address the above then http -&gt; https redirects stop working.
so to make it working with nlb i needed set the backend protocol to ssl: service.beta.kubernetes.io/aws-load-balancer-backend-protocol: ssl
and then:
spec:
  type: loadbalancer
  externaltrafficpolicy: local
  ports:
    - name: http
      port: 80
      protocol: tcp
      targetport: http
    - name: https
      port: 443
      protocol: tcp
      targetport: https

"
64608453,how do i export a kubernetes manifest file without the metadata?,"i'm trying to export a daemonset from my kubernetes cluster but i dont want any of the metadata. is there a way i can export the manifest file without the metadata, like creationtimestamp, uid_selflink, etc.
for example, something like this would be perfect:
kubectl get daemonset mydaemonset --no-meta-data -o yaml &gt; exported-mydaemonset.yaml

i want to discard information about the current object state.
",<bash><amazon-web-services><kubernetes><devops><amazon-eks>,64609091,2,"you can make use of the annotation field kubectl.kubernetes.io/last-applied-configuration, which holds the resource initial applied configuration without auto-generated fields.
get it manually, or parse it with yq:
kubectl get daemonset mydaemonset -o yaml | \
yq r - 'metadata.annotations.&quot;kubectl.kubernetes.io/last-applied-configuration&quot;'

"
61142550,loop thru lines of plain text file passed by --set-file helm option then parse each line by column,"i have a cron file and i am trying to pass it thru --set-file option.
i want to loop thru the cron file lines and create for each line new kubernetes object of kind cronjob.

i used it like this helm instal ... --set-file crons.file=mycron

where mycron file looks like a typical cron file:

0,10,20,30,40,50 * * * * /usr/bin/cmd1 opta optb
35 2-23/3 * * * /usr/bin/cmd2


i am not able to iterate thru lines of this simple plain text : 

{{- range $indx, $line := .values.crons.file }}
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: {{ regexfind ""[^/]+$"" ""$line""}}
  jobtemplate:
    spec:
      template:
        spec:
          containers:
          - name: cron-{{ $indx }}
            image: busybox
            args: 
            - /bin/sh
            - -c
            - {{ regexfind ""[^/]+$"" ""$line""}}
          restartpolicy: onfailure
{{- end  }}


is there a function like fromyaml which makes a plain text file iterable by range function ?
",<kubernetes><kubernetes-helm><sprig-template-functions>,61151071,5,"the sprig support library includes functions for splitting and joining strings into lists, and for manipulating lists in general.  if splitlist the file on newlines, you'll get a list of lines.  you can again splitlist each line on spaces to get the separate time and command parts out of the individual cron lines.

{{/* iterate over individual lines in the string */}}
{{- range $line := splitlist ""\n"" .values.crons.file -}}

{{/* break the line into words */}}
{{- $words := splitlist "" "" $line -}}

{{/* reconstitute the schedule and command parts from the words */}}
{{- $time := slice $words 0 5 | join "" "" -}}
{{- $command := slice $words 5 -}}

---
schedule: {{ $time }}
command: {{- $command | toyaml | nindent 2}}
{{ end -}}

"
70913822,"kubernetes (k3s) pod gets ""enotfound"" after 5-20 hours of airing time","i'm running my backend on kubernetes on around 250 pods under 15 deployments, backend in written in nodejs.
sometimes after x number of hours (5&lt;x&lt;30) i'm getting enotfound in one of the pods, as follows:
{
  &quot;name&quot;: &quot;main&quot;,
  &quot;hostname&quot;: &quot;entrypoint-sdk-54c8788caa-aa3cj&quot;,
  &quot;pid&quot;: 19,
  &quot;level&quot;: 50,
  &quot;error&quot;: {
    &quot;errno&quot;: -3008,
    &quot;code&quot;: &quot;enotfound&quot;,
    &quot;syscall&quot;: &quot;getaddrinfo&quot;,
    &quot;hostname&quot;: &quot;employees-service&quot;
  },
  &quot;msg&quot;: &quot;failed calling getemployee&quot;,
  &quot;time&quot;: &quot;2022-01-28t13:44:36.549z&quot;,
  &quot;v&quot;: 0
}

i'm running a stress test on the backend of yy number of users per second, but i'm keeping this stress level steady and not changing it, and then it happens out of nowhere with no specific reason.
kubernetes is k3s server version: v1.21.5+k3s2
any idea what might cause this weird enotfound?
",<javascript><node.js><kubernetes><kubernetes-pod><k3s>,70924542,3,"already saw your same question on github and reference to getaddrinfo enotfound with newest versions.
as per comments this issue does not appear in k3s 1.21, that is 1 version below yours. i know it almost impossible, but any chance to try similar setup on this ver?
and it seems error comes from node/lib/dns.js.
function errnoexception(err, syscall, hostname) {
  // fixme(bnoordhuis) remove this backwards compatibility nonsense and pass
  // the true error to the user. enotfound is not even a proper posix error!
  if (err === uv.uv_eai_memory ||
      err === uv.uv_eai_nodata ||
      err === uv.uv_eai_noname) {
    err = 'enotfound';
  }

what i wanted to suggest you is to check solving dns lookup failures in kubernetes. article describes long hard way of catching the same error you have that also  bothered from time to time.
as a solution aftet investigating all the metrics, logs, etc - was installing   k8s cluster add-on called node local dns cache, that

improves cluster dns performance by running a dns
caching agent on cluster nodes as a daemonset. in today's
architecture, pods in clusterfirst dns mode reach out to a kube-dns
serviceip for dns queries. this is translated to a kube-dns/coredns
endpoint via iptables rules added by kube-proxy. with this new
architecture, pods will reach out to the dns caching agent running on
the same node, thereby avoiding iptables dnat rules and connection
tracking. the local caching agent will query kube-dns service for
cache misses of cluster hostnames(cluster.local suffix by default).
motivation

with the current dns architecture, it is possible that pods with the    highest dns qps have to reach out to a different node, if there
is no    local kube-dns/coredns instance. having a local cache will
help    improve the latency in such scenarios.
skipping iptables dnat and connection tracking will help reduce    conntrack races and avoid udp dns entries filling up conntrack table.
connections from local caching agent to kube-dns service can be    upgraded to tcp. tcp conntrack entries will be removed on connection
close in contrast with udp entries that have to timeout (default
nf_conntrack_udp_timeout is 30 seconds)
upgrading dns queries from udp to tcp would reduce tail latency    attributed to dropped udp packets and dns timeouts usually up to 30s
(3 retries + 10s timeout). since the nodelocal cache listens for udp
dns queries, applications don't need to be changed.
metrics &amp; visibility into dns requests at a node level.
negative caching can be re-enabled, thereby reducing number of    queries to kube-dns service.


"
69654097,in k8s find what nodes do pods exist in,"i want to know what nodes correspond to pods in a k8s cluster. i am working with a 3 node k8s cluster which has 2 specific pods among other pods.
how can i see which pod exists in which node using kubectl?
when i use kubectl get pods, i get the following:
name                                  ready   status    restarts   age
pod1-7485f58945-zq8tg                 1/1     running   2          2d
pod2-64c4564b5c-8rh5x                 1/1     running   0          2d1h

following is the version of k8s (kubectl version) that i am using
client version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.0&quot;, gitcommit:&quot;af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-12-08t17:59:43z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;darwin/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;19&quot;, gitversion:&quot;v1.19.13&quot;, gitcommit:&quot;53c7b65d4531a749cd3a7004c5212d23daa044a9&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-07-15t20:53:19z&quot;, goversion:&quot;go1.15.14&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

",<kubernetes><kubernetes-helm><kubernetes-pod>,69654121,2,"try kubectl get pods -o wide.
you can get more details in this very detailed kubernetes cheatsheet.
"
37071200,auto-scaling is taking more time to bring up new pod and giving connection error in google container engine,"i have used following command  for autoscaling.

kubectl autoscale deployment catch-node --cpu-percent=50 --min=1 --max=10


the status of autoscaling in my case on load test is as like below .

27th minute

name         reference                     target    current   minpods   maxpods   age
catch-node   deployment/catch-node/scale   50%       20%      1         10        27m

name         desired   current   up-to-date   available   age
catch-node   1         1         1            1           27m


29th minute

name         reference                     target    current   minpods   maxpods   age
catch-node   deployment/catch-node/scale   50%       35%      1         10        29m

name         desired   current   up-to-date   available   age
catch-node   1         1         1            1           29m


31st minute

name         reference                     target    current   minpods   maxpods   age
catch-node   deployment/catch-node/scale   50%       55%      1         10        31m

name         desired   current   up-to-date   available   age
catch-node   1         1         1            1           31m


34th minute

name         reference                     target    current   minpods   maxpods   age
catch-node   deployment/catch-node/scale   50%       190%      1         10        34m

name         desired   current   up-to-date   available   age
catch-node   4         4         4            4           34m


here i am  getting connection refusing error in the time between transition of 1 pod to 4pods on autoscaling. please let me know how much time it will take to bring up new pods once it exceed the cpu % limit given during autoscale .also please let me know is there any method to reduce this time .once all new pods comes up, the issue is not there . thanks in advance
",<kubernetes><google-kubernetes-engine><google-container-registry>,37104992,3,"as documented in this doc, there are two factors affect the reaction time of the autoscaler:


--horizontal-pod-autoscaler-sync-period, which defines how often the autoscaler checks the status of the controlled resources. the default value is 30s. it can be changed via the flag of the controller-manager.
upscaleforbiddenwindow, which defines how often the autoscaler can scale up the resource. the default value is 3 mins. currently it's not adjustable.


according to the log you pasted, if the load is stable, the autoscaler should reacted in 30s after cpu usage reaches 55%, is that the case?
"
62013028,"is kube2iam unnecessary with, and/or a part of, eks?","in the amazon eks user guide, there is a page dedicated to creating alb ingress controllers by using an eponymous third-party tool, aws alb ingress controller for kubernetes.

both the eks user guide and the documentation for the controller have their own walkthroughs for how to set up the controller. 

the walkthrough provided by the controller has you either hard-code your aws secret key into a deployment manifest, or else install yet another third-party tool called kube2iam. 

the walkthrough in the aws eks user guide has you post exactly the same deployment manifest, but you don't have to modify it at all. instead, you create both an iam role (step 5) and a kubernetes service account (step 4) for the controller, and then you link them together by annotating the service account with the arn for the iam role. prima facie, this seems to be what kube2iam is for.

this leads me to one of three conclusions, which i rank in rough order of plausibility:


eks contains the functionality of kube2iam as one of its features (possibly by incorporating kube2iam into its codebase), and so installing kube2iam is superfluous.
eksctl installs kube2iam behind the scenes as part of associate-iam-oidc-provider.
the documentation for the controller was written for an earlier version of kubernetes, and this functionality is now built into the stock control plane.


does anyone happen to know which it is? why doesn't the aws walkthrough need me to install kube2iam?
",<kubernetes><kubernetes-ingress><amazon-eks>,62019491,6,"
  does anyone happen to know which it is? why doesn't the aws walkthrough need me to install kube2iam?


yes, i can authoritatively answer this. in 09/2019 we launched a feature in eks called iam roles for service accounts. this makes kube2iam and other solutions obsolete since we support least-privileges access control on the pod level now natively.

also, yes, the alb ic walkthrough should be updated.
"
75447815,"error from server (forbidden): pods is forbidden: user cannot list resource ""pods"" in api group at the cluster scope","my private aks cluster is accessible only to the root user using kubectl on a jumphost. but for a non-root user it throws below error message:
someuser@jump-vm$ kubectl get pods -a
error from server (forbidden): pods is forbidden: user &quot;xx-xx-xx-xx-xx&quot; cannot list resource &quot;xx&quot; in api group &quot; &quot; at the cluster scope

how to resolve this error?
",<kubernetes><kubectl><azure-aks><kubeconfig>,75468560,2,"in this case solution was to delete the old config from $home/.kube/ and re-initialize it after az login with the user in question
"
62334306,how can i tail an arbitrary file using kubectl?,"is it possible to tail an arbitrary file from a kubernetes pod using kubectl? kubectl cp doesn't appear to support this.  and i don't want to tail all the logs, which i know i could do with kubectl logs -f.
",<kubernetes><kubectl>,62334407,4,"perhaps with kubectl exec.

untested, and i haven't done a lot with k8s but:

kubectl exec -i podname -- tail -f filename


might work.
"
48747967,"kubernetes endpoints empty , can i restart the pods?","i have a situation where i have zero endpoints available for one service. to test this, i specially crafted a yaml descriptor that uses a simple node server to set and retrieve the ready/live status for a pod:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: nodejs-deployment
  labels:
    app: nodejs
spec:
  replicas: 3
  selector:
    matchlabels:
      app: nodejs
  template:
    metadata:
      labels:
        app: nodejs
    spec:
      containers:
      - name: nodejs
        image: nodejs_server
        ports:
        - containerport: 8080
        livenessprobe:
          httpget:
            path: /is_alive
            port: 8080
          initialdelayseconds: 5
          timeoutseconds: 3
          periodseconds: 10
        readinessprobe:
          httpget:
            path: /is_ready
            port: 8080
          initialdelayseconds: 5
          timeoutseconds: 3
          periodseconds: 10
---
apiversion: v1
kind: service
metadata:
  name: nodejs-service
  labels:
    app: nodejs
spec:
  ports:
  - port: 80
    protocol: tcp
    targetport: 8080
  selector:
    app: nodejs
---    
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: nodejs-ingress
spec:
  backend:
    servicename: nodejs-service
    serviceport: 80


the node server has methods to set and retrieve the liveness and readiness. 

when the app start i can see that 3 replicas are created and the status of them is ready. ok then now i trigger manually the status of their readiness to set to false [from outside the ingress]. one pod is correctly removed from the endpoint so no traffic is routed to it[that's ok as this is the expected behavior]. when i set all the ready-statuses to false for all pods the endpoints list is empty [still the expected behavior].

at that point i cannot set ready=true from outside the ingress as the traffic is not routed to any pod. is there a way here for example of triggering a restart of the pod when the ready is not achieved after n-timer or n-seconds? or when the endpoints list is empty?
",<kubernetes><kubernetes-health-check><kubernetes-ingress>,48748336,2,"well, that is perfectly normal and expected behaviour. what you can do, on the side, is to forward traffic from localhost to a particular pod with kubectl port-forward. that way you can access the pod directly, without ingresses etc. and set it's readiness back to ok. if you want to restart when host it not ready for to long, just use the same endpoint for liveness probe, but trigger it after more tries.
"
77870543,unable to mount gcp filestore pvc to job pods,"i have a kubernetes job (with parallelism: 50) running on gke autopilot cluster, that needs more storage than maximum ephemeral storage provisioned by autopilot cluster per node (i.e. 10gi). as i need readwritemany access for pods on the storage, i decided on gcp filestore (though it would've been nice if minimum instance size for filestore was less than 1 tib) for creating pvc that can be mounted on job pods, but job pods are stuck in containercreating state and looking at the event logs, mountvolume.mountdevice failure seems to be the reason:
 warning  failedscheduling  11m                   gke.io/optimize-utilization-scheduler  0/12 nodes are available: 11 insufficient memory, 12 insufficient cpu. preemption: 0/12 nodes are available: 12 no preemption victims found for incoming pod..
  normal   triggeredscaleup  11m                   cluster-autoscaler                     pod triggered scale-up
  normal   scheduled         6m39s                 gke.io/optimize-utilization-scheduler  successfully assigned default/mypod-7l5k9 to gk3-mycluster-3-e79620bd-jvsg
  warning  failedmount       4m8s (x6 over 4m39s)  kubelet                                mountvolume.mountdevice failed for volume &quot;pvc-435bf565-25f0-43f7-86d4-b3ecadce43a3&quot; : rpc error: code = aborted desc = an operation with the given volume key modeinstance/asia-northeast1-b/pvc-435bf565-25f0-43f7-86d4-b3ecadce43a3/vol1 already exists.
 --- most likely a long process is still running to completion. retrying.
  warning  failedmount  2m19s                kubelet  unable to attach or mount volumes: unmounted volumes=[my-mounted-storage], unattached volumes=[kube-api-access-4gs6h shared-storage]: timed out waiting for the condition
  warning  failedmount  96s (x2 over 4m39s)  kubelet  mountvolume.mountdevice failed for volume &quot;pvc-435bf565-25f0-43f7-86d4-b3ecadce43a3&quot; : rpc error: code = deadlineexceeded desc = context deadline exceeded
  warning  failedmount  5s (x2 over 4m36s)   kubelet  unable to attach or mount volumes: unmounted volumes=[my-mounted-storage], unattached volumes=[my-mounted-storage kube-api-access-4gs6h]: timed out waiting for the condition

here's my pvc and job manifest:
kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: podpvc
spec:
  accessmodes:
    - readwritemany
  storageclassname: standard-rwx
  resources:
    requests:
      storage: 1ti

apiversion: batch/v1
kind: job
metadata:
  name: mypod
  labels:
    app.kubernetes.io/name: mypod
spec:
  parallelism: 50
  template:
    metadata:
      name: mypod
    spec:
      serviceaccountname: workload-identity-sa
      volumes:
      - name: my-mounted-storage
        persistentvolumeclaim:
          claimname: podpvc
      containers:
      - name: mypod-container
        image: mypod-image:staging-0.1
        imagepullpolicy: always
        env:
        - name: env
          value: &quot;stg&quot;
        resources:
          requests:
            cpu: &quot;4&quot;
            memory: &quot;16gi&quot;
        volumemounts:
        - name: my-mounted-storage
          mountpath: /mnt/data
      restartpolicy: onfailure


both pv and pvc seems to be healthy and bound, and there doesn't seem to be any existing volume attachments on the nodes (kubectl describe nodes | grep attach). i've also tried deleting both the pvc and job, and recreating them but the issue persists.

",<kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-pvc><google-cloud-filestore>,77871329,3,"below checkpoints can help you to resolve your issue:
1. checking if the filestore is in default network:
check if the gke cluster and filestore are created under a non-default network, and use the gke supported storageclasses: standard-rwx, enterprise-rwx, premium-rwx, which you can find in the networking section of cluster. this would cause the filestore instance to provision in a default network. this results in the mount failing as filestore (default network) cannot be mounted on the nodes (non-default network).
to resolve this issue, you need to specify the network parameter for the filestore mount to match the network of the gke cluster by adding the storageclass.parameters.network field as follows:
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: filestore-example
provisioner: filestore.csi.storage.gke.io
volumebindingmode: immediate
allowvolumeexpansion: true
parameters:
  tier: standard
  network: default

2. check the ip addresses:
check if the ip address of the filestore and the ip address present in the pvc are different. the pvc should contain the ip address of the filestore and the name of the filestore. if they are different, try editing the yaml file and setting the correct ip address in the pvc.
for more information follow this document.
"
59703760,helmfile sync vs helmfile apply,"
sync      sync all resources from state file (repos, releases and chart deps)
apply     apply all resources from state file only when there are changes


sync

the helmfile sync sub-command sync your cluster state as described in your helmfile ... under 
the covers, helmfile executes helm upgrade --install for each release declared in the 
manifest, by optionally decrypting secrets to be consumed as helm chart values. it also 
updates specified chart repositories and updates the dependencies of any referenced local 
charts.

for helm 2.9+ you can use a username and password to authenticate to a remote repository.


apply

the helmfile apply sub-command begins by executing diff. if diff finds that there is any changes
sync is executed. adding --interactive instructs helmfile to request your confirmation before sync.
an expected use-case of apply is to schedule it to run periodically, so that you can auto-fix skews
between the desired and the current state of your apps running on kubernetes clusters.


i went through the helmfile repo readme to figure out the difference between helmfile sync and helmfile apply. it seems that unlike the apply command, the sync command doesn't do a diff and helm upgrades the hell out of all releases 😃. but from the word sync, you'd expect the command to apply those releases that have been changed. there is also mention of the potential application of helmfile apply to periodically syncing of releases. why not use helmfile sync for this purpose? overall, the difference didn't become crystal clear, and i though there could probably be more to it. so, i'm asking.
",<kubernetes><kubernetes-helm><helmfile>,60204724,26,"consider the use case where you have a jenkins job that gets triggered every 5 minutes and in that job you want to upgrade your helm chart, but only if there are changes.
if you use helmfile sync which calls helm upgrade --install every five minutes, you will end up incrementing chart revision every five minutes.
$ helm upgrade --install httpd bitnami/apache &gt; /dev/null
$ helm list
name    revision        updated                         status          chart           app version     namespace
httpd   1               thu feb 13 11:27:14 2020        deployed        apache-7.3.5    2.4.41          default
$ helm upgrade --install httpd bitnami/apache &gt; /dev/null
$ helm list
name    revision        updated                         status          chart           app version     namespace
httpd   2               thu feb 13 11:28:39 2020        deployed        apache-7.3.5    2.4.41          default

so, each helmfile sync will result new revision. now if you were to run helmfile apply, which will first check for diffs and only then (if found) will call helmfile sync which will in turn call helm upgrade --install this will not happen.
"
66882040,what is the purpose of attribute keywords in helm chart's chart.yaml?,"i have seen in many helm chart's chart.yaml where developers provide keywords, as for example
keywords:
  - &quot;http&quot;
  - &quot;https&quot;
  - &quot;web server&quot;

what is the significance of providing these? are these getting validated by something in helm?
i tried to look out for reasons, but i did not get useful information, so posting here.
",<kubernetes><kubernetes-helm>,66882382,5,"the keywords field specifies a list of keywords about the project. it helps user search charts based on keywords. for example, helm search repo database will bring up the charts which contain the database keyword such as postgres, mariadb, etc.
search by keyword:
$ helm search repo database
name                            chart version   app version             description                                       
stable/cockroachdb              3.0.8           19.2.5                  deprecated -- cockroachdb is a scalable, surviv...
stable/couchdb                  2.3.0           2.3.1                   deprecated a database featuring seamless multi-...
stable/dokuwiki                 6.0.11          0.20180422.201901061035 deprecated dokuwiki is a standards-compliant, s...
stable/ignite                   1.2.2           2.7.6                   deprecated - apache ignite is an open-source di...
stable/janusgraph               0.2.6           1.0                     deprecated - open source, scalable graph database.
stable/kubedb                   0.1.3           0.8.0-beta.2            deprecated kubedb by appscode - making running ...
stable/mariadb                  7.3.14          10.3.22                 deprecated fast, reliable, scalable, and easy t...
stable/mediawiki                9.1.9           1.34.0                  deprecated extremely powerful, scalable softwar...
stable/mongodb                  7.8.10          4.2.4                   deprecated nosql document-oriented database tha...
stable/mongodb-replicaset       3.17.2          3.6                     deprecated - nosql document-oriented database t...
stable/mysql                    1.6.9           5.7.30                  deprecated - fast, reliable, scalable, and easy...
stable/mysqldump                2.6.2           2.4.1                   deprecated! - a helm chart to help backup mysql...
stable/neo4j                    3.0.1           4.0.4                   deprecated neo4j is the world's leading graph d...
stable/pgadmin                  1.2.2           4.18.0                  pgadmin is a web based administration tool for ...
stable/postgresql               8.6.4           11.7.0                  deprecated chart for postgresql, an object-rela...
stable/prisma                   1.2.4           1.29.1                  deprecated prisma turns your database into a re...
stable/prometheus               11.12.1         2.20.1                  deprecated prometheus is a monitoring system an...
stable/rethinkdb                1.1.4           0.1.0                   deprecated - the open-source database for the r...
stable/couchbase-operator       1.0.4           1.2.2                   deprecated a helm chart to deploy the couchbase...
stable/hazelcast                3.3.2           4.0.1                   deprecated hazelcast imdg is the most widely us...
stable/influxdb                 4.3.2           1.7.9                   deprecated scalable datastore for metrics, even...
stable/percona                  1.2.3           5.7.26                  deprecated - free, fully compatible, enhanced, ...
stable/percona-xtradb-cluster   1.0.8           5.7.19                  deprecated - free, fully compatible, enhanced, ...
stable/redis                    10.5.7          5.0.7                   deprecated open source, advanced key-value stor...
stable/redis-ha                 4.4.6           5.0.6                   deprecated - highly available kubernetes implem...

check whether the chart has that keyword:
$  helm show chart stable/mariadb
apiversion: v1
appversion: 10.3.22
deprecated: true
description: deprecated fast, reliable, scalable, and easy to use open-source relational database system. mariadb server is intended for mission-critical, heavy-load production systems as well as for embedding into mass-deployed software. highly available mariadb cluster.
home: https://mariadb.org
icon: https://bitnami.com/assets/stacks/mariadb/img/mariadb-stack-220x234.png
keywords:
- mariadb
- mysql
- database
- sql
- prometheus
name: mariadb
sources:
- https://github.com/bitnami/bitnami-docker-mariadb
- https://github.com/prometheus/mysqld_exporter
version: 7.3.14

"
40266518,deployment not detecting change of container image tag in init-container,"i have been using init-containers since they became available and find them super useful. my core image (below as web-dev) does not change much, but my init-container image (below as web-data-dev) does change often.

the init-container uses a container image with a version number. i change this version number to the latest value, and then do kubectl apply -f deployment.yaml

for instance, i change eu.gcr.io/project/web-data-dev:187 to eu.gcr.io/project/web-data-dev:188 before running kubectl apply.

when i do this however, no deployment happens, if i make any changes to the image the init-container uses, the deployment will still not happen. i assume this is because the init-container changes are not being detected.

i then tried to just put some garbage in the image field, like this: ""image"": ""thisisnotanimage"" and run kubectl apply -f again, but the update is still not applied.

my question is - how do i make kubectl apply -f detect an image tag change in an init-container? am i doing something wrong, is this a bug, or is this simply not implemented yet because init-containers are alpha?

the full deployment yaml is below.

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: web-deployment
spec:
  replicas: 1
  strategy:
    rollingupdate:
      maxunavailable: 0
  template:
    metadata:
      labels:
        app: web
        tier: frontend
      annotations:
        pod.alpha.kubernetes.io/init-containers: '[
            {
                ""name"": ""initialiser1"",
                ""image"": ""eu.gcr.io/project/web-data-dev:187"",
                ""command"": [""cp"", ""-r"", ""/data-in/"", ""/opt/""],
                ""volumemounts"": [
                    {
                        ""name"": ""file-share"",
                        ""mountpath"": ""/opt/""
                    }
                ]
            }
        ]'
    spec:
      containers:

        - image: eu.gcr.io/project/web-dev:20
          name: web
          resources:
            requests:
              cpu: 10m
              memory: 40mi
          ports:
            - containerport: 80
              name: http
            - containerport: 443
              name: https
          volumemounts:
            - name: file-share
              mountpath: /opt/

      volumes:
        - name: file-share
          emptydir: {}

",<kubernetes><google-cloud-platform><google-kubernetes-engine>,40281436,6,"if you are using kubernetes 1.4, try to change pod.alpha.kubernetes.io/init-containers to pod.beta.kubernetes.io/init-containers.

i can't find a proper issue on github, but behaviour of these two annotations is different. i can do kubectl apply -f with the second one and the deployment will be updated.

you can test it using the example below:

kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: nginx
spec:
  template:
    metadata:
      labels:
        app: nginx
      annotations:
        pod.beta.kubernetes.io/init-containers: '[
            {
                ""name"": ""install"",
                ""image"": ""busybox"",
                ""command"": [""/bin/sh"", ""-c"", ""echo foo &gt; /work-dir/index.html""],
                ""volumemounts"": [
                  {
                    ""name"": ""workdir"",
                    ""mountpath"": ""/work-dir""
                    }
                ]
            }
        ]'
    spec:
      volumes:
        - name: workdir
          emptydir: {}
      containers:
        - name: nginx
          image: nginx
          ports:
            - containerport: 80
          volumemounts:
            - name: workdir
              mountpath: /usr/share/nginx/html


try to change foo to bar and see the result:

$ cat nginx.yaml | kubectl apply -f -
deployment ""nginx"" created
$ curl $(minikube service nginx --url)
waiting, endpoint for service is not ready yet...
foo
$ cat nginx.yaml | sed -e 's/foo/bar/g' | kubectl apply -f -
deployment ""nginx"" configured
$ curl $(minikube service nginx --url)
waiting, endpoint for service is not ready yet...
bar


the same thing using pod.alpha.kubernetes.io/init-containers:

$ curl $(minikube service nginx --url)
waiting, endpoint for service is not ready yet...
foo
$ cat nginx.yaml | sed -e 's/foo/bar/g' | kubectl apply -f -
deployment ""nginx"" configured
$ curl $(minikube service nginx --url)
foo

"
57518631,how to prevent a gce kubernetes pod from working on a gpu instance?,"i use google cloud platform for my project.
now, i have a cluster with 4 node pools:
- ""micro-pool"": with minimal machines for managing the cluster
- ""cpu-pool"": with cpu-only machines for processes that don't need a gpu
- 2 ""gpu-pools"": two pools with machines that have gpus attached.  

now, what i need is for my cpu processes to never work on a gpu machine because they take so much time and doing that on a gpu machine is just costing money for nothing.
i run my pods using the
kubectl run dc-1 --image={image-name} --replicas=1 --restart=never --limits=""nvidia.com/gpu=0,cpu=4000m,memory=2gi"" -- bash -c ""command to execute""    

now, this works fine if there were no ""gpu-machines"" created from previous gpu runs. but if there was a very recent gpu run, this command will run on that instance because it has the minimum cpu and memory requirements. i thought the --limits=""nvidia.com/gpu=0 would do the trick but obviously it didn't.  

what should i do? 
",<kubernetes><google-cloud-platform><gpu><kubectl>,57518682,1,"if you want to assign the pod on particular instance or node you can use the kubernetes node selector

for example :

apiversion: v1
kind: pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagepullpolicy: ifnotpresent
  nodeselector:
    disktype: ssd


here it will assign pod based on the node selector which is disk type.

you can also check this url for further documentation : https://kubernetes.io/docs/concepts/configuration/assign-pod-node

edit 1 : 

as you are on gcp you can use this way also :

nodeselector:
        #&lt;labelname&gt;:value
        cloud.google.com/gke-nodepool: pool-highcpu8 (poolname)


edit 2 : 

if you have knowledge of affinity and anity-affinity you can implement it also.

spec:
  affinity:
    nodeaffinity:
      requiredduringschedulingignoredduringexecution:
        nodeselectorterms:
        - matchexpressions:
          - key: kubernetes.io/node-type
            operator: in
            values:
            - gpu


for cpu :

spec:
  affinity:
    podantiaffinity:
      requiredduringschedulingignoredduringexecution:
      - weight: 100
        podaffinityterm:
          labelselector:
            matchexpressions:
            - key: resources
              operator: in
              values:
              - cpu-only

"
60199159,airflow fails to write logs to s3 (v1.10.9),"i am trying to setup remote logging in airflow stable/airflow helm chart on  v1.10.9 i am using kubernetes executor and puckel/docker-airflow image. here's my values.yaml file.

airflow:
  image:
     repository: airflow-docker-local
     tag: 1.10.9
  executor: kubernetes
  service:
    type: loadbalancer
  config:
    airflow__kubernetes__worker_container_repository: airflow-docker-local
    airflow__kubernetes__worker_container_tag: 1.10.9
    airflow__kubernetes__worker_container_image_pull_policy: never
    airflow__kubernetes__worker_service_account_name: airflow
    airflow__kubernetes__dags_volume_claim: airflow
    airflow__kubernetes__namespace: airflow
    airflow__core__remote_logging: true
    airflow__core__remote_base_log_folder: ""s3://xxx""
    airflow__core__remote_log_conn_id: ""s3://aws_access_key_id:aws_secret_access_key@bucket""
    airflow__core__encrypt_s3_logs: false
persistence:
  enabled: true
  existingclaim: ''
postgresql:
  enabled: true
workers:
  enabled: false
redis:
  enabled: false
flower:
  enabled: false


but my logs don't get exported to s3, all i get on ui is

*** log file does not exist: /usr/local/airflow/logs/icp_job_dag/icp-kube-job/2019-02-13t00:00:00+00:00/1.log
*** fetching from: http://icpjobdagicpkubejob-f4144a374f7a4ac9b18c94f058bc7672:8793/log/icp_job_dag/icp-kube-job/2019-02-13t00:00:00+00:00/1.log
*** failed to fetch log file from worker. httpconnectionpool(host='icpjobdagicpkubejob-f4144a374f7a4ac9b18c94f058bc7672', port=8793): max retries exceeded with url: /log/icp_job_dag/icp-kube-job/2019-02-13t00:00:00+00:00/1.log (caused by newconnectionerror('&lt;urllib3.connection.httpconnection object at 0x7f511c883710&gt;: failed to establish a new connection: [errno -2] name or service not known'))


any one have more insights what could i be missing? 

edit: from @trejas's suggestion below. i created a separate connection and using that. here's what my airflow config in values.yaml look like

airflow:
  image:
     repository: airflow-docker-local
     tag: 1.10.9
  executor: kubernetes
  service:
    type: loadbalancer
  connections:
  - id: my_aws
    type: aws
    extra: '{""aws_access_key_id"": ""xxxx"", ""aws_secret_access_key"": ""xxxx"", ""region_name"":""us-west-2""}'
  config:
    airflow__kubernetes__worker_container_repository: airflow-docker-local
    airflow__kubernetes__worker_container_tag: 1.10.9
    airflow__kubernetes__worker_container_image_pull_policy: never
    airflow__kubernetes__worker_service_account_name: airflow
    airflow__kubernetes__dags_volume_claim: airflow
    airflow__kubernetes__namespace: airflow

    airflow__core__remote_logging: true
    airflow__core__remote_base_log_folder: s3://airflow.logs
    airflow__core__remote_log_conn_id: my_aws
    airflow__core__encrypt_s3_logs: false


i still have the same issue.
",<kubernetes><airflow><kubernetes-helm>,61551987,2,"i was running into the same issue and thought i'd follow up with what ended up working for me. the connection is correct but you need to make sure that the worker pods have the same environment variables:

airflow:
  image:
     repository: airflow-docker-local
     tag: 1.10.9
  executor: kubernetes
  service:
    type: loadbalancer
  connections:
  - id: my_aws
    type: aws
    extra: '{""aws_access_key_id"": ""xxxx"", ""aws_secret_access_key"": ""xxxx"", ""region_name"":""us-west-2""}'
  config:
    airflow__kubernetes__worker_container_repository: airflow-docker-local
    airflow__kubernetes__worker_container_tag: 1.10.9
    airflow__kubernetes__worker_container_image_pull_policy: never
    airflow__kubernetes__worker_service_account_name: airflow
    airflow__kubernetes__dags_volume_claim: airflow
    airflow__kubernetes__namespace: airflow

    airflow__core__remote_logging: true
    airflow__core__remote_base_log_folder: s3://airflow.logs
    airflow__core__remote_log_conn_id: my_aws
    airflow__core__encrypt_s3_logs: false
    airflow__kubernetes_environment_variables__airflow__core__remote_logging: true
    airflow__kubernetes_environment_variables__airflow__core__remote_log_conn_id: my_aws
    airflow__kubernetes_environment_variables__airflow__core__remote_base_log_folder: s3://airflow.logs
    airflow__kubernetes_environment_variables__airflow__core__encrypt_s3_logs: false



i also had to set the fernet key for the workers (and in general) otherwise i get an invalid token error:

airflow:
  fernet_key: ""abcdefghijkl1234567890zxcvbnmasdfghyrewsdsddfd=""

  config:
    airflow__kubernetes_environment_variables__airflow__core__fernet_key: ""abcdefghijkl1234567890zxcvbnmasdfghyrewsdsddfd=""

"
67112451,install list of charts in parallel with ok status,"i use the following code which works and installs helm charts.
i got a list of charts and it installs each chart (via loop) and wait (upgradeaction.wait = true, see below ) that the chart is up and running (using the wait=true flag of the helm) and then install the next one, the problem is that it takes a lot of time to wait that each chart is up-and-running and just then proceed to the next one, is there a way to install all in parallel and just verify at the end (of all the charts installations)  that it works (like how the wait works but for list of charts).
here is the code:
mpfile, err := ioutil.tempfile(kp, kcp)
if err != nil {
    log.error(err, &quot;error&quot;)
}

defer os.remove(tmpfile.name()) 

if _, err := tmpfile.write(cfg); err != nil {
    return err
}
if err := tmpfile.close(); err != nil {
    return err
}

kcfgfilepath := tmpfile.name()
settings := cli.new()
ac := new(action.configuration)
clientgetter := genericclioptions.newconfigflags(false)
clientgetter.kubeconfig = &amp;kcfgfilepath

for _, chartinstallation := range charts {
    chart, err := loader.load(chartinstallation.path)
    if err != nil {
        return err
    }

    releasename := releasename + &quot;-&quot; + chartinstallation.name
    if err := ac.init(clientgetter, settings.namespace(), os.getenv(&quot;helm_driver&quot;), func(format string, v ...interface{}) {
        
    }); err != nil {
        return err
    }
    releasepresent := true
    statusaction := action.newstatus(ac)
    status, err := statusaction.run(releasename)
    if err != nil {
        if strings.contains(err.error(), driver.errreleasenotfound.error()) {
            releasepresent = false
        } else {
            return err
        }
    }

    if !releasepresent {
        // install chart
        installaction := action.newinstall(ac)
        installaction.createnamespace = true
        installaction.namespace = chartinstallation.namespace
        installaction.releasename = releasename

        _, err := installaction.run(chart, nil)
        if err != nil {
            return err
        }
        log.info(&quot;chart installed: &quot;, &quot;releasename&quot;, releasename)
    }

    if status != nil {
        if releasepresent &amp;&amp; status.info.status.string() == release.statusfailed.string() { 
            upgradeaction := action.newupgrade(ac)
            // here it wait for the chart to verify that everything is up
            upgradeaction.wait = true
            upgradeaction.reusevalues = false
            upgradeaction.recreate = false
            _, err := upgradeaction.run(releasename, chart, nil)
            if err != nil {
                return err
            }
        }
    }
}

if i change it to  upgradeaction.wait = false , it starts to install all the charts without waiting to each one health checks, however not sure how can i verify it at the end of all the charts installations
",<go><kubernetes><concurrency><parallel-processing><kubernetes-helm>,67129929,2,"you could start goroutines for each chart you're installing (wrapping chart install code inside go routines) and then use sync.waitgroup to wait all goroutines to finish. something like this:
package main

import (
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;strings&quot;
    &quot;sync&quot;
)

func main() {
    kcfgfilepath := tmpfile.name()
    settings := cli.new()
    ac := new(action.configuration)
    clientgetter := genericclioptions.newconfigflags(false)
    clientgetter.kubeconfig = &amp;kcfgfilepath
    var wg sync.waitgroup

    for _, chartinstallation := range charts {
        wg.add(1)
        go installchart(&amp;wg, chartinstallation.path)
    }

    fmt.println(&quot;installing...&quot;)
    wg.wait()
    fmt.println(&quot;installed!&quot;)
}

func installchart(wg *sync.waitgroup, chartinstallationpath string) error {
    defer wg.done()

    chart, err := loader.load(chartinstallationpath)
    if err != nil {
        return err
    }

    releasename := releasename + &quot;-&quot; + chartinstallation.name
    if err := ac.init(clientgetter, settings.namespace(), os.getenv(&quot;helm_driver&quot;), func(format string, v ...interface{}) {

    }); err != nil {
        return err
    }
    releasepresent := true
    statusaction := action.newstatus(ac)
    status, err := statusaction.run(releasename)
    if err != nil {
        if strings.contains(err.error(), driver.errreleasenotfound.error()) {
            releasepresent = false
        } else {
            return err
        }
    }

    if !releasepresent {
        // install chart
        installaction := action.newinstall(ac)
        installaction.createnamespace = true
        installaction.namespace = chartinstallation.namespace
        installaction.releasename = releasename

        _, err := installaction.run(chart, nil)
        if err != nil {
            return err
        }
        log.info(&quot;chart installed: &quot;, &quot;releasename&quot;, releasename)
    }

    if status != nil {
        if releasepresent &amp;&amp; status.info.status.string() == release.statusfailed.string() {
            upgradeaction := action.newupgrade(ac)
            // here it wait for the chart to verify that everything is up
            upgradeaction.wait = true
            upgradeaction.reusevalues = false
            upgradeaction.recreate = false
            _, err := upgradeaction.run(releasename, chart, nil)
            if err != nil {
                return err
            }
        }
    }
}

here's a good resource for that: https://goinbigdata.com/golang-wait-for-all-goroutines-to-finish/
"
66199574,ingress .yml file isn't being applied to gke but works fine in minikube,"i've been using minikube and this yml file:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-service
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$1
spec:
  rules:
    - http:
        paths:
          - path: /?(.*)
            pathtype: prefix
            backend:
              service:
                name: client-cluster-ip
                port:
                  number: 3000
          - path: /api/?(.*)
            pathtype: prefix
            backend:
              service:
                name: server-cluster-ip
                port:
                  number: 5000

i've installed helm on my gke cluster and installed ingress-nginx via helm following their directions here.
i kubectl apply my k8s and they all spin up besides the ingress-service from the file above.
any help is much appreciated.
i've tried this:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-service
  namespace: my-ingress-nginx
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$1
spec:
  rules:
    - http:
        paths:
          - path: /*
            backend:
              servicename: client-cluster-ip
              serviceport: 3000
          - path: /api/*
            backend:
              servicename: server-cluster-ip
              serviceport: 5000

i'm really stuck here. not seeing ingress-service show up like i would in minikube and i have no idea why.
server-cluster-ip:
apiversion: v1
kind: service
metadata:
  name: server-cluster-ip
spec:
  type: clusterip
  selector:
    component: server
  ports:
    - port: 5000
      targetport: 5000

client-cluster-ip:
apiversion: v1
kind: service
metadata:
  name: client-cluster-ip
spec:
  type: clusterip
  selector:
    component: web
  ports:
    - port: 3000
      targetport: 3000

the deployments and the clusterip services above are being applied to the cluster but the ingress-service to direct traffic to them is not.
services:
name                                    type           
client-cluster-ip              clusterip      
kubernetes                              clusterip      
my-ingress-nginx-controller             loadbalancer   
my-ingress-nginx-controller-admission   clusterip      
postgres-cluster-ip            clusterip      
redis-cluster-ip               clusterip      
server-cluster-ip              clusterip  

the my-ingress-nginx-controller and my-ingress-nginx-controller-admission was created when i did helm install my-ingress-nginx ingress-nginx/ingress-nginx
why can't i create an ingress service?
",<kubernetes><google-kubernetes-engine><kubernetes-ingress><nginx-ingress>,66208251,1,"i realized i needed to open port 8443 from the documentation.
so i went to the firewall list in google cloud. found the rules that had tcp:80,443 in the protocols / ports. clicked it, clicked edit and added 8443 to it.
i had an error after but this fixed it:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: ingress-resource
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$1
spec:
  rules:
    - http:
        paths:
          - path: /?(.*)
            backend:
              servicename: client-cluster-ip
              serviceport: 3000
          - path: /api/?(.*)
            backend:
              servicename: server-cluster-ip
              serviceport: 5000

notice i changed * for ?(.*)
"
62311123,verifying that a kubernetes pod is deleted using client-go,"i am trying to ensure that a pod is deleted before proceeding with another kubernetes operation. so the idea i have is to call the pod delete function and then call the pod get function.

// delete pod
err := kubeclient.corev1().pods(tr.namespace).delete(podname, &amp;metav1.deleteoptions{})

if err != nil {
   ....
}

pod, err := kubeclient.corev1().pods(tr.namespace).get(podname, &amp;metav1.deleteoptions{})

// what do i look for to confirm that the pod has been deleted?


",<kubernetes><kubernetes-pod><client-go>,62311674,4,"err != nil &amp;&amp; errors.isnotfound(err)

also this is silly and you shouldn't do it.
"
73158505,terraform kubernetes secrets not applying due to namespace,"i am learning terraform and trying to translate kubernetes infrastructure over to terraform.
i have a terraform script which creates a given namespace, and then creates secrets from local files. most of the files do not create properly due to the namespace not being created fast enough.
is there a correct method to create and wait for confirmation of the name space before continuing within the terraform script? such as depends_on, etc.?
my current approach:
resource &quot;kubernetes_namespace&quot; &quot;namespace&quot; {
  metadata {
    name = &quot;specialnamespace&quot;
  }
}

resource &quot;kubernetes_secret&quot; &quot;api-env&quot; {
  metadata {
    name      = var.k8s_name_api_env
    namespace = &quot;specialnamespace&quot;
  }

  data = {
    &quot;.api&quot; = file(&quot;${path.cwd},${var.local_dir_path_api_env_file}&quot;)
  }
}

resource &quot;kubernetes_secret&quot; &quot;password-env&quot; {
  metadata {
    name      = var.k8s_name_password_env
    namespace = &quot;specialnamespace&quot;
  }

  data = {
    &quot;.password&quot; = file(&quot;${path.cwd},${var.local_dir_path_password_env_file}&quot;)
  }
}

resource &quot;kubernetes_secret&quot; &quot;tls-crt-env&quot; {
  metadata {
    name      = var.k8s_name_tls_crt_env
    namespace = &quot;specialnamespace&quot;
  }

  data = {
    &quot;server.crt&quot; = file(&quot;${path.cwd},${var.local_dir_path_tls_crt_env_file}&quot;)
  }
}

resource &quot;kubernetes_secret&quot; &quot;tls-key-env&quot; {
  metadata {
    name      = var.k8s_name_tls_key_env
    namespace = &quot;specialnamespace&quot;
  }

  data = {
    &quot;server.key&quot; = file(&quot;${path.cwd},${var.local_dir_path_tls_key_env_file}&quot;)
  }
}

",<kubernetes><terraform><namespaces><kubernetes-secrets>,73159145,4,"since there is a way to get the name property of the metadata from the kubernetes_namespace resource, i would advise going with that. for example, for the kubernetes_secret resource:
resource &quot;kubernetes_secret&quot; &quot;api-env&quot; {
  metadata {
    name      = var.k8s_name_api_env
    namespace = kubernetes_namespace.namespace.metadata[0].name
  }

  data = {
    &quot;.api&quot; = file(&quot;${path.cwd},${var.local_dir_path_api_env_file}&quot;)
  }
}

also, note that most of the resources also have the _v1 version (e.g., namespace [1], secret [2] etc.), so i would strongly suggest going with those ones.

[1] https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/namespace_v1
[2] https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/secret_v1
"
58774462,nginx ingress controller set up issues,"i have set up a baremetal k8 cluster ( 1 master node - intel nuc &amp; 2 worker nodes on raspberry pi). i managed to set up a metal-lb load balance and nginx ingress controller.  i have launched two applications, ghost (listens on default port 2368) and nextcloud ( listens on default port 80) .  i'm trying to access the applications from public ip myhomeserver.io ( to access the ghost application) and nextcloud.myhomeserver.io ( to access the next cloud application). i can access the ghost application but i can't seem to access nextcloud.given below are the yaml files for ingress and services. not sure where am i going wrong.

kubectl get services --all-namespaces
namespace       name                type           cluster-ip       external-ip       port(s)                      age
default         kubernetes          clusterip      10.96.0.1        &lt;none&gt;            443/tcp                      98d
ghost           ghost-service       clusterip      10.107.116.108   &lt;none&gt;            2368/tcp                     7h37m
ingress-nginx   ingress-nginx       loadbalancer   10.109.177.223   192.168.178.200   80:31619/tcp,443:30365/tcp   7d23h
kube-system     kube-dns            clusterip      10.96.0.10       &lt;none&gt;            53/udp,53/tcp,9153/tcp       98d
nextcloud       nextcloud-service   clusterip      10.105.24.162    &lt;none&gt;            8080/tcp                     137m

=============================================================================================================================
namespace   name                hosts                       address           ports   age
ghost       ingress-ghost       myhomeserver.io             192.168.178.200   80      7d22h
nextcloud   ingress-nextcloud   nextcloud.myhomeserver.io   192.168.178.200   80      140m


=============================================================================================================================
cat ingress-object-ghost.yaml

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-ghost
  namespace: ghost

spec:
  rules:
  - host: myhomeserver.io
    http:
      paths:
      - backend:
          servicename: ghost-service
          serviceport: 2368


=============================================================================================================================
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-nextcloud
  namespace: nextcloud

spec:
  rules:
  - host: nextcloud.myhomeserver.io
    http:
      paths:
      - backend:
          servicename: nextcloud-service
          serviceport: 8080

================================================================================================================================

cat ingress-object-nextcloud.yaml

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-nextcloud
  namespace: nextcloud

spec:
  rules:
  - host: nextcloud.myhomeserver.io
    http:
      paths:
      - backend:
          servicename: nextcloud-service
          serviceport: 8080
===================================================================================
apiversion: apps/v1

kind: deployment
metadata:
  name:
    deployment-nextcloud
  namespace: nextcloud
  labels:
    env: prod
    app: nextcloud-app

spec:
  template:
    metadata:
      name: nextcloud-app-pod
      labels:
        app:  nextcloud-app
        env:  production
    spec:
      containers:
        - name: nextcloud
          image: arm32v7/nextcloud
          imagepullpolicy: ifnotpresent
          ports:
            - containerport: 8080
          volumemounts:
           - mountpath: /var/www/html
             name: nextcloud-data
          securitycontext:
            privileged: true


      volumes:
      - name: nextcloud-data
        persistentvolumeclaim:
          claimname: pvc-nextcloud
      nodeselector:
        kubernetes.io/arch: arm

  replicas: 2
  selector:
    matchlabels:
      app: nextcloud-app


================================================================================================================
apiversion: v1
kind: service
metadata:
  name: nextcloud-service
  namespace: nextcloud
  labels:
    app: nextcloud-app
spec:
  type: clusterip
  selector:
    app: nextcloud-app
  ports:
  - port: 8080
    targetport: 8080
    protocol: tcp

",<kubernetes><kubernetes-ingress><nginx-ingress>,58776178,2,"note your nginx ingress controller is running in the ghost namespace so it only knows about the ghost service. you need to have another ingress controller for your nextcloud namespace if you want to have an ingress there. if you don't want another ingress controller then you can resolve the nextcloud service by targeting its dns in the following way servicename.namespacename.svc.cluster.local

on a side, there is not really a point in dividing your applications that much. kubernetes already gives you enough privacy among applications in the same namespace.

update
ingress that works for you given you have only 1 ingress controller. since there are two services i have added a path rule which will be rewritten to / so each service will receive a clean uri. use myhomeserver.io/ghost to reach ghost and myhomeserver.io/nextcloud to reach nextcloud.

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-ghost
  namespace: ghost
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: myhomeserver.io
    http:
      paths:
      - path: /ghost
        backend:
          servicename: ghost-service
          serviceport: 2368
      - path: /nextcloud
        backend:
          servicename: nextcloud-service.nextcloud.svc.cluster.local
          serviceport: 8080


update 2
so your ingress controller is running in the ghost namespace. thus, your  ingress has to be deployed in the ghost namespace. note the http rules for each host. 

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-ghost
  namespace: ghost
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: myhomeserver.io
    http:
      paths:
      - path: /
        backend:
          servicename: ghost-service
          serviceport: 2368
  - host: nextcloud.myhomeserver.io
    http:
      - path: /
        backend:
          servicename: nextcloud-service.nextcloud.svc.cluster.local
          serviceport: 8080

"
76742027,handling long-running initcontainers for kubernetes jobs,"after a recent upgrade to gke 1.26, i began encountering an issue related to a kubernetes job that has been historically running without issue.
the job itself consists two components:

a simple initcontainer that just functions as a health check against an api/service that can sometimes take some time to respond when spinning up (~10 minutes at times)
a script that handles logic and a variety of calls to said api service

it looks something like the following in a nutshell (some things omitted for brevity):
apiversion: batch/v1
kind: job
metadata:
  name: my-job-{{ now | date &quot;20060102150405&quot; }}
  labels:
    app: my-job
spec:
  backofflimit: 0
  template:
    metadata:
      labels:
        app: my-job
      annotations:
        &quot;cluster-autoscaler.kubernetes.io/safe-to-evict&quot;: &quot;true&quot;
    spec:
      restartpolicy: never
      ...
      initcontainers:
      - name: wait-service
        ...
        command: ['bash', '-c', 'while [[ &quot;$(curl -s -o /dev/null -w ''%{http_code}'' http://someservice/api/v1/status)&quot; != &quot;200&quot; ]]; do echo waiting for service; sleep 2s; done']
      containers:
        - name: run-job
          ...
      volumes:
          ...
      tolerations: 
          ...

the problem i’m encountering is that after ~5 minutes after a deployment, while the initcontainer is running and awaiting the service, kubernetes will create a new instance of the job (complete with its own initcontainer etc.) this is problematic primarily because two instances of the script being run in the primary container (run-job) could easily cause the operations within it to get out of sync/into a bad state (the script involves the suspension and restoration of various services via the api in a specific order).
i can verify this within the logs of the original job:
│ wait-service waiting for service 
| failed container &quot;run-job&quot; in pod &quot;my-job-20230721165715-rh6s2&quot; is waiting to start: podinitializing for .../my-job-20230721165715-rh6s2 (run-job)                            
| wait-service waiting for service   

so roughly ~5 minutes after a new deployment of this job, i have two instances of it running (aligning with the failed container message above). this typically ends with one or both of them in bad states.
i’ve attempted a few configuration changes with little success and i’m wondering what the best way to handle this would be? essentially i need to allow an adequate toleration for the initcontainer such that it doesn’t trigger the above failure and recreate a new job (but rather continue forth with the original instance).
",<kubernetes><containers><google-kubernetes-engine><kubernetes-jobs>,76745659,1,"since you're using helm, and you've named the job using timestamped name (my-job-{{ now | date &quot;20060102150405&quot; }}), this will create a fresh job each time you do the helm install, but this makes no connection with the existing job(s) that may or may not be running at the time you do the upgrade.
if you want to ensure existing jobs are terminated when you deploy, you should consider using pre-upgrade hooks to delete any existing jobs in the application namespace before the upgrade is applied.

update 1
i've spun up a 1.26 cluster and used your example (with a few tweaks in order to get it to run), left it for 10 minutes, and got no additional job or pods.
what you can do in the meanwhile however, is trace the pods backwards to find out what &quot;owns&quot; them. if you kubectl describe {pod}, you'll see within the output a line reading &quot;controlled by&quot;. for example:
controlled by:  job/example-service-deploy-jobs-20230722170514

if you see two pods, describe both and see if the same job is referenced or not. if you have both pointing at the same job, then the job has spawned two pods -- this normally means it considered the first pod as failed and has spawned the second to try again.
if you see a different job referenced, it means another job has been deployed without deleting the first one.
describe the jobs and see they it also have a &quot;controlled by&quot; field (they shouldn't if they were installed by helm or manually deployed using kubectl apply or similar) -- my reason for this check is to see if something (like a cronjob) is triggering a job.
separate question: how is your cluster being hosted, is it bare metal or hosted (aks, eks, gke, etc?)
another possibility, if you're running on hosted is that you're running on spot/preemptible instances, or the node is having some other issue. you can watch the nodes (watch kubectl get nodes) to see if any of them terminate while you're watching the init container -- and if they do, you can start investigating the reason for the node termination.
in short, it is not the job itself that is the issue, but something else around it (or in the cluster).
"
61355744,how do i make sure my cronjob job does not retry on failure?,"i have a kubernetes cronjob that runs on gke and runs cucumber jvm tests. in case a step fails due to assertion failure, some resource being unavailable, etc., cucumber rightly throws an exception which leads the cronjob job to fail and the kubernetes pod's status changes to error. this leads to creation of a new pod that tries to run the same cucumber tests again, which fails again and retries again.

i don't want any of these retries to happen. if a cronjob job fails, i want it to remain in the failed status and not retry at all. based on this, i have already tried setting backofflimit: 0 in combination with restartpolicy: never in combination with concurrencypolicy: forbid, but it still retries by creating new pods and running the tests again. 

what am i missing? here's my kube manifest for the cronjob:

apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: quality-apatha
  namespace: default
  labels:
    app: quality-apatha
spec:
  schedule: ""*/1 * * * *""
  concurrencypolicy: forbid
  jobtemplate:
    spec:
      backofflimit: 0
      template:
        spec:
          containers:
            - name: quality-apatha
              image: foo-image-path
              imagepullpolicy: ""always""
              resources:
                limits:
                  cpu: 500m
                  memory: 512mi
              env:
                - name: foo
                  value: bar
              volumemounts:
                - name: foo
                  mountpath: bar
              args:
                - java
                - -cp
                - qe_java.job.jar:qe_java-1.0-snapshot-tests.jar
                - org.junit.runner.junitcore
                - com.liveramp.qe_java.runcucumbertest
          restartpolicy: never
          volumes:
            - name: foo
              secret:
                secretname: bar


is there any other kubernetes kind i can use to stop the retrying?

thank you!
",<kubernetes><google-kubernetes-engine><cucumber-jvm><kubernetes-pod><kubernetes-cronjob>,61368328,25,"to make things as simple as possible i tested it using this example from the official kubernetes documentation, applying to it minor modifications to illustrate what really happens in different scenarios.

i can confirm that when backofflimit is set to 0 and restartpolicy to never everything works exactly as expected and there are no retries. note that every single run of your job which in your example is scheduled to run at intervals of 60 seconds (schedule: ""*/1 * * * *"") is not considerd a retry.

let's take a closer look at the following example (base yaml avialable here):

apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: ""*/1 * * * *""
  jobtemplate:
    spec:
      backofflimit: 0
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - non-existing-command
          restartpolicy: never


it spawns new cron job every 60 seconds according to the schedule, no matter if it fails or runs successfully. in this particular example it is configured to fail as we are trying to run non-existing-command.

you can check what's happening by running:

$ kubectl get pods
name                     ready   status              restarts   age
hello-1587558720-pgqq9   0/1     error               0          61s
hello-1587558780-gpzxl   0/1     containercreating   0          1s


as you can see there are no retries. although the first pod failed, the new one is spawned exactly 60 seconds later according to our specification. i'd like to emphasize it again. this is not a retry.

on the other hand when we modify the above example and set backofflimit: 3, we can observe the retries. as you can see, now new pods are created much more often than every 60 seconds. this are retries.

$ kubectl get pods
name                     ready   status   restarts   age
hello-1587565260-7db6j   0/1     error    0          106s
hello-1587565260-tcqhv   0/1     error    0          104s
hello-1587565260-vnbcl   0/1     error    0          94s
hello-1587565320-7nc6z   0/1     error    0          44s
hello-1587565320-l4p8r   0/1     error    0          14s
hello-1587565320-mjnb6   0/1     error    0          46s
hello-1587565320-wqbm2   0/1     error    0          34s


what we can see above are 3 retries (pod creation attempts), related with hello-1587565260 job and 4 retries (including the orignal 1st try not counted in backofflimit: 3) related with hello-1587565320 job.

as you can see the jobs themselves are still run according to the schedule, at 60 second intervals:

kubectl get jobs
name               completions   duration   age
hello-1587565260   0/1           2m12s      2m12s
hello-1587565320   0/1           72s        72s
hello-1587565380   0/1           11s        11s


however due to our backofflimit set this time to 3, every time the pod responsible for running the job fails, 3 additional retries occur.

i hope this helped to dispel any possible confusions about running cronjobs in kubernetes.

if you are rather interested in running something just once, not at regular intervals, take a look at simple job instead of cronjob.

also consider changing your cron configuration if you still want to run this particular job on regular basis but let's say once in 24 h, not every minute.
"
77664196,helm template entire yaml section as json configmap,"i'm trying to pass an entire yaml stanza as a json config mapped file into my service. a simple example is
values.yaml:
servicename: &quot;mysupercoolservice&quot;

configmaps:
  - filename: &quot;file1.json&quot;
    content: &quot;{{ .values.content1 }}&quot;
  - filename: &quot;file2.json&quot;
    content: &quot;{{ .values.content2 }}&quot;

content1:
  field1: &quot;value1&quot;
  field2:
    field3: &quot;value3&quot;
    field4: &quot;value4&quot;

content2:
  field5: &quot;value5&quot;
  field6:
    field7: &quot;value7&quot;
    field8: &quot;value8&quot;

templates/configmap.yaml:
apiversion: v1
kind: configmap
metadata:
  name: {{ .values.servicename }}-jsonconfigmap
data:
  {{- range .values.configmaps }}
  {{ .filename }}: | 
  {{ tpl .content $ | toprettyjson | indent 4}}
  {{- end }}

my desired output for the configmap.yaml template would be:
apiversion: v1
kind: configmap
metadata:
  name: mysupercoolservice-jsonconfigmap
data:
  file1.json: | 
    {
      &quot;field1&quot;: &quot;value1&quot;,
      &quot;field2&quot;:
      {
        &quot;field3&quot;: &quot;value3&quot;,
        &quot;field4&quot;: &quot;value4&quot;
      }
    }
  file2.json: | 
    {
      &quot;field5&quot;: &quot;value5&quot;,
      &quot;field6&quot;:
      {
        &quot;field7&quot;: &quot;value7&quot;,
        &quot;field8&quot;: &quot;value8&quot;
      }
    }

however no matter what various things i try it always seems to come out:
apiversion: v1
kind: configmap
metadata:
  name: mysupercoolservice-jsonconfigmap
data:
  file1.json: | 
      &quot;map[field1:value1 field2:map[field3:value3 field4:value4]]&quot;
  file2.json: | 
      &quot;map[field5:value5 field6:map[field7:value7 field8:value8]]&quot;


how to i convert the map type object into actual json?
",<kubernetes><kubernetes-helm>,77666106,1,"a couple of aspects of the go text/template language are very oriented around strings.  a {{ ... }} double-brace expression always evaluates to a string; in helm more specifically, include and tpl always return strings.  if maps or lists are returned here, they get converted back to a string using a default go serialization, which is the map[key:value] syntax you see.
the most direct answer to this is to make sure, when you include part of the values inside a template expression, that you serialize it to json there:
configmaps:
  - filename: &quot;file1.json&quot;
    content: &quot;{{ .values.content1 | toprettyjson }}&quot;
  - filename: &quot;file2.json&quot;
    content: &quot;{{ .values.content2 | toprettyjson }}&quot;

{{ tpl .content $ | indent 4}}

i wonder if you're trying to make the configuration too flexible, though.  what you have shown as configuration closely mirrors the structure of a kubernetes configmap, to the point where just writing out a configmap yaml wouldn't actually be more difficult.  putting keys in a configmap on its own isn't useful unless a pod knows to access them.  it might make more sense to enumerate the specific known configmap keys in your template file, which in this particular case would remove tpl entirely
apiversion: v1
kind: configmap
metadata:
  name: {{ .release.name }}-jsonconfigmap
data:
  file1.json: |
{{ .values.content1 | toprettyjson | indent 4 }}
  file2.json: |
{{ .values.content2 | toprettyjson | indent 4 }}

or even to put the core of the json structure in your template code, and take more specific configuration values where needed:
data:
  file1.json: |
    {
      &quot;field1&quot;: {
        &quot;field2&quot;: {{ .values.frobnicationlevel | tojson }}
      }
    }

"
59147373,kubectl config set-credentials --auth-provider: error: unknown flag: --auth-provider,"i've installed kubectl (version 1.16.0) on windows 10, and the command works fine.

however, when tryin to run kubectl config set-credentials &lt;some_param&gt; --auth-provider=oidc, i get the following error: error: unknown flag: --auth-provider.

this happens even though when i run kubectl config set-credentials -h i can see the --auth-provider as a possible option..

how can it be fixed?
",<windows><kubernetes><openid-connect><kubectl>,59156358,1,"if you want to use the kubectl oidc authenticator during authentication process, which sets the id_token as a bearer token for all requests and refreshes the token once it expires. after you’ve logged into your provider, use kubectl to add your id_token, refresh_token, client_id, and client_secret to configure the plugin.

proper configuration of command kubectl config set-credentials is that:

first you have to define user name for whom credentials will be created. then you can pass additional parameters (enable oidc as auth-provider and add arguments to it). this is how proper syntax of kubectl config set-credentials command should look like:

   $ kubectl config set-credentials user_name \
       --auth-provider=oidc \
       --auth-provider-arg=idp-issuer-url=( issuer url ) \
       --auth-provider-arg=client-id=( your client id ) \
       --auth-provider-arg=client-secret=( your client secret ) \
       --auth-provider-arg=refresh-token=( your refresh token ) \
       --auth-provider-arg=idp-certificate-authority=( path to your ca certificate ) \
       --auth-provider-arg=id-token=( your id_token )


more information about authentication you can find here: kubernetes-authentication.
"
63781463,gke metrics-server generates error - flag.parse: e0907,"created new cluster in gke and see in logs error:
&quot;error: logging before flag.parse: e0907 16:33:58.813216       1 nanny_lib.go:128] get https://10.0.0.1:443/api/v1/nodes?resourceversion=0: http2: no cached connection was available
&quot;
{
  textpayload: &quot;error: logging before flag.parse: e0907 16:33:58.813216       1 nanny_lib.go:128] get https://10.0.0.1:443/api/v1/nodes?resourceversion=0: http2: no cached connection was available&quot;
  insertid: &quot;zzz&quot;
  resource: {
    type: &quot;k8s_container&quot;
    labels: {
      project_id: &quot;zzz&quot;
      namespace_name: &quot;kube-system&quot;
      container_name: &quot;metrics-server-nanny&quot;
      pod_name: &quot;metrics-server-v0.3.6-7b7d6c7576-jksst&quot;
      cluster_name: &quot;zzz&quot;
      location: &quot;zzz&quot;
    }
  }
  timestamp: &quot;2020-09-07t16:33:58.813411604z&quot;
  severity: &quot;error&quot;
  labels: {
    gke.googleapis.com/log_type: &quot;system&quot;
    k8s-pod/version: &quot;v0.3.6&quot;
    k8s-pod/k8s-app: &quot;metrics-server&quot;
    k8s-pod/pod-template-hash: &quot;7b7d6c7576&quot;
  }
  logname: &quot;projects/zzz/logs/stderr&quot;
  receivetimestamp: &quot;2020-09-07t16:34:05.273766386z&quot;
}

i try to find a solution on how to fix this error.
master version: 1.16.13-gke.1
cloud operations for gke: system and workload logging and monitoring
",<kubernetes><google-kubernetes-engine><metrics-server>,63829454,1,"i've test in my account with versions: 1.16.13-gke.1, 1.16.13-gke.400 and 1.17.9-gke1503 and got a similar error, but not the same:
$ kubectl logs metrics-server-v0.3.6-547dc87f5f-jrnjt -c metrics-server-nanny -n kube-system

error: logging before flag.parse: i0910 11:57:46.951966       1 pod_nanny.go:67] invoked by [/pod_nanny --config-dir=/etc/config --cpu=40m --extra-cpu=0.5m --memory=35mi --extra-memory=4mi --threshold=5 --deployment=metrics-server-v0.3.6 --container=metrics-server --poll-period=300000 --estimator=exponential --scale-down-delay=24h --minclustersize=5]
error: logging before flag.parse: i0910 11:57:46.952179       1 pod_nanny.go:68] version: 1.8.8
error: logging before flag.parse: i0910 11:57:46.952258       1 pod_nanny.go:84] watching namespace: kube-system, pod: metrics-server-v0.3.6-547dc87f5f-jrnjt, container: metrics-server.
error: logging before flag.parse: i0910 11:57:46.952320       1 pod_nanny.go:85] storage: missing, extra_storage: 0gi
error: logging before flag.parse: i0910 11:57:46.954042       1 pod_nanny.go:115] cpu: 40m, extra_cpu: 0.5m, memory: 35mi, extra_memory: 4mi
error: logging before flag.parse: i0910 11:57:46.954164       1 pod_nanny.go:144] resources: [{base:{i:{value:40 scale:-3} d:{dec:&lt;nil&gt;} s:40m format:decimalsi} extrapernode:{i:{value:5 scale:-4} d:{dec:&lt;nil&gt;} s: format:decimalsi} name:cpu} {base:{i:{value:36700160 scale:0} d:{dec:&lt;nil&gt;} s:35mi format:binarysi} extrapernode:{i:{value:4194304 scale:0} d:{dec:&lt;nil&gt;} s:4mi format:binarysi} name:memory}]

since i haven't deployed anything in the cluster, it seems to me some issue in system and workload logging and monitoring plugin enabled by default in gke.
my sugestion is open a ticket public issue in gcp issue tracker since the containers are managed by gke.
"
61387463,"uninstall: release not loaded: new: release: not found, chart deployed using helm 3","i have both helm 2 and helm 3 installed in my localhost. i have created a new chart using helm2 

sanket@admins-macbook-pro poc % helm create new
creating new


created a chart 'new ' using helm version 2. now i have deployed the chart using helm version 3 

sanket@admins-macbook-pro poc % helm3 install new new --namespace test 
name: new
last deployed: thu apr 23 17:56:03 2020
namespace: test
status: deployed
revision: 1
notes:
1. get the application url by running these commands:
  export pod_name=$(kubectl get pods --namespace test -l ""app.kubernetes.io/name=new,app.kubernetes.io/instance=new"" -o jsonpath=""{.items[0].metadata.name}"")
  echo ""visit http://127.0.0.1:8080 to use your application""
  kubectl port-forward $pod_name 8080:80


now when i try to delete the 'new' release it shows :- 

sanket@admins-macbook-pro poc % helm3 delete new 
error: uninstall: release not loaded: new: release: not found


any idea how to resolve this issue .
",<kubernetes><kubernetes-helm>,61388781,20,"need to pass --namespace with the delete command.
helm3 ls --namespace test
helm3 ls --namespace deployment_name

"
59872478,templating external files in helm,"i want to use application.yaml file to be passed as a config map.

so i have written this.

 apiversion: v1
 kind: configmap
 metadata:
  name: conf
data:
{{ (.files.glob ""foo/*"").asconfig | indent 2 }}


my application.yaml is present in foo folder and 
contains a service name which i need it to be dynamically populated via helm interpolation.

foo:
  service:
    name: {{.release.name}}-service


when i dry run , i am getting this

apiversion: v1
kind: configmap
metadata:
  name: conf
data:
  application.yaml: ""ei:\r\n  service:\r\n    name: {{.release.name}}-service""


but i want name: {{.release.name}}-service to contain actual helm release name.

is it possible to do templating for external files using helm , if yes then how to do it ?
i have gone through https://v2-14-0.helm.sh/docs/chart_template_guide/#accessing-files-inside-templates
i didn't find something which solves my use case.
 i can also copy the content to config map yaml and can do interpolation but i don't want to do it. i want application.yml to be in a separate file, so that, it will be simple to deal with config changes..
",<kubernetes><kubernetes-helm>,59877268,15,"helm includes a tpl function that can be used to expand an arbitrary string as a go template.  in your case the output of ...asconfig is a string that you can feed into the template engine.

apiversion: v1
kind: configmap
metadata:
  name: {{ .release.name }}-conf
data:
{{ tpl (.files.glob ""foo/*"").asconfig . | indent 2 }}


once you do that you can invoke arbitrary template code from within the config file.  for example, it's common enough to have a defined template that produces the name prefix of the current chart as configured, and so your config file could instead specify

foo:
  service:
    name: {{ template ""mychart.name"" . }}-service

"
57192850,how to log to kubernetes container log from python process,"with kubernetes container running a python script:

import time
while true:
    try:
        for i in range(10):
            if i==0:
                raise exception('exception occurred!')
    except:
        pass
    time.sleep(1)


i would like to pass the exception's message 'exception occurred!' down to the container so this error message could be seen with:

kubectl describe pod pod_id

would it be possible?
",<python><amazon-web-services><docker><kubernetes><amazon-eks>,57211592,5,"anything you print() will be visible in kubectl logs.  (you may need to set an environment variable pythonunbuffered=1 in your pod spec.)

your code as you've written it will never print anything.  the construct

try:
  ...
except:
  pass


silently ignores any and all exceptions out of the try block.  the bare except: even captures some system-level exceptions like systemexit or keyboardinterrupt; this is almost always wrong.  often you want your except blocks to be as tightly scoped as you can, and the python tutorial on user-defined exceptions is a helpful pattern.

(the exception to this, particularly in a kubernetes context, is that you will often want a very broad exception handler to do something like return an http 500 error to a network request, rather than crashing the application.)

a better example might look like:

import time

class oneexception(exception):
  pass

def iteration():
  for i in range(10):
    try:
      if i == 1:
        raise oneexception(""it is one"")
      print(i, math.sqrt(i), math.sqrt(-i))
      # will work when i==0 but fail when i==2
    except oneexception as e:
      print(i, repr(e))
      # and proceed to the next iteration

if __name__ == '__main__':
  while true:
    # the top-level loop.  we want a very broad catch here.
    try:
      iteration()
    except exception as e:
      print('iteration failed', repr(e))
    time.sleep(1)

"
69430640,"kubernetes ""shared"" persistent volume on digitalocean","i have a persistent volume defined as
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: ghost-cms-content
spec:
  accessmodes:
  - readwriteonce
  resources:
    requests:
      storage: 5gi
  storageclassname: do-block-storage

and a deployment defined as
---
kind: deployment
apiversion: apps/v1
metadata:
  name: ghost-cms
spec:
  replicas: 4
  strategy:
    type: rollingupdate
    rollingupdate:
      maxsurge: 1
      maxunavailable: 1
  selector:
    matchlabels:
      app: ghost-cms
      tier: frontend
  template:
    metadata:
      labels:
        app: ghost-cms
        tier: frontend
    spec:
      topologyspreadconstraints:
        - maxskew: 1
          topologykey: topology.kubernetes.io/region
          whenunsatisfiable: scheduleanyway
          labelselector:
            matchlabels:
              app: ghost-cms
              tier: frontend
      containers:
        - name: ghost-cms
          image: ghost:4.6-alpine
          imagepullpolicy: always
          ports:
            - containerport: 2368
          volumemounts:
            - mountpath: /var/lib/ghost/content
              name: content
          env:
            - name: url
              value: https://ghost.site
          resources:
            requests:
              cpu: 100m
              memory: 128mi
            limits:
              cpu: 250m
              memory: 256mi
      volumes:
        - name: content
          persistentvolumeclaim:
            claimname: ghost-cms-content

but each replica appears to have a unique volume that is not shared with the rest of the replicas. for instance, when i create a text file inside /var/lib/ghost/content in one of the pods, i don't see it in the volume of the other pods. what am i doing wrong?
",<kubernetes><digital-ocean><kubernetes-pod>,69430760,4,"pvc with permission
accessmodes:
  - readwriteonce

each pod will get the one volume or pvc, as it's readwrite once.
if you want to keep shared volume across replicas you can use the nfs with accessmode readwritemany
 accessmodes:
      - readwritemany

read more at : https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes
example : https://medium.com/asl19-developers/create-readwritemany-persistentvolumeclaims-on-your-kubernetes-cluster-3a8db51f98e3
you can also use minio, glusterfs to creeat the nfs or any managed service like gcp filestore providing nfs and attach that to pod.
gke example : https://medium.com/@sushil_kumar/readwritemany-persistent-volumes-in-google-kubernetes-engine-a0b93e203180
"
50122524,pod ready before container finishes starting jetty server,"i have a container that will start a jetty server. it takes about 1 minutes to start
the pod says it is started even tho the server is still starting.

is there a way to wait until for the container to finish starting before the pod says it is ready?

i tried adding a readiness probe but it fails because the server has not started

""readinessprobe"": {
  ""httpget"": {
    ""path"": ""/api/health"",
    ""port"": 8080,
    ""scheme"": ""http""
  },

",<kubernetes><kubectl>,50122580,2,"use initialdelayseconds attribute in readinessprobe as explained at https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-readiness-probes

for example, add 60 seconds delay before you run first test

initialdelayseconds: 60
"
77855298,expose eureka server port to outside in helm chart,"i'm implementing a helm chart which deploys a simple eureka server with one work node and one control plane:
https://github.com/rcbandit111/mockup/tree/master/helm_chart/mockup-chart
i deploy this helm chart on native kubernetes installation.
how i can expose port 8761 to be visible to outside network so that i can open it in my browser by running http://....:8761?
",<kubernetes><kubernetes-helm>,77856748,1,"it depends on the provider that you have, if it support service type load balancers you should change your values.yaml to
service:
  type: loadbalancer
  port: 8761

then your eureka server should be available at http://....:8761

based on what you have in service.yaml and values.yaml your eureka server should be available at http://....:30066 as you are using nodeport
"
43186611,kubectl and seeing (cluster)roles assigned to subjects,"i can use kubectl to see to which subjects a cluster role is applied, eg:

kubectl get clusterrolebindings system:node --all-namespaces -o json                                                                                                                                                                    
{
    ""apiversion"": ""rbac.authorization.k8s.io/v1beta1"",
    ""kind"": ""clusterrolebinding"",
     ....
     ....
    ""subjects"": [
        {
            ""apigroup"": ""rbac.authorization.k8s.io"",
            ""kind"": ""group"",
            ""name"": ""system:nodes""
        }
    ]
}


i would like to get this info the other way around, eg: i want to list all policies applied to the ""system:nodes"" subject.

how can i do that?
",<kubernetes><kubectl>,43190945,32,"there is no api for the reverse index. you can look up bindings and filter on ones containing the expected subject. for example, using bash, jq, and kubectl:

# $1 is kind (user, group, serviceaccount)
# $2 is name (""system:nodes"", etc)
# $3 is namespace (optional, only applies to kind=serviceaccount)
function getroles() {
    local kind=""${1}""
    local name=""${2}""
    local namespace=""${3:-}""

    kubectl get clusterrolebinding -o json | jq -r ""
      .items[]
      | 
      select(
        .subjects[]?
        | 
        select(
            .kind == \""${kind}\"" 
            and
            .name == \""${name}\""
            and
            (if .namespace then .namespace else \""\"" end) == \""${namespace}\""
        )
      )
      |
      (.roleref.kind + \""/\"" + .roleref.name)
    ""
}

$ getroles group system:authenticated
clusterrole/system:basic-user
clusterrole/system:discovery

$ getroles serviceaccount attachdetach-controller kube-system
clusterrole/system:controller:attachdetach-controller

"
71140601,how to get the system hostname of kubernetes deployment inside pod?,"in kubernetes we can use environment variable to pass hostip using
 env:
    - name: node_ip
      valuefrom:
        fieldref:
          fieldpath: status.hostip

so similarly how get hostname instead of hostip?
",<kubernetes><kubernetes-pod>,71140814,3,"env:
- name: my_node_name
  valuefrom:
    fieldref:
      fieldpath: spec.nodename

see: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#the-downward-api
"
61515570,how to make kubernetes pod have access to postgresql pod,"i am trying local kubernetes(docker-on-mac), and trying to submit a spark job. the spark job, connects with a postgresql database and do some calculations.

the postgresql is running on my kube and since i have published it, i can access it from the host via localhost:5432. however, when the spark application is trying to connect to postgresql, it throws 

exception in thread ""main"" org.postgresql.util.psqlexception: connection to localhost:5432 refused. check that the hostname and port are correct and that the postmaster is accepting tcp/ip connections.


kubectl cluster-info

kubernetes master is running at https://kubernetes.docker.internal:6443
kubedns is running at https://kubernetes.docker.internal:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy



kubectl get service postgresql-published



kubectl describe service spark-store-1588217023181-driver-svc 

name:              spark-store-1588217023181-driver-svc
namespace:         default
labels:            &lt;none&gt;
annotations:       &lt;none&gt;
selector:          spark-app-selector=spark-533ecb8556b6439eb938d487cc77c330,spark-role=driver
type:              clusterip
ip:                none
port:              driver-rpc-port  7078/tcp
targetport:        7078/tcp
endpoints:         &lt;none&gt;
port:              blockmanager  7079/tcp
targetport:        7079/tcp
endpoints:         &lt;none&gt;
session affinity:  none


how can i make my spark job, have access to postgresql service?
",<docker><kubernetes><kubernetes-helm><kubectl>,61650736,1,"name                  type           cluster-ip      external-ip   ports
postgresql-published  loadbalancer   10.106.15.112   localhost     5432:31277


means that the service shall be accessible within the cluster at 10.106.15.112:5432 , postgresql-published:5432 and externally at localhost:31277. 

please note that for the pod the localhost is the pod itself. in this very case localhost looks ambiguous. however that is how the expose works.
"
60725815,azure kubernetes - no connection to server,"when i execute the following powershell command:

.\kubectl get nodes


i get no nodes in response. i noticed that the config file from kubectl is empty too:

apiversion: v1
clusters:
- cluster:
    server: """"
  name: cl-kubernetes
contexts: []
current-context: """"
kind: config
preferences: {}
users: []


when i enter the server address at the config file, i get the message that the connection was refused. i suspect that it is due to missing certificates. during another installation this (apparently) following information was created automatically, which is now missing:

certificate-authority-data,
contexts - cluster,
contexts - user,
current context,
users - name,
client-certificate-data,
client-key-data,
token,

could that be it? if so, where do i get this information?

many thanks for the help
",<azure><kubernetes><kubectl>,60725958,1,"you need to use the azure cli first to get the credentials. run

az aks get-credentials


https://learn.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az-aks-get-credentials
"
66257592,k8s env variable using volume mountpath value,"i have a k8s deployment yaml definition where few env variables are declared. i want to declare an environment variable whose value to be referenced from a specific volume's mountpath.
for example, i want it as shown in below yaml from line #42 to #45. (note: i have used it as an example only. i know it is not correct). is it possible to achieve this and how?
 37     spec:
 38       containers:
 39         - name: appplugin
 40           image: {{app_version}}
 41           env:
 42           - name: infra_access_ip
 43             valuefrom:
 44               fieldref:
 45                 fieldpath: status.hostip
 42           - name: log_base_dir
 43             valuefrom:
 44               fieldref:
 45                 fieldpath: volumemounts.app-logs.mountpath.subpath
 46           envfrom:
 47           - configmapref:
 48               name: infra-config
 49           - configmapref:
 50               name: core-config
 51           ports:
 52           - containerport: 9095
 53           volumemounts:
 54           - name: app-certs
 55             mountpath: /etc/secrets/certs
 56             readonly: true
 57           - name: app-logs
 58             mountpath: /var/log/tohost/
 59             subpath: app-logs

",<kubernetes><kubectl>,66259930,2,"not directly.  if you look at the api documentation for the envvarsource object, you can see that a limited number of fields are supported for the downward api; generally only the metadata fields, the service-account name, the dynamic ip and node information, and the resource limits.
in the context of the file you show, the file path is fixed and you don't need a dynamic lookup.  since each container has an isolated filesystem, it's a little unlikely you'll actually change this path in different deployments, and it will work to just specify that path directly:
env:
  - name: log_base_dir
    value: app-logs
volumemounts:
  - name: app-logs
    mountpath: /var/log/tohost/
    subpath: app-logs

if you're using a templating tool like helm you can make this value configurable at deploy time.  helm has the notion of &quot;values&quot; that are configurable at deployment time, and can inject those values (or do much more complex manipulation) when it installs things.  you could use this to set the path inside the container if you had a reason to:
image: {{ .values.appversion }}
env:
  - name: log_base_dir
    value: {{ .values.logbasedir | default &quot;app-logs&quot; }}
volumemounts:
  - name: app-logs
    mountpath: /var/log/tohost/
    subpath: {{ .values.logbasedir | default &quot;app-logs&quot; }}

(for logs specifically, it might be better to skip this configuration entirely and just send logs to your process's stdout.  then kubectl logs can retrieve them later.  you can also deploy a log collector as a daemonset that will capture these logs to some other system.)
"
70123319,how to use helm charts to deploy using google cloud build,"i am in the learning phase of kubernetes and want to set up the ci/cd pipeline for my project. i am using google cloud and have the following elements are ready

3 node cluster is deployed on google cloud
github has been integrated with google cloud build to trigger the build.
i am using helm to maintain my k8s templates.
cloudbuilld.yaml is developed to compile the docker image and push it to google container registry.

i am stuck at - once my cloudbuild.yaml is done with building the docker image and pushed it to the registry, how do i use helm to upgrade the chart?
here is my sample cloudbuild.yaml
steps:
  - name: 'gcr.io/cloud-builders/docker'
    args: [&quot;build&quot;, &quot;-t&quot;, &quot;gcr.io/kubernetes-amit-test/github.com/0xvoila/apache/phoenix:$short_sha&quot;, &quot;.&quot;]

  - name: &quot;gcr.io/cloud-builders/docker&quot;
    args: [&quot;push&quot;, &quot;gcr.io/kubernetes-amit-test/github.com/0xvoila/apache/phoenix:$short_sha&quot;]

  - name: &quot;alpine/helm:latest&quot;.   --- it is not working 
    args: [&quot;helm&quot;,&quot;upgrade&quot;,&quot;mychart&quot;,&quot;image&quot;, &quot;gcr.io/kubernetes-amit-test/github.com/0xvoila/apache/phoenix:$short_sha&quot;]


my question is

how can i use helm to upgrade the latest charts.
as i am new to kubernetes, it is even the best practice for k8s deployment? do people even use helm?

",<kubernetes><kubernetes-helm>,70124043,5,"
how can i use helm to upgrade the latest charts.

there is already default helm exist : gcr.io/$project_id/cloud-builders-helm
- name: 'gcr.io/$project_id/cloud-builders-helm'
  args: ['upgrade', '--install', 'filebeat', '--namespace', 'filebeat', 'stable/filebeat']

for managing chart version you should check the : https://cloud.google.com/artifact-registry/docs/helm/manage-charts
helm cloud builder github

as i am new to kubernetes, it is even the best practice for k8s
deployment? do people even use helm?

helm is the best way to manage it instead of using any other.
i would suggest checking out the helm atomic
helm upgrade --install --atomic

which will also auto rollback deployment if it's failing in k8s.

--atomic                       if set, upgrade process rolls back changes made in case of failed upgrade. the --wait flag will be set
automatically if --atomic is used

read more
extra :
instead of fixing the gcr name, you can also use variables this template will work across the branches of across repo also.
- id: 'build test core image'
  name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/$project_id/$repo_name/$branch_name:$short_sha', '.']
- id: 'push test core image'
  name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$project_id/$repo_name/$branch_name:$short_sha']

update :
adding gke cluster details to cloud build
- name: 'gcr.io/cloud-builders/kubectl'
  args: ['apply', '-f', 'deployment.yaml']
  env:
  - 'cloudsdk_compute_zone=${_cloudsdk_compute_zone}'
  - 'cloudsdk_container_cluster=${_cloudsdk_container_cluster}'

i am using the kubectl apply but you can add these environment variables to your helm step.
file location
full file
substitutions:
    _cloudsdk_compute_zone: us-central1-c  # default value
    _cloudsdk_container_cluster: standard-cluster-1      # default value
steps:
- id: 'set test core image in yamls'
  name: 'ubuntu'
  args: ['bash','-c','sed -i &quot;s,test_image_name,gcr.io/$project_id/$repo_name/$branch_name:$short_sha,&quot; deployment.yaml']
- name: 'gcr.io/cloud-builders/kubectl'
  args: ['apply', '-f', 'deployment.yaml']
  env:
  - 'cloudsdk_compute_zone=${_cloudsdk_compute_zone}'
  - 'cloudsdk_container_cluster=${_cloudsdk_container_cluster}'

"
55303827,access pod localhost from service,"new to kubernetes. 

i have a private dockerhub image deployed on a kubernetes instance. when i exec into the pod i can run the following so i know my docker image is running:

root@private-reg:/# curl 127.0.0.1:8085
hello world!root@private-reg:/# 


from the dashboard i can see my service has an external endpoint which ends with port 8085. when i try to load this i get 404. my service yaml is as below:

{
  ""kind"": ""service"",
  ""apiversion"": ""v1"",
  ""metadata"": {
    ""name"": ""test"",
    ""namespace"": ""default"",
    ""selflink"": ""/api/v1/namespaces/default/services/test"",
    ""uid"": ""a1a2ae23-339b-11e9-a3db-ae0f8069b739"",
    ""resourceversion"": ""3297377"",
    ""creationtimestamp"": ""2019-02-18t16:38:33z"",
    ""labels"": {
      ""k8s-app"": ""test""
    }
  },
  ""spec"": {
    ""ports"": [
      {
        ""name"": ""tcp-8085-8085-7vzsb"",
        ""protocol"": ""tcp"",
        ""port"": 8085,
        ""targetport"": 8085,
        ""nodeport"": 31859
      }
    ],
    ""selector"": {
      ""k8s-app"": ""test""
    },
    ""clusterip"": ""******"",
    ""type"": ""loadbalancer"",
    ""sessionaffinity"": ""none"",
    ""externaltrafficpolicy"": ""cluster""
  },
  ""status"": {
    ""loadbalancer"": {
      ""ingress"": [
        {
          ""ip"": ""******""
        }
      ]
    }
  }
}


can anyone point me in the right direction.
",<kubernetes><kubectl>,55304599,1,"what is the output from the below command

curl cluzterip:8085

if you get hello world message then it means that the service is routing the traffic correctly to the backend pod. 

curl hostip:nodeport should also be working

most likely that service is not bound to the backend pod. did you define the below label on the pod? 

labels: {
      ""k8s-app"": ""test""
    }

"
42095142,kubectl proxy unauthorized when accessing from another machine,"i have kubernetes running on a vm on my dev box.  i want to view the kubernetes dashboard from the vm host.  when i run the following command:

kubectl proxy --address 0.0.0.0 --accept-hosts ^/.*


when i try to access the dashboard i get an unauthorized error.  

what am i missing?
",<proxy><kubernetes><kubectl>,42095931,40,"the --accept-hosts access control is for checking of the hostname, so it won't start with a / (slash). you need to do:

kubectl proxy --address 0.0.0.0 --accept-hosts '.*'


(make sure you shell escape the .* as it may match files in the current directory!)

more information at: https://kubernetes.io/docs/user-guide/kubectl/kubectl_proxy/
"
47129376,"kubernetes / kubectl - ""a container name must be specified"" but seems like it is?","i'm debugging log output from kubectl that states:

error from server (badrequest): a container name must be specified for pod postgres-operator-49202276-bjtf4, choose one of: [apiserver postgres-operator]


ok, so that's an explanatory error message, but looking at my json template it ought to just create both containers specified, correct? what am i missing? (please forgive my ignorance.)

i'm using just a standard kubectl create -f command to create the json file within a shell script. the json deployment file is as follows:

{
    ""apiversion"": ""extensions/v1beta1"",
    ""kind"": ""deployment"",
    ""metadata"": {
        ""name"": ""postgres-operator""
    },
    ""spec"": {
        ""replicas"": 1,
        ""template"": {
            ""metadata"": {
                ""labels"": {
                    ""name"": ""postgres-operator""
                }
            },
            ""spec"": {
                ""containers"": [{
                    ""name"": ""apiserver"",
                    ""image"": ""$ccp_image_prefix/apiserver:$co_image_tag"",
                    ""imagepullpolicy"": ""ifnotpresent"",
                    ""env"": [{
                        ""name"": ""debug"",
                        ""value"": ""true""
                    }],
                    ""volumemounts"": [{
                        ""mountpath"": ""/config"",
                        ""name"": ""apiserver-conf"",
                        ""readonly"": true
                    }, {
                        ""mountpath"": ""/operator-conf"",
                        ""name"": ""operator-conf"",
                        ""readonly"": true
                    }]
                }, {
                    ""name"": ""postgres-operator"",
                    ""image"": ""$ccp_image_prefix/postgres-operator:$co_image_tag"",
                    ""imagepullpolicy"": ""ifnotpresent"",
                    ""env"": [{
                        ""name"": ""debug"",
                        ""value"": ""true""
                    }, {
                        ""name"": ""namespace"",
                        ""valuefrom"": {
                            ""fieldref"": {
                                ""fieldpath"": ""metadata.namespace""
                            }
                        }
                    }, {
                        ""name"": ""my_pod_name"",
                        ""valuefrom"": {
                            ""fieldref"": {
                                ""fieldpath"": ""metadata.name""
                            }
                        }
                    }],
                    ""volumemounts"": [{
                        ""mountpath"": ""/operator-conf"",
                        ""name"": ""operator-conf"",
                        ""readonly"": true
                    }]
                }],
                ""volumes"": [{
                    ""name"": ""operator-conf"",
                    ""configmap"": {
                        ""name"": ""operator-conf""
                    }
                }, {
                    ""name"": ""apiserver-conf"",
                    ""configmap"": {
                        ""name"": ""apiserver-conf""
                    }
                }]
            }
        }
    }
}

",<json><kubernetes><kubectl>,47134395,131,"if a pod has more than 1 containers then you need to provide the name of the specific container. 

in your case, there is a pod (postgres-operator-49202276-bjtf4) which has 2 containers (apiserver and postgres-operator ).
following commands will provide logs for the specific containers 

kubectl logs deployment/postgres-operator -c apiserver


kubectl logs deployment/postgres-operator -c postgres-operator

"
30449843,how to connect a kubernetes pod to the outside world without a forwarding rule (google container engine),"i'm using google's container engine service, and got a pod running a server listening on port 3000. i set up the service to connect port 80 to that pod's port 3000. i am able to curl the service using its local and public ip from within the node, but not from outside. i set up a firewall rule to allow port 80 and send it to the node, but i keep getting 'connection refused' from outside the network. i'm trying to do this without a forwarding rule, since there's only one pod and it looked like forwarding rules cost money and do load balancing. i think the firewall rule works, because when i add the createexternalloadbalancer: true to the service's spec, the external ip created by the forwarding rule works as expected. do i need to do something else? set up a route or something?

controller.yaml

kind: replicationcontroller
apiversion: v1beta3
metadata:
    name: app-frontend
    labels:
        name: app-frontend
        app: app
        role: frontend
spec:
    replicas: 1
    selector:
        name: app-frontend
    template:
        metadata:
            labels:
                name: app-frontend
                app: app
                role: frontend
        spec:
            containers:
                - name: node-frontend
                  image: gcr.io/project_id/app-frontend
                  ports:
                    - name: app-frontend-port
                      containerport: 3000
                      targetport: 3000
                      protocol: tcp


service.yaml

kind: service
apiversion: v1beta3
metadata:
  name: app-frontend-service
  labels:
    name: app-frontend-service
    app: app
    role: frontend
spec:
  ports:
    - port: 80
      targetport: app-frontend-port
      protocol: tcp
  publicips:
   - 123.45.67.89
  selector:
    name: app-frontend




edit (additional details):
creating this service adds these additional rules, found when i run iptables -l -t nat

chain kube-portals-container (1 references)
target     prot opt source               destination         
redirect   tcp  --  anywhere             10.247.247.206       /* default/app-frontend-service: */ tcp dpt:http redir ports 56859
redirect   tcp  --  anywhere             89.67.45.123.bc.googleusercontent.com  /* default/app-frontend-service: */ tcp dpt:http redir ports 56859
chain kube-portals-host (1 references)
target     prot opt source               destination         
dnat       tcp  --  anywhere             10.247.247.206       /* default/app-frontend-service: */ tcp dpt:http to:10.241.69.28:56859
dnat       tcp  --  anywhere             89.67.45.123.bc.googleusercontent.com  /* default/app-frontend-service: */ tcp dpt:http to:10.241.69.28:56859


i don't fully understand iptables, so i'm not sure how the destination port matches my service. i found that the dns for 89.67.45.123.bc.googleusercontent.com resolves to 123.45.67.89.

kubectl get services shows the ip address and port i specified:

name                             ip(s)               port(s)
app-frontend-service             10.247.243.151      80/tcp
                                 123.45.67.89


nothing recent from external ips is showing up in  /var/log/kube-proxy.log 
",<firewall><kubernetes><google-kubernetes-engine>,30588220,6,"tl;dr: use the internal ip of your node as the public ip in your service definition. 



if you enable verbose logging on the kube-proxy you will see that it appears to be creating the appropriate ip tables rule:

i0602 04:07:32.046823   24360 roundrobin.go:98] loadbalancerrr service ""default/app-frontend-service:"" did not exist, created
i0602 04:07:32.047153   24360 iptables.go:186] running iptables -a [kube-portals-host -t nat -m comment --comment default/app-frontend-service: -p tcp -m tcp -d 10.119.244.130/32 --dport 80 -j dnat --to-destination 10.240.121.42:36970]
i0602 04:07:32.048446   24360 proxier.go:606] opened iptables from-host portal for service ""default/app-frontend-service:"" on tcp 10.119.244.130:80
i0602 04:07:32.049525   24360 iptables.go:186] running iptables -c [kube-portals-container -t nat -m comment --comment default/app-frontend-service: -p tcp -m tcp -d 23.251.156.36/32 --dport 80 -j redirect --to-ports 36970]
i0602 04:07:32.050872   24360 iptables.go:186] running iptables -a [kube-portals-container -t nat -m comment --comment default/app-frontend-service: -p tcp -m tcp -d 23.251.156.36/32 --dport 80 -j redirect --to-ports 36970]
i0602 04:07:32.052247   24360 proxier.go:595] opened iptables from-containers portal for service ""default/app-frontend-service:"" on tcp 23.251.156.36:80
i0602 04:07:32.053222   24360 iptables.go:186] running iptables -c [kube-portals-host -t nat -m comment --comment default/app-frontend-service: -p tcp -m tcp -d 23.251.156.36/32 --dport 80 -j dnat --to-destination 10.240.121.42:36970]
i0602 04:07:32.054491   24360 iptables.go:186] running iptables -a [kube-portals-host -t nat -m comment --comment default/app-frontend-service: -p tcp -m tcp -d 23.251.156.36/32 --dport 80 -j dnat --to-destination 10.240.121.42:36970]
i0602 04:07:32.055848   24360 proxier.go:606] opened iptables from-host portal for service ""default/app-frontend-service:"" on tcp 23.251.156.36:80


listing the iptables entries using -l -t shows the public ip turned into the reverse dns name like you saw:

chain kube-portals-container (1 references)
target     prot opt source               destination         
redirect   tcp  --  anywhere             10.119.240.2         /* default/kubernetes: */ tcp dpt:https redir ports 50353
redirect   tcp  --  anywhere             10.119.240.1         /* default/kubernetes-ro: */ tcp dpt:http redir ports 54605
redirect   udp  --  anywhere             10.119.240.10        /* default/kube-dns:dns */ udp dpt:domain redir ports 37723
redirect   tcp  --  anywhere             10.119.240.10        /* default/kube-dns:dns-tcp */ tcp dpt:domain redir ports 50126
redirect   tcp  --  anywhere             10.119.244.130       /* default/app-frontend-service: */ tcp dpt:http redir ports 36970
redirect   tcp  --  anywhere             36.156.251.23.bc.googleusercontent.com  /* default/app-frontend-service: */ tcp dpt:http redir ports 36970


but adding the -n option shows the ip address (by default, -l does a reverse lookup on the ip address, which is why you see the dns name):

chain kube-portals-container (1 references)
target     prot opt source               destination         
redirect   tcp  --  0.0.0.0/0            10.119.240.2         /* default/kubernetes: */ tcp dpt:443 redir ports 50353
redirect   tcp  --  0.0.0.0/0            10.119.240.1         /* default/kubernetes-ro: */ tcp dpt:80 redir ports 54605
redirect   udp  --  0.0.0.0/0            10.119.240.10        /* default/kube-dns:dns */ udp dpt:53 redir ports 37723
redirect   tcp  --  0.0.0.0/0            10.119.240.10        /* default/kube-dns:dns-tcp */ tcp dpt:53 redir ports 50126
redirect   tcp  --  0.0.0.0/0            10.119.244.130       /* default/app-frontend-service: */ tcp dpt:80 redir ports 36970
redirect   tcp  --  0.0.0.0/0            23.251.156.36        /* default/app-frontend-service: */ tcp dpt:80 redir ports 36970


at this point, you can access the service from within the cluster using both the internal and external ips:

$ curl 10.119.244.130:80
app-frontend-5pl5s
$ curl 23.251.156.36:80
app-frontend-5pl5s


without adding a firewall rule, attempting to connect to the public ip remotely times out. if you add a firewall rule then you will reliably get connection refused:

$ curl 23.251.156.36
curl: (7) failed to connect to 23.251.156.36 port 80: connection refused


if you enable some iptables logging:

sudo iptables -t nat -i kube-portals-container -m tcp -p tcp --dport 
80 -j log --log-prefix ""wtf: ""


and then grep the output of dmesg for wtf it's clear that the packets are arriving on the 10. ip address of the vm rather than the ephemeral external ip address that had been set as the public ip on the service.

it turns out that the problem is that gce has two types of external ips: forwardingrules (which forward with the dstip intact) and 1-to-1 nat (which actually rewrites the dstip to the internal ip). the external ip of the vm is the later type so when the node receives the packets the ip tables rule doesn't match. 

the fix is actually pretty simple (but non-intuitive): use the internal ip of your node as the public ip in your service definition. after updating your service.yaml file to set publicips to the internal ip  (e.g. 10.240.121.42) you will be able to hit your application from outside of the gce network. 
"
38360862,sharing docker registry images among gcloud projects,"we're hoping to use a google project to share docker images containing microservices across projects.

i was thinking i could do it using the kubernetes run command and pull an image from a project other than the current one:

kubectl run  gdrive-service --image=us.gcr.io/foo/gdrive-service 


my user credentials have access to both projects. however, it seems like the run command can only pull mages from the current project. 

is there an approach for doing this?  it seems like an obvious use case.
",<docker><kubernetes><gcloud><google-kubernetes-engine><google-container-registry>,38361868,2,"there are a few options here.


use _json_key auth described here with kubernetes pull secrets.
this describes how to add robots across projects as well, still without needing pull secrets.

"
71184041,kubernetes egress rule blocks all outgoing traffic,"the problem
i've defined a kubernetes egress rule from pod test-1 to a specific pod test-2, but this rule blocks also blocks traffic from test-1 to test-2:

i've created two pods: test-1 and test-2
i've created a networkpolicy that allows only egress traffic from test-1 to test-2
i've tried to call test-2 from test-1 by curl test-2. but this call is blocked!
i've checked the selectors

both selectors return the expected pod:
kubectl describe networkpolicies test-1-policy
kubectl get pod --selector app.kubernetes.io/name=test-1
kubectl get pod --selector app.kubernetes.io/name=test-2

when i remove the networkpolicy the connect by curl test-2 works.
my question: what did i miss?
here's how to reproduce the problem

paste yaml into file deployment.yaml (see below)
deploy demo kubectl apply -f deployment.yaml
exec into pod: kubectl exec --stdin --tty $(kubectl get pod -l app.kubernetes.io/name=test-1 -o jsonpath=&quot;{.items[0].metadata.name}&quot;) -- /bin/bash
call request in pod: curl test-2 =&gt; request is blocked
remove networkpolicy: kubectl delete networkpolicy test-1-policy
exec in pod and call request =&gt; request is executed

here's the complete yaml:
apiversion: apps/v1
kind: deployment
metadata:
  name: test-1
  labels:
    app.kubernetes.io/name: test-1
spec:
  replicas: 1
  selector:
    matchlabels:
      app.kubernetes.io/name: test-1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: test-1
    spec:
      containers:
        - name: nginx
          image: nginx
          ports:
            - name: http
              containerport: 80
---
apiversion: apps/v1
kind: deployment
metadata:
  name: test-2
  labels:
    app.kubernetes.io/name: test-2
spec:
  replicas: 1
  selector:
    matchlabels:
      app.kubernetes.io/name: test-2
  template:
    metadata:
      labels:
        app.kubernetes.io/name: test-2
    spec:
      containers:
        - name: nginx
          image: nginx
          ports:
            - name: http
              containerport: 80
---
apiversion: v1
kind: service
metadata:
  name: test-1
  labels:
    app.kubernetes.io/name: test-1
spec:
  type: clusterip
  ports:
    - port: 80
      targetport: http
      name: http
  selector:
    app.kubernetes.io/name: test-1
---
apiversion: v1
kind: service
metadata:
  name: test-2
  labels:
    app.kubernetes.io/name: test-2
spec:
  type: clusterip
  ports:
    - port: 80
      targetport: http
      name: http
  selector:
    app.kubernetes.io/name: test-2
---
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: test-1-policy
spec:
  podselector:
    matchlabels:
      app.kubernetes.io/name: test-1
  policytypes:
    - ingress
    - egress
  ingress: []
  egress:
    - to:
        - podselector:
            matchlabels:
              app.kubernetes.io/name: test-2
      ports:
        - port: 80
          protocol: tcp

",<kubernetes><kubernetes-networkpolicy>,71186497,2,"the dns egress rule is missing:
when you add the egress rules for port 53 everything works as expected:
  egress:
    - ports:
      - port: 53
        protocol: udp
      - port: 53
        protocol: tcp

https://github.com/ahmetb/kubernetes-network-policy-recipes/blob/master/11-deny-egress-traffic-from-an-application.md
"
68717683,programmatically issuing a kubernetes certificate,"i was able to manually create a certificate:

i created a csr file
i created and applied a certificatesigningrequest k8s resource
i approved the request using

kubectl certificate approve &lt;name&gt;


i extracted the certificate from the certificatesigningrequest's status.certificate field.

now i want to repeat the process programmatically. i'm using the @kubernetes/client-node npm package for this purpose.
i'm able to create and apply the certificatesigningrequest resource:
const csrresource = await admincertapi.createcertificatesigningrequest({
    metadata: {
        name: 'my.email@my.company.com',
    },
    spec: {
        request: csrbase64,
        signername: 'kubernetes.io/kube-apiserver-client',
        usages: [
            'client auth'
        ],
    },
});

but then i get stuck trying to approve the request (trying to follow the documentation). i tried several variations that look like this:
csrresource.body.status.conditions = [
    {
        message: 'approved by cwadmin graphql lambda function',
        reason: 'approvedbycwadmin',
        type: 'approved',
    }
];
const response = await admincertapi.patchcertificatesigningrequest('my.email@my.company.com', csrresource.body, undefined, undefined, undefined, undefined, { headers: { 'content-type': 'application/strategic-merge-patch+json' } });


unfortunately, this does not update the status.conditions field. even if it did, what triggers the signing of the certificate? the documentation states that the kube-controller-manager never auto-approves requests of type kubernetes.io/kube-apiserver-client.
in other words, what is the programmatic equivalent of kubectl certificate approve?
",<kubernetes><client-certificates><kubernetes-apiserver>,68729553,1,"i found this bit of documentation that helped me solve the issue:


status is required and must be true, false, or unknown
approved/denied conditions can only be set via the /approval subresource


so i added the status field to the condition and changed the api call to patchcertificatesigningrequestapproval.
the working code now looks like this:
const body = {
    status: {
        conditions: [
            {
                message: 'approved by cwadmin graphql lambda function',
                reason: 'approvedbycwadmin',
                type: 'approved',
                status: 'true',
            }
        ]
    }
};

const response = await admincertapi.patchcertificatesigningrequestapproval('my.email@my.company.com', body, undefined, undefined, undefined, undefined, { headers: { 'content-type': 'application/strategic-merge-patch+json' } });


"
59980445,setting image pull policy using kubectl,"following the docs and this question, i am trying to pull a image that i created locally with docker while creating deployment with kubectl. i am looking for something like this,

kubectl create deployment first-k8s-deploy --image=""laxman/nodejs/express-app"" --image-pull-policy=""never""

looking into kubectl create deployment --help doesn't provide any --image-pull-policy option.

is there any global config to set imagepullpolicy and how can i set this flag for some specific deployments only?
",<kubernetes><kubectl>,59980669,20,"you might have gone past what can be done with the command line. see creating a deployment for how to specify a deployment in a yaml file. 

the imagepullpolicy is part of the container definition.

you can get the yaml for any kubectl command by adding -o yaml --dry-run to the command. using your example deployment:

kubectl create deployment first-k8s-deploy \
  --image=""laxman/nodejs/express-app"" \
  -o yaml \
  --dry-run


gives you:

apiversion: apps/v1
kind: deployment
metadata:
  creationtimestamp: null
  labels:
    app: first-k8s-deploy
  name: first-k8s-deploy
spec:
  replicas: 1
  selector:
    matchlabels:
      app: first-k8s-deploy
  strategy: {}
  template:
    metadata:
      creationtimestamp: null
      labels:
        app: first-k8s-deploy
    spec:
      containers:
      - image: laxman/nodejs/express-app
        name: express-app
        resources: {}


then add the imagepullpolicy property into a container in the list:

    spec:
      containers:
      - image: laxman/nodejs/express-app
        name: express-app
        resources: {}
        imagepullpolicy: never


the yaml file you create can then be deployed with the following command

kubectl apply -f &lt;filename&gt;
"
69390660,"nginx: [emerg] host not found in upstream ""udagram-users:8080"" in /etc/nginx/nginx.conf:11","after deploying to aws eks i get this error 
gtihub repo: https://github.com/oussamabouchikhi/udagram-microservices
steps to reproduce

create aws eks cluster and node groups
configure eks cluster with kubectl
deploy to eks cluster (secrets first, then other services, then reverserproxy)
. kubectl apply -f env-secret.yaml
. kubectl apply -f aws-secret.yaml
. kubectl apply -f env-configmap.yaml
. ...
. kubectl apply -f reverseproxy-deployment.yaml
. kubectl apply -f reverseproxy-service.yaml


nginx-config
worker_processes 1;
  
events { worker_connections 1024; }
error_log /dev/stdout debug;

http {

    sendfile on;

    upstream users {
        server udagram-users:8080;
    }

    upstream feed {
        server udagram-feed:8080;
    }
    
    proxy_set_header   host $host;
    proxy_set_header   x-real-ip $remote_addr;
    proxy_set_header   x-forwarded-for $proxy_add_x_forwarded_for;
    proxy_set_header   x-forwarded-host $server_name;
    
    server {
        listen 8080;
        location /api/v0/feed {
            resolver           8.8.8.8;
            proxy_pass         http://feed;
        }
        location /api/v0/users {
            resolver           8.8.8.8;
            proxy_pass         http://users;
        }            
    }

}

docker-compose
version: '3'
services:
  reverseproxy:
    image: oussamabouchikhi/reverseproxy
    ports:
      - 8080:8080
    restart: always
    depends_on:
      - udagram-users
      - udagram-feed
    networks:
      - example-net
  udagram-users:
    image: oussamabouchikhi/udagram-api-users
    volumes:
      - $home/.aws:/root/.aws
    environment:
      postgres_username: $postgres_username
      postgres_password: $postgres_password
      postgres_db: $postgres_db
      postgres_host: $postgres_host
      aws_region: $aws_region
      aws_profile: $aws_profile
      aws_media_bucket: $aws_bucket
      jwt_secret: $jwt_secret
      url: $url
      networks:
        - example-net
  udagram-feed:
    image: oussamabouchikhi/udagram-api-feed
    volumes:
      - $home/.aws:/root/.aws
    environment:
      postgres_username: $postgres_username
      postgres_password: $postgres_password
      postgres_db: $postgres_db
      postgres_host: $postgres_host
      aws_region: $aws_region
      aws_profile: $aws_profile
      aws_media_bucket: $aws_bucket
      jwt_secret: $jwt_secret
      url: $url
    networks:
      - example-net
  udagram-frontend:
    image: oussamabouchikhi/udagram-frontend
    ports:
      - '8100:80'
    networks:
      - example-net
networks:
  example-net:
    external: true

reverseproxy-deployment
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    service: reverseproxy
  name: reverseproxy
spec:
  replicas: 1
  selector:
    matchlabels:
      service: reverseproxy
  template:
    metadata:
      labels:
        service: reverseproxy
    spec:
      containers:
        - image: oussamabouchikhi/reverseproxy:latest
          name: reverseproxy
          imagepullpolicy: always
          resources:
            requests:
              memory: '64mi'
              cpu: '250m'
            limits:
              memory: '1024mi'
              cpu: '500m'
          ports:
            - containerport: 8080
      restartpolicy: always


reverseproxy-service
apiversion: v1
kind: service
metadata:
  labels:
    service: reverseproxy
  name: reverseproxy
spec:
  ports:
  - name: &quot;8080&quot;
    port: 8080
    targetport: 8080
  selector:
    service: reverseproxy
  type: loadbalancer

",<amazon-web-services><nginx><kubernetes><amazon-eks><nginx-reverse-proxy>,69422197,2,"use resolver in nginx config
the nginx resolver directive is required.
nginx is a multiplexing server (many connections in one os process), so each call of system resolver will stop processing all connections till the resolver answer is received. that's why nginx implemented its own internal non-blocking resolver.
if your config file has static dns names (not generated), and you do not care about track ip changes without nginx reload, you don't need nginx's resolver. in this case all dns names will be resolved on startup.
nginx's resolver
nginx resolver directive should be used, if you want to resolve domain name in runtime without nginx reload.
e.g.:
location /my_uri {
  resolver kube-dns.kube-system valid=10s;
  ...
}

location /my_uri {
  resolver 127.0.0.1:53 ipv6=off valid=10s;
  ...
}

use the same network (not your case, but still worth noting)
containers you are trying to link may not be on the same network.
you may want to put them all on the same network.
in your case subnets are the same, it's ok:
docker-compose
version: '3'
services:
  reverseproxy:
    ...
    networks:
      - example-net
  udagram-users:
    ...
      networks:
        - example-net
  udagram-feed:
    ...
    networks:
      - example-net
  udagram-frontend:
    ...
    networks:
      - example-net
networks:
  example-net:
    external: true

"
68729966,kubernetes config map data value externalisation,"i'm installing fluent-bit in our k8s cluster.  i have the helm chart for it on our repo, and argo is doing the deployment.
among the resources in the helm chart is a config-map with data value as below:
apiversion: v1
kind: configmap
metadata:
  name: fluent-bit
  labels:
    app: fluent-bit
data:
...
  output-s3.conf: |
    [output]
        name s3
        match *
        bucket bucket/prefix/random123/test
        region ap-southeast-2
...

my question is how can i externalize the value for the bucket so it's not hardcoded (please note  that the bucket value has random numbers)? as the s3 bucket is being created by a separate app that gets ran on the same master node, the randomly generated s3 bucket name is available as environment variable, e.g. doing &quot;echo $s3bucketname&quot; on the node would give the actual value).
i have tried doing below on the config map but it didn't work and is just getting set as it is when inspected on pod:
bucket $(echo $s3bucketname) 

using helm, i know it can be achieved something like below and then can populate using scripting something like helm --set to set the value from environment variable.  but the deployment is happening auto through argocd so it's not like there is a place to do helm --set command or please let me know if otherwise.
bucket {{.values.s3.bucket}}

tia
",<kubernetes><kubernetes-helm><configmap>,68905680,1,"with fluentbit you should be able to use environment variables such as:
  output-s3.conf: |
    [output]
        name s3
        match *
        bucket ${s3_bucket_name}
        region ap-southeast-2

you can then set the environment variable on your helm values. depending on the chart you are using and how values are passed you may have to perform a different setup, but for example using the official fluentbit charts with a values-prod.yml like:
env:
- name: s3_bucket_name
  value: &quot;bucket/prefix/random123/test&quot;

using argocd, you probably have a git repository where helm values files are defined (like values-prod.yml) and/or an argocd application defining values direct. for example, if you have an argocd application defined such as:
apiversion: argoproj.io/v1alpha1
kind: application
metadata:
  # [...]
spec:
  source:
    # ...
    helm:      
      # helm values files for overriding values in the helm chart
      valuefiles:
      # you can update this file
      - values-prod.yaml

      # helm values
      values: |
        # or update values here
        env:
        - name: s3_bucket_name
          value: &quot;bucket/prefix/random123/test&quot;
        # ...

you should be able to update either values-prod.yml on the repository used by argocd or update directly values: with you environment variable
"
63618937,how to assign an hostname to an azure application gateway with agic,"i'm using the azure kubernetes service to deploy a web application on k8s and i'm using the application gateway ingress controller to forward the requests from the outside of the k8s cluster.
i defined the ingress in this way:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    kubernetes.io/ingress.class: azure/application-gateway
    appgw.ingress.kubernetes.io/backend-path-prefix: /
    appgw.ingress.kubernetes.io/use-private-ip: &quot;true&quot;
    appgw.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
spec:
  tls:
  - hosts:
    - my.hostname.com
    secretname: my-cert
  rules:
  - host: my.hostname.com
    http:
      paths:
      - backend:
          servicename: my-backend
          serviceport: 80

my-cert is a secret i created that contains a ssl certificate my company bought some time ago that is valid for all the names *.hostname.com (is an example).
now, if i apply this yaml the agic gets configured with the secret (i can see from the agic's pod logs that everything is fine) but i cannot access my application at the url my.hostname.com, neither via http nor via https.
if, instead, i drop the line host: my.hostname.com from the ingress definition i can access the application via the application gateway's private ip.
do you know if i have to perform some special operations to assign the hostname to my application gateway when using agic?
",<azure><kubernetes><kubernetes-ingress><azure-aks><azure-application-gateway>,63630309,1,"ok, i found the problem/solution. i only had to assign the my.hostname.com hostname to the private network's ip in the company domain controller. this way in the company network the hostname is resolvable to the ip
"
53519080,how many pods to run a single kubernetes node in google kubernetes engine?,"i have multiple node.js apps / services running on google kubernetes engine (gke), actually 8 pods are running. i didnot set up resources limit when i created the pods so now i'm getting cpu unscheduled error.  

i understand i have to set up resource limits. from what i know, 1 cpu / node = 1000mi ? my question is, 

1) what's the ideal resource limit i should set up? like the minimum? for a pod that's rarely used, can i set up 20mi? or 50mi? 

2) how many pods are ideal to run on a single kubernetes node? right now i have 2 nodes set up which i want to reduce to 1. 

3) what do people use in production? and for development cluster?

here are my nodes

node 1:

namespace                  name                                                    cpu requests  cpu limits  memory requests  memory limits
  ---------                  ----                                                    ------------  ----------  ---------------  -------------
  default                    express-gateway-58dff8647-f2kft                         100m (10%)    0 (0%)      0 (0%)           0 (0%)
  default                    openidconnect-57c48dc448-9jmbn                          100m (10%)    0 (0%)      0 (0%)           0 (0%)
  default                    web-78d87bdb6b-4ldsv                                    100m (10%)    0 (0%)      0 (0%)           0 (0%)
  kube-system                event-exporter-v0.1.9-5c8fb98cdb-tcd68                  0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                fluentd-gcp-v2.0.17-mhpgb                               100m (10%)    0 (0%)      200mi (7%)       300mi (11%)
  kube-system                kube-dns-5df78f75cd-6hdfv                               260m (27%)    0 (0%)      110mi (4%)       170mi (6%)
  kube-system                kube-dns-autoscaler-69c5cbdcdd-2v2dj                    20m (2%)      0 (0%)      10mi (0%)        0 (0%)
  kube-system                kube-proxy-gke-qp-cluster-default-pool-7b00cb40-6z79    100m (10%)    0 (0%)      0 (0%)           0 (0%)
  kube-system                kubernetes-dashboard-7b89cff8-9xnsm                     50m (5%)      100m (10%)  100mi (3%)       300mi (11%)
  kube-system                l7-default-backend-57856c5f55-k9wgh                     10m (1%)      10m (1%)    20mi (0%)        20mi (0%)
  kube-system                metrics-server-v0.2.1-7f8dd98c8f-5z5zd                  53m (5%)      148m (15%)  154mi (5%)       404mi (15%)
allocated resources:
  (total limits may be over 100 percent, i.e., overcommitted.)
  cpu requests  cpu limits  memory requests  memory limits
  ------------  ----------  ---------------  -------------
  893m (95%)    258m (27%)  594mi (22%)      1194mi (45%)


node 2:

 namespace                  name                                                    cpu requests  cpu limits  memory requests  memory limits
  ---------                  ----                                                    ------------  ----------  ---------------  -------------
  default                    kube-healthcheck-55bf58578d-p2tn6                       100m (10%)    0 (0%)      0 (0%)           0 (0%)
  default                    pubsub-function-675585cfbf-2qgmh                        100m (10%)    0 (0%)      0 (0%)           0 (0%)
  default                    servicing-84787cfc75-kdbzf                              100m (10%)    0 (0%)      0 (0%)           0 (0%)
  kube-system                fluentd-gcp-v2.0.17-ptnlg                               100m (10%)    0 (0%)      200mi (7%)       300mi (11%)
  kube-system                heapster-v1.5.2-7dbb64c4f9-bpc48                        138m (14%)    138m (14%)  301656ki (11%)   301656ki (11%)
  kube-system                kube-dns-5df78f75cd-89c5b                               260m (27%)    0 (0%)      110mi (4%)       170mi (6%)
  kube-system                kube-proxy-gke-qp-cluster-default-pool-7b00cb40-9n92    100m (10%)    0 (0%)      0 (0%)           0 (0%)
allocated resources:
  (total limits may be over 100 percent, i.e., overcommitted.)
  cpu requests  cpu limits  memory requests  memory limits
  ------------  ----------  ---------------  -------------
  898m (95%)    138m (14%)  619096ki (22%)   782936ki (28%)


my plan is to move all this into 1 node. 
",<kubernetes><google-kubernetes-engine>,53519786,4,"according to kubernetes official documentation

1) you can go low in terms of memory and cpu, but you need to give enough cpu and memory to pods to function properly. i have gone as low as to cpu 100 and memory 200 (it is highly dependent on the application you're running also the number of replicas)

2) there should not be 100 pods per node (this is the extreme case)

3) production cluster are not of single node in any case. this is a very good read around kubernetes in production

but keep in mind, if you increase the number of pod on single node, you might need to increase the size (in terms of resources) of node.

memory and cpu usage tends to grow proportionally with size/load on cluster

here is the official documentation stating the requirements


  https://kubernetes.io/docs/setup/cluster-large/

"
66202397,failed to provision volume with storageclass - could not get storage key for storage account,"i'm trying to provide a pvc to a pod deployment and i'm facing this error:

failed to provision volume with storageclass &quot;xxxxxxxxxxx&quot;: could not get storage key for storage account yyyyyyyyyyy: could not get storage key for storage account yyyyyyyyyyy: retriable: false, retryafter: 0s, httpstatuscode: 400, rawerror: retriable: false, retryafter: 0s, httpstatuscode: 400, rawerror: azure.bearerauthorizer#withauthorization: failed to refresh the token for request to http://localhost:7788/subscriptions/zzzzzzzzzzz-aaaaaa-bbbbbb/resourcegroups/mc_kkkkkkkkkkkkkkkkkkkk/providers/microsoft.storage/storageaccounts/yyyyyyyyyyyyyyy/listkeys?api-version=2019-06-01: statuscode=400 -- original error: adal: refresh request failed. status code = '400'. response body: {&quot;error&quot;:&quot;unauthorized_client&quot;,&quot;error_description&quot;:&quot;aadsts700016: application with identifier 'aaaaaa-bbbbbbbb-cccccccccccccccc' was not found in the directory 'ppppppppppp-aaaaaaaaaaaa-tttttttttttt'. this can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. you may have sent your authentication request to the wrong tenant.

i'm pretty new to aks and i believe there's something very primary i'm missing, but haven't found any help on the web.
this is what i've already double-checked:

using correct account login and subscription
the storage account referred do exists
it is in the same region and resource group as the aks cluster

storage class manifest
kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: xxxxxxxx
provisioner: kubernetes.io/azure-file
parameters:
  skuname: standard_lrs
  storageaccount: yyyyyyyyyyyy
  resourcegroup: mc_zzzzzzzzzzzzzzzzz

pvc manifest
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: my-pvc
spec:
  accessmodes:
  - readwritemany
  storageclassname: xxxxxxxx
  resources:
    requests:
      storage: 5gi 

i'm using lens to manage my cluster. the pvc resource hangs in the pending state:

can you guys help me to figure it out?
",<azure><kubernetes><azure-aks><kubernetes-pvc>,66202622,2,"according to the github issue here this happens if the cluster does not have service principal or the service principal is expired after validity of 1 year.
you can verify it by running below command. retrieve the details by opening /etc/kubernetes/azure.json file on any master node or agent node.
az login --service-principal -u &lt;aadclientid&gt; -p &lt;aadclientsecret&gt; -t &lt;tenantid&gt;

updating or rotating the credential following the doc should solve it.
alternatively, you can use a managed identity for permissions instead of a service principal. managed identities are easier to manage than service principals and do not require updates or rotations. for more information, see use managed identities
"
71837512,ingress not forwarding traffic to pod,"ingress is not forwarding traffic to pods.
application is deployed on azure internal network.
i can access app successfully using pod ip and port but when trying ingress ip/ host i am getting 404 not found. i do not see any error in ingress logs.
bellow are my config files.
please help me if i am missing anything or a how i can troubleshoot to find issue.
deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: aks-helloworld-one
spec:
  replicas: 1
  selector:
    matchlabels:
      app: aks-helloworld-one
  template:
    metadata:
      labels:
        app: aks-helloworld-one
    spec:
      containers:
      - name: aks-helloworld-one
        image: &lt;image&gt;
        ports:
            - containerport: 8290
              protocol: &quot;tcp&quot;
        env:
        - name: env1
          valuefrom:
              secretkeyref:
                name: configs
                key: env1
        volumemounts:
         - mountpath: &quot;mnt/secrets-store&quot;
           name: secrets-mount
      volumes:      
        - name: secrets-mount
          csi:
            driver: secrets-store.csi.k8s.io
            readonly: true
            volumeattributes:
              secretproviderclass: &quot;azure-keyvault&quot;
      imagepullsecrets:
        - name: acr-secret
---
apiversion: v1
kind: service
metadata:
  name: aks-helloworld-one
spec:
  type: clusterip
  ports:
  - name: http
    protocol: tcp
    port: 8080
    targetport: 8290
  selector:
    app: aks-helloworld-one

ingress.yaml
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: hello-world-ingress
  namespace: ingress-basic
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  ingressclassname: nginx
  rules:
  - http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: aks-helloworld
            port:
              number: 80
  

",<nginx><kubernetes><kubernetes-ingress><azure-aks>,71838717,2,"correct your service name and service port in ingress.yaml.
spec:
  ingressclassname: nginx
  rules:
  - http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            # wrong: name: aks-helloworld
            name: aks-helloworld-one  
            port:
              # wrong: number: 80
              number: 8080

actually, you can use below command to confirm if ingress has any endpoint.
kubectl describe ingress hello-world-ingress -n ingress-basic

"
73251570,cannot mount volumes to jenkins helm chart,"i'm trying to mount existing google cloud persistent disk(balanced) to jenkins in kubernetes.
in the root of the disk located fully configured jenkins. i want to bring up jenkins in k8s with already prepared configuration on google persistent disk.
i'm using latest chart from the https://charts.jenkins.io repo
before run helm install i'm applying pv and pvc.
pv for existent disk:
apiversion: v1
kind: persistentvolume
metadata:
  name: jenkins-persistent-volume
spec:
  storageclassname: standard
  capacity:
    storage: 50gi
  accessmodes:
    - readwriteonce
  csi:
    driver: pd.csi.storage.gke.io
    volumehandle: projects/project/zones/us-central1-a/disks/jenkins-pv
    fstype: ext4

pvc
kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: jenkins-pvc
  namespace: jenkins
spec:
  volumename: jenkins-persistent-volume
  accessmodes:
    - &quot;readwriteonce&quot;
  resources:
    requests:
      storage: &quot;50gi&quot;



files in persistent google disk are 100% 1000:1000 permissions (uid, gid)
i made only one change in official helm chart, it was in values file
  existingclaim: &quot;jenkins-pvc&quot;

after running helm install jenkins-master . -n jenkins
i'm getting next:

just for ensure that problem not from gcp side.
i mount pvc to busybox and it works perfect.
apiversion: v1
kind: pod
metadata:
  name: my-pod
spec:
  containers:
    - name: busybox
      image: busybox:1.32.0
      command:
        - &quot;/bin/sh&quot;
      args:
        - &quot;-c&quot;
        - &quot;while true; do echo $(date) &gt;&gt; /app/buffer; cat /app/buffer; sleep 5; done;&quot;
      volumemounts:
        - name: my-volume
          mountpath: /app
  volumes:
    - name: my-volume
      persistentvolumeclaim:
        claimname: jenkins-pvc


i tried to change a lot of values in values.yaml also tried use old charts, or even bitnami charts with deployment instead of stateful set, but always error is the same.
could somebody shows my the right way please.
storage classes

",<kubernetes><jenkins><google-cloud-platform><google-cloud-storage><google-kubernetes-engine>,73264776,1,"try set the podsecuritycontextoverride and re-install:
controller:
  podsecuritycontextoverride:
    runasuser: 1000
    runasnonroot: true
    supplementalgroups: [1000]
persistence:
  existingclaim: &quot;jenkins-pvc&quot;

"
60861531,unable to pull docker image from artifactory repo to kubernetes cluster,"i deployed kubernetes cluster with weave cni and so far i am able to deploy pods as needed. now we are trying pull the docker images from articatory, but somehow its not working. getting the below error. surprisingly i am able to pull/push images from aws ecr repo. just baffling why we are failed to pull images to kubernetes cluster from artifactory which does not have any restrictions nor authentication. able to the images from this artifactory to regular docker vm's(which are running outside kubernetes cluster):

version:

client version: v1.17.2
server version: v1.17.2

host os:
centos 7.7

cni:
weave


error:

**trying to pull repository artifactory.gns.rms-internal.com/rms-docker-pr-local/sdp/rms/model-platform/model-engine-kubernetes ... **

get https://artifactory.internal.com/v1/_ping: dial tcp :443: connect: no route to host

appreciate any inputs or suggestions.

thanks,
cs
",<kubernetes><kubernetes-ingress>,60867364,1,"problem is with a network, you have to remove all unused networks:

$ docker network prune  


then set the bit option on.

docker -&gt; deamon.json -&gt; bip 


just add ""bip"": "" xxx.yyy.zzz.vvv/ww"" line to deamon.json .
restart docker:

$ docker restart


docker is creating sub-networks on the same range that your private registry .

take a look here: pulling-images-issue, bridge-networks, docker-compose-subnet,
docker-pulling-issue.

take a look also on: artifactory-on-prem.

please let me know if it helps.
"
44968836,google container connect to service,"i'm following a course on pluralsight where the course author puts a docker image onto kubernetes and then access it via his browser. i'm trying to replicate what he does but i cannot manage to reach the website. i believe i might be connecting to the wrong ip.

i have a replicationcontroller that's running 10 pods:

rc.yml

apiversion: v1
kind: replicationcontroller
metadata:
          name: hello-rc
spec:
        replicas: 10
        selector:
                app: hello-world
        template:
             metadata:
                labels:
                        app: hello-world
             spec:
                     containers:
                             - name: hello-pod
                               image: nigelpoulton/pluralsight-docker-ci:latest
                               ports:
                                       - containerport: 8080


i then  tried to expose the rc:

kubectl expose rc hello-rc --name=hello-svc --target-port=8080 --type=nodeport


$ kubectl get services
name         cluster-ip      external-ip   port(s)          age
hello-svc    10.27.254.160   &lt;nodes&gt;       8080:30488/tcp   30s
kubernetes   10.27.240.1     &lt;none&gt;        443/tcp          1h


my google container endpoint is : 35.xxx.xx.xxx and when running kubectl describe svc hello-svc the nodeport is 30488

thus i try to access the app at 35.xxx.xx.xxx:30488 but the site can’t be reached.
",<kubernetes><gcloud><google-kubernetes-engine>,44973936,2,"if you want to access your service via the nodeport port, you need to open your firewall for that port (and that instance).

a better way is to create a service of type loadbalancer (--type=loadbalancer) and access it on the ip google will give you.

do not forget to delete the load balancer when you are done.
"
65899092,why are my pods not utilizing multiple nodes?,"currently, i have 2 nodes on aws
name                                           status   roles    age   version
node-1-xxx-xxx-xxx-xxx.cn-north-1.compute.internal   ready    &lt;none&gt;   15d   v1.16.13-eks-2ba888
node-2-xxx-xxx-xxx-xxx.cn-north-1.compute.internal   ready    &lt;none&gt;   13d   v1.16.13-eks-2ba888

here is also a screenshot of my cpu loads
node 1

node 2

my problem is whenever i deploy my application to production i will max out my cpu usage on node 2 and it will slow down the entire site
here is my deployment config
apiversion: apps/v1
kind: deployment
metadata:
  name: backend # name of the deployment
  namespace: backend
  labels: # these labels apply to the deployment
    app: root
    component: backend

spec:
  replicas: 2
  minreadyseconds: 20
  selector:
    matchlabels:
      app: root
  strategy:
    type: rollingupdate
    rollingupdate:
      maxsurge: 1
      maxunavailable: 0
  template:
    metadata:
      labels: # these labels apply to our container
        app: root
        component: backend
        version: xxx_${bitbucket_build_number}
    spec:
      containers:
      - name: backend # name of our container
        image: xxx/xxx_main:${bitbucket_build_number} # the uri that we got from ecr
        imagepullpolicy: always
        envfrom:
        - configmapref:
            name: env
        ports:
        - containerport: 3000 # expose the running contianer on port 3000
          name: backend
          protocol: tcp
        readinessprobe:
          tcpsocket:
            port: backend
          initialdelayseconds: 20
          periodseconds: 5
          timeoutseconds: 1
          successthreshold: 1
          failurethreshold: 20

      imagepullsecrets:
       - name: xxx

am i not scaling things out properly here? what is the point of having two nodes if only one is ever in use? how can i properly scale my applications to use multiple nodes?
",<amazon-web-services><kubernetes><amazon-eks>,65900207,9,"this happens because the node scheduling algorithm is based on priority score with different priority algorithms contributing to the score. one such priority algorithm is the imagelocalitypriority which adds a positive priority score for nodes already having the images used by the pod. so initially, a node that already has the first replica of the pod running, gets a small priority bump due to the imagelocalitypriority. once more and more replicas are added, the number of pods running on each node even out because other priorities like balancedresourceallocation etc also take affect.
there is also a selectorspreadpriority which helps in minimising
the number of pods belonging to a same service on a node. so if you create your service object before creating the deployment, it might help.
to enforce the pods to spread out, you should add inter-pod anti-affinity constraints to your pods.
you should also consider adding requests and limits to your containers. this helps in spreading out the pods as the leastrequestedpriority priority also kicks in. (note: there is also mostrequestedpriority which adds priority for used nodes but it is not enabled by default).
"
71292004,golang kubernetes go-client cast deployment to deploymentlist,"i am creating a program that gets a list of all deployments from kubernetes as a *v1.deploymentlist. i managed to do that and it works. then i do some processing of this list and execute many actions afterwards. now, i have a new requirement; need to also be able to pull just one deployment and apply the same logic to it. the problem is when i use get the deployment what i get is *v1.deployment which of course is different from *v1.deploymentlist as this is a list. now, this deploymentlist is not a slice, so i can not just use append and do not know how to convert/cast. as a &quot;pragmatic&quot; solution, what i am trying to do it to just convert that deployment into deploymentlist and then apply the rest of my logic as just a deployment as changing everything else would imply a lot of burden at this point.
i have the following code:
func listk8sdeployments(the_clientset *kubernetes.clientset, mirrordeploy *string) *v1.deploymentlist {
    if mirrordeploy != nil {
        tmp_deployments, err := the_clientset.appsv1().deployments(apiv1.namespacedefault).get(context.todo(), *mirrordeploy, metav1.getoptions{})
        if err != nil {
            panic(err.error())
        }
        // here would need to convert the *v1.deployment into *v1.deploymentlist a list to retun it according to my existing logic. if i can do this, i do not need to change anything else on the program.
        // return the deployment list with one single deployment inside and finish.
    }
    deployments_list, err := the_clientset.appsv1().deployments(apiv1.namespacedefault).list(context.todo(), metav1.listoptions{})
    if err != nil {
        panic(err.error())
    }
    return deployments_list
}

it returns a *v1.deployment, but i need this data as a list even if it *v1.deploymentlist i have tried to append, but the *v1.deploymentlist is not a slice, so i can not do it. any ideas as to how to achieve this or should i change the way things are done? please explain. fyi: i am new to go and to programming k8s related things too.
",<go><kubernetes><kubernetes-go-client>,71293409,5,"when you look at the definition of v1.deploymentlist you can see where the deployment is located:
// deploymentlist is a list of deployments.
type deploymentlist struct {
    metav1.typemeta `json:&quot;,inline&quot;`
    // standard list metadata.
    // +optional
    metav1.listmeta `json:&quot;metadata,omitempty&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`

    // items is the list of deployments.
    items []deployment `json:&quot;items&quot; protobuf:&quot;bytes,2,rep,name=items&quot;`
}


then you can easily create a new instance of it with your value:
func listk8sdeployments(the_clientset *kubernetes.clientset, mirrordeploy *string) *v1.deploymentlist {
    if *mirrordeploy != &quot;&quot; {
        tmp_deployments, err := the_clientset.appsv1().deployments(apiv1.namespacedefault).get(context.todo(), *mirrordeploy, metav1.getoptions{})
        if err != nil {
            panic(err.error())
        }
        // create a new list with your deployment and return it
        deployments_list := v1.deploymentlist{items: []v1.deployment{*tmp_deployments}}
        return &amp;deployments_list
    }
    deployments_list, err := the_clientset.appsv1().deployments(apiv1.namespacedefault).list(context.todo(), metav1.listoptions{})
    if err != nil {
        panic(err.error())
    }
    return deployments_list
}

"
69712277,unknown flag --from-file (kubectl),"i'm trying to create a config map from my mongodb configuration file. i have used the following command:
kubectl create configmap mongodb-config-file --from-file=conf=mongodb.cfg

and i get this error:

error: unknown flag: --from-file
see 'kubectl create --help' for usage.

why is --from-file an unknown flag? am i missing something? i'm using windows if that information is useful. i'm still new to kubernetes and kubectl so any extra information on configmaps is welcome.
i tried to find a solution on google or other stack overflow questions and couldn't find one.
",<kubernetes><kubectl>,69712367,2,"the proper syntax for a configmap object creation is as follows:
kubectl create configmap name [--from-file=[key=]source]

the resource object is configmap and not configmap:
kubectl create configmap mongodb-config-file --from-file=conf=mongodb.cfg

"
72661619,"can't deploy bitnami/rabbitmq helm chart on gke, permission to create role is required","introduction :
i am trying to deploy a rabbitmq helm chart to gke, with my gitlab ci/cd pipeline. the command i use to install my chart is:
helm upgrade --install rabbitmq --create-namespace --namespace kubi-app-main -f envs/main/rabbitmq/rabbitmq.yaml bitnami/rabbitmq

envs/rabbitmq/rabbitmq.yaml:
auth:
  username: user
  password: password
# the used vhost is default-vhost
extraconfiguration: |-
  default_vhost = default-vhost
  default_permissions.configure = .*
  default_permissions.read = .*
  default_permissions.write = .*

the gitlab job first connect to gke cluster with gcloud:
echo &quot;$service_account_key&quot; &gt; key.json
gcloud auth activate-service-account --key-file=key.json
gcloud config set project project-kubi-app
gcloud container clusters get-credentials cluster-1 --zone europe-west9-a --project project-kubi-app

the issue:
but the helm upgrade fails:

error: roles.rbac.authorization.k8s.io is forbidden: user &quot;kubiapp-cluster-sa@project-kubi-app.iam.gserviceaccount.com&quot; cannot create resource &quot;roles&quot; in api group &quot;rbac.authorization.k8s.io&quot; in the namespace &quot;kubi-app-main&quot;: requires one of [&quot;container.roles.create&quot;] permission(s).


checking the roles of the user (service account) on the project


gcloud projects get-iam-policy project-kubi-app  --flatten=&quot;bindings[].members&quot; --format='table(bindings.role)' --filter=&quot;bindings.members:kubiapp-cluster-sa@project-kubi-app.iam.gserviceaccount.com&quot;

this will return role roles/editor, meaning that my service account has an editor role on the project.

from what i understand, the service account kubiapp-cluster-sa@project-kubi-app.iam.gserviceaccount.com has the editor role on the project project-kubi-app. 
but the service account that i am using can't create a role in the namespace kubi-app-main.
i don't understand the use of this role, but it's origin is from the rabbitmq helm chart.
from the rabbitmq helm chart:
...
# source: rabbitmq/templates/rolebinding.yaml
kind: rolebinding
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: rabbitmq-endpoint-reader
  namespace: &quot;kubi-app-main&quot;
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-10.1.8
    app.kubernetes.io/instance: rabbitmq
    app.kubernetes.io/managed-by: helm
subjects:
  - kind: serviceaccount
    name: rabbitmq
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: rabbitmq-endpoint-reader
...
---


edit:
i have changed my service account role to owner and now it works, but i would like to know the role required to create other roles.
",<kubernetes><google-kubernetes-engine><k8s-serviceaccount><k8s-rolebinding>,72698247,1,"roles/editor allows you to create/update/delete resources for most/many services, but does not include the permission to perform any of those operations on roles in general.  roles/owner, on the other hand, does as it essentially makes you an admin of (almost every) resource.
for gke, the usual role required to create/modify/update roles within the cluster is roles/container.clusteradmin.  check out gke roles.
"
63412274,404 page not found when kubernetes ingress-nginx is run on docker windows,"i am running docker on windows machine and trying to access the http://posts.com/posts as i get http error 404.0 - not found.
windows host config file has been configured correctly
127.0.0.1 posts.com
as i can browse to http://posts.com
i can also access using the port number http://posts.com:31783/posts.
i am not sure why i cannot access over port 80.
following are the logs from kubernetes


and ingress configuration
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata: 
    name: ingress-srv
    annotations: 
        kubernetes.io/ingress.class: nginx
spec:
  rules: 
    - host: posts.com
      http:
        paths:
          - path: /posts
            backend:
              servicename: posts-clusterip-srv            
              serviceport: 4000

deployment and service file
apiversion: apps/v1
kind: deployment
metadata:
    name: posts-depl
spec:
    replicas: 1
    selector:
        matchlabels:
            app: posts
    template:
        metadata:
            labels:
                app: posts
        spec:
            containers:
                - name: posts
                  image: nishank/posts:latest
---
apiversion: v1
kind: service
metadata:
    name: posts-clusterip-srv
spec:
    type: clusterip
    selector:
        app: posts
    ports:
        - name: posts
          protocol: tcp
          port: 4000
          targetport: 4000

",<docker><kubernetes><kubernetes-ingress>,64638891,3,"alright i finally have a solution to this issue.
first of all, this question is in reference to stephen grider's microservices with node js and react course. i know this because the service/configuration attempted is straight from the course content.
there is something running on your windows pc that is already using port 80, and that is why you receive a 404. to find out what process is doing this, first run the following inside a powershell / windows terminal instance:
netstat -ano | findstr &quot;:80&quot; | findstr &quot;listening&quot;

you will see something like the following:
❯ netstat -ano | findstr &quot;:80&quot; | findstr &quot;listening&quot;
tcp    0.0.0.0:80             0.0.0.0:0              listening       13056
tcp    [::]:80                [::]:0                 listening       13056
tcp    [::1]:80               [::]:0                 listening       16852

once you note the pid listening on port 80, open up task manager using &quot;ctrl+alt+delete&quot; and go to the details tab. sort by pid and find the process that you found listening to port 80. when i had the issue, the pid was 4.
sometimes the process name is distinct, and other times it will just be called &quot;system&quot;. so regardless of the name, right click the name and click &quot;open file location&quot;.
if you are taken to &quot;ntoskrnl.exe&quot;, then the guilty culprit is most likely the &quot;world wide web publishing service&quot;. you can check this by typing &quot;services&quot; in the windows search bar, opening services, and finding it on the list. if it is running, go ahead and stop it.
if that was not the case, there are other services/processes that can get in the way as well. the stackoverflow here has a bunch of responses from other people with other processes sitting on port 80.
once you have tackled that, apply your service again using:
kubectl apply -f ingress-srv.yaml

and you should be good to go.
"
58793391,do role/clusterrole changes require the restart/replacement of the pods that are bound to those roles?,"for example, i change role verbs

apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: provisioning-role
rules:
- apigroups: [""apps""]
  resources: [""deployments""]
  verbs: [""get"", ""list"", ""watch""]


and run a helm upgrade. should the pods bound to those roles be restarted/replaced? (those pods may be created manually without helm.)
",<kubernetes><kubernetes-helm>,58797950,4,"no need to recreate the pods. when you create a role/rolebinding or clusterrole/clusterrolebinding, the entities automatically get these permissions right away.

one prove used to be helm itself. when you fresh install helm, you get this error from tiller saying has no access to the cluster to do anything, but then you give tiller cluster-role (or any other with more caution) permissions and it starts working right away.
"
62708657,eksctl apply cluster changes after create,"i've created a cluster using
eksctl create cluster -f mycluster.yaml

everything is running but now i would want to add cluster autoscaler. there does not seem to be an option to specify this for the eksctl update cluster command.
when creating a new cluster i can add the --asg-access flag, is there an option to enable asg support for an existing cluster via eksctl?
",<kubernetes><amazon-eks><eksctl>,62710654,3,"the --asg-access flag only adds relevant iam policy and labels to a node group.
you can do that by creating a new node group with the autoscaler option set as true
nodegroup:
  iam:
    withaddonpolicies:
      autoscaler: true

and the labels as mentioned here
then you need to install the autoscaler itself
note:
you won't be able to edit your current nodegroup, so you will have to add a new one first and then delete your current one. (https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability)
"
51701389,kubectl top deosn't work,"i'm using kubernetes 1.11.0 and running heapster. when i run 

kubectl top pod


it will show error

error from server (serviceunavailable): the server is currently unable to handle the request (get services http:heapster:)


while i have installed heapster already

kubectl create -f deploy/kube-config/influxdb/
kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml


any suggest?

update:

the command kubectl top pod works now but the endpoint doesn't work

kubectl get --raw ""/apis/metrics.k8s.io/v1beta1/pods""
#error from server (serviceunavailable): the server is currently unable to handle the request

",<kubernetes><kubectl><heapster>,51706222,3,"can you check and ensure that your kubectl binary is the latest? something like 


client version: version.info{major:""1"", minor:""11"", gitversion:""v1.11.0"", gitcommit:""91e7b4fd31fcd3d5f436da26c980becec37ceefe"", gittreestate:""clean"", builddate:""2018-06-27t22:29:25z"", goversion:""go1.10.3"", compiler:""gc"", platform:""darwin/amd64""}

this generally happens if kubectl is older. old kubectl versions were looking for heapster service to be present but new ones should not have this problem. 
hope this helps.

in addition to above, you might want to consider moving to metrics server since heapster is on its way to being deprecated. 

https://github.com/kubernetes/heapster/blob/master/docs/deprecation.md
"
52886446,amazon eks: setting up worker nodes on spot instances,"when using aws eks, is it possible to set up the worker nodes on spot instances?


how can i do this?
anything special i should pay attention to, in such a setup?

",<amazon-web-services><amazon-ec2><kubernetes><amazon-eks>,52887068,2,"yes, you can, you will have to modify the cloudformation template (which is mentioned in this document) in the launchconfiguration section to specify a spot price.

nodelaunchconfig:
  type: aws::autoscaling::launchconfiguration
  properties:
    spotprice: ""20"" # &lt;=== here
    associatepublicipaddress: 'true'
    iaminstanceprofile: !ref nodeinstanceprofile
    imageid: !ref nodeimageid
    instancetype: !ref nodeinstancetype
    keyname: !ref keyname
    securitygroups:
    - !ref nodesecuritygroup
    blockdevicemappings:
      - devicename: /dev/xvda
        ebs:
          volumesize: !ref nodevolumesize
          volumetype: gp2
          deleteontermination: true
    userdata:
      fn::base64:
        !sub |
          #!/bin/bash
          set -o xtrace
          /etc/eks/bootstrap.sh ${clustername} ${bootstraparguments}
          /opt/aws/bin/cfn-signal --exit-code $? \
                   --stack  ${aws::stackname} \
                   --resource nodegroup  \
                   --region ${aws::region}

"
76456422,"google cloud kubernetes clusters dashboard does not show clusters from ""kubectl config view""","i am discovering google cloud kubernetes being fairly new to the topic. i have created couple of clusters and later deleted them (that is what i thought).
when i go to the console i see one new cluster:

but when i run the command:
kubectl config view

i see other clusters defined
apiversion: v1
clusters:
- cluster:
    certificate-authority-data: data+omitted
    server: https://34.68.77.89
  name: gke_question-tracker_us-central1-c_hello-java-cluster
- cluster:
    certificate-authority-data: data+omitted
    server: https://34.135.56.138
  name: gke_quizdev_us-central1_autopilot-cluster-1
contexts:
- context:
    cluster: gke_question-tracker_us-central1-c_hello-java-cluster
    user: gke_question-tracker_us-central1-c_hello-java-cluster
  name: gke_question-tracker_us-central1-c_hello-java-cluster
- context:
    cluster: gke_quizdev_us-central1_autopilot-cluster-1
    user: gke_quizdev_us-central1_autopilot-cluster-1
  name: gke_quizdev_us-central1_autopilot-cluster-1
current-context: gke_quizdev_us-central1_autopilot-cluster-1
kind: config
preferences: {}
users:
- name: gke_question-tracker_us-central1-c_hello-java-cluster
  user:
    exec:
      apiversion: client.authentication.k8s.io/v1beta1
      args: null
      command: gke-gcloud-auth-plugin
      env: null
      installhint: install gke-gcloud-auth-plugin for use with kubectl by following
        https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke
      interactivemode: ifavailable
      provideclusterinfo: true
- name: gke_quizdev_us-central1_autopilot-cluster-1
  user:
    exec:
      apiversion: client.authentication.k8s.io/v1beta1
      args: null
      command: gke-gcloud-auth-plugin
      env: null
      installhint: install gke-gcloud-auth-plugin for use with kubectl by following
        https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke
      interactivemode: ifavailable
      provideclusterinfo: true


where in the google cloud dashboard  i can see the clusters mentioned in the config file (gke_question-tracker_us-central1-c_hello-java-cluster, gke_quizdev_us-central1_autopilot-cluster-1)?

where in the google cloud dashboard  i can see the users mentioned in the config file?

why i do not see the questy-java-cluster after running the kubectl  config view command?


",<kubernetes><google-cloud-platform><kubectl>,76458526,1,"this is a tad confusing.
there are 2 related but disconnected &quot;views&quot; of the clusters.
the first view is google cloud's &quot;view&quot;. this is what you're seeing in cloud console. you would see the same (!) details using e.g. gcloud container clusters list --project=quizdev (see docs). this is the current set of kubernetes clusters resources (there's one cluster questy-java-cluster in the current project (quizdev).
kubectl generally (though you can specify the projects on the command line too) uses a so-called kubeconfig file (default linux location: ~/.kube/config) to hold the configuration information for clusters, contexts (combine clusters with user and possible more) with users. see organizing cluster access using kubeconfig files.
now, it's mostly up to you (the developer) to keep the google cloud view and the kubectl view in sync.
when you gcloud container clusters create (or use cloud console), gcloud creates the cluster (and iirc) configures the default kubeconfig file for you. this is to make it easier to immediately use kubectl after creating the cluster. you can also always gcloud container clusters get-credentials to repeat the credentials step (configuring kubeconfig).
if you create clusters using cloud console, you must gcloud container clusters get-credentials manually in order to update your local kubeconfig file(s) with the cluster's credentials.
i don't recall whether gcloud container clusters delete deletes the corresponding credentials in the default kubeconfig file; i think it doesn't.
the result is that there's usually 'drift' between what the kubeconfig file contains and the clusters that exist; i create|delete clusters daily and periodically tidy my kubeconfig file for this reason.
one additional complication is that (generally) there's one kubeconfig file (~/.kube/config) but you may also have multiple google cloud projects. the clusters that you've get-credentials (either manually or automatically) that span multiple (!) google cloud projects will all be present in the one local kubeconfig.
there's a one-to-one mapping though between google cloud projects, locations and cluster names and kubeconfig cluster's:
gke_{project}_{location}_{cluster-name}

lastly, if one (or more developers) use multiple hosts to access kubernetes clusters, each host will need to reflect the kubeconfig configuration (server, user, context) for each cluster that it needs to access.
gke does a decent job in helping you manage kubeconfig configurations. the complexity|confusion arises because it does some of this configuration implicitly (gcloud container clusters create) and it would be better to make this more transparent. if you use any managed kubernetes offering (aws, azure, linode, vultr etc. etc.), these all provide some analog of this process either manual or automatic for helping manage the entries in kubeconfig.
"
56833757,how to replace fields value of angular config.json using environment variable in kubernetes and nginx in ci &cd vsts,"i am trying to replace authenticationendpoint url and other configuation in the config.json of angular project using environment variable in kubernetes dynamically. for that configured in the helm chart for environment variable in the ci &amp; cd pipeline of vsts. but not sure how config.json field will be replaced with environment variable in kubernetes. could you please help me on this.?

    env in pods (kubernetes) ran printenv cmd

 authenticationendpoint=http://localhost:8888/security/auth


    config.json

 {
   ""authenticationendpoint"": ""http://localhost:8080/security/auth"",
   ""authenticationclientid"": ""my-project"",
   ""baseapiurl"": ""http://localhost:8080/"",
   ""homeurl"": ""http://localhost:4300/""
 }


   generated yaml file from helm chart

        # source: sample-web/templates/service.yaml
        apiversion: v1
        kind: service
        metadata:
          name: cloying-rattlesnake-sample-web
          labels:
            app.kubernetes.io/name: sample-web
            helm.sh/chart: sample-web-0.1.0
            app.kubernetes.io/instance: cloying-rattlesnake
            app.kubernetes.io/managed-by: tiller
        spec:
          type: clusterip
          ports:
            - port: 80
              targetport: 80
              protocol: tcp
              name: http
          selector:
            app.kubernetes.io/name: sample-web
            app.kubernetes.io/instance: cloying-rattlesnake
        ---
        # source: sample-web/templates/deployment.yaml
        apiversion: apps/v1
        kind: deployment
        metadata:
          name: cloying-rattlesnake-sample-web
          labels:
            app.kubernetes.io/name: sample-web
            helm.sh/chart: sample-web-0.1.0
            app.kubernetes.io/instance: cloying-rattlesnake
            app.kubernetes.io/managed-by: tiller
        spec:
          replicas: 1
          selector:
            matchlabels:
              app.kubernetes.io/name: sample-web
              app.kubernetes.io/instance: cloying-rattlesnake
          template:
            metadata:
              labels:
                app.kubernetes.io/name: sample-web
                app.kubernetes.io/instance: cloying-rattlesnake
            spec:
              containers:
                - name: sample-web
                  image: ""sample-web:stable""
                  imagepullpolicy: ifnotpresent
                  ports:
                    - name: http
                      containerport: 80
                      protocol: tcp
                  livenessprobe:
                    httpget:
                      path: /
                      port: http
                  readinessprobe:
                    httpget:
                      path: /
                      port: http
                  env:
                    - name: authenticationendpoint
                      value: ""http://localhost:8080/security/auth""
                  resources:
                    {}
        ---
        # source: sample-web/templates/ingress.yaml
        apiversion: extensions/v1beta1
        kind: ingress
        metadata:
          name: cloying-rattlesnake-sample-web
          labels:
            app.kubernetes.io/name: sample-web
            helm.sh/chart: sample-web-0.1.0
            app.kubernetes.io/instance: cloying-rattlesnake
            app.kubernetes.io/managed-by: tiller
          annotations:
            kubernetes.io/ingress.class: nginx
            nginx.ingress.kubernetes.io/rewrite-target: /$1
            nginx.ingress.kubernetes.io/ssl-redirect: ""false""

        spec:
          rules:
            - host: """"
              http:
                paths:
                  - path: /?(.*)
                    backend:
                      servicename: cloying-rattlesnake-sample-web
                      serviceport: 80


absolute path of config.json

ran shell cmd - kubectl exec -it sample-web-55b71d19c6-v82z4 /bin/sh

path: usr/share/nginx/html/config.json

",<docker><nginx><kubernetes><angular6><kubernetes-helm>,56834531,1,"use a init container to modify your config.json when the pod starts.

updated your deployment.yaml

    # source: sample-web/templates/deployment.yaml
    apiversion: apps/v1
    kind: deployment
    metadata:
      name: cloying-rattlesnake-sample-web
      labels:
        app.kubernetes.io/name: sample-web
        helm.sh/chart: sample-web-0.1.0
        app.kubernetes.io/instance: cloying-rattlesnake
        app.kubernetes.io/managed-by: tiller
    spec:
      replicas: 1
      selector:
        matchlabels:
          app.kubernetes.io/name: sample-web
          app.kubernetes.io/instance: cloying-rattlesnake
      template:
        metadata:
          labels:
            app.kubernetes.io/name: sample-web
            app.kubernetes.io/instance: cloying-rattlesnake
        spec:
          initcontainers:
            - name: init-myconfig
              image: busybox:1.28
              command: ['sh', '-c', 'cat /usr/share/nginx/html/config.json | sed -e ""s#\$authenticationendpoint#$authenticationendpoint#g"" &gt; /tmp/config.json &amp;&amp; cp /tmp/config.json /usr/share/nginx/html/config.json']
              env:
                - name: authenticationendpoint
                  value: ""http://localhost:8080/security/auth""
          containers:
            - name: sample-web
              image: ""sample-web:stable""
              imagepullpolicy: ifnotpresent
              ports:
                - name: http
                  containerport: 80
                  protocol: tcp
              livenessprobe:
                httpget:
                  path: /
                  port: http
              readinessprobe:
                httpget:
                  path: /
                  port: http
              env:
                - name: authenticationendpoint
                  value: ""http://localhost:8080/security/auth""
              volumemounts:
                - mountpath: /usr/share/nginx/html/config.json
                  name: config-volume
          volumes:
            - name: config-volume
              hostpath:
                path: /mnt/data.json # create this file in the host where the pod starts. content below.
                type: file


create /mnt/data.json file in the host where the pod starts

{
      ""authenticationendpoint"": ""$authenticationendpoint"",
      ""authenticationclientid"": ""my-project"",
      ""baseapiurl"": ""http://localhost:8080/"",
      ""homeurl"": ""http://localhost:4300/""
}

"
66304706,kubernetes object creation time,"is there a command/method to get the time elapsed from the instance a kubernetes object creation command is launched  (e.g., kubectl create -f mydeployment-pod.yaml),  until the kubernetes object  (deployment/pod…) is fully created and in running/ready state.
",<kubernetes><kubernetes-pod>,66314161,1,"as mentioned by @sahadat: there is no native way of calculating that. however, you can use kubectl get events to see the creationtimestamp, firsttimestamp and lasttimestamp. you can either request the output in yaml/json format by executing kubectl get events -o yaml or use  custom columns and fields selectors to narrow down the output, for example:
kubectl get events -o custom-columns=firstseen:.firsttimestamp,lastseen:.lasttimestamp,created:.creationtimestamp

that of course can be adjusted according to your needs.
"
75308525,why does minikube doesn't have access to k8s registry?,"running the minikube start command, i am getting this message:
this container is having trouble accessing https://registry.k8s.io
and after this the booting up control plane process takes a long time then gives the following error:
error starting cluster: wait: /bin/bash -c &quot;sudo env path=&quot;/var/lib/minikube/binaries/v1.26.1:$path&quot; kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=diravailable--etc-kubernetes-manifests,diravailable--var-lib-minikube,diravailable--var-lib-minikube-etcd,fileavailable--etc-kubernetes-manifests-kube-scheduler.yaml,fileavailable--etc-kubernetes-manifests-kube-apiserver.yaml,fileavailable--etc-kubernetes-manifests-kube-controller-manager.yaml,fileavailable--etc-kubernetes-manifests-etcd.yaml,port-10250,swap,numcpu,mem,systemverification,filecontent--proc-sys-net-bridge-bridge-nf-call-iptables&quot;: process exited with status 1
i have the right minikube, kubectl , docker ... versions.
$ echo $(minikube docker-env) this command outputs the following error:
exiting due to guest_status: state: unknown state &quot;minikube&quot;: docker container inspect minikube --format=: exit status 1
stderr:
got permission denied while trying to connect to the docker daemon socket at unix:///var/run/docker.sock: get &quot;http://%2fvar%2frun%2fdocker.sock/v1.24/containers/minikube/json&quot;: dial unix /var/run/docker.sock: connect: permission denied
but what i don't understand, if i run the docker run hello-world , it works (i have the super user permission)
",<docker><ubuntu><kubernetes><kubectl><minikube>,75309501,4,"try running the below commands:
remove unused data:
docker system prune

clear minikube's local state:
minikube delete

start the cluster:
minikube start --driver=&lt;driver_name&gt;

(in your case driver name is docker as per minikube profile list info shared by you)
check the cluster status:
minikube status

also refer to this github link.
"
53889595,"apt-get update stuck in my k8s, fail to install any tool to debug","i am new in k8s world and i am using helm to install the stable/mysql template then i would like to test it. 

i run below to spawn a new ubuntu container as mysql client. however the apt-get update stuck at ""waiting for headers"" always.

kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=never -- bash -il

root@ubuntu:/# apt-get update
0% [waiting for headers] [waiting for headers]


i think it is network issue, but i am not able to install any tool to debug as the apt-get not work.

i tried couple of ways like modifying the /etc/resolv.conf, but it seems it doesn't help.

anyone can share me some lights about how to proceed?

thanks!
",<kubernetes><ubuntu-16.04><kubernetes-helm>,54082767,1,"follow this to setup the proxy will make it work. https://askubuntu.com/questions/109673/how-to-use-apt-get-via-http-proxy-like-this

add below content to file /etc/apt/apt.conf.

acquire::http::proxy ""http://proxy.server.port:8080"";

"
74594131,how to describe a kubernetes cluster using kubectl?,"i want to check the kubernetes configuration - how many nodes, etc. i tried the following command.
kubectl describe cluster
error: the server doesn't have a resource type &quot;cluster&quot;

btw, i tried to use the following command to check the az of the nodes of the pods. but it returns &lt;none&gt; for all the pods' nodes.
kubectl get pods -o=custom-columns=name:.metadata.name,zone:.metadata.labels.'topology\.kubernetes\.io/zone'

how to use kubectl to find the azs of the pods?
",<amazon-web-services><kubernetes><amazon-eks>,74603567,2,"here are my nodes showing zone info(made up) in the cluster:
kubectl get node -ltopology.kubernetes.io/zone
name                            status   roles           age   version   zone
development-kube-controller-1   ready    control-plane   48d   v1.24.6   zone
development-kube-worker-1       ready    &lt;none&gt;          48d   v1.24.6   zone-a
development-kube-worker-2       ready    &lt;none&gt;          48d   v1.24.6   zone-b

using the awk command, the label topology.kubernetes.io/zone is merged with the name of the pods scheduled on that particular node.
note: i have used lowercase k in the label key topology\.kubernetes\.io/zone; however, in your case, it's uppercase k in the question. you might want to calibrate your command.
kubectl describe  node |awk '/topology.kubernetes.io\/zone/{zone=$1;next} /^  namespace/{flag=1; getline; next} /^allocated resources:/{flag=0} flag{print  $2, zone}' |column -t
calico-node-swz7j                                      topology.kubernetes.io/zone=zone
coredns-74d6c5659f-4mpcp                               topology.kubernetes.io/zone=zone
dns-autoscaler-59b8867c86-w4dls                        topology.kubernetes.io/zone=zone       
kubernetes-dashboard-648989c4b4-b4k7h                  topology.kubernetes.io/zone=zone-a
kubernetes-metrics-scraper-84bbbc8b75-x72pf            topology.kubernetes.io/zone=zone-a
nginx-proxy-development-kube-worker-1                  topology.kubernetes.io/zone=zone-a
nodelocaldns-xt6hr                                     topology.kubernetes.io/zone=zone-a
metallb-controller-94c85f6db-6j8j5                     topology.kubernetes.io/zone=zone-a
metallb-speaker-4fz99                                  topology.kubernetes.io/zone=zone-a
argocd-application-controller-0                        topology.kubernetes.io/zone=zone-b
argocd-applicationset-controller-5bff759d68-kk7tx      topology.kubernetes.io/zone=zone-b
argocd-dex-server-59c59b5d96-7z7th                     topology.kubernetes.io/zone=zone-b
argocd-notifications-controller-6df97c8577-26z9m       topology.kubernetes.io/zone=zone-b
argocd-redis-684fb8c6dd-bxb25                          topology.kubernetes.io/zone=zone-b
argocd-repo-server-79d8c5f7b4-fnh7g                    topology.kubernetes.io/zone=zone-b

ps: you can print $1 in the awk command to print the namespace, in case of filtering based on namespace is needed.
"
62336763,[cloud-running-a-container]: no resources found in default namespace,"i did a small deployment in k8s using docker image but it is not showing in deployment but only showing in pods.
reason: it is not creating any default namespace in deployments.

please suggest:

following are the commands i used.

$ kubectl run hello-node --image=gcr.io/$devshell_project_id/hello-node:1.0 --port=8080 --namespace=default
pod/hello-node created

$ kubectl get pods
name         ready   status    restarts   age
hello-node   1/1     running   0          12s

$ kubectl get pods --all-namespaces
namespace     name                                                       ready   status    restarts   age
default       hello-node                                                 1/1     running   0          9m9s
kube-system   event-exporter-v0.2.5-599d65f456-4dnqw                     2/2     running   0          23m
kube-system   kube-proxy-gke-hello-world-default-pool-c09f603f-3hq6      1/1     running   0          23m

$ kubectl get deployments
**no resources found in default namespace.**

$ kubectl get deployments --all-namespaces
namespace     name                                       ready   up-to-date   available   age
kube-system   event-exporter-v0.2.5                      1/1     1            1           170m
kube-system   fluentd-gcp-scaler                         1/1     1            1           170m
kube-system   heapster-gke                               1/1     1            1           170m
kube-system   kube-dns                                   2/2     2            2           170m
kube-system   kube-dns-autoscaler                        1/1     1            1           170m
kube-system   l7-default-backend                         1/1     1            1           170m
kube-system   metrics-server-v0.3.1                      1/1     1            1           170m

",<kubernetes><google-kubernetes-engine><kubernetes-pod>,62345162,2,"arghya sadhu's answer is correct. in the past kubectl run command indeed created by default a deployment instead of a pod. actually in the past you could use it with so called generators and you were able to specify exactly what kind of resource you want to create by providing --generator flag followed by corresponding value. currently --generator flag is deprecated and has no effect.   

note that you've got quite clear message after running your kubectl run command:

$ kubectl run hello-node --image=gcr.io/$devshell_project_id/hello-node:1.0 --port=8080 --namespace=default
pod/hello-node created


it clearly says that the pod hello-node was created. it doesn't mention about a deployment anywhere.

as an alternative to using imperative commands for creating either deployments or pods you can use declarative approach:

apiversion: apps/v1
kind: deployment
metadata:
  name: hello-node
  namespace: default
  labels:
    app: hello-node
spec:
  replicas: 3
  selector:
    matchlabels:
      app: hello-node
  template:
    metadata:
      labels:
        app: hello-node
    spec:
      containers:
      - name: hello-node-container
        image: gcr.io/$devshell_project_id/hello-node:1.0
        ports:
        - containerport: 8080


declaration of namespace can be ommitted in this case as by default all resources are deployed into the default namespace.

after saving the file e.g. as nginx-deployment.yaml you just need to run:

kubectl apply -f nginx-deployment.yaml


update:

expansion of the environment variables within the yaml manifest actually doesn't work so the following line from the above deployment example cannot be used:

image: gcr.io/$devshell_project_id/hello-node:1.0


the simplest workaround is a fairly simple sed ""trick"".

first we need to change a bit our project id's placeholder in our deployment definition yaml. it may look like this:

image: gcr.io/{{devshell_project_id}}/hello-node:1.0


then when applying the deployment definition instead of simple kubectl apply -f deployment.yaml run this one-liner:

sed ""s/{{devshell_project_id}}/$devshell_project_id/g"" deployment.yaml | kubectl apply -f -


the above command tells sed to search through deployment.yaml document for {{devshell_project_id}} string and each time this string occurs, to substitute it with the actual value of $devshell_project_id environment variable.
"
63102235,url regex match for istio- virtualservice throwing 404,"my gateway and virtualservice for the sample bookinfo looks like this:
apiversion: networking.istio.io/v1alpha3
kind: gateway
metadata:
  name: bookinfo-gateway
spec:
  selector:
    istio: ingressgateway # use istio default controller
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &quot;*&quot;
    tls:
      httpsredirect: true
  - port:
      number: 443
      name: https
      protocol: https
    hosts:
    - &quot;*&quot;
    tls:
      mode: simple 
      servercertificate: /etc/istio/ingressgateway-certs/tls.crt
      privatekey: /etc/istio/ingressgateway-certs/tls.key
---
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: bookinfo
spec:
  hosts:
  - &quot;*&quot;
  gateways:
  - bookinfo-gateway
  http:
  - match:
    - uri:
        exact: /productpage
    - uri:
        prefix: /static
    - uri:
        exact: /login
    - uri:
        exact: /logout
    route:
    - destination:
        host: productpage
        port:
          number: 9080
  - match:
    - uri:
        regex: &quot;v1&quot;
    route:
    - destination:
        host: productpage
        port:
          number: 9080

i am terminating tls at the gateway and in the http route, i have configured a regex match on &quot;v1&quot; for http and routing it the productpage service.
i am testing this by sending a request to http://external-ip/api/v1/products (the sample application's productpage service is configured to return a text body on this endpoint), but the request fails with http 404. i am not sure what i am doing wrong here, any help is highly appreciated.
",<kubernetes><kubernetes-ingress><istio><azure-aks>,63104683,3,"i think i found the mistake here, the regex : &quot;v1&quot; does not do partial match.
  - match:
    - uri:
        regex: v1
    route:
    - destination:
        host: productpage
        port:
          number: 9080

instead i had to specify regex : .*v1.* to make it work. i am able to route now.
  - match:
    - uri:
        regex: .*v1.*
    route:
    - destination:
        host: productpage
        port:
          number: 9080

"
66839879,how to configure https on deployment yaml file for asp.net core app locally in minikube?,"i have an asp.net core app that i want to configure with https in my local kubernetes clustur using minikube.
the deployment yaml file is:
apiversion: apps/v1
kind: deployment
metadata:
  name: kube-volume
  labels:
    app: kube-volume-app
spec:
  replicas: 1
  selector: 
    matchlabels:
      component: web
  template:
    metadata: 
      labels:
        component: web
    spec:
      containers:
        - name: ckubevolume
          image: kubevolume
          imagepullpolicy: never
          ports:
            - containerport: 80
            - containerport: 443
          env:
            - name: aspnetcore_environment
              value: development
            - name: aspnetcore_urls
              value: https://+:443;http://+:80
            - name: aspnetcore_https_port
              value: '443'
            - name: aspnetcore_kestrel__certificates__default__password
              value: mypass123
            - name: aspnetcore_kestrel__certificates__default__path
              value: /app/https/aspnetapp.pfx
          volumemounts:
            - name: ssl
              mountpath: &quot;/app/https&quot;
      volumes:
        - name: ssl
          configmap:
            name: game-config

you can see i have added environment variables for https in yaml file.
i also created a service for this deployment. the yaml file of the service is:
apiversion: v1
kind: service
metadata:
  name: service-1
spec:
  type: nodeport
  selector:
    component: web
  ports:
    - name: http
      protocol: tcp
      port: 100
      targetport: 80
    - name: https
      protocol: tcp
      port: 200
      targetport: 443

but unfortunately the app is not opening by the service when i run the minikube service service-1 command.
however when i remove the env variables for https then the app is opening by the service. these are the lines which when i remove the app opens:
- name: aspnetcore_urls
  value: https://+:443;http://+:80
- name: aspnetcore_https_port
  value: '443'
- name: aspnetcore_kestrel__certificates__default__password
  value: mypass123
- name: aspnetcore_kestrel__certificates__default__path
  value: /app/https/aspnetapp.pfx

i also confirmed with the shell that the certificate is present in the /app/https folder.
whay i am doing wrong?
",<asp.net-core><kubernetes><asp.net-core-mvc><kubectl><minikube>,66840146,2,"i think your approach does not fit well with the architecture of kubernetes. a tls certificate (for https) is coupled to a hostname.
i would recommend one of two different approaches:

expose your app with a service of type: loadbalancer
expose your app with an ingress resource

expose your app with a service of type loadbalancer
this is typically called a network loadbalancer as it exposes your app for tcp or udp directly.
see loadbalancer access in the minikube documentation. but beware that your app get an external address from your loadbalancer, and your tls certificate probably has to match that.
expose your app with an ingress resource
this is the most common approach for microservices in kubernetes. in addition to your service of type: nodeport you also need to create an ingress resource for your app.
the cluster needs an ingress controller and the gateway will handle your tls certificate, instead of your app.
see how to use custom tls certificate with ingress addon for how to configure both ingress and tls certificate in minikube.
i would recommend to go this route.
"
52563999,how to assign public ip to kubernetes's ingress,"i have deployed kong-ingress-controller using helm 

and i have kubernetes's cluster v1.10 on centos 7 

i am using dedicated server from ovh provider 

when i create ingress 

cat ingress.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: jenkins 
spec:
  backend:
    servicename: jenkins
    serviceport: 8080




kubectl get ing
name      hosts     address   ports     age
jenkins   *                   80        3s




kubectl get svc
name                   type        cluster-ip      external-ip   port(s)          age
jenkins                clusterip   10.254.104.80   &lt;none&gt;        8080/tcp         1d


now i can not access this ingress from out side because i am using ovh server.

is there a solution? 
",<kubernetes><kubernetes-ingress><kong><kubernetes-helm>,52564902,2,"ovh is not officially supported by kubernetes. it was supported then generally you would create a service jenkins of the type loadbalancer and that would be your externally facing endpoint with a public ip.

since it's not supported the next best thing is to create a nodeport service. that will create a service that listens on a specific port on all the kubernetes nodes and forwards the requests to your pods (only where they are running). so, in this case, you will have to create an ovh load balancer with a public ip and point the backend of that load balancer to the nodeport of the service where your ingress is listening on.
"
63361182,login unauthorized error whle connecting to external hashicorp vault with kubernetes service account,"scenario:
i have two kubernetes 1.17 clusters, and one cluster have hashicorp vault configured. i am trying to connect to it from other cluster using kubernetes auth method and i am getting 403 error as below:

2020-08-11t14:22:46.971z [error] auth.kubernetes.auth_kubernetes_f530e086: login unauthorized due to: {&quot;kind&quot;:&quot;status&quot;,&quot;apiversion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{},&quot;status&quot;:&quot;failure&quot;,&quot;message&quot;:&quot;tokenreviews.authentication.k8s.io is forbidden: user &quot;system:serviceaccount:default:vault-auth&quot; cannot create resource &quot;tokenreviews&quot; in api group &quot;authentication.k8s.io&quot; at the cluster scope: rbac: clusterrole.rbac.authorization.k8s.io &quot;system:auth-delegator&quot; not found&quot;,&quot;reason&quot;:&quot;forbidden&quot;,&quot;details&quot;:{&quot;group&quot;:&quot;authentication.k8s.io&quot;,&quot;kind&quot;:&quot;tokenreviews&quot;},&quot;code&quot;:403}

clusterrolebinding:
kind: clusterrolebinding
metadata:
  name: role-tokenreview-binding
  namespace: default
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: system:auth-delegator
subjects:
- kind: serviceaccount
  name: vault-auth
  namespace: default

someone please help me here? what am i missing?
",<kubernetes><hashicorp-vault><amazon-eks>,63361426,3,"the clusterrole system:auth-delegator does not exist which is giving this error.
to check if it exists use below command
kubectl get clusterrole | grep system:auth-delegator

if it does not exist create one using below yaml
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: system:auth-delegator
rules:
- apigroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apigroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create

"
73011138,referencing secrets in kubernetes,"what is the difference between env and envfrom fields in kubernetes when referencing secrets? thank you!
",<kubernetes><kubernetes-secrets>,73012511,2,"below is the &quot;env:&quot; sample which will load variables into container environment as environment variables which can referenced using &quot;$demo_greeting&quot; then you will get &quot;hello from the environment&quot;
    env:
    - name: demo_greeting
      value: &quot;hello from the environment&quot;
    - name: demo_farewell
      value: &quot;such a sweet sorrow&quot;

similarly you can load secret as environment variable as below
  envfrom:
  - secretref:
      name: mysecret

here the secret will be loaded as environment variable and this can be referenced as $mysecret inside the container.
"
69466546,"warning: networking.k8s.io/v1beta1 ingress is deprecated in v1.19+, unavailable in v1.22+; use networking.k8s.io/v1 ingress","my ingress.yml file is bellow
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: example-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: &quot;0&quot;
    nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;600&quot;
    nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;600&quot;
    kubernetes.io/tls-acme: &quot;true&quot;
    cert-manager.io/cluster-issuer: &quot;example-issuer&quot;
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: example-service
          serviceport: http
        path: /                 
  tls:
  - secretname: example-tls-cert
    hosts:
      - example.com

after changing apiversion: networking.k8s.io/v1beta1 to networking.k8s.io/v1 getting bellow error.
error validating data: [validationerror(ingress.spec.rules[0].http.paths[0].backend): unknown field &quot;servicename&quot; in io.k8s.api.networking.v1.ingressbackend, validationerror(ingress.spec.rules[0].http.paths[0].backend)
",<kubernetes><kubernetes-ingress>,69466670,3,"try bellow
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: example-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: &quot;0&quot;
    nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;600&quot;
    nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;600&quot;
    kubernetes.io/tls-acme: &quot;true&quot;
    cert-manager.io/cluster-issuer: &quot;example-issuer&quot;
spec:
  rules:
  - host: example.com
    http:
      paths:
      - pathtype: prefix
        path: /
        backend:
          service:
            name: example-service
            port:
              number: 80
  tls:
   - secretname: example-tls-cert
     hosts:
       - example.com

"
61200847,how to modify the minikube start parameter setting apiserver from 8443 to 6443,"i'm using minikube to test the kompose. 
i installed k8s using the following minikube command

# minikube start --driver=none --kubernetes-version v1.16.0
minikube v1.9.2 on ubuntu 18.04
✨  using the none driver based on user configuration
👍  starting control plane node  in cluster minikube
🤹  running on localhost (cpus=xx, memory=xxxxxmb, disk=xxxxxmb) ...
ℹ️  os release is ubuntu 18.04.3 lts
🐳  preparing kubernetes v1.16.0 on docker 18.09.7 ...
    ▪ kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
❗  this bare metal machine is having trouble accessing https://k8s.gcr.io
💡  to pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
🌟  enabling addons: default-storageclass, storage-provisioner
🤹  configuring local host environment ...

❗  the 'none' driver is designed for experts who need to integrate with an existing vm
💡  most users should use the newer 'docker' driver instead, which does not require root!
📘  for more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/

❗  kubectl and minikube configuration will be stored in /root
❗  to use kubectl or minikube commands as your own user, you may need to relocate them. for example, to overwrite your own settings, run:

    ▪ sudo mv /root/.kube /root/.minikube $home
    ▪ sudo chown -r $user $home/.kube $home/.minikube

💡  this can also be done automatically by setting the env var change_minikube_none_user=true
🏄  done! kubectl is now configured to use ""minikube""
💡  for best results, install kubectl: https://kubernetes.io/docs/tasks/tools/install-kubectl/


and curl, chmod, mv install kubectl

# kubectl versionclient version: version.info{major:""1"", minor:""16"", gitversion:""v1.16.0"", gitcommit:""2bd9643cee5b3b3a5ecbd3af49d09018f0773c77"", gittreestate:""clean"", builddate:""2019-09-18t14:36:53z"", goversion:""go1.12.9"", compiler:""gc"", platform:""linux/amd64""}
server version: version.info{major:""1"", minor:""16"", gitversion:""v1.16.0"", gitcommit:""2bd9643cee5b3b3a5ecbd3af49d09018f0773c77"", gittreestate:""clean"", builddate:""2019-09-18t14:27:17z"", goversion:""go1.12.9"", compiler:""gc"", platform:""linux/amd64""}


but when i use the kompose up command, it shows connection rejection

kompose -f docker-compose.yaml up
info we are going to create kubernetes deployments, services and persistentvolumeclaims for your dockerized application. if you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

fata error while deploying application: get https://127.0.0.1:6443/api: dial tcp 127.0.0.1:6443: connect: connection refused


querying the kubectl configuration found that its port was 8443, different from the 6443 connected by kompose up

# kubectl cluster-info
kubernetes master is running at https://172.26.90.122:8443
kubedns is running at https://172.26.90.122:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

to further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.


i think that's the problem, but i don't know how to fix it to make the ports match, right.

i would appreciate it if you could tell me how to solve it?
",<kubernetes><kubectl><minikube><kube-apiserver><kompose>,61202716,3,"you add this flag in the start command

--apiserver-port=6443 

"
65049488,kube-controller-manager is not logging details,"i have an issue setting up persistant volumes for gitlab on my bare-metal kubernetes cluster:
operation for &quot;provision-gitlab/repo-data-gitlab-gitaly-0[3f758288-290c-4d9c-a084-5506f58a22d7]&quot; failed. no retries permitted until 2020-11-28 11:55:56.533202624 +0000 utc m=+305.008238514 (durationbeforeretry 4s). error: &quot;failed to create volume: failed to create volume: see kube-controller-manager.log for details&quot;
problem is: this file doesn't exist anywhere, and i cannot get any more details about the problem, even by adapting the configuration:
apiversion: v1
kind: pod
metadata:
  creationtimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=192.168.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --node-cidr-mask-size=24
    - --port=0
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    - --log-dir=/var/log/
    - --log-file=kube-controller-manager.log
    - --logtostderr=false
    image: k8s.gcr.io/kube-controller-manager:v1.19.4
    imagepullpolicy: ifnotpresent
    livenessprobe:
      failurethreshold: 8
      httpget:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: https
      initialdelayseconds: 10
      periodseconds: 10
      timeoutseconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    startupprobe:
      failurethreshold: 24
      httpget:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: https
      initialdelayseconds: 10
      periodseconds: 10
      timeoutseconds: 15
    volumemounts:
    - mountpath: /var/log/kube-controller-manager.log
      name: logfile
    - mountpath: /etc/ssl/certs
      name: ca-certs
      readonly: true
    - mountpath: /etc/ca-certificates
      name: etc-ca-certificates
      readonly: true
    - mountpath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountpath: /etc/kubernetes/pki
      name: k8s-certs
      readonly: true
    - mountpath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readonly: true
    - mountpath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readonly: true
    - mountpath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readonly: true
  hostnetwork: true
  priorityclassname: system-node-critical
  volumes:
  - hostpath:
      path: /var/log/kube-controller-manager.log
    name: logfile
  - hostpath:
      path: /etc/ssl/certs
      type: directoryorcreate
    name: ca-certs
  - hostpath:
      path: /etc/ca-certificates
      type: directoryorcreate
    name: etc-ca-certificates
  - hostpath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      type: directoryorcreate
    name: flexvolume-dir
  - hostpath:
      path: /etc/kubernetes/pki
      type: directoryorcreate
    name: k8s-certs
  - hostpath:
      path: /etc/kubernetes/controller-manager.conf
      type: fileorcreate
    name: kubeconfig
  - hostpath:
      path: /usr/local/share/ca-certificates
      type: directoryorcreate
    name: usr-local-share-ca-certificates
  - hostpath:
      path: /usr/share/ca-certificates
      type: directoryorcreate
    name: usr-share-ca-certificates
status: {}

i tried to create it by hand, change permissions on it, but the pod is still not logging in this file
",<kubernetes><kubectl><glusterfs><kube-controller-manager>,65055184,1,"control plane components use klog library for logging which, for the moment, is rather badly documented.
actually --log-dir and --log-file are mutually exclusive.
## it should be either --log-dir
--log-dir=/var/log/kube
...
volumemounts:
- mountpath: /var/log/kube
  name: log
...
volumes:
- hostpath:
    path: /var/log/kube
    type: directoryorcreate
  name: log

## or --log-file
--log-file=/var/log/kube-controller-manager.log
...
volumemounts:
- mountpath: /var/log/kube-controller-manager.log
  name: log
...
volumes:
- hostpath:
    path: /var/log/kube-controller-manager.log
    type: fileorcreate
  name: log

with --log-dir a component will write each log level a into separate file inside a given dir.
so you'll have a set of files with names like kube-controller-manager.info.log
with --log-file you'll have a single file as expected.
don't forget to specify fileorcreate in your volume definition, otherwise a directory will created by default.
"
68621599,kubernetes: multiple domain setup and loadbalancer/ingress strategy,"how is it possible to use more than one domain in the same cluster?
at the moment i've running one cluster with one domain pointing to a hardware loadbalancer and traefik as an ingress-controller.
now i wanna add a second domain pointing to different workloads/services.
do i need

a second ingress-controller with a second loadbalancer (and pointing the second domain to that second lb)?
to point the second domain to the same first loadbalancer to use only one ìngress-controller`?

i am asking, because i have troubles when pointing the second domain to the second loadbalancer and pointing that one to the existing ingress-controller (nothing happens)
but when i point my second domain, to the first loadbalancer, it seems working as expected.
(my guess is: solution &quot;2&quot;)?
(i wanna keep one ingress-controller, thought i need two loadbalanacers)
does this have to do with the occupied ports 443 and 80?
thank you
",<kubernetes><kubernetes-ingress><traefik-ingress>,68672906,2,"
a second ingress-controller with a second loadbalancer (and pointing
the second domain to that second lb)?

no there is no requirement for a second loadbalancer. you can single lb backed by the ingress controller and map the multiple domains.
to point the second domain to the same first loadbalancer to use only one ìngress-controller`?
yes, you can use the single ingress controller, inside dns for both domains you have to add the a value of cname value.
from dns all traffic will get forwarded to lb, which is backed by the ingress controller.
if you are using the nginx ingress controller different domain or hosts goes like in config
spec:
  rules:
  - host: foobar.com
    http:
      paths:
      - backend:
          servicename: foobar
          serviceport: 80
  - host: api.foobar.com
    http:
      paths:
      - backend:
          servicename: foobar
          serviceport: 80

for treafik also it will be the same, or else you can create a two separate ingress instead of one.
ingress-1.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: kubernetes-dashboard
spec:
  rules:
  - host: dashboard.test.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: frontend
          serviceport: 80

ingress-2.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: kubernetes-ingress-two
spec:
  rules:
  - host: dashboard.domain.com
    http:
      paths:
      - path: /api
        backend:
          servicename: backend
          serviceport: 80

path-based further routing you can implement on ingress.
so you over all arch will be something like
all traffic comes from a single point, treafik controller which is exposed as loadbalancer service.
all your other microservices will be running as the clusterip, as we don't want to direct access from the internet.
read more at : https://medium.com/kubernetes-tutorials/deploying-traefik-as-ingress-controller-for-your-kubernetes-cluster-b03a0672ae0c
"
55393772,kubectl get pods shows crashloopbackoff,"im trying to create a pod using my local docker image as follow.

1.first i run this command in terminal 

eval $(minikube docker-env)


2.i created a docker image as follow

sudo docker image build -t my-first-image:3.0.0 .


3.i created the pod.yml as shown below and i run this command

kubectl -f create pod.yml.


4.then i tried to run this command

kubectl get pods


but it shows following error 


name                                  ready   status             restarts   age
multiplication-6b6d99554-d62kk        0/1     crashloopbackoff   9          22m
multiplication2019-5b4555bcf4-nsgkm   0/1     crashloopbackoff   8          17m
my-first-pod                          0/1     crashloopbackoff   4          2m51


5.i get the pods logs

kubectl describe pod my-first-pod 



events:
  type     reason     age                    from               message
  ----     ------     ----                   ----               -------
  normal   scheduled  6m22s                  default-scheduler  successfully assigned default/my-first-pod to minikube
  normal   pulled     5m20s (x4 over 6m17s)  kubelet, minikube  successfully pulled image ""docker77nira/myfirstimage:latest""
  normal   created    5m20s (x4 over 6m17s)  kubelet, minikube  created container
  normal   started    5m20s (x4 over 6m17s)  kubelet, minikube  started container
  normal   pulling    4m39s (x5 over 6m21s)  kubelet, minikube  pulling image ""docker77nira/myfirstimage:latest""
  warning  backoff    71s (x26 over 6m12s)   kubelet, minikube  back-off restarting failed container




dockerfile

    from node:carbon
    workdir /app
    copy . .
    cmd [ ""node"", ""index.js"" ]



pods.yml

    kind: pod
    apiversion: v1
    metadata:
     name: my-first-pod
    spec:
     containers:
     - name: my-first-container
       image: my-first-image:3.0.0



index.js

    var http = require('http');
    var server = http.createserver(function(request, response) {
     response.statuscode = 200;
     response.setheader('content-type', 'text/plain');
     response.end('welcome to the golden guide to kubernetes
    application development!');
    });
    server.listen(3000, function() {
     console.log('server running on port 3000');
    });


",<kubernetes><kubectl><minikube>,55400907,1,"i succeeded in running your image by performing these steps:

docker build -t foo .

then check if the container is working docker run -it foo 

/app/index.js:5
response.end('welcome to the golden guide to kubernetes
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

syntaxerror: invalid or unexpected token
    at createscript (vm.js:80:10)
    at object.runinthiscontext (vm.js:139:10)
    at module._compile (module.js:617:28)
    at object.module._extensions..js (module.js:664:10)
    at module.load (module.js:566:32)
    at trymoduleload (module.js:506:12)
    at function.module._load (module.js:498:3)
    at function.module.runmain (module.js:694:10)
    at startup (bootstrap_node.js:204:16)
    at bootstrap_node.js:625:3


not sure if this was the outcome you wanted to see, the container itself runs. but in kubernetes it gets into errimagepull 

then after editing your pod.yaml inspired by @harsh manvar it works fine with this. so the problem with exiting after completed command was just part of the problem. 

apiversion: v1
kind: pod
metadata:
  name: hello-pod
spec:
  restartpolicy: never
  containers:
  - name: hello
    image: ""foo""
    imagepullpolicy: never
    command: [ ""sleep"" ]
    args: [ ""infinity"" ]


this is minikube so you can reuse the images, but if you would have more nodes this might not work at all. you can find a good explanation about using local docker images with kubernetes here. 
"
54137546,how to find out if a k8s job failed or succeeded using kubectl?,"i have a kubernetes job that runs for some time, and i need to check if it failed or was successful. 

i am checking this periodically: 

kubectl describe job/myjob | grep ""1 succeeded""


this works but i am concerned that a change in kubernetes can break this; say, the message is changed to ""1 completed with success"" (stupid text but you know what i mean) and now my grep will not find what it is looking for. 

any suggestions? this is being done in a bash script. 
",<kubernetes><kubectl><kubernetes-jobs>,54137885,8,"you can get this information from the job using jsonpath filtering to select the .status.succeeded field of the job you are interested in. it will only return the value you are interested in.

from kubectl explain job.status.succeeded:


  the number of pods which reached phase succeeded.


this command will get you that field for the particular job specified:

kubectl get job &lt;jobname&gt; -o jsonpath={.status.succeeded}

"
67148209,kubernetess multiple deployments using one code base but different configuration (environement variables),"i have a project where we are consuming data from kafka and publishing to mongo. in fact the code base does only one task, may be mongo to kafka migration, kafka to mongo migration or something else.
we have to consume from different kafka topics and publish to different mongo collections. now these are parallel streams of work.
current design is to have one codebase which can consume from any topic and publish to any mongo collection which is configurable using environment variables. so we created one kubernetes pod and have multiple containers inside it. each container has different environment variables.
my questions:

is it wise to use multiple containers in one pod. easy to distinguish, but as they are tightly coupled , i am guessing high chance of failure and not actually proper microservice design.
should i create multiple deployments for each of these pipelines ? would be very difficult to maintain as each will have different deployment configs.
is there any better way to address this ?

sample of step 1:
apiversion: apps/v1
kind: deployment
metadata:
  annotations: {}
  name: test-raw-mongodb-sink-apps
  namespace: test-apps
spec:
  selector:
    matchlabels:
      app: test-raw-mongodb-sink-apps
  template:
    metadata:
      labels:
        app: test-raw-mongodb-sink-apps
    spec:
      containers:
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-alchemy
        - name: input_topic
          value: test.raw.ptv.alchemy
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_password
          value: test123
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8081&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/dpl/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-alchemy
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-bloomberg
        - name: input_topic
          value: test.raw.pretrade.bloomberg
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8082&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-bloomberg
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-calypso
        - name: input_topic
          value: test.raw.ptv.calypso
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8083&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-calypso
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-dtres
        - name: input_topic
          value: test.raw.ptv.dtres
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8084&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-dtres
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-feds
        - name: input_topic
          value: test.raw.ptv.feds
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8085&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-feds
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-hoops
        - name: input_topic
          value: test.raw.ptv.hoops
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8086&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-hoops
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxcore
        - name: input_topic
          value: test.raw.ptv.murex_core
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8087&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxcore
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxeqd
        - name: input_topic
          value: test.raw.ptv.murex_eqd_sa
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8088&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxeqd
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxgts
        - name: input_topic
          value: test.raw.ptv.murex_gts_sa
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8089&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxgts
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxmr
        - name: input_topic
          value: test.raw.ptv.murex_mr
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8090&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxmr
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxgtscf
        - name: input_topic
          value: test.raw.cashflow.murex_gts_sa
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8091&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxgtscf
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxcoll
        - name: input_topic
          value: test.raw.collateral.mxcoll
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8092&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxcoll
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-mxcoll-link
        - name: input_topic
          value: test.raw.collateral.mxcoll_link
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8093&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-mxcoll-link
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-ost
        - name: input_topic
          value: test.raw.ptv.ost
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8094&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-ost
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      - env:
        - name: events_topic
          value: test.ops.proc-events
        - name: group_id
          value: test-mongodb-sink-posmon
        - name: input_topic
          value: test.raw.ptp.posmon
        - name: mongodb_auth_db
          value: admin
        - name: mongodb_host0
          value: test-mongodb-0.test-mongodb-headless.test-infra
        - name: mongodb_host1
          value: test-mongodb-1.test-mongodb-headless.test-infra
        - name: mongodb_password
          value: test123
        - name: mongodb_port
          value: &quot;27017&quot;
        - name: mongodb_username
          value: root
        - name: server_port
          value: &quot;8095&quot;
        - name: kafka_brokers
          value: kafka-cluster-kafka-bootstrap.kafka:9093
        - name: truststore_password
          valuefrom:
            secretkeyref:
              key: ca.password
              name: kafka-ca-cert
        - name: keystore_password
          valuefrom:
            secretkeyref:
              key: user.password
              name: kafka
        image: tools.testcompany.co.za:8093/local/tt--mongodb-map:0.0.7.0-snapshot
        name: test-mongodb-sink-posmon
        securitycontext:
          allowprivilegeescalation: true
          privileged: true
        volumemounts:
        - mountpath: /app/resources
          name: properties
        - mountpath: /stores
          name: stores
          readonly: true
      

thanks
",<kubernetes><kubernetes-pod><kubernetes-deployment>,67148453,2,"a templating tool like helm will let you fill in the environment-variable values from deploy-time settings.  in helm this would look like:
env:
  - name: events_topic
    value: {{ .values.eventstopic }}
  - name: group_id
    value: {{ .values.groupid }}
  - name: input_topic
    value: {{ .values.inputtopic }}

you could then deploy this multiple times with different sets of topics:
helm install alchemy . \
  --set eventstopic=test.ops.proc-events \
  --set groupid=test-mongodb-sink-alchemy \
  --set inputtopic=test.raw.ptv.alchemy
helm install bloomberg . \
  --set eventstopic=test.ops.proc-events \
  --set groupid=test-mongodb-sink-bloomberg \
  --set inputtopic=test.raw.pretrade.bloomberg

you could write the helm chart to be configured with a list of topic sets, too, and only deploy the set once:
{{- $top := . -}}{{-/* because &quot;range&quot; overwrites &quot;.&quot; */-}}
{{- $topic := range $topics -}}
---
apiversion: v1
kind: deployment
metadata:
  name: {{ $topic.name }}
spec:
  ...
    env:
      - name: event_topic
        value: {{ $top.values.eventtopic }}{{/* common to all deployments */}}
      - name: group_id
        value: test-mongodb-sink-{{ $topic.name }}
      - name: input_topic
        value: {{ $topic.inputtopic }}

write configuration like:
eventtopic: test.ops.proc-events
topics:
  - name: alchemy
    inputtopic: test.raw.ptv.alchemy
  - name: bloomberg
    inputtopic: test.raw.pretrade.bloomberg

and deploy like:
helm install connector . -f topic-listing.yaml

in any case, you will want only one container per pod.  there are a couple of reasons for this.  if the list of topics ever changes, this lets you create or delete deployments without interfering with the other topics; if everything was in a single pod, you'd have to stop and restart everything together, and it can take kafka a minute or two to figure out what happens.  in a kafka context, you can also run as many consumers as there are partitions on a topic, but not really more; if you have a very busy topic you can easily set that deployment's replicas: to have multiple consumers for multiple partitions, but if everything together is in one pod, your only choice is to scale everything together.
"
66833650,using kubectl to wait until a pvc is bound,"i wanna use kubectl wait command to wait until a pvc is bound.
i tried kubectl wait --for=condition=bound pvc/my-pvc-claim --timeout=2s with a pvc which is already bound, but it doesn't seem to work. this is the output error: timed out waiting for the condition on persistentvolumeclaims/my-pvc-claim.
i read kubectl wait documentation, but still can't understand which condition i should use. how can i accomplish that? is there a more complete documentation explaining how to do that?
",<kubernetes><kubectl>,66835636,6,"you can use the following command:
while [[ $(kubectl get pvc myclaim -o 'jsonpath={..status.phase}') != &quot;bound&quot; ]]; do echo &quot;waiting for pvc status&quot; &amp;&amp; sleep 1; done

"
77345948,allow scheduling multiple pod when we have anti affinity enabled,"i have a deployment where i have added affinity as below -
affinity:
  nodeaffinity:
    requiredduringschedulingignoredduringexecution:
      nodeselectorterms:
      - matchexpressions:
        - key: kubernetes.io/hostname
          operator: in
          values:
          - example.com
  podantiaffinity:
    requiredduringschedulingignoredduringexecution:
    - labelselector:
        matchexpressions:
        - key: component
          operator: in
          values:
          - myapp
      topologykey: &quot;kubernetes.io/hostname&quot;

now, whenever i update configurations in this pod, upgraded pod is not being scheduled due to error -
warning failedscheduling 12s default-scheduler 0/1 nodes are available: 1 node(s) didn't match pod anti-affinity rules. preemption: 0/1 nodes are available: 1 no preemption victims found for incoming pod

please provide suggestions, how can i fix this issue.
tried preferredduringschedulingignoredduring execution method, but no luck
i have 3 nodes in my cluster.
",<docker><kubernetes><kubernetes-helm><kubernetes-pvc>,77431569,2,"given that you have 3 replicas and 3 nodes in your cluster, it seems like the pods are evenly distributed across the nodes. however, when you update a configuration, a new pod is created, and the kubernetes scheduler tries to place it on a node where no other pod with the component label myapp is running. if all nodes already have a pod with this label, the new pod cannot be scheduled, leading to the error message you're seeing.
to address this issue, please consider the following options;

use preferredduringschedulingignoredduringexecution for pod anti-affinity to specify that the anti-affinity rule is a &quot;soft&quot; requirement, rather than a &quot;hard&quot; requirement.

example;
affinity:
 podantiaffinity:
 preferredduringschedulingignoredduringexecution:
 - weight: 100
   podaffinityterm:
     labelselector:
       matchexpressions:
       - key: component
         operator: in
         values:
         - myapp
     topologykey: &quot;kubernetes.io/hostname&quot;


adjust the maxunavailable parameter in your deployment strategy.

example;
strategy:
 type: rollingupdate
 rollingupdate:
 maxunavailable: 1

in the 2nd example, the maxunavailable value is set to 1, which means that kubernetes can evict one pod to make room for a new one. this should allow the new pod to be scheduled, even if it means violating the anti-affinity rule.
if the 1 &amp; 2 solutions don't work, i suggest if not require to scale down your application to have fewer than 3 pods running at the same time (e.i, kubectl scale deployment myapp --replicas=2). this would allow the new pod to be scheduled on one of the nodes that currently has a pod running.
"
68272422,using nginx ingress with https not on 443,"how do you use an nginx ingress controller to route to an app using ssl that is not running on 443?    i found this post which seems to say it's not possible.
deployment:
apiversion: apps/v1
kind: deployment
metadata:
  name: test-deployment
spec:
  selector:
    matchlabels:
      app: foo
  replicas: 2 
  template:
    metadata:
      labels:
        app: foo
    spec:
      containers:
      - name: foo
        image: bar
        ports:
        - containerport: 3000

trying:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: foo-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: foo.com
  - http:
      paths:
      - path: /
        backend:
          servicename: foo
          serviceport: 3000

",<kubernetes><amazon-eks>,68273876,2,"nginx ingress controller is a layer 7 technology, it does host based (layer 7) routing and not on ports (layer 4). so, your clients are expected to connect using standard port 80/443.
so, your clients will simply connect to the https://example.com (port 443) and kubernetes ingress controller will redirect it to your https service on port 3000.
however, since your service is ssl enabled, you will have to use the proper annotations
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: foo-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;
spec:
rules:
- host: example.com
  http:
    paths:
    - backend:
        servicename: foo
        serviceport: 3000

"
55016997,what's the relationship between deployment and configmap?,"i'm curious about how configmap and deployment works in kubernetes. 

i wanted to use the values in configmap as arguments to my deployment pods. i've tried this with different images and found different behaviours when passing configmap value as command arguments between containers that use sh as entry point and other commands as entry point.

here is an example configuration to better illustrate my case:

configmap.yaml

apiversion: v1
kind: configmap
metadata:
  name: app-envs
data:
  key: ""value""
  bucket_name: ""gs://bucket-name/""
  output_path: ""/data""


deployment.yaml

apiversion: extensions/v1beta1
kind: deployment
spec:
  template:
    containers:
    - name: firstcontainer
      image: busybox
      command: [""sh""]
      args: 
      - c
      - |
        echo $key
        echo ${bucket_name}
        echo $(output_path)
      envfrom:
      - configmapref:
          name: app-envs
    - name: secondcontainer
      image: someimage
      args: [ ""cmd"", ""${bucket_name}"", ""${output_data}"", ""${key}"" ] 
      envfrom:
      - configmapref:
          name: app-envs
    - name: thirdcontainer
      image: someimage
      args: [ ""cmd"", ""$(bucket_name)"", ""$(output_data)"", ""$(key)"" ] 
      envfrom:
      - configmapref:
          name: app-envs


someimage is a docker image, which has certain bash script as its entry point that prints the environment values.



the firstcontainer and thirdcontainer are able to print all the configmap values correctly, meaning, all value, gs://bucket-name/ and /data are received as input arguments.

however, the secondcontainer is unable to print these values correctly. i tried to echo the received arguments, and it turned out that it receives:


  ${bucket_name}, ${output_data}, and ${key} literally as input
  arguments instead of the actual values from configmaps.


so after observing the above behaviours, here are my questions:


what's the relationship between deployment and configmap? is there
some kind of order which specify how resources are created in a k8s pod/deployment (e.g., whether configmap is loaded first, then the volumemounts, and then the container or some kind of orderings)?
what's the difference between ${} and $()? why does the configmap values are received as literal strings when using ${} to a container that has different entry point than bash or sh?


thank you. your help would be appreciated.
",<bash><shell><docker><kubernetes><google-kubernetes-engine>,55021276,3,"kubernetes only directly understands environment variable references in parentheses $(var); see for example the note in define a command and arguments for a container.

args: [ ""cmd"", ""$(bucket_name)"", ""$(output_data)"", ""$(key)"" ] 


kubernetes itself knows what the environment variables are and does the substitution, so the container is launched as cmd gs://bucket-name/ /data key.

command: [""sh""]
args: 
- c
- |
  echo $key
  echo ${bucket_name}
  echo $(output_path)


kubernetes expands $(output_path) but doesn't understand any other form of braces, so the other strings get sent on as-is.  since you're explicitly running this through a shell, though, both $key and ${bucket_name} are standard shell variable expansions, so the shell expands these values.

args: [ ""cmd"", ""${bucket_name}"", ""${output_data}"", ""${key}"" ] 


kubernetes doesn't expand things in curly braces, and there's no shell or anything else to expand these variables, so the variable strings (and not their contents) get passed along as-is.
"
55780971,kubernetes: mysql pod failed to open log file /var/log/pods/,"i am following the official tutorial here to run a stateful mysql pod on the kubernetes cluster which is already running on gcp. i have used the exact same commands to first create the persistent volume and persistent volume chain and then deployed the contents of the mysql yaml file as per the documentation. the mysql pod is not running and is in runcontainererror state. checking the logs of this mysql pod shows:

failed to open log file ""/var/log/pods/045cea87-6408-11e9-84d3-42010aa001c3/mysql/2.log"": open /var/log/pods/045cea87-6408-11e9-84d3-42010aa001c3/mysql/2.log: no such file or directory


update: as asked by @matthew in the comments, the result of kubectl describe pods -l app=mysql is provided here:

name:               mysql-fb75876c6-tk6ml
namespace:          default
priority:           0
priorityclassname:  &lt;none&gt;
node:               gke-mycluster-default-pool-b1c1d316-xv4v/10.160.0.13
start time:         tue, 23 apr 2019 13:36:04 +0530
labels:             app=mysql
                    pod-template-hash=963143272
annotations:        kubernetes.io/limit-ranger=limitranger plugin set: cpu request for container mysql
status:             running
ip:                 10.52.0.7
controlled by:      replicaset/mysql-fb75876c6
containers:
  mysql:
    container id:   docker://451ec5bf67f60269493b894004120b627d9a05f38e37cb50e9f283e58dbe6e56
    image:          mysql:5.6
    image id:       docker-pullable://mysql@sha256:5ab881bc5abe2ac734d9fb53d76d984cc04031159152ab42edcabbd377cc0859
    port:           3306/tcp
    host port:      0/tcp
    state:          waiting
      reason:       runcontainererror
    last state:     terminated
      reason:       containercannotrun
      message:      error while creating mount source path '/mnt/data': mkdir /mnt/data: read-only file system
      exit code:    128
      started:      tue, 23 apr 2019 13:36:18 +0530
      finished:     tue, 23 apr 2019 13:36:18 +0530
    ready:          false
    restart count:  1
    requests:
      cpu:  100m
    environment:
      mysql_root_password:  password
    mounts:
      /var/lib/mysql from mysql-persistent-storage (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jpkzg (ro)
conditions:
  type              status
  initialized       true
  ready             false
  containersready   false
  podscheduled      true
volumes:
  mysql-persistent-storage:
    type:       persistentvolumeclaim (a reference to a persistentvolumeclaim in the same namespace)
    claimname:  mysql-pv-claim
    readonly:   false
  default-token-jpkzg:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-jpkzg
    optional:    false
qos class:       burstable
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason     age               from                                               message
  ----     ------     ----              ----                                               -------
  normal   scheduled  32s               default-scheduler                                  successfully assigned default/mysql-fb75876c6-tk6ml to gke-mycluster-default-pool-b1c1d316-xv4v
  normal   pulling    31s               kubelet, gke-mycluster-default-pool-b1c1d316-xv4v  pulling image ""mysql:5.6""
  normal   pulled     22s               kubelet, gke-mycluster-default-pool-b1c1d316-xv4v  successfully pulled image ""mysql:5.6""
  normal   pulled     4s (x2 over 18s)  kubelet, gke-mycluster-default-pool-b1c1d316-xv4v  container image ""mysql:5.6"" already present on machine
  normal   created    3s (x3 over 18s)  kubelet, gke-mycluster-default-pool-b1c1d316-xv4v  created container
  warning  failed     3s (x3 over 18s)  kubelet, gke-mycluster-default-pool-b1c1d316-xv4v  error: failed to start container ""mysql"": error response from daemon: error while creating mount source path '/mnt/data': mkdir /mnt/data: read-only file system


as asked by @hanx:
result of kubectl describe pv mysql-pv-volume

name:            mysql-pv-volume
labels:          type=local
annotations:     kubectl.kubernetes.io/last-applied-configuration={""apiversion"":""v1"",""kind"":""persistentvolume"",""metadata"":{""annotations"":{},""labels"":{""type"":""local""},""name"":""mysql-pv-volume"",""namespace"":""""},""spec"":{""a...
                 pv.kubernetes.io/bound-by-controller=yes
finalizers:      [kubernetes.io/pv-protection]
storageclass:    manual
status:          bound
claim:           default/mysql-pv-claim
reclaim policy:  retain
access modes:    rwo
capacity:        1gi
node affinity:   &lt;none&gt;
message:
source:
    type:          hostpath (bare host directory volume)
    path:          /mnt/data
    hostpathtype:
events:            &lt;none&gt;


result of kubectl describe pvc mysql-pv-claim

name:          mysql-pv-claim
namespace:     default
storageclass:  manual
status:        bound
volume:        mysql-pv-volume
labels:        &lt;none&gt;
annotations:   kubectl.kubernetes.io/last-applied-configuration={""apiversion"":""v1"",""kind"":""persistentvolumeclaim"",""metadata"":{""annotations"":{},""name"":""mysql-pv-claim"",""namespace"":""default""},""spec"":{""accessmodes"":[""r...
               pv.kubernetes.io/bind-completed=yes
               pv.kubernetes.io/bound-by-controller=yes
finalizers:    [kubernetes.io/pvc-protection]
capacity:      1gi
access modes:  rwo
events:        &lt;none&gt;


mysql-pv.yaml

kind: persistentvolume
apiversion: v1
metadata:
  name: mysql-pv-volume
  labels:
    type: local
spec:
  storageclassname: manual
  capacity:
    storage: 20gi
  accessmodes:
    - readwriteonce
  hostpath:
    path: ""/mnt/data""
---
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: mysql-pv-claim
spec:
  storageclassname: manual
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 20gi


mysql.yaml

apiversion: v1
kind: service
metadata:
  name: mysql
spec:
  ports:
  - port: 3306
  selector:
    app: mysql
  clusterip: none
---
apiversion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: deployment
metadata:
  name: mysql
spec:
  selector:
    matchlabels:
      app: mysql
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
          # use secret in real usage
        - name: mysql_root_password
          value: password
        ports:
        - containerport: 3306
          name: mysql
        volumemounts:
        - name: mysql-persistent-storage
          mountpath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentvolumeclaim:
          claimname: mysql-pv-claim

",<mysql><docker><kubernetes><google-kubernetes-engine>,55829064,1,"this is because you do not need to create those volumes and storageclasses on gke. those yaml files are completely  valid if you would want to use minikube or kubeadm, but not in case of gke which can take care of some of the manual steps on its own. 

you can use this official guide to run mysql on gke, or just use files edited by me and tested on gke.

kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: mysql-volumeclaim
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 20gi


and mysql deployment: 

apiversion: v1
kind: service
metadata:
  name: mysql
spec:
  ports:
  - port: 3306
  selector:
    app: mysql
  clusterip: none
---
apiversion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: deployment
metadata:
  name: mysql
spec:
  selector:
    matchlabels:
      app: mysql
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
          # use secret in real usage
        - name: mysql_root_password
          value: password
        ports:
        - containerport: 3306
          name: mysql
        volumemounts:
        - name: mysql-persistent-storage
          mountpath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentvolumeclaim:
          claimname: mysql-volumeclaim


make sure you read the linked guide as it explains the gke specific topics there. 
"
48535231,failed to create clusterrole for kube-lego,"i did this example https://github.com/jetstack/kube-lego/tree/master/examples/gce , then failed to create clusterrole kube-lego.

the error is:

error from server (forbidden): error when creating ""k8s/kube-lego/hoge.yaml"": clusterroles.rbac.authorization.k8s.io ""kube-lego"" is forbidden: attempt to grant extra privileges: [policyrule{resources:[""pods""], apigroups:[""""], verbs:[""get""]} policyrule{resources:[""pods""], apigroups:[""""], verbs:[""list""]} policyrule{resources:[""services""], apigroups:[""""], verbs:[""create""]} policyrule{resources:[""services""], apigroups:[""""], verbs:[""get""]} policyrule{resources:[""services""], apigroups:[""""], verbs:[""delete""]} policyrule{resources:[""services""], apigroups:[""""], verbs:[""update""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""create""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""get""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""delete""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""update""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""get""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""update""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""create""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""list""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""patch""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""delete""]} policyrule{resources:[""ingresses""], apigroups:[""extensions""], verbs:[""watch""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""get""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""create""]} policyrule{resources:[""endpoints""], apigroups:[""""], verbs:[""update""]} policyrule{resources:[""secrets""], apigroups:[""""], verbs:[""get""]} policyrule{resources:[""secrets""], apigroups:[""""], verbs:[""create""]} policyrule{resources:[""secrets""], apigroups:[""""], verbs:[""update""]}] user=&amp;{myemail@gmail.com  [system:authenticated] map[]} ownerrules=[policyrule{resources:[""selfsubjectaccessreviews"" ""selfsubjectrulesreviews""], apigroups:[""authorization.k8s.io""], verbs:[""create""]} policyrule{nonresourceurls:[""/api"" ""/api/*"" ""/apis"" ""/apis/*"" ""/healthz"" ""/swagger-2.0.0.pb-v1"" ""/swagger.json"" ""/swaggerapi"" ""/swaggerapi/*"" ""/version""], verbs:[""get""]}] ruleresolutionerrors=[]


i tried on 1.8.6-gke.0, 1.8.7-gke.0 and 1.9.2-gke.0.

thanks.
",<kubernetes><google-kubernetes-engine>,48535335,9,"as commented in kube-lego issue 225:

turns out the error i was receiving in an known issue with gke 1.6. i resolved by following this article:
get current google identity

$ gcloud info | grep account
account: [myname@example.org]


grant cluster-admin to your current identity

$ kubectl create clusterrolebinding myname-cluster-admin-binding --clusterrole=cluster-admin --user=myname@example.org
clusterrolebinding &quot;myname-cluster-admin-binding&quot; created

for the actual rbac to define, see issue 99
it refers to adds official rbac rules, which applies the right settings:
# rbac objects
kubectl apply -f lego/service-account.yaml
kubectl apply -f lego/cluster-role.yaml
kubectl apply -f lego/cluster-role-binding.yaml

"
45022651,logging using stackdriver api on kubernetes / google container engine (gke),"i have a go application that leverages google cloud logging api.

the relevant code is the same as this sample from their documentation: https://github.com/googlecloudplatform/golang-samples/blob/master/logging/logging_quickstart/main.go

after checking it works with minikube (my payload appears in the global category of my logs viewer), i deploy the app on google container engine (gke). 

once deployed there, i can no longer see the logs the app sends through the logging api.
the logs written to std appears in the gke container category, but no trace of the entries i send using the api.

my cluster has stackdriver logging api enabled / write only, the default service account is editor (even tried with owner), i also tried with a dedicated service account (using the env google_application_credentials) with log writer or even owner access, i can’t see the logs and no error are reported from the client library.

what could be the cause or where could i start debugging such issue?

thank you,
",<go><google-cloud-platform><kubernetes><google-kubernetes-engine><stackdriver>,45085569,4,"so turns out the log were there but not where i'd expect them.

using the gcloud cli i could see those logs got the resource type gce_instance and therefore appears in the gce vm instance category

to figure this out:

  $ gcloud beta logging logs list
  projects/&lt;project&gt;/logs/&lt;log_name&gt;
  ...


then

$ gcloud beta logging read projects/&lt;project&gt;/logs/&lt;log_name&gt;
---
insertid: ...
jsonpayload:
   ...
logname: ...
receivetimestamp: ...
resource:
  labels:
    instance_id: ...
    project_id: ...
    zone: ...
  type: gce_instance
timestamp: ...


note type being gce_instance
"
64720983,error converting yaml to json: did not find expected key - error in pipeline,"i am getting the below error in my deployment pipeline
error: yaml parse error on cnhsst/templates/deployment.yaml: error converting yaml to json: yaml: line 38: did not find expected key

the yml file corresponding to this error is below:
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ template &quot;fullname&quot; . }}
  namespace: {{ .values.namespace }}
  labels:
    app: {{ template &quot;fullname&quot; . }}
    chart: &quot;{{ .chart.name }}-{{ .chart.version }}&quot;
    release: &quot;{{ .release.name }}&quot;
    heritage: &quot;{{ .release.service }}&quot;
spec:
  replicas: {{ .values.replicas }}
  selector:
    matchlabels:
      app: {{ template &quot;fullname&quot; . }}
      release: &quot;{{ .release.name }}&quot;
  # we dont need a large deployment history limit as helm keeps it's own
  # history
  revisionhistorylimit: 2
  template:
    metadata:
      namespace: {{ .values.namespace }}
      labels:
        app: {{ template &quot;fullname&quot; . }}
        release: &quot;{{ .release.name }}&quot;
      annotations:
        recreatepods: {{ randalphanum 8 | quote }}
    spec:
      containers:
      - name: {{ template &quot;fullname&quot; . }}
        image: {{ template &quot;docker-image&quot; . }}
        imagepullpolicy: always
        ports:
        # the port that our container listens for http requests on
        - containerport: {{ default 8000 .values.portoverride }}
          name: http
        
      {{- if .values.resources }}
        resources:
{{ toyaml .values.resources | indent 10 }}
      {{- end }}
      {{- if and (.values.livenessprobe) (.values.apipod)}}
        livenessprobe:
{{ toyaml .values.livenessprobe | indent 10 }}
      {{- end }}
      {{- if and (.values.readinessprobe) (.values.apipod)}}
        readinessprobe:
{{ toyaml .values.readinessprobe | indent 10 }}
      {{- end }}
      imagepullsecrets:
      - name: regcred
       securitycontext:
        runasnonroot: true
        runasuser: 5000
        runasgroup: 5000 
      affinity:
        podantiaffinity:
          preferredduringschedulingignoredduringexecution:
          - weight: 100
            podaffinityterm:
              labelselector:
                matchexpressions:
                - key: app
                  operator: in
                  values:
                  - {{ template &quot;fullname&quot; . }}
              topologykey: failure-domain.beta.kubernetes.io/zone

i am stuck with this issue for few hours. i have gone through numerous posts, tried online tools trying to figure out syntax errors, but unfortunately no luck. if anyone is able to point out the issue, that would be really great.
",<kubernetes><yaml><kubernetes-helm>,64722469,2,"you can see the mismatched indentation under regcred:
      imagepullsecrets:
      - name: regcred
      # &lt;-- indented &quot;-&quot;
      #vvv not indented
       securitycontext:
        runasnonroot: true

which, as luck would have it, is the 38th line in the output yaml
$ helm template --debug my-chart . 2&gt;&amp;1| sed -e '1,/^apiversion:/d' | sed -ne 38p
       securitycontext:

"
60468776,gke neg ingress always returns 502 bad gateway,"i have a statefulset, service with neg, and ingress set up on google cloud kubernetes engine cluster. 

every workload and network object is ready and healthy. ingress is created and neg status is updated for all the services. vpc-native (alias-ip) and http load balancer options are enabled for the cluster. 

but when i try to access my application using a path specified in my ingress i always get 502 (bad gateway) error.

here is my configuration (names are redacted including image name):

apiversion: v1
kind: service
metadata:
  annotations:
    cloud.google.com/neg: '{""ingress"": true}'
  labels:
    app: myapp
  name: myapp
spec:
  ports:
  - port: 80
    protocol: tcp
    targetport: tcp
  selector:
    app: myapp
---
apiversion: apps/v1
kind: statefulset
metadata:
  labels:
    app: myapp
  name: myapp
spec:
  replicas: 1
  selector:
    matchlabels:
      app: myapp
  servicename: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        livenessprobe:
          httpget:
            path: /
            port: tcp
            scheme: http
          initialdelayseconds: 60
        image: myapp:8bebbaf
        ports:
        - containerport: 1880
          name: tcp
          protocol: tcp
        readinessprobe:
          failurethreshold: 1
          httpget:
            path: /
            port: tcp
            scheme: http
        volumemounts:
        - mountpath: /data
          name: data
      securitycontext:
        fsgroup: 1000
      terminationgraceperiodseconds: 10
  volumeclaimtemplates:
  - metadata:
      labels:
        app: myapp
      name: data
    spec:
      accessmodes:
      - readwriteonce
      resources:
        requests:
          storage: 1gi
---
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: myapp-ingress
spec:
  rules:
  - http:
      paths:
      - path: /workflow
        backend:
          servicename: myapp
          serviceport: 80



what's wrong with it and how can i fix it?
",<kubernetes><google-kubernetes-engine><gke-networking>,60469433,2,"after much digging and tests i finally found what's wrong. also, it seems like gke neg ingress is not very stable (indeed neg is in beta) and does not always conform to kubernetes specs. 

there was an issue with gke ingress related to named ports in targetport field. the fix is implemented and available from 1.16.0-gke.20 cluster version (release), which as of today (february 2020) is available under rapid channel, but i have not tested the fix as i had other issues with an ingress on a version from this channel.

so basically there are 2 options if you experience the same issue:


specify exact port number and not port name in a targetport field in your service. here is a fixed service config file from my example:

apiversion: v1
kind: service
metadata:
  annotations:
    cloud.google.com/neg: '{""ingress"": true}'
  labels:
    app: myapp
  name: myapp
spec:
  ports:
  - port: 80
    protocol: tcp
    # !!!
    # targetport: tcp
    targetport: 1088
  selector:
    app: myapp

upgrade gke cluster to 1.16.0-gke.20+ version (haven't tested it myself).

"
44480405,configuring lets encrypt with traefik using helm,"i'm deploying taefik to my kubernetes cluster using helm.  here's what i have at the moment:

helm upgrade --install load-balancer --wait --set ssl.enabled=true,ssl.enforced=true,acme.enabled=true,acme.email=an@email.com stable/traefik


i'm trying to configure letsencrypt. according to this documentation - you add the domains to the bottom of the .toml file.

looking at the code for the helm chart, there's no provision for such configuration.

is there another way to do this or do i need to fork the chart to create my own variation of the .toml file?
",<kubernetes><lets-encrypt><kubernetes-helm><traefik>,44591882,6,"turns out this is the chicken and the egg problem, described here.

for the helm chart, if acme.enabled is set to true, then treafik will automatically generate and serve certificates for domains configured in kubernetes ingress rules. this is the purpose of the onhostrule = true line in the yaml file (referenced above).

to use traefik with let's encrypt, we have to create an a record in our dns server that points to the ip address of our load balancer. which we can't do until traefik is up and running. however, this configuration needs to exist before traefik starts.

the only solution (at this stage) is to kill the first pod after the a record configuration has propagated.
"
58607603,binary authorization - deployment failed - denied by attestor. attestor cannot attest to an image in gke,"i was trying to showcase binary authorization to my client as poc. during the deployment, it is failing with the following error message:


  pods ""hello-app-6589454ddd-wlkbg"" is forbidden: image policy webhook backend denied one or more images: denied by cluster admission rule for us-central1.staging-cluster. denied by attestor. image gcr.io//hello-app:e1479a4 denied by projects//attestors/vulnz-attestor: attestor cannot attest to an image deployed by tag


i have adhered all steps mentioned in the site.

i have verified the image repeatedly for few occurances, for example using below command to force fully make the attestation:

gcloud alpha container binauthz attestations sign-and-create   --project ""projectxyz""  --artifact-url ""gcr.io/projectxyz/hello-app@sha256:82f1887cf5e1ff80ee67f4a820703130b7d533f43fe4b7a2b6b32ec430ddd699""   --attestor ""vulnz-attestor""   --attestor-project ""projectxyz""   --keyversion ""1""   --keyversion-key ""vulnz-signer""   --keyversion-location ""us-central1""   --keyversion-keyring ""binauthz""   --keyversion-project ""projectxyz""


it throws error as:


  error: (gcloud.alpha.container.binauthz.attestations.sign-and-create) resource in project [project xyz] is the subject of a conflict: occurrence id ""c5f03cc3-3829-44cc-ae38-2b2b3967ba61"" already exists in project ""projectxyz""


so when i verify, i found the attestion present:

gcloud beta container binauthz attestations list       --artifact-url ""gcr.io/projectxyz/hello-app@sha256:82f1887cf5e1ff80ee67f4a820703130b7d533f43fe4b7a2b6b32ec430ddd699""       --attestor ""vulnz-attestor""       --attestor-project ""projectxyz""       --format json  | jq '.[0].kind' \
&gt;       | grep 'attestation'
""attestation""


here are the screen shots:







any feedback please?

thanks in advance.
",<security><kubernetes><google-kubernetes-engine><google-cloud-kms>,58608207,4,"thank you for trying binary authorization. i just updated the binary authorization solution, which you might find helpful.

a few things i noticed along the way:


  ... denied by projects//attestors/vulnz-attestor:


there should be a project id in between projects and attestors, like:

projects/my-project/attestors/vulnz-attestor


similarly, your gcr.io links should include that same project id, for example:


  gcr.io//hello-app:e1479a4


should be

gcr.io/my-project/hello-app:e1479a4


if you followed a tutorial, it likely asked you to set a variable like $project_id, but you may have accidentally unset it or ran the command in a different terminal session.
"
67720625,kubernetes liveness probe httpget schema not working correctly,"i am deploying some web app on kubernetes and i want to set liveness probe for this application.
when i configure my deployment with liveness probe, kubelet start health check. i was defined httpget with scheme &quot;http&quot; parameter but kubelet using https schema randomly.
this is my liveness probe configuration:
livenessprobe:
  failurethreshold: 4
  httpget:
    path: /
    port: 80
    scheme: http
  initialdelayseconds: 40
  periodseconds: 5
  successthreshold: 1
  timeoutseconds: 2

this is result from kubelet:
kubectl describe pod greenlight-7877dc58b7-6s78l
output:

warning  unhealthy  31s (x4 over 46s)  kubelet            liveness
probe failed: get &quot;https://10.244.4.182/&quot;: dial tcp 10.244.4.182:443:
connect: connection refused

kubernetes version: v1.19.9
thanx for help!
",<kubernetes><deployment><kubernetes-health-check><kubernetes-deployment><livenessprobe>,67735055,1,"since you are explicitly stating livenessprobe to use http, it's probably your application that redirects traffic to https. make sure that your application returns a 200 ok on basepath /, and not a redirection (any of 3xx codes).
you can either fix that, or use tcp probe
apiversion: v1
kind: pod
metadata:
  name: goproxy
  labels:
    app: goproxy
spec:
  containers:
  - name: goproxy
    image: k8s.gcr.io/goproxy:0.1
    ports:
    - containerport: 8080
    readinessprobe:
      tcpsocket:
        port: 8080
      initialdelayseconds: 5
      periodseconds: 10
    livenessprobe:
      tcpsocket:
        port: 8080
      initialdelayseconds: 15
      periodseconds: 20

"
66209477,kubernetes : refering to containerports from services with their name,"hi the documentation  says about the name field in containers.ports :

name  if specified, this must be an iana_svc_name and unique within the pod. each named port in a pod must have a unique name. name for the port that can be referred to by services.

i tried to use it in my service as follows but i have an error from the parser :
kind: pod
apiversion: v1
metadata:
  name: banana-app
  labels:
    app: banana
spec:
  containers:
    - name: banana-app
      image: hashicorp/http-echo
      args:
        - &quot;-text=banana&quot;
      ports:
      - containerport: 5678
        name: bananaport
  terminationgraceperiodseconds: 0
---

kind: service
apiversion: v1
metadata:
  name: banana-service
spec:
  selector:
    app: banana
  ports:
    - port: bananaport

the parser error is :

error: error validating &quot;temp.yml&quot;: error validating data: validationerror(service.spec.ports[0].port): invalid type for io.k8s.api.core.v1.serviceport.port: got &quot;string&quot;, expected &quot;integer&quot;; if you choose to ignore these errors, turn validation off with --validate=false

so i guess i am not using the port name correctly. what is the correct way to use the port name in my service?
thanks in advance,
abdelghani
",<kubernetes><kubernetes-service>,66209736,4,"the port field represents the port at which the service object listens to and the targetport represents the port at which the container is listening.
try this:
kind: service
apiversion: v1
metadata:
  name: banana-service
spec:
  selector:
    app: banana
  ports:
  - port: 8080
    targetport: bananaport

"
65482653,nginx ingress controller rewrite-target annotation and rule to add a trailing slash to url,"i'm trying to deploy a static website to a kubernetes cluster which is using the official nginx ingress controller. the folder structure of the website looks somewhat like this:
/
├── about
│   └── index.html
├── casestudy
│   ├── data-and-analytics
│   │   └── index.html
│   └── workflow-automation
│       └── index.html
├── contact
│   └── index.html
├── css
│   ├── font-awesome.min.css
│   ├── fonts
│   │   ├── slick.eot
│   │   ├── slick.svg
│   │   ├── slick.ttf
│   │   └── slick.woff
│   ├── footer.css
│   ├── layout.css
...

my ingress definition looks like this:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: website-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    # nginx.ingress.kubernetes.io/rewrite-target: /$2
    cert-manager.io/cluster-issuer: letsencrypt
spec:
  tls:
    - hosts:
        - website.com
      secretname: website-tls
  rules:
    - host: website.com
      http:
        paths:
          - path: /
            backend:
              servicename: website-svc
              serviceport: 8080

this works fine for the most part, except that if i forget to put a trailing slash at the end of the url like https://website.com/about i get routed into an error page. i understand why this is happening - nginx is looking for a about.html file and is failing to find one. but i don't know how to fix this.
what i'd ideally like to do is that i want to add a trailing / to requests which don't have one. but i also want to not do this when the browser is requesting for a css file.
what redirect annotation and rule should i use for this?
thanks.
",<kubernetes><kubernetes-ingress><nginx-ingress>,65941913,11,"what ultimately worked for this situation is a snippet like this:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: website-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/rewrite-target: /
    # rewrite all urls not ending with a segment containing . or ? with a trailing slash
    # so basically we are rewriting all folder names with a trailing slash.
    nginx.ingress.kubernetes.io/configuration-snippet: |
      rewrite ^([^.?]*[^/])$ $1/ redirect;
spec:
  tls:
    - hosts:
        - website.com
      secretname: website-tls
  rules:
    - host: website.com
      http:
        paths:
          - path: /
            backend:
              servicename: website-svc
              serviceport: 8080

this will let us rewrite all urls ending with a segment containing no . (period - thus avoiding filenames) and ? (question mark - thus avoiding all query strings) with a trailing slash. this works for my case.
"
66007364,how can i summarize all the resource limits and requests in kubernetes with kubectl?,"i started using lens and noticed that it gives you some warnings when the pods inside the nodes have limits higher than the actual capacity.

so i tried to get this information with kubectl but i'm new to jsonpath and i just managed to get the raw info using something like this:
kubectl get pods -o=jsonpath='{.items..resources.limits}' -a

that produces something like this:
{&quot;cpu&quot;:&quot;200m&quot;,&quot;memory&quot;:&quot;1gi&quot;} {&quot;cpu&quot;:&quot;200m&quot;,&quot;memory&quot;:&quot;1gi&quot;} {&quot;cpu&quot;:&quot;200m&quot;,&quot;memory&quot;:&quot;512mi&quot;} {&quot;cpu&quot;:&quot;500m&quot;,&quot;memory&quot;:&quot;250mi&quot;} {&quot;memory&quot;:&quot;170mi&quot;} {&quot;memory&quot;:&quot;170mi&quot;} {&quot;cpu&quot;:&quot;2&quot;,&quot;memory&quot;:&quot;2gi&quot;} {&quot;cpu&quot;:&quot;2&quot;,&quot;memory&quot;:&quot;2gi&quot;} {&quot;cpu&quot;:&quot;2&quot;,&quot;memory&quot;:&quot;2gi&quot;} {&quot;cpu&quot;:&quot;1&quot;,&quot;memory&quot;:&quot;1gi&quot;} {&quot;cpu&quot;:&quot;1&quot;,&quot;memory&quot;:&quot;1gi&quot;} {&quot;cpu&quot;:&quot;2&quot;,&quot;memory&quot;:&quot;2gi&quot;} {&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;128mi&quot;} {&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;128mi&quot;} {&quot;cpu&quot;:&quot;500m&quot;,&quot;memory&quot;:&quot;600mi&quot;} {&quot;cpu&quot;:&quot;1&quot;,&quot;memory&quot;:&quot;1gi&quot;} {&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;25mi&quot;} {&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;25mi&quot;}

so, my questions are, how can i sum all these values? will these values be accurate or am i missing any other query? i've checked using limitrange and the values i got seem to be correct, the results include the limits set by the limitrange configuration.
",<kubernetes><kubectl><jsonpath>,66012252,11,"it is not possible with just kubectl commands. however, you can use the output of kubectl and write a basic shell script to compute the total values.
the following shell script will output total cpu limits(in m units) of all the pods in all namespaces.
res=$(kubectl get pods -o=jsonpath='{.items[*]..resources.limits.cpu}' -a)
let tot=0
for i in $res
do
   if [[ $i =~ &quot;m&quot; ]]; then
      i=$(echo $i | sed 's/[^0-9]*//g')
      tot=$(( tot + i ))
   else
      tot=$(( tot + i*1000 ))
   fi
done
echo $tot

you can extend the above to compute the cpu requests and the memory requests and limits values as well.
"
76490253,external ip was pending while applied service.yaml file,"i had installed kubectl, minikube, vcluster.

i had created a namespace(a-team) and applied a service.yaml file to create a service in the namespace. in service.yaml file i used type: loadbalancer and type: nodeport. but the external ip is not generating


service.yaml file
apiversion: v1
kind: service
metadata:
  name: a-team-cluster
spec:
  selector:
    app: vcluster
    release: a-team
  ports:
    - name: https
      port: 443
      targetport: 8443
      protocol: tcp
  type: loadbalancer


values.yaml file
syncer:
  extraargs:
  - --tls-san=

",<kubernetes><ip><kubectl><minikube><vcluster>,76490299,1,"ensure that you have a loadbalancer implementation running. for minikube this could be minikube tunnel in a separate terminal window.
"
52784640,nginx ingress resource - redirect from to www (ssl doesn't work),"use case

i deployed the nginx ingress controller in my kubernetes cluster using this helm chart:

https://github.com/helm/charts/tree/master/stable/nginx-ingress

i created an ingress resource for my frontend serving webserver and it is supposed to redirect from non-www to the www version. i am using ssl as well.

the problem

when i visit the www version of my website everything is fine and nginx serves the page using my lets encrypt ssl certificate (which exists as secret in the right namespace). however when i visit the non-www version of the website i get the failing ssl certificate page in my browser (net::err_cert_authority_invalid) and one can see the page is served using the kubernetes ingress fake certificate. i assume that's also the reason why the redirect to the www version does not work at all.

this is my ingress resource (actual hostnames have been redacted):

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: ""true""
    nginx.ingress.kubernetes.io/from-to-www-redirect: ""true""
  creationtimestamp: 2018-10-03t19:34:41z
  generation: 3
  labels:
    app: nodejs
    chart: nodejs-1.0.1
    heritage: tiller
    release: example-frontend
  name: example-frontend
  namespace: microservices
  resourceversion: ""5700380""
  selflink: /apis/extensions/v1beta1/namespaces/microservices/ingresses/example-frontend
  uid: 5f6d6500-c743-11e8-8aaf-42010a8401fa
spec:
  rules:
  - host: www.example.io
    http:
      paths:
      - backend:
          servicename: example-frontend
          serviceport: http
        path: /
  tls:
  - hosts:
    - example.io
    - www.example.io
    secretname: example-frontend-tls


the question

why doesn't nginx use the provided certificate on the non-www version as well?
",<nginx><kubernetes><kubernetes-ingress><nginx-ingress>,52784952,5,"looks like you fixed the issue for receiving an invalid certificate by adding an additional rule.

the issue with the redirect looks like it's related to this and it's not fixed as of this writing. however, there is a workaround as described on the same link:

nginx.ingress.kubernetes.io/configuration-snippet: |
  if ($host = 'foo.com' ) {
    rewrite ^ https://www.foo.com$request_uri permanent;
  }

"
52910214,what and where is the default kubeadm config file?,"using kubeadm init initializes the control plane with default configuration options.

is there a way to see what default values/configuration it will use for the control plane, how can i view that configuration file, and where is it stored?
",<kubernetes><kubectl><kubeadm>,52916922,6,"found the command: ( just in case someone needs it)

c02w84xmhtd5:~ iahmad$ kubectl get configmap kubeadm-config -o yaml --namespace=kube-system
apiversion: v1
data:
  masterconfiguration: |
    api:
      advertiseaddress: 192.168.64.4
      bindport: 8443
      controlplaneendpoint: localhost
    apiserverextraargs:
      admission-control: initializers,namespacelifecycle,limitranger,serviceaccount,defaultstorageclass,defaulttolerationseconds,noderestriction,mutatingadmissionwebhook,validatingadmissionwebhook,resourcequota
    auditpolicy:
      logdir: /var/log/kubernetes/audit
      logmaxage: 2
      path: """"
    authorizationmodes:
    - node
    - rbac
    certificatesdir: /var/lib/minikube/certs/
    cloudprovider: """"
    crisocket: /var/run/dockershim.sock
    etcd:
      cafile: """"
      certfile: """"
      datadir: /data/minikube
      endpoints: null
      image: """"
      keyfile: """"
    imagerepository: k8s.gcr.io
    kubeproxy:
      config:
        bindaddress: 0.0.0.0
        clientconnection:
          acceptcontenttypes: """"
          burst: 10
          contenttype: application/vnd.kubernetes.protobuf
          kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
          qps: 5
        clustercidr: """"
        configsyncperiod: 15m0s
        conntrack:
          max: null
          maxpercore: 32768
          min: 131072
          tcpclosewaittimeout: 1h0m0s
          tcpestablishedtimeout: 24h0m0s
        enableprofiling: false
        healthzbindaddress: 0.0.0.0:10256
        hostnameoverride: """"
        iptables:
          masqueradeall: false
          masqueradebit: 14
          minsyncperiod: 0s
          syncperiod: 30s
        ipvs:
          minsyncperiod: 0s
          scheduler: """"
          syncperiod: 30s
        metricsbindaddress: 127.0.0.1:10249
        mode: """"
        nodeportaddresses: null
        oomscoreadj: -999
        portrange: """"
        resourcecontainer: /kube-proxy
        udpidletimeout: 250ms
    kubeletconfiguration: {}
    kubernetesversion: v1.10.0
    networking:
      dnsdomain: cluster.local
      podsubnet: """"
      servicesubnet: 10.96.0.0/12
    notaintmaster: true
    nodename: minikube
    privilegedpods: false
    token: """"
    tokengroups:
    - system:bootstrappers:kubeadm:default-node-token
    tokenttl: 24h0m0s
    tokenusages:
    - signing
    - authentication
    unifiedcontrolplaneimage: """"

"
67732738,helm configmap support for binary files,"i am trying to create a helm chart of kind configmap that will replace the following command from kubernates.
kubectl create configmap my-config -n $namespace --from-file=./my-directory

my-directory contains around 5 files, 2 of them are properties file and 2 of them jpg file. i see the following result for kubectl get cm, i can see 4 data files in configmap
[admin@cluster ~]$ kubectl get cm
name                   data   age
warm-up-config         4      41m

i created a template as follows, it work if i specify only properties file but if i add jpg files it doesn't work at all
apiversion: v1
kind: configmap
metadata:
  name: my-config
data:
{{ (.files.glob &quot;resources/*&quot;).asconfig | nindent 2 }}

does anyone know how i make this work.
",<kubernetes><kubernetes-helm><configmap>,67737759,6,"jpg files are binary, and should be added as such.
data:
  binarydata:
    {{ .files.get &quot;/path/to/file.jpg&quot; }}

files in binarydata field must be encoded with base64, so:
{{ .files.get &quot;/path/to/file.jpg&quot; | b64enc }}

don't forget proper indentation:
{{ .files.get &quot;/path/to/file.jpg&quot; | b64enc | nindent 4 }}

"
41527367,kubectl jsonpath expression for named path,"i have kube service running with 2 named ports like this:

$ kubectl get service elasticsearch --output json
{
    ""apiversion"": ""v1"",
    ""kind"": ""service"",
    ""metadata"": {
        ... stuff that really has nothing to do with my question ...
    },
    ""spec"": {
        ""clusterip"": ""10.0.0.174"",
        ""ports"": [
             {
                ""name"": ""http"",
                ""nodeport"": 31041,
                ""port"": 9200,
                ""protocol"": ""tcp"",
                ""targetport"": 9200
            },
            {
                ""name"": ""transport"",
                ""nodeport"": 31987,
                ""port"": 9300,
                ""protocol"": ""tcp"",
                ""targetport"": 9300
            }
        ],
        ""selector"": {
            ""component"": ""elasticsearch""
        },
        ""sessionaffinity"": ""none"",
        ""type"": ""nodeport""
    },
    ""status"": {
        ""loadbalancer"": {}
    }
}


i'm trying to get output containing just the 'http' port:

$ kubectl get service elasticsearch --output jsonpath={.spec.ports[*].nodeport}
31041 31987


except when i add the test expression as hinted in the cheatsheet here http://kubernetes.io/docs/user-guide/kubectl-cheatsheet/ for the name i get an error

$ kubectl get service elasticsearch --output jsonpath={.spec.ports[?(@.name==""http"")].nodeport}
-bash: syntax error near unexpected token `('

",<bash><kubernetes><kubectl>,41527769,15,"( and ) mean something in bash (see subshell), so your shell interpreter is doing that first and getting confused.  wrap the argument to jsonpath in single quotes, that will fix it:

$ kubectl get service elasticsearch --output jsonpath='{.spec.ports[?(@.name==""http"")].nodeport}'


for example:

# this won't work:
$ kubectl get service kubernetes --output jsonpath={.spec.ports[?(@.name==""https"")].targetport}
-bash: syntax error near unexpected token `('

# ... but this will:
$ kubectl get service kubernetes --output jsonpath='{.spec.ports[?(@.name==""https"")].targetport}'
443

"
67996301,unable to setup kubernetes ingress for questdb via helm,"i'm a beginner to kubernetes, helm and yaml. i'm trying to access the questdb console via kubernetes ingress controller setup in my minikube, but i'm getting the below error when running a helm upgrade. could anyone advice how i can correct this?
error: upgrade failed: failed to create resource: ingress.extensions &quot;questdb&quot; is invalid: spec: invalid value: []networking.ingressrule(nil): either `defaultbackend` or `rules` must be specified

here's my overriding value.yaml
ingress:
  enabled: true
  rules:
    - host: localhost
      http:
        paths:
          - path: /questdb
            backend:
              servicename: questdb-headless
              serviceport: 9000
          - path: /influxdb
            backend:
              servicename: questdb-headless
              serviceport: 9009     

i've installed the questdb helm chart using a local version which has only slightly modified the original ingress.yaml to reference networking.k8s.io/v1 instead of networking.k8s.io/v1beta1. here's what it is locally:
{{- if .values.ingress.enabled -}}
{{- $fullname := include &quot;questdb.fullname&quot; . -}}
{{- $svcport := .values.service.port -}}
{{- if semvercompare &quot;&gt;=1.14-0&quot; .capabilities.kubeversion.gitversion -}}
apiversion: networking.k8s.io/v1
{{- else -}}
apiversion: extensions/v1
{{- end }}
kind: ingress
metadata:
  name: {{ $fullname }}
  labels:
    {{- include &quot;questdb.labels&quot; . | nindent 4 }}
  {{- with .values.ingress.annotations }}
  annotations:
    {{- toyaml . | nindent 4 }}
  {{- end }}
spec:
  {{- if .values.ingress.tls }}
  tls:
    {{- range .values.ingress.tls }}
    - hosts:
        {{- range .hosts }}
        - {{ . | quote }}
        {{- end }}
      secretname: {{ .secretname }}
    {{- end }}
  {{- end }}
  rules:
    {{- range .values.ingress.hosts }}
    - host: {{ .host | quote }}
      http:
        paths:
          {{- range .paths }}
          - path: {{ . }}
            backend:
              servicename: {{ $fullname }}
              serviceport: {{ $svcport }}
          {{- end }}
    {{- end }}
  {{- end }}

i'm running on these versions:
- helm : v3.6.0
- kubernetes : 
client version: version.info{major:&quot;1&quot;, minor:&quot;19&quot;, gitversion:&quot;v1.19.7&quot;, gitcommit:&quot;1dd5338295409edcfff11505e7bb246f0d325d15&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-01-13t13:23:52z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.2&quot;, gitcommit:&quot;faecb196815e248d3ecfb03c680a4507229c2a56&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-01-13t13:20:00z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

name                    namespace       chart                           app version
kubernetes-ingress      default         kubernetes-ingress-1.15.2       1.6.2
questdb                 default         questdb-0.8.0                   6.0.3

more details on the original chart and templates can be found here: https://github.com/questdb/questdb-kubernetes/tree/master/charts/questdb
",<kubernetes><kubernetes-helm><kubernetes-ingress><questdb>,67997551,2,"the ingress template expects things to stay under .values.ingress.hosts but in your values are under .values.ingress.rules.
additionally, paths needs to stay directly under hosts items, not under http, because the ingress is using it with a
{{- range .paths }}

under .values.ingress.hosts items. and, paths are just strings, as the service name and port are directly taken from the fullname and the .values.service.port

i would try changing your values to something like:
ingress:
  enabled: true
  hosts:
    - host: localhost
      paths:
        - &quot;/questdb&quot;
        - &quot;/influxdb&quot;

or something close to this.
additionally, you can try and see what is the output of an helm upgrade or install command if you add the parameters --debug --dry-run which could greatly help you identify problems like those, showing the definitions as they will be created (if there's no error while building the template, of course)

update: since you also changed the ingress template to use networking.k8s.io/v1, you need to also change how the template is created, because the new kind of ingress expects things in a different way, as you can see in the documentation: https://kubernetes.io/docs/concepts/services-networking/ingress/
rules could becomes something like this:
rules:
{{- range .values.ingress.hosts }}
- host: {{ .host | quote }}
  http:
    paths:
      {{- range .paths }}
      - path: {{ .path }}
        backend:
          service:
            name: {{ .svc }}
            port:
              number: {{ .port }}
      {{- end }}
{{- end }}

and remove the declarations of
{{- $fullname := include &quot;questdb.fullname&quot; . -}}
{{- $svcport := .values.service.port -}}

which are now useless. with this, you can change your values in the following:
ingress:
  enabled: true
  hosts:
    - host: localhost
      paths:
        - path: &quot;/questdb&quot;
          svc: questdb-headless
          port: 9000
        - path: &quot;/influxdb&quot;
          svc: questdb-headless
          port: 9009

but the service taht you specify in the values must be created somehwere of course (by the ingress and it needs to expose the desired ports)
"
62833181,azure aks loadbalancer serving multiple pods using service on same ip,"i currently have a load balancer per pod.  in my instance 2 pods with the following yaml definitions.
apiversion: v1
kind: service
metadata:
  name: service1
spec:
  ports:
  - name: https-service1
    port: 6379
    targetport: 6379
  selector:
       app: service1-consoleapp
  type: loadbalancer

apiversion: v1
kind: service
metadata:
  name: service2
spec:
  ports:
  - name: https-service2
    port: 443
    targetport: 443
  selector:
       app: service2-consoleapp
  type: loadbalancer

when i apply the above 2 yaml files i will get 2 external ip's that i then use to configure my a records in my dns subdomains.
service1.company.com   =&gt;  external ip 1 for service1-consoleapp
service2.company.com   =&gt;  external ip 2 for service2-consoleapp
is there a way to combine the yaml file into one,  so that i can only use one ip address instead of 2 ?
also , it looks like in ingress you can do it but not sure how i deal with the &quot;host&quot; requirement.
can someone please explain how the routing will work as i'm not sure what values should be in the path property ?
will i still get 2 external ip's on this that i can use to populate the dns subdomains ?
 spec:
  rules:
  - host: service1.company.com
    http:
      paths:
      - backend:
          servicename: service1
          serviceport: 6379
        path: ??
  - host: service2.company.com
    http:
      paths:
      - backend:
          servicename: service2
          serviceport: 433
        path: ??

the result i'm looking for is if i type
service1.company.com:6379 in my browser then i should hit the pod endpoint (service1-consoleapp) and if i type
service2.company.com:443 in my browser then i should hit the pod endpoint (service2-consoleapp).
where the service1.company.com and service2.company.com is on the same ip address.
thanks in advance.
",<azure><kubernetes><kubernetes-ingress><azure-load-balancer>,62833343,1,"the ingress resource that you have currently should work. remove the path section completely. also in your dns you need to create subdomains service1.company.com, service2.company.com and a a record to point to ip of the loadbalancer.
this loadbalancer is the one which will route traffic form outside to ingress controller pods and ingress controller will forward the traffic to the backend pods according to rules defined in the ingress resource. the host rule works this way - if a http request has a host header service1.company.com ingress controller will send that request to  service1 and if it has a host header service2.company.com ingress controller will send that request to  service2
when you deploy a ingress controller such as nginx you need to create a loadbalancer type service.so you will have only one loadbalancer which is for exposing ingress controller pods.
"
49845021,getting an kubernetes ingress endpoint/ip address,"base os : centos (1 master 2 minions)
k8s version : 1.9.5 (deployed using kubespray)


i am new to kubernetes ingress and am setting up 2 different services, each reachable with its own path.

i have created 2 deployments :

kubectl run nginx --image=nginx --port=80
kubectl run echoserver --image=gcr.io/google_containers/echoserver:1.4 --port=8080


i have also created their corresponding services :

kubectl expose deployment nginx --target-port=80 --type=nodeport
kubectl expose deployment echoserver --target-port=8080 --type=nodeport


my svc are :

[root@node1 kubernetes]# kubectl get svc
name         type       cluster-ip      external-ip   port(s)          age
echoserver   nodeport   10.233.48.121   &lt;none&gt;        8080:31250/tcp   47m
nginx        nodeport   10.233.44.54    &lt;none&gt;        80:32018/tcp     1h


my nodeip address is 172.16.16.2 and i can access both pods using

http://172.16.16.2:31250 &amp;
http://172.16.16.2:32018


now on top of this i want to deploy an ingress so that i can reach both pods not using 2 ips and 2 different ports but 1 ip address with different paths.

so my ingress file is :

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: fanout-nginx-ingress
spec:
  rules:
  - http:
      paths:
      - path: /nginx
        backend:
          servicename: nginx
          serviceport: 80
      - path: /echo
        backend:
          servicename: echoserver
          serviceport: 8080


this yields :

[root@node1 kubernetes]# kubectl describe  ing fanout-nginx-ingress
name:             fanout-nginx-ingress
namespace:        development
address:          
default backend:  default-http-backend:80 (&lt;none&gt;)
rules:
  host  path  backends
  ----  ----  --------
  *     
        /nginx   nginx:80 (&lt;none&gt;)
        /echo    echoserver:8080 (&lt;none&gt;)
annotations:
events:  &lt;none&gt;


now when i try accessing the pods using the nodeip address (172.16.16.2), i get nothing.

http://172.16.16.2/echo
http://172.16.16.2/nginx


is there something i have missed in my configs ? 
",<kubernetes><kubernetes-ingress>,53618759,21,"i had the same issue on my bare metal installation - or rather something close to that (kubernetes virtual cluster - set of virtual machines connected via host-only-adapter). here is link to my kubernetes vlab.

first of all make sure that you have ingress controller installed. currently there are two ingress controller worth trying kubernetes nginx ingress controller and nginx kubernetes ingress controller -i installed first one.

installation

go to installation instructions and execute first step 

# prerequisite-generic-deployment-command
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml


next get ip addresses of cluster nodes.

$ kubectl get nodes -o wide
name     status   roles    ...   internal-ip    
master   ready    master   ...   192.168.121.110
node01   ready    &lt;none&gt;   ...   192.168.121.111
node02   ready    &lt;none&gt;   ...   192.168.121.112


further, crate ingress-nginx service of type loadbalancer. i do it by downloading nodeport template service from installation tutorial and making following adjustments in svc-ingress-nginx-lb.yaml file.

$ curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/baremetal/service-nodeport.yaml &gt; svc-ingress-nginx-lb.yaml

# my changes svc-ingress-nginx-lb.yaml
type: loadbalancer
externalips:
  - 192.168.121.110
  - 192.168.121.111
  - 192.168.121.112
externaltrafficpolicy: local

# create ingress- service
$ kubectl apply -f svc-ingress-nginx-lb.yaml


verification

check that ingress-nginx service was created.

$ kubectl get svc -n ingress-nginx
name            type           cluster-ip     external-ip                                                       port(s)                      age
ingress-nginx   loadbalancer   10.110.127.9   192.168.121.110,192.168.121.111,192.168.121.112   80:30284/tcp,443:31684/tcp   70m


check that nginx-ingress-controller deployment was created.

$ kubectl get deploy -n ingress-nginx
name                       desired   current   up-to-date   available   age
nginx-ingress-controller   1         1         1            1           73m


check that nginx-ingress pod is running.

$ kubectl get pods --all-namespaces -l 

app.kubernetes.io/name=ingress-nginx
namespace       name                                        ready   status    restarts   age
ingress-nginx   nginx-ingress-controller-5cd796c58c-lg6d4   1/1     running   0          75m


finally, check ingress controller version. don't forget to change pod name!

$ kubectl exec -it nginx-ingress-controller-5cd796c58c-lg6d4 -n ingress-nginx -- /nginx-ingress-controller --version
-------------------------------------------------------------------------------
nginx ingress controller
  release:    0.21.0
  build:      git-b65b85cd9
  repository: https://github.com/aledbf/ingress-nginx
-------------------------------------------------------------------------------


testing

test that ingress controller is working by executing steps in this tutorial -of course, you will omit minikube part. 

successful, execution of all steps will create ingress controler resource that should look like this. 

$ kubectl get ing
name               hosts                                address                                          ports    age
ingress-tutorial   myminikube.info,cheeses.all          192.168.121.110,192.168.121.111,192.168.121.112   80      91m


and pods that looks like this.

$ kubectl get pods 
name                              ready   status             restarts   age
cheddar-cheese-6f94c9dbfd-cll4z   1/1     running            0          110m
echoserver-55dcfbf8c6-dwl6s       1/1     running            0          104m
stilton-cheese-5f6bbdd7dd-8s8bf   1/1     running            0          110m


finally, test that request to myminikube.info propagates via ingress load balancer. 

$ curl myminikube.info
client values:
client_address=10.44.0.7
command=get
real path=/
query=nil
request_version=1.1
request_uri=http://myminikube.info:8080/

server values:
server_version=nginx: 1.10.0 - lua: 10001

headers received:
accept=*/*
host=myminikube.info
user-agent=curl/7.29.0
x-forwarded-for=10.32.0.1
x-forwarded-host=myminikube.info
x-forwarded-port=80
x-forwarded-proto=http
x-original-uri=/
x-real-ip=10.32.0.1
x-request-id=b2fb3ee219507bfa12472c7d481d4b72
x-scheme=http
body:


it was a long journey to make ingress working on bear metal like environment.thus, i will include relevant links that helped me along. 


reproducable tutorial 
installation of minikube on ubuntu
ingress i
ingress ii
digging
reverse engineering on ingress in kubernetes

"
61075582,"error: failed to download ""stable/mssql-linux"" (hint: running `helm repo update` may help)","please see the command below:

helm install --name mymssql stable/mssql-linux --set accepteula.value=y --set edition.value=developer


which i got from here: https://github.com/helm/charts/tree/master/stable/mssql-linux

after just one month it appears the --name is no longer needed so i now have (see here: helm install unknown flag --name):

helm install mymssql stable/mssql-linux --set accepteula.value=y --set edition.value=developer


the error i see now is:

error: failed to download ""stable/mssql-linux"" (hint: running `helm repo update` may help)


what is the problem?

update

following on from the answers; the command above now works, however i cannot connect to the database using sql studio manager from my local pc.  the additional steps i have followed are:

1) kubectl expose deployment mymssql-mssql-linux --type=nodeport --name=mymssql-mssql-linux-service

2) kubectl get service - the below service is relevant here
mymssql-mssql-linux-service   nodeport    10.107.98.68             1433:32489/tcp   7s

3) then try to connect to the database using sql studio manager 2019:
server name: localhost,32489
authentication: sql server authentication
login: sa
password: i have tried: b64enc quote and mystrongpassword1234

i cannot connect using sql studio manager.
",<kubernetes><kubernetes-helm>,61076028,7,"check if the stable repo is added or not

helm repo list


if not then add

helm repo add stable https://kubernetes-charts.storage.googleapis.com
helm repo update


and then run below to install mssql-linux

helm install mymssql stable/mssql-linux --set accepteula.value=y --set edition.value=developer

"
48211549,kubernetes - scaling the resource failed with: job.batch is invalid:,"i'm trying to delete an existent job using

kubectl delete job/job-name -n my-namespace


but this error is displayed

caling the resource failed with: job.batch ""kong-loop"" is invalid:
spec.template: invalid value: api.podtemplatespec{...}: field is
immutable; current resource version 12189833

",<kubernetes><jobs><kubectl>,50060263,4,"the solution posted by @esnible does work in this scenario, but it is simpler do these  steps:


delete job with cascade false


kubectl delete job/jobname -n namespace --cascade=false


delete any pod that exists 


kubectl delete pod/podname -n namespace

solution found at in this google groups discussion https://groups.google.com/forum/#!topic/kubernetes-users/yvmugktoqti
"
50916801,kubernetes - pod which encapsulates db is crashing,"i am experiencing issues when i try to deploy my django application to kubernetes cluster. more specifically, when i try to deploy postgresql.

here is what my .yml deployment file looks like:

apiversion: v1
kind: service
metadata:
  name: postgres-service
spec:
  selector:
    app: postgres-container
    tier: backend
  ports:
    - protocol: tcp
      port: 5432
      targetport: 5432
  type: clusterip
---
apiversion: v1
kind: persistentvolume
metadata:
  name: postgres-pv
  labels:
      type: local
spec:
  accessmodes:
    - readwriteonce
  capacity:
    storage: 2gi
  hostpath:
    path: /tmp/data/persistent-volume-1 #u okviru cvora n
  persistentvolumereclaimpolicy: retain
---
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: postgres-pv-claim
  labels:
    type: local
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 2gi
---
apiversion: apps/v1beta2
kind: deployment
metadata:
  name: postgres
spec:
  replicas: 1
  selector:
    matchlabels:
      app: postgres-container
      tier: backend
  template:
    metadata:
      labels:
        app: postgres-container
        tier: backend
    spec:
      containers:
        - name: postgres-container
          image: postgres:9.6.6
          env:
            - name: postgres_user
              valuefrom:
                secretkeyref:
                  name: postgres-credentials
                  key: user

            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: postgres-credentials
                  key: password

            - name: postgres_db
              value: agent_technologies_db
          ports:
            - containerport: 5432
          volumemounts:
            - name: postgres-volume-mount
              mountpath: /var/lib/postgresql/data/db-files

      volumes:
        - name: postgres-volume-mount
          persistentvolumeclaim:
            claimname: postgres-pv-claim
        - name: postgres-credentials
          secret:
            secretname: postgres-credentials


here is what i get when i run kubectl get pods command :

name                                             ready     status             restarts   age
agent-technologies-deployment-7c7c6676ff-8p49r   1/1       running            0          2m
agent-technologies-deployment-7c7c6676ff-dht5h   1/1       running            0          2m
agent-technologies-deployment-7c7c6676ff-gn8lp   1/1       running            0          2m
agent-technologies-deployment-7c7c6676ff-n9qql   1/1       running            0          2m
postgres-8676b745bf-8f7jv                        0/1       crashloopbackoff   4          3m


and here is what i get when i try to inspect what is going on with postgresql deployment by using kubectl logs $pod_name:

initdb: directory ""/var/lib/postgresql/data"" exists but is not empty
if you want to create a new database system, either remove or empty
the directory ""/var/lib/postgresql/data"" or run initdb
with an argument other than ""/var/lib/postgresql/data"".
the files belonging to this database system will be owned by user ""postgres"".
this user must also own the server process.

the database cluster will be initialized with locale ""en_us.utf8"".
the default database encoding has accordingly been set to ""utf8"".
the default text search configuration will be set to ""english"".

data page checksums are disabled.


note: i am using google cloud as a provider.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,50917972,15,"you can't have your db in /var/lib/postgres/data/whatever.
change that path by /var/lib/postgres/whatever and it will work.

17.2.1. use of secondary file systems
many installations create their database clusters on file systems (volumes) other than the machine's &quot;root&quot; volume. if you choose to do this, it is not advisable to try to use the secondary volume's topmost directory (mount point) as the data directory. best practice is to create a directory within the mount-point directory that is owned by the postgresql user, and then create the data directory within that. this avoids permissions problems, particularly for operations such as pg_upgrade, and it also ensures clean failures if the secondary volume is taken offline.

and, by the way, i had to create a secret, as it is not in the post:
apiversion: v1
kind: secret
metadata:
  name: postgres-credentials
type: opaque
data:
  user: cg9zdgdyzxm=            #postgres
  password: cgfzc3dvcmq=        #password

note that the username needs to be &quot;postgres&quot;. i don't know if you are covering this...
"
57491894,how to access the ingress from all hosts?,"i'm setting a bare-metal kubernetes cluster for a web application in a google cloud instance, i am connecting to microservices through an ingress controller. how do i access the ingress controller from all incoming hosts?

there is a pod running angular web application and another pod running a  node api microservice. angular web application has been exposed globally. when accessing the microservice externally and passing the header with the hostname i was able to get the expected response. on removing the host in the ingress yaml i am not able to access the ingress.

kind: ingress
metadata:
  annotations:
    ingress.kubernetes.io/rewrite-target: nginx
  creationtimestamp: ""2019-08-12t07:41:37z""
  generation: 7
  name: test
  namespace: default
  resourceversion: ""546400""
  selflink: /apis/extensions/v1beta1/namespaces/default/ingresses/test
  uid: 374836d2-34c3-4053-b0e3-9fe3f63167cc
spec:
  rules:
  - host: bar.com
    http:
      paths:
      - backend:
          servicename: login-service
          serviceport: 3000
        path: /login-service
      - backend:
          servicename: organization-service
          serviceport: 3000
        path: /organization-service
status:
  loadbalancer:
    ingress:
    - ip: 10.128.0.16
    - ip: 203.0.113.2


i except the ingress to be accessed from all the hosts other than the specified host(bar.com) in ingress.

any other way to access the api microservice from the outside cluster(globally)?
",<kubernetes><web-hosting><kubernetes-ingress><resolve><nginx-ingress>,57603739,3,"in order to access the api service from outside the cluster(globally).

create a proxy nginx server and expose the port of the nginx proxy server. from the web application server, call a request to the proxy server through the external ip and exposed port. the proxy server will pass the request to the respected api microservice and return the expected response.

edit the nginx.conf file.

location /&lt;your_requested_url&gt; {
proxy_pass http://service_name:port;
}

"
63488004,can't install ingress-merge with helm,"following the install instructions i can not install &quot;ingress-merge&quot;.
i first tried :
helm install --namespace kube-system --name ingress-merge ./helm

that gave me the error - &quot;error: unknown flag: --name&quot;
i searched that issue up and found out that the --name flag is no longer needed.
i next tried the following:
helm install ingress-merge --namespace kube-system ./helm

that gave me the error - error: path &quot;./helm&quot; not found
i then took out the ./helm:
helm install ingress-merge --namespace kube-system

that gave me the error - error: must either provide a name or specify --generate-name
what is the correct command structure?
here is the link with the install instructions:
https://github.com/jakubkulhan/ingress-merge
",<kubernetes><kubernetes-helm>,63488147,2,"first clone the git repo
git clone https://github.com/jakubkulhan/ingress-merge.git

then use below command with helm 3. notice --name is not needed with helm 3
helm install --namespace kube-system ingress-merge ingress-merge/helm

or below command with helm 2
helm install --namespace kube-system --name ingress-merge ingress-merge/helm

"
53184263,how to call spring api from frontend in kubernetes,"i am trying to create a kubernetes application in which, i have created one pod and service for backend(spring boot microservice) &amp; frontend pod and 
a loadbalancer service.

i wanted to know how would i call the backend api from frontend pod in kubernetes?

here are the running services:

name         type           cluster-ip      external-ip       port(s)          age       selector
angular      loadbalancer   10.100.15.215   a17f17fd2e25011e886100a0e002191e-1613530232.us-east-1.elb.amazonaws.com   4200:30126/tcp   12s       app=angular
kubernetes   clusterip      10.100.0.1      &lt;none&gt;                                                                    443/tcp          35m       &lt;none&gt;
login        clusterip      10.100.99.52    &lt;none&gt;                                                                    5555/tcp         13m       app=login,tier=backend


i am calling the following api from frontend and it is showing name not resolved error:

http://login/login


i have also tried to call the  api with cluster ip but that failed.
",<amazon-web-services><kubernetes><devops-services><kubernetes-pod><amazon-eks>,53184681,3,"looks like your backend service is running on port 5555, so you would have to call your backend service like this:

http://login:5555/login


this assuming the pods for your frontend are on the same kubernetes namespace. if they are on a different namespace you would call something like this:

http://login.&lt;namespace&gt;.svc.cluster.local:5555/login


also as described here.

note that this will work only within the cluster, if you are hitting your angular frontend from a web browser outside of the cluster, this will not work, because the web browser would have no idea of where your backend is in the cluster. so either you will have to expose your backend using another loadbalancer type of service or you may consider using a kubernetes ingress with an ingress controller.
"
66493877,kubernetes nginx ingress controller missing path,"i have two deffinitions for nginx ingress controller. each of them routes to services for web app(react app hosted on nginx) and web api(.net core).
first is workig fine, but it is cumbresome since i need to add entry in etc file for each specified host to make it work:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-nginx-controller
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
spec:
  rules:
    - host: testapp-web-dev
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: testapp-portal-web-service
                port:
                  number: 80
    - host: testapp-api-dev
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: testapp-portal-api-service
                port:
                  number: 80

i decided to modify it to have single host with multiple paths, so i will have only one entry in etc file. but it does not work. first request is routed correctly to http://testapp//testapp-web-dev but every other next
request fails i.e. request for manifest goes to http://testapp/manifest.json but it should go to http://testapp/testapp-web-dev/manifest.json.
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-nginx-controller
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  rules:
    - host: testapp
      http:
        paths:
          - path: /testapp-web-dev(/|$)(.*)
            pathtype: prefix
            backend:
              service:
                name: testapp-portal-web-service
                port:
                  number: 80
          - path: /testapp-api-dev(/|$)(.*)
            pathtype: prefix
            backend:
              service:
                name: testapp-portal-api-service
                port:
                  number: 80

tried couple different url rewrite but without luck.
",<kubernetes><kubernetes-ingress><nginx-ingress>,66494904,2,"if you want to preserve the requested path, you need to remove the nginx.ingress.kubernetes.io/rewrite-target: /$2 annotation.
as per nginx ingress rewrite:

in this ingress definition, any characters captured by (.*) will be
assigned to the placeholder $2, which is then used as a parameter in
the rewrite-target annotation.

i.e., the annotation is redirecting http://testapp/testapp-web-dev/manifest.json to http://testapp/manifest.json.
"
63285220,pods not getting scheduled to node with matching labels,"i'm getting this error when exec'ing into my pod. error from server (badrequest): pod es-master-5cb49c68cc-w6dxv does not have a host assigned
it seemed to be related to my nodeaffinity but i don't see anything immediately wrong with it. i can't seem to get my deployment to attach its pod to any of my nodes. i don't have any taints or tolerations setup on the node or pod. i've tried switching to labels that are automatically generated that are on every node, but nothing seems to work. i've even tried removing my affinity section entirely, and also tried adding nodeselector to spec by itself.
here is my deployment config and output from kubectl describe pod  -n elasticsearch


---
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    component: elasticsearch
    role: master
  name: es-master
  namespace: elasticsearch
spec:
  replicas: 3
  selector:
    matchlabels:
      component: elasticsearch
      role: master
  template:
    metadata:
      labels:
        component: elasticsearch
        role: master
      annotations:
        iam.amazonaws.com/role: {redacted}
    spec:
      affinity:
        podantiaffinity:
          requiredduringschedulingignoredduringexecution:
          - topologykey: ""kubernetes.io/hostname""
            labelselector:
              matchlabels:
                component: elasticsearch
                role: master
        nodeaffinity:
          requiredduringschedulingignoredduringexecution:
            nodeselectorterms:
            - matchexpressions:
              - key: topology.kubernetes.io/region
                operator: in
                values:
                - us-east-2





name:           es-master-866f7fb558-298ht
namespace:      elasticsearch
priority:       0
node:           &lt;none&gt;
labels:         component=elasticsearch
                pod-template-hash=866f7fb558
                role=master
annotations:    iam.amazonaws.com/role: {redacted}
                kubernetes.io/psp: eks.privileged
status:         pending
ip:             
controlled by:  replicaset/es-master-866f7fb558
init containers:
  init-sysctl:
    image:      busybox:1.27.2
    port:       &lt;none&gt;
    host port:  &lt;none&gt;
    command:
      sysctl
      -w
      vm.max_map_count=262144
    environment:  &lt;none&gt;
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xflv6 (ro)
containers:
  elasticsearch:
    image:       amazon/opendistro-for-elasticsearch:0.9.0
    ports:       9300/tcp, 9200/tcp, 9600/tcp
    host ports:  0/tcp, 0/tcp, 0/tcp
    limits:
      cpu:     2
      memory:  12gi
    requests:
      cpu:     2
      memory:  12gi
    liveness:  tcp-socket :transport delay=60s timeout=1s period=10s #success=1 #failure=3
    environment:
      cluster_name:            logs
      number_of_masters:       3
      node_master:             true
      node_ingest:             false
      node_data:               false
      network_host:            0.0.0.0
      transport_tls_pem_pass:  
      http_tls_pem_pass:       
      node_name:               es-master-866f7fb558-298ht (v1:metadata.name)
      discovery_service:       elasticsearch-discovery
      kubernetes_namespace:    elasticsearch (v1:metadata.namespace)
      processors:              2 (limits.cpu)
      es_java_opts:            -xms6g -xmx6g
    mounts:
      /usr/share/elasticsearch/config/admin-crt.pem from certs (ro,path=""admin-crt.pem"")
      /usr/share/elasticsearch/config/admin-key.pem from certs (ro,path=""admin-key.pem"")
      /usr/share/elasticsearch/config/admin-root-ca.pem from certs (ro,path=""admin-root-ca.pem"")
      /usr/share/elasticsearch/config/elasticsearch.yml from config (rw,path=""elasticsearch.yml"")
      /usr/share/elasticsearch/config/elk-crt.pem from certs (ro,path=""elk-crt.pem"")
      /usr/share/elasticsearch/config/elk-key.pem from certs (ro,path=""elk-key.pem"")
      /usr/share/elasticsearch/config/elk-root-ca.pem from certs (ro,path=""elk-root-ca.pem"")
      /usr/share/elasticsearch/config/logging.yml from config (rw,path=""logging.yml"")
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xflv6 (ro)
conditions:
  type           status
  podscheduled   false 
volumes:
  config:
    type:      configmap (a volume populated by a configmap)
    name:      elasticsearch
    optional:  false
  certs:
    type:        secret (a volume populated by a secret)
    secretname:  elasticsearch-tls-data
    optional:    false
  default-token-xflv6:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-xflv6
    optional:    false
qos class:       burstable
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason            age                  from               message
  ----     ------            ----                 ----               -------
  warning  failedscheduling  59s (x3 over 3m44s)  default-scheduler  0/8 nodes are available: 8 insufficient cpu.



all nodes are m5a.large ec2 instances.
",<kubernetes><amazon-eks>,63285950,4,"the error is pretty clear 0/8 nodes are available: 8 insufficient cpu which means nodes don't have 2 cpu cores free as specified in requests. solution is to either provision nodes with more cpu or reduce the cpu requests in pod spec.
"
79181645,how to change pv storageclass of strimzi kafka cluster,"i am new at strimzi and want to get some advice
we have kafka cluster in gke. it is deployed with strimzi and
we have it on all stands including prod env.
our configuration of pvc that used by
kafka:
    template:
      pod:
    .....
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: {{ .values.kafka.storagesize | quote }}
        deleteclaim: true

and storage that zookeeper is using:
zookeeper:
...
    storage:
      type: persistent-claim
      size: {{ .values.zookeeper.storagesize | quote }}
      deleteclaim: true

with this configuration pvs are created with reclaimpolicy: delete, because it is default storage class and i need to change it to custom (with reclaimpolicy: retain)
and now i need to save all data in topics and change storageclass of both broker's and zookeeper's storages.
so my question is what should i do and in what order because if i just change the class through .spec.storage.class then pvc will be released and pv would be deleted.
",<kubernetes><apache-kafka><google-kubernetes-engine><persistent-volumes><strimzi>,79181937,1,"you can't really change the storage class for existing volumes.
there are several options how to work around it for kafka:

if you use jbod storage (it looks like it), you can add a new disk with the new storage class, and then move all partition-replicas from the old disk to the new one and finally remove the old disk once it is empty. to move the data, you right now have to use the kafka-reassign-partitions.sh script.
if you use kafkanodepool resources (and if you don't, you can migrate to node pools), you can create a new node pool with the new storage class and move all partition-replicas to it, and then remove the old node pool once empty. here, you can use cruise control to move the partition-replicas, so it is a but easier.

for zookeeper, none of these are really possibly. there are only hacky ways how to change the storage type. but maybe you can use the kraft-migration that you would anyway need to go through sooner or later as an opportunity to change the storage type.
"
51118561,kubernetes pod fails to deploy; docker image is missing/misplacing a file?,"i'm trying to learn my way around kubernetes with google cloud platform. i have a small vue-based application working locally with the following dockerfile and docker-compose.yml. 

building and bringing up this project locally works great. however, when using kompose up to create a deployment/svc/etc. for this thing, the container fails to build properly. ultimately it ends up in a crashing loop.

inspecting the logs shows that the issue is that npm cannot find /opt/eyeball/package.json or /opt/eyeball/package-lock.json. i'm confused since this isn't an issue when i build and push the image that my cluster is ultimately pulling down - those files are right where you'd expect them to be based on my dockerfile. any idea why this might be happening?

dockerfile

from node:8-alpine
run apk --no-cache --update add gzip
run mkdir -p /opt/eyeball
add ./package.json /opt/eyeball
add ./package-lock.json /opt/eyeball
workdir /opt/eyeball
run npm install
add . /opt/eyeball


docker-compose.yml

version: '3'

networks:
  default:
    external:
      name: overmind

services:
  eyeball:
    image: registry.gitlab.com/souldeux/eyeball:latest
    environment:
      - host=0.0.0.0
    ports:
      - ""8080:8080""
    volumes:
      - ./:/opt/eyeball
    entrypoint: ""npm run dev""

",<docker><npm><kubernetes><google-kubernetes-engine>,51122660,4,"you need to delete the volumes: block in your docker-compose.yml file.

the volumes: block in your docker-compose.yml directs docker to take the contents of your local directory and mount them into the container, which hides everything that you add in the dockerfile.  when you deploy this with kompose, this gets translated to kubernetes directives, but since the kubernetes environment doesn't have your local development environment, this results in the deployed containers failing.
"
59305999,is it possible to have an ingress point to a service from another namespace?,"what i want to do is have a service in the default namespace and ingresses in my other namespaces, which point to that service. i tried implementing the service and ingress shown below, but it didn't work.

kind: service
apiversion: v1
metadata:
  name: servicex
  namespace: default
spec:
  type: externalname
  externalname: servicex.default.svc.cluster.local
ports:
- port: 123


kind: ingress
apiversion: extensions/v1beta1
metadata:
  name: web-ingress-test-vpndev
  namespace: my-namespace
spec:
  tls:
  - hosts:
    - abc.my-namespace.domain.com
    secretname: tls-secret-my-namespace
  rules:
  - http:
      paths:
      - path: ""/""
        backend:
          servicename: servicex
          serviceport: 123
status:
  loadbalancer:
    ingress: {}


i know that i could implement the service in every namespace, but i was wondering if it's possible to have a single service. if i try to type the externalname of the service in the backend-&gt;servicename handler of the ingress, i get and error saying that the name of the service can only contain numbers, letter and '-'.
",<kubernetes><kubernetes-ingress><kubernetes-service>,59315520,4,"i would have to say that this isnt a good way. as all of ingress in different ns would be convert to nginx rule and take effect in ingress-controller pod. 

and if you take a look the nginx rule(nginx.conf in ingress-controller pod), you will see each block of location in nginx.conf has variable set $namespace      ""****""; which means the ingress has been isolated by ns

also, if you still want to implement your idea, might need to modify the ingress-contoller.
"
57728178,why outgoing requests from app running on nginx not hit kubernetes services,"i deployed an application running on nginx in kubernetes, it's a simple static index.html. i defined a button with a url to http://backservice:8080/action. backservice is a k8s service backing a spring application. 

the problem is, when i click on that button, nothing happens. backservice is not hit. i expect a cors error but it seems like nginx blocks all outbound requests. i don't want to proxy the backend service into nginx. 

nginx config:

user  nginx;
worker_processes  auto;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;
events {
    worker_connections  1024;
}
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] ""$request"" '
                      '$status $body_bytes_sent ""$http_referer"" '
                      '""$http_user_agent"" ""$http_x_forwarded_for""';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}


server conf:

server {
    listen       80;
    server_name  _;
    root /usr/share/nginx/html; 

    location / {
        index  index.html index.htm;
        try_files $uri $uri/ /index.html;
    }

    location /svg/ {
    }

    location /assets/ {
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
    }
}


the backendservice is in the same namespace as the nginx app.
",<nginx><kubernetes><kubernetes-service>,57728649,1,"your static app runs in your browser. the browser isn't part of the k8s cluster so it is not aware of the url http://backservice:8080/action

expose your backend service using ingress. for example https://backend.example.com/action

https://kubernetes.io/docs/concepts/services-networking/ingress/ 
(you can expose using loadbalancer type too but i suggest ingress)

then change your frontend code to hit https://backend.example.com/action
"
48172310,kubernetes: ca file when deploying via kops,"i have created a cluster on aws using kops.

however i am unable to find the file used as/by the certificate authority for spawning off client certs.

does kops create such a thing by default?

if so, what is the recommended process for creating client certs?

the kops documentation is not very clear about this.
",<kubernetes><kops><kubernetes-security>,48172829,10,"i've done it like this in the past:


download the kops-generated ca certificate and signing key from s3:  


s3://&lt;bucket_name&gt;/&lt;cluster_name&gt;/pki/private/ca/*.key
s3://&lt;bucket_name&gt;/&lt;cluster_name&gt;/pki/issued/ca/*.crt

generate a client key: openssl genrsa -out client-key.pem 2048
generate a csr:

openssl req -new \
  -key client-key.pem \
  -out client-csr.pem \
  -subj ""/cn=&lt;client_cn&gt;/o=dev""`

generate a client certificate:

openssl x509 -req \
  -in client-csr.pem \
  -ca &lt;path_to_downloaded_ca_cert&gt; \
  -cakey &lt;path_to_downloaded_ca_key&gt; \
  -cacreateserial \
  -out client-crt.pem \
  -days 10000

base64-encode the client key, client certificate, and ca certificate, and populate those values in a config.yml, e.g. this
distribute the populated config.yml to your developers.


5 and 6 can obviously be distributed by whatever means you want, don't need to make the config.yml for your developers.
"
72395843,creating a configmap from file is critical to file type and lines count in the file,"i have a template that creates a configmap from the jmeter-test-data-file-configmap.yaml file in helm chart:
{{- if .values.env.datafile }}
apiversion: v1
kind: configmap
metadata:
  name: jmeter-testdata
data:
  {{ .values.env.datafile }}: |-
  {{ .files.get .values.env.datafile | indent 4}}
{{- end }}

the corresponding yaml.configuration is:
env:
  testfile: sample
  datafile: example.csv

when i do the helm upgrade, everything is ok, if the example.csv is a single line text file like that:
1,1

but is it would have at least two or even more lines
1,1
2,2

the deployment fails with unrelated error message:
upgrade.go:123: [debug] preparing upgrade for jmeter
error: upgrade failed: yaml parse error on jmeter/templates/jmeter-test-data-file-configmap.yaml: error converting yaml to json: yaml: line 7: did not find expected key
helm.go:81: [debug] error converting yaml to json: yaml: line 7: did not find expected key
yaml parse error on jmeter/templates/jmeter-test-data-file-configmap.yaml

and the debug details are:
helm.sh/helm/v3/pkg/releaseutil.(*manifestfile).sort
        /home/circleci/helm.sh/helm/pkg/releaseutil/manifest_sorter.go:146
helm.sh/helm/v3/pkg/releaseutil.sortmanifests
        /home/circleci/helm.sh/helm/pkg/releaseutil/manifest_sorter.go:106
helm.sh/helm/v3/pkg/action.(*configuration).renderresources
        /home/circleci/helm.sh/helm/pkg/action/action.go:165
helm.sh/helm/v3/pkg/action.(*upgrade).prepareupgrade
        /home/circleci/helm.sh/helm/pkg/action/upgrade.go:215
helm.sh/helm/v3/pkg/action.(*upgrade).run
        /home/circleci/helm.sh/helm/pkg/action/upgrade.go:124
main.newupgradecmd.func2
        /home/circleci/helm.sh/helm/cmd/helm/upgrade.go:155
github.com/spf13/cobra.(*command).execute
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:850
github.com/spf13/cobra.(*command).executec
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:958
github.com/spf13/cobra.(*command).execute
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:895
main.main
        /home/circleci/helm.sh/helm/cmd/helm/helm.go:80
runtime.main
        /usr/local/go/src/runtime/proc.go:204
runtime.goexit
        /usr/local/go/src/runtime/asm_amd64.s:1374
upgrade failed
main.newupgradecmd.func2
        /home/circleci/helm.sh/helm/cmd/helm/upgrade.go:157
github.com/spf13/cobra.(*command).execute
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:850
github.com/spf13/cobra.(*command).executec
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:958
github.com/spf13/cobra.(*command).execute
        /go/pkg/mod/github.com/spf13/cobra@v1.1.1/command.go:895
main.main
        /home/circleci/helm.sh/helm/cmd/helm/helm.go:80
runtime.main
        /usr/local/go/src/runtime/proc.go:204
runtime.goexit

so, the error points to this line:
  {{ .values.env.datafile }}: |-

what could be wrong here and how can the file itself hurt the template processing because of its new lines? we tired /r/n, /n, /r with no success, all the same
we also tried to hadcode the line:7 like that:
{{- if .values.env.datafile }}
apiversion: v1
kind: configmap
metadata:
  name: jmeter-testdata
data:
  example.csv: |-
  {{ .files.get .values.env.datafile | indent 4}}
{{- end }}

and still the same error. and even to replace the template value with the hardcode:
{{- if .values.env.datafile }}
apiversion: v1
kind: configmap
metadata:
  name: jmeter-testdata
data:
  {{ (printf &quot;example.csv&quot; ) }}: |-
  {{ .files.get (printf &quot;example.csv&quot; ) | indent 4}}
{{- end }}

but still the same error.
and that doesn't happens with almost the same config, that bring the multiline xml file to the configmap exactly the same way:
apiversion: v1
kind: configmap
metadata:
  name: jmeter-test
data:
  test.jmx: |-
{{ .files.get (printf &quot;%s.jmx&quot; .values.env.testfile ) | indent 4}}

i suppose, that for some reason, probaby the intend is't applied to all lines for csv file, when it is applied to the jmx file. but how to figure that out ad how to work it around?
upd:
1, 1
    2, 2
    3, 3

&quot;intending&quot; files manually like above made the trick, it was deployed, however this file isn't ok to use for the needs then. how to avoid that?
",<kubernetes><kubernetes-helm><go-templates>,72399512,1,"if you have a line containing indent it probably needs to begin at the start of the line, even if it's in otherwise indented context.
{{- if .values.env.datafile }}
...
data:
  {{ .values.env.datafile }}: |-
{{ .files.get .values.env.datafile | indent 4}}
{{/*- previous line is not indented */}}
{{- end }}

in your original example, let's focus on these two lines:
  {{ .values.env.datafile }}: |-
  {{ .files.get .values.env.datafile | indent 4}}
## (these two spaces are important)

now, if the input line is your second example
1,1
2,2

now: the line containing indent 4 is itself indented by 2 spaces.  so in that line you have the two spaces at the start of the line, plus the four spaces from indent 4, so 6 spaces; then a newline and four spaces from indent 4, but no start-of-line spaces (you're still in the output from indent), so only 4 spaces.
  test.jmx: |-
      1,1
    2,2

if you run helm template --debug on your original chart, you will still get the yaml parsing error, but it should also print out this output.
in some contexts you may find it slightly more aesthetic to use nindent, which includes a newline before the first line's indentation, in combination with a - just inside the curly braces to consume the preceding whitespace (including both spaces and newlines).  this should also work:
data:
  {{ .values.env.datafile }}: |-
  {{- .files.get .values.env.datafile | nindent 4}}
  {{/*- indented, starts with -, uses nindent */}}

but also for example:
metadata:
  labels: {{- include &quot;common.labels&quot; . | nindent 4 }}
  annotations: {{- include &quot;common.annotations&quot; . | nindent 4 }}

"
67231631,how to point to a service in a different ns than the ingress,"i am looking at creating an alb using https://github.com/kubernetes-sigs/aws-load-balancer-controller
lets say i have two namespaces kubernetes-dashboard and otherns.
in the first namespace i have a service called kubernetes-dashboard and in the second namespace i have a service called otherservice
would the below ingress work?
ingress.yml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: general-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/listen-ports: '[{&quot;http&quot;:80,&quot;https&quot;: 443}]'
    alb.ingress.kubernetes.io/certificate-arn: &lt;redacted&gt;
    alb.ingress.kubernetes.io/tags: environment=staging,team=dev
    alb.ingress.kubernetes.io/healthcheck-path: /health
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '300'
spec:
  rules:
    - host: k8s.acme.com
      http:
        paths:
          - path: /*
            backend:
              servicename: kubernetes-dashboard.kubernetes-dashboard
              serviceport: 8080
    - host: otherservice.acme.com
      http:
        paths:
          - path: /*
            backend:
              servicename: otherservice.otherns
              serviceport: 80

",<kubernetes><kubernetes-ingress><amazon-elb>,67236051,6,"i found there is two solutions to this problem.
the second solution did not work for me because i am using a library which does not support that. https://github.com/kubernetes-sigs/aws-load-balancer-controller

create multiple ingress files delcaring the same group.name.

https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/ingress/annotations/#ingressgroup

ingressgroup feature enables you to group multiple ingress resources
together. the controller will automatically merge ingress rules for
all ingresses within ingressgroup and support them with a single alb.
in addition, most annotations defined on a ingress only applies to the
paths defined by that ingress.


use an externalname service

https://kubernetes.io/docs/concepts/services-networking/service/#externalname
you can create an externalname service in the same namespace as your ingress, your ingress will then point to this special externalname service
"
40621249,gke / kube-ui password not showing via `kubectl config view`,"trying to simply connect to the master ui ui interface.

i guess we got it all in the title, just tried any commands related to auth, nothing to do. kubectl config view won't provide a user and its associated password.

hope that'll sound obvious to some;

best
",<kubernetes><google-cloud-platform><kubectl>,40626305,1,"if you are running the google gke, you may not find your admin pass(web-ui too) with kubectl config view.

however, you can get it from https://console.cloud.google.com/ --> container engine --> show credentials. 
"
71265398,kuberentes rbac rule to allow creating jobs only from a cronjob,"is it possible to create a kubernetes rbac rule that allows creating a job from an existing cronjob, but prevents creating a job any other way?
we want to keep our clusters tightly locked down to avoid arbitrary deployments not managed by cicd - but we also need to facilitate manual testing of cronjobs, or rerunning failed jobs off schedule. i'd like developers to be able to run a command like:
kubectl create job --from=cronjob/my-job my-job-test-run-1

but not be able to run something like:
kubectl create job my-evil-job -f evil-job.yaml

is that possible?
",<kubernetes><kubernetes-rbac>,71306197,3,"in this scenario in order to successfully execute this command:
kubectl create job --from=cronjob/&lt;cronjob_name&gt;  

user/serviceaccount should have proper rbac rules (at least two from the output provided below, create jobs and get cronjobs.
in first example i granted access to create jobs and get cronjobs and i was able to create job and job --from cronjob
user@minikube:~$ cat test_role
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  namespace: default
  name: job
rules:
- apigroups: [&quot;batch&quot;]
  resources: [&quot;jobs&quot;]
  verbs: [&quot;create&quot;]
- apigroups: [&quot;batch&quot;]
  resources: [&quot;cronjobs&quot;]
  verbs: [&quot;get&quot;]
user@minikube:~$ kubectl create job --image=inginx testjob20
job.batch/testjob20 created
user@minikube:~$ kubectl create job --from=cronjobs/hello testjob21
job.batch/testjob21 created

but if i granted access only to create job without get cronjob, i was be able to create job but not to create job --from cronjob
user@minikube:~$ cat test_role
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  namespace: default
  name: job
rules:
- apigroups: [&quot;batch&quot;]
  resources: [&quot;jobs&quot;]
  verbs: [&quot;create&quot;]
user@minikube:~$ kubectl create job --image=nginx testjob3
job.batch/testjob3 created
user@minikube:~$ kubectl create job --from=cronjobs/hello testjob4
error from server (forbidden): cronjobs.batch &quot;hello&quot; is forbidden: user &quot;system:serviceaccount:default:t1&quot; cannot get resource &quot;cronjobs&quot; in api group &quot;batch&quot; in the namespace &quot;default&quot;

when i deleted access to create jobs, i couldn't create job and also job --from cronjob
user@minikube:~$ cat test_role
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  namespace: default
  name: job
rules:
- apigroups: [&quot;batch&quot;]
  resources: [&quot;cronjobs&quot;]
  verbs: [&quot;get&quot;]
user@minikube:~$ kubectl create job --image=inginx testjob10
error: failed to create job: jobs.batch is forbidden: user &quot;system:serviceaccount:default:t1&quot; cannot create resource &quot;jobs&quot; in api group &quot;batch&quot; in the namespace &quot;default&quot;  
user@minikube:~$ kubectl create job --from=cronjobs/hello testjob11
error: failed to create job: jobs.batch is forbidden: user &quot;system:serviceaccount:default:t1&quot; cannot create resource &quot;jobs&quot; in api group &quot;batch&quot; in the namespace &quot;default&quot;

as you can see if user/serviceaccount doesn't have both permission in this scenario it's impossible to create (job or job --from cronjob) so it's impossible to create such restrictions using only rabc rules.
one possible solution is to split this permission into two different user/serviceaccount for two different tasks (first user can create jobs + get cronjobs, second user without permission to create jobs).
another possibility is to try to use k8s admission controller with f.e. open policy agent
"
71301192,is psp only for pods created through deplyment/replica set?,"i am trying to set up the security polices in the cluster. i enabled pod security and created a restricted psp
1.step 1 - created psp
2.step 2 - created cluster role
3.step 3 - create clusterrolebinding
psp
apiversion: policy/v1beta1
kind: podsecuritypolicy
metadata:
  annotations:
    serviceaccount.cluster.cattle.io/pod-security: restricted
    serviceaccount.cluster.cattle.io/pod-security-version: &quot;2315292&quot;
  creationtimestamp: &quot;2022-02-28t20:48:12z&quot;
  labels:
    cattle.io/creator: norman
  name: restricted-psp
spec:
  allowprivilegeescalation: false
  fsgroup:
    ranges:
    - max: 65535
      min: 1
    rule: mustrunas
  requireddropcapabilities:
  - all
  runasuser:
    rule: runasany
  selinux:
    rule: runasany
  supplementalgroups:
    ranges:
    - max: 65535
      min: 1
    rule: mustrunas
  volumes:
  - configmap
  - emptydir
  - projected
  - secret
  - downwardapi
  - persistentvolumeclaim

cluster role -
apiversion: rbac.authorization.k8s.io/v1
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  annotations:
    serviceaccount.cluster.cattle.io/pod-security: restricted
  labels:
    cattle.io/creator: norman
  name: restricted-clusterrole
rules:
- apigroups:
  - extensions
  resourcenames:
  - restricted-psp
  resources:
  - podsecuritypolicies
  verbs:
  - use

clusterrolebinding
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: restricted-crb
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: restricted-clusterrole
subjects:
- apigroup: rbac.authorization.k8s.io
  kind: group
  name: system:serviceaccounts:security
- apigroup: rbac.authorization.k8s.io
  kind: group
  name: system:authenticated

create couple of yams one for deplyment and other for pod
kubectl create ns security

$ cat previleged-pod.yaml
apiversion: v1
kind: pod
metadata:
  labels:
    app: privileged-deploy
  name: privileged-pod
spec:
      containers:
        - image: alpine
          name: alpine
          stdin: true
          tty: true
          securitycontext:
            privileged: true
      hostpid: true
      hostnetwork: true

$ cat previleged-deploy.yaml
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: privileged-deploy
  name: privileged-deploy
spec:
  replicas: 1
  selector:
    matchlabels:
      app: privileged-deploy
  template:
    metadata:
      labels:
        app: privileged-deploy
    spec:
      containers:
        - image: alpine
          name: alpine
          stdin: true
          tty: true
          securitycontext:
            privileged: true
      hostpid: true
      hostnetwork: true

the expectation was both pod and deployment to be prevented . but the pod got created and deployment failed
$ kg all -n security
name                 ready   status    restarts   age
**pod/privileged-pod   1/1     running   0          13m**

name                                ready   up-to-date   available   age
deployment.apps/privileged-deploy   0/1     0            0           13m

name                                           desired   current   ready   age
replicaset.apps/privileged-deploy-77d7c75dd8   1         0         0       13m

as expected error for deployment came as below
events:
  type     reason        age                   from                   message
  ----     ------        ----                  ----                   -------
  warning  failedcreate  3m10s (x18 over 14m)  replicaset-controller  error creating: pods &quot;privileged-deploy-77d7c75dd8-&quot; is forbidden: podsecuritypolicy: unable to admit pod: [spec.securitycontext.hostnetwork: invalid value: true: host network is not allowed to be used spec.securitycontext.hostpid: invalid value: true: host pid is not allowed to be used spec.containers[0].securitycontext.privileged: invalid value: true: privileged containers are not allowed spec.securitycontext.hostnetwork: invalid value: true: host network is not allowed to be used spec.securitycontext.hostpid: invalid value: true: host pid is not allowed to be used spec.containers[0].securitycontext.privileged: invalid value: true: privileged containers are not allowed spec.securitycontext.hostnetwork: invalid value: true: host network is not allowed to be used spec.securitycontext.hostpid: invalid value: true: host pid is not allowed to be used spec.containers[0].securitycontext.privileged: invalid value: true: privileged containers are not allowed]

but the pod created directly though yaml worked . is psp only for pods getting created through deplyment/rs ? please help , how can we prevent users from creating pods which are previleged and dangerous
",<kubernetes><kubernetes-pod>,71311067,1,"
but the pod created directly though yaml worked . is psp only for pods
getting created through deplyment/rs ?

that's because when you create a bare pod (creating a pod directly) it will be created by the user called kubernetes-admin (in default scenarios), who is a member of the group system:masters, which is mapped to a cluster role called cluster-admin, which has access to all the psps that get created on the cluster. so the creation of bare pods will be successful.
whereas pods that are created by deployment,rs,sts,ds (all the managed pods) will be created using the service account mentioned in their definition. the creation of these pods will be successful only if these service accounts have access to psp via a cluster role or role.

how can we prevent users from creating pods which are previleged and dangerous

we need to identify what is that user and group that will be creating these pods (by checking ~/kube/config or its certificate) and then make sure, it does not have access to psp via any cluster role or role.
"
70746452,kubernetes redirect front-end to back-end,"in kubernetes i have a load balancer and 2 web apps (with names ui and kuard) that are both publicly available through services and ingress rules similar to:
kuard service:
apiversion: v1
kind: service
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |xxx
  creationtimestamp: &quot;2022-01-17t15:44:30z&quot;
  labels:
    app: kuard
    app.kubernetes.io/managed-by: pulumi
  name: mykuard
  namespace: nginx-test-frwjnfp0
  resourceversion: &quot;975&quot;
  uid: 819d94ca-b63d-44d5-9af9-a83da3f4bbd8
spec:
  clusterip: 10.3.250.8
  clusterips:
  - 10.3.250.8
  ipfamilies:
  - ipv4
  ipfamilypolicy: singlestack
  ports:
  - port: 8080
    protocol: tcp
    targetport: http
  selector:
    app: kuard
  sessionaffinity: none
  type: clusterip
status:
  loadbalancer: {}

kuard ingress
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: | xxx
    kubernetes.io/ingress.class: nginx
    pulumi.com/autonamed: &quot;true&quot;
  creationtimestamp: &quot;2022-01-17t15:44:42z&quot;
  generation: 2
  labels:
    app: kuard
    app.kubernetes.io/managed-by: pulumi
  name: kuard-tuy3sb0v
  namespace: nginx-test-frwjnfp0
  resourceversion: &quot;13091&quot;
  uid: 4d14f3fc-d116-4233-a717-c38d92741139
spec:
  rules:
  - host: kuard.xxx.com
    http:
      paths:
      - backend:
          service:
            name: mykuard
            port:
              name: http
        path: /
        pathtype: implementationspecific
status:
  loadbalancer:
    ingress:
    - ip: xxx

as you can see for now i can access the kuard app by going to kuard.xxx.com where xxx is the public lb ip.
currently i am able to navigate to the kuard app from the ui app by hardcoding kuard.xxx.com in my ui app. this is stupid because i'm using the www address rather than using the internal cluster address.
which url (and ingress?) can i use in order to open the kuard app in the browser from the ui app based on its internal cluster address, rather than the www url?
i tried hardcoding http://mykuard:80 in the &quot;ui&quot; web app because the service name for the kuard app is mykuard, but i'm definitely missing something.
",<nginx><kubernetes><service><kubernetes-ingress>,70752103,1,"what you want is not possible.
when accessing a service from a browser, you are making request from outside your cluster. for this you need external ip.
the internal cluster address (&lt;service-name&gt;:&lt;port&gt;) is for internal communication only (e.g. pod to pod) , and is resolved by your internal dns, to which your browser does not have access.
"
67282365,how could be memory dump saved in kubernetes cluster after crashing?,"when jvm crashes with outofmemoryerror there are some options to store a dump:
-xx:+heapdumponoutofmemoryerror 
-xx:heapdumppath=./java_pid&lt;pid&gt;.hprof

but what does it happen in kubernetes cluster after crashing? it seems kubernetes will clean up everything related to the pod crushed? how can i save it?
",<java><kubernetes><out-of-memory><kubernetes-pod><heap-dump>,67282433,4,"just mount it as a volume.
volumemounts:
        - name: heap-dumps
          mountpath: /dumps
      volumes:
      - name: heap-dumps
        emptydir: {}

how to do a java heap dump in k8s
"
62565629,helm error converting yaml to json: yaml: line 20: did not find expected key,"i don't really know what is the error here, is a simple helm deploy with a _helpers.tpl, it doesn't make sense and is probably a stupid mistake, the code:
deploy.yaml
apiversion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: deployment
{{ include &quot;metadata.name&quot; . }}-deploy
spec:
  selector:
    matchlabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerport: 80
        vars: {{- include &quot;envs.var&quot; .values.secret.data }}

_helpers.tpl
{{- define &quot;envs.var&quot;}}
{{- range $key := . }}
- name: {{ $key | upper | quote}}
  valuefrom:
    secretkeyref:
      key: {{ $key | lower }}
      name: {{ $key }}-auth
{{- end }}
{{- end }}

values.yaml
secret:
  data:
    username: root
    password: test

the error
error: yaml parse error on mychart/templates/deploy.yaml: error converting yaml to json: yaml: line 21: did not find expected key

",<kubernetes><kubernetes-helm><go-templates>,62569458,10,"here this problem happens because of indent. you can resolve by updating
env: {{- include &quot;envs.var&quot; .values.secret.data | nindent 12  }}

"
52953815,securing specific nginx-ingress location with client cert verification,"i'm setting up an instance of ghost and i'm trying to secure the /ghost path with client cert verification. 

i've got an initial ingress up and running that serves the site quite happily with the path specified as /. 

i'm trying to add a second ingress (that's mostly the same) for the /ghost path. if i do this and add the annotations for basic auth, everything seems to work. i.e. if i browse to /ghost i am prompted for credentials in the basic-auth secret, if i browse to any other url it is served without auth. 

i then switched to client cert verification based on this example: https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/auth/client-certs

when i try this either the whole site or none of the site is secured, rather than the path-based separation, i got with basic-auth. looking at the nginx.conf from the running pod the  proxy_set_header ssl-client-verify, proxy_set_header ssl-client-subject-dn &amp; proxy_set_header ssl-client-issuer-dn elements are added under the root / path and the /ghost path. i've tried removing those (from the root only) and copying the config directly back to the pod but not luck there either.

i'm pulling nginx-ingress (chart version 0.23.0) in as a dependency via helm

ingress definition for / location - this one works

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt-staging
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: ""true""
  labels:
    app: my-app
    chart: my-app-0.1.1
    heritage: tiller
    release: my-app
  name: my-app
  namespace: default
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: my-app
          serviceport: http
        path: /
  tls:
  - hosts:
    - example.com
    secretname: mysite-tls


ingress definition for /ghost location - this one doesn't work

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/auth-tls-verify-client: ""on""
    nginx.ingress.kubernetes.io/auth-tls-secret: ""default/auth-tls-chain""
    nginx.ingress.kubernetes.io/auth-tls-verify-depth: ""1""
    nginx.ingress.kubernetes.io/auth-tls-error-page: ""http://www.example.com/error-cert.html""
    nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: ""false""
    kubernetes.io/ingress.class: ""nginx""
  labels:
    app: my-app
    chart: my-app-0.1.1
    heritage: tiller
    release: my-app
  name: my-app-secure
  namespace: default
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: my-app
          serviceport: http
        path: /ghost
  tls:
  - hosts:
    - example.com
    secretname: mysite-tls

",<ssl><nginx><kubernetes><nginx-ingress><kubernetes-helm>,52980862,2,"you need a '*' on your path on your second ingress if you want to serve all the pages securely under /ghost and if you want just /ghost you need another rule. something like this:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/auth-tls-verify-client: ""on""
    nginx.ingress.kubernetes.io/auth-tls-secret: ""default/auth-tls-chain""
    nginx.ingress.kubernetes.io/auth-tls-verify-depth: ""1""
    nginx.ingress.kubernetes.io/auth-tls-error-page: ""http://www.example.com/error-cert.html""
    nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: ""false""
    kubernetes.io/ingress.class: ""nginx""
  labels:
    app: my-app
    chart: my-app-0.1.1
    heritage: tiller
    release: my-app
  name: my-app-secure
  namespace: default
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: my-app
          serviceport: http
        path: /ghost
      - backend:
          servicename: my-app
          serviceport: http
        path: /ghost/*
  tls:
  - hosts:
    - example.com
    secretname: mysite-tls


however, if you want something like / unsecured and /ghost secured, i believe you won't be able to do it. for example, if you are using nginx, this is a limitation from nginx itself, when you configure a server {} block with tls in nginx it looks something like this:

server {
    listen              443 ssl;
    server_name         example.com;
    ssl_certificate     example.com.crt;
    ssl_certificate_key example.com.key;
    ssl_protocols       tlsv1 tlsv1.1 tlsv1.2;
    ssl_ciphers         high:!anull:!md5;
    ...
}


the ingress controller creates paths like this:

server {
    listen              443 ssl;
    server_name         example.com;
    ssl_certificate     example.com.crt;
    ssl_certificate_key example.com.key;
    ssl_protocols       tlsv1 tlsv1.1 tlsv1.2;
    ssl_ciphers         high:!anull:!md5;
    ...

    location / {
       ...
    }

    location /ghost {
       ...
    }

}


so when you configure another server {} block with the same hostname and with no ssl it will override the first one.

you could do it with different - host: rules in your ingress for example ghost.example.com with tls and main.example.com without tls. so in your nginx.conf you would have different server {} blocks.

you can always shell into the ingress controller pod to check the configs, for example:

$ kubectl exec -it nginx-ingress-controller-xxxxxxxxx-xxxxx bash
www-data@nginx-ingress-controller-6bd7c597cb-8kzjh:/etc/nginx$ cat nginx.conf

"
53331837,unable to ping one service to another service in kubernetes cluster?,"i have created a local ubuntu kubernetes cluster,  having 1 master and 2 slave nodes.

i deployed 2 applications in 2 pods and created service for both of the pods, it's working fine.
i entered inside pod by typing this command ,

$ kubectl exec -it firstpod /bin/bash
# apt-get update


unable to make update and i'm getting an error:

err http://security.debian.org jessie/updates inrelease

err http://deb.debian.org jessie inrelease

err http://deb.debian.org jessie-updates inrelease

err http://security.debian.org jessie/updates release.gpg   temporary failure resolving 'security.debian.org' err http://deb.debian.org jessie-backports inrelease

err http://deb.debian.org jessie release.gpg   temporary failure resolving 'deb.debian.org' err http://deb.debian.org jessie-updates release.gpg   temporary failure resolving 'deb.debian.org' err http://deb.debian.org jessie-backports release.gpg   temporary failure resolving 'deb.debian.org' reading package lists... done w: failed to fetch http://deb.debian.org/debian/dists/jessie/inrelease

w: failed to fetch http://deb.debian.org/debian/dists/jessie-updates/inrelease

w: failed to fetch http://security.debian.org/dists/jessie/updates/inrelease

w: failed to fetch http://deb.debian.org/debian/dists/jessie-backports/inrelease

w: failed to fetch http://security.debian.org/dists/jessie/updates/release.gpg  temporary failure resolving 'security.debian.org'

w: failed to fetch http://deb.debian.org/debian/dists/jessie/release.gpg  temporary failure resolving 'deb.debian.org'

w: failed to fetch http://deb.debian.org/debian/dists/jessie-updates/release.gpg  temporary failure resolving 'deb.debian.org'

w: failed to fetch http://deb.debian.org/debian/dists/jessie-backports/release.gpg  temporary failure resolving 'deb.debian.org'

w: some index files failed to download. they have been ignored, or old ones used instead.


i'm trying to ping my second pod service:

# ping secondservice (this is the service name of secondpod)
ping secondservice.default.svc.cluster.local (10.100.190.196): 56 data bytes
unable to ping.


how can i ping/call the second service from the first node?
",<kubernetes><kubernetes-service>,53335148,2,"there are two (unrelated) questions i see there. i'm going to focus on the second one since the first is unclear to me (what is the ask?).

so, you wonder why the following doesn't work:

# ping secondservice 


this is not a bug or unexpected (actually, i wrote about it here). in short: the fqdn secondservice.default.svc.cluster.local gets resolved via the dns plugin to a virtual ip (vip), the very essence of this vip is that it is virtual, that is, it's not attached to a network interface, it's just a bunch of iptables rules. hence, the icmp-based ping has nothing to work against, since it's not a 'real' ip. you can curl the service, though. assuming the service runs on port 9876, the following should work:

# curl secondservice:9876

"
66421225,why does gke console list an internal lb as an external lb?,"when i create a loadbalancer like this:
apiversion: v1
kind: service
metadata:
  name: webhook-event-source-service
  namespace: argo-events
  annotations:
    networking.gke.io/load-balancer-type: &quot;internal&quot;
spec:
  type: loadbalancer
  loadbalancerip: 10.196.xxx.xxx
  selector:
    controller: eventsource-controller
  ports:
  - port: 1212
    targetport: 1212
    protocol: tcp

why does the gke console list it as an &quot;external load balancer&quot;?

",<kubernetes><google-kubernetes-engine>,66439470,1,"in fact, this problem has already been reported some time ago on google's public issue tracker and it's currently under investigation:

problem you have encountered:
i created a deployment and a loadbalancer service as described in the
official
docs
notice the loadbalancer service is annotated with
networking.gke.io/load-balancer-type: &quot;internal&quot;
what you expected to happen:
i expected to see this service listed as  internal load balancer  in
the  services &amp; ingress  view of the gcp console.
instead it is listed as an  external load balancer. (see attachment)
going to the specific load balancer in the  load balancing  view
shows it as internal.
steps to reproduce:
just follow the docs and head to the  services &amp; ingress  view in
the console.

and the answer from gcp support, confirming that they were also able to reproduce the issue and are analyzing it at the moment:

hello,
thank you for reaching out.
i've managed to reproduce the same scenario that you've included in
your message.
i forwarded this information to the engineering team.
please follow this issue in case of any further updates.
best regards

so if you are interested in progressing on this issue, feel free to follow this thread for further updates.
"
59375922,"serviceaccount cannot list resource ""pods"" in namespace though it has role with appropriate resources","i have the following definitions in my custom namespace:

apiversion: v1
kind: serviceaccount
metadata:
  name: test-sa
---
kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: test
rules:
  - apigroups: [""""]
    resources: [""pods"", ""pods/exec""]
    verbs: [""get"", ""list"", ""delete"", ""patch"", ""create""]
  - apigroups: [""extensions"", ""apps""]
    resources: [""deployments"", ""deployments/scale""]
    verbs: [""get"", ""list"", ""delete"", ""patch"", ""create""]
---
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: test
subjects:
  - kind: user
    name: test-sa
    apigroup: rbac.authorization.k8s.io
roleref:
  kind: role
  name: test
  apigroup: rbac.authorization.k8s.io


running describe role test

name:         test
labels:       &lt;none&gt;
annotations:  kubectl.kubernetes.io/last-applied-configuration:
                {""apiversion"":""rbac.authorization.k8s.io/v1"",""kind"":""role"",""metadata"":{""annotations"":{},""name"":""test"",""namespace"":""test-namesapce...
policyrule:
  resources                     non-resource urls  resource names  verbs
  ---------                     -----------------  --------------  -----
  pods/exec                     []                 []              [get list delete patch create]
  pods                          []                 []              [get list delete patch create]
  deployments.apps/scale        []                 []              [get list delete patch create]
  deployments.apps              []                 []              [get list delete patch create]
  deployments.extensions/scale  []                 []              [get list delete patch create]
  deployments.extensions        []                 []              [get list delete patch create]


when i'm trying to run the command kubectl get pods in a pod that is using this service account, i'm getting the following error:


  error from server (forbidden): pods is forbidden: user
  ""system:serviceaccount:test-namespace:test-sa"" cannot list resource
  ""pods"" in api group """" in the namespace ""test-namespace""


where is that misconfigured?
",<kubernetes><kubectl><rbac>,59378979,7,"the problem was with the subjects of rolebinding. the correct definition would be:

apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: test
subjects:
  - kind: serviceaccount
    name: test-sa
roleref:
  kind: role
  name: test
  apigroup: rbac.authorization.k8s.io

"
53949329,kubernetes runasnonroot failing: createcontainerconfigerror,"i have added a security context in my pod which looks as follows:

spec:
  securitycontext:
    runasnonroot: true


while running the pod i am getting error message (kubectl get pod pod-name -o=yaml):


  container has runasnonroot and image has non-numeric user (default),
            cannot verify user is non-root


the message is intuitive but, after reading this kubernetes blog it seems to me it should be very straight forward, what i am missing here?
",<kubernetes><kubernetes-helm>,53949466,18,"this error comes only when your uid == nil,. based on the error text, we need to set a numeric user value.

so, for the user with uid=1000 you can do it in your pod definition like:

securitycontext:
  runasuser: 1000


so your securitycontext should be like:

securitycontext:
  fsgroup: 2000
  runasnonroot: true
  runasuser: 1000


checkout it in official docs here
"
73998754,kubernetes networkpolicy applied is not taking effect,"i was testing the kubernetes network policy first before trying in a production requirement but unfortunately, i could not make it work yet and looking for a solution.
my test environment is a kind k8 cluster on wsl.
trying everything in the namespace &quot;networkpolicy&quot;:
→ kubectl -n networkpolicy get ns networkpolicy
name            status   age
networkpolicy   active   174m

two pods running in that namespace:
→ kubectl -n networkpolicy get pods --show-labels -o wide
name         ready   status    restarts   age     ip            node                   nominated node   readiness gates   labels
np-busybox   1/1     running   0          151m    10.244.0.11   selfie-control-plane   &lt;none&gt;           &lt;none&gt;            app=client
np-nginx     1/1     running   0          9m52s   10.244.0.12   selfie-control-plane   &lt;none&gt;           &lt;none&gt;            app=nginx

you can see the pod &quot;np-nginx&quot; has the label &quot;app=nginx&quot;
network policy created with podselector &quot;app: nginx&quot;
→ kubectl -n networkpolicy describe networkpolicy
name:         my-networkpolicy
namespace:    networkpolicy
created on:   2022-10-08 21:49:16 +0530 ist
labels:       &lt;none&gt;
annotations:  &lt;none&gt;
spec:
  podselector:     app=nginx
  allowing ingress traffic:
    &lt;none&gt; (selected pods are isolated for ingress connectivity)
  allowing egress traffic:
    &lt;none&gt; (selected pods are isolated for egress connectivity)
  policy types: ingress, egress

so i think, specifying policy types ingress and egress without explicitly specifying any rules under it, means it by default denies any connections. is that correct?
i tried to curl the nginx pod ip from the busybox client pod and it is able to connect fine even if the network policy is in place.
→ kubectl -n networkpolicy exec np-busybox -- curl -s 10.244.0.12 | html2text
****** welcome to nginx! ******
if you see this page, the nginx web server is successfully installed and
working. further configuration is required.
for online documentation and support please refer to nginx.org.
commercial support is available at nginx.com.
thank you for using nginx.

is there something wrong with what i tried?
",<kubernetes><windows-subsystem-for-linux><kubernetes-networkpolicy><kind>,73999107,1,"ok, i figured out the solution now.
kind ships with a simple networking implementation kindnet which does not seem to support networkpolicy.
you can change the cni on your kind cluster to calico(which does support networkpolicy) as follows:
you can see kindnet and no calico present:
~ → kubectl -n kube-system get all | grep calico
~ →

~ → kubectl -n kube-system get all | grep kindnet
pod/kindnet-mmlgj                                  1/1     running   4 (2d1h ago)   2d21h
daemonset.apps/kindnet      1         1         1       1            1           &lt;none&gt;                   2d21h

get into the docker container:
~ → docker ps -a
container id   image                  command                  created      status      ports                       names
1beac63b6221   kindest/node:v1.25.2   &quot;/usr/local/bin/entr…&quot;   2 days ago   up 2 days   127.0.0.1:34235-&gt;6443/tcp   selfie-control-plane

~ → docker exec -it 1beac63b6221 bash
root@selfie-control-plane:/#

create the following yaml file with option &quot;disabledefaultcni&quot; to disable default kindnet of kind cluster:
root@selfie-control-plane:/# cat &lt;&lt;eof &gt;/etc/kubernetes/manifests/kind-calico.yaml
kind: cluster
apiversion: kind.sigs.k8s.io/v1alpha3
networking:
  disabledefaultcni: true # disable kindnet
eof

root@selfie-control-plane:/# exit
exit

exit from the container, then stop and start the kind cluster docker container
~ → docker stop selfie-control-plane
selfie-control-plane

~ → docker start selfie-control-plane
selfie-control-plane

~ → docker ps -a
container id   image                  command                  created      status         ports                       names
1beac63b6221   kindest/node:v1.25.2   &quot;/usr/local/bin/entr…&quot;   2 days ago   up 7 seconds   127.0.0.1:34235-&gt;6443/tcp   selfie-control-plane
~ →

install calico cni plugin now:
~ → kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
poddisruptionbudget.policy/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
serviceaccount/calico-node created
configmap/calico-config created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
deployment.apps/calico-kube-controllers created

now you cannot curl it and it simply timesout after waiting for long:
→ kubectl -n networkpolicy exec np-busybox -- curl -s 10.244.100.66
.
.
.

"
66428311,how to get flask app accessible through ingress without setting rewrite-target,"i have a kubernetes cluster that is making use of an ingress to forward on traffic to a frontend react app and a backend flask app. my problem is that the react app only works if rewrite-target annotation is not set and the flask app only works if it is.
how can i get my flask app accessible without setting this value (commented out in below yaml).
here is the ingress controller:
metadata:
  name: thesis-ingress
  namespace: thesis
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/add-base-url: &quot;true&quot;
#    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/service-upstream: &quot;true&quot;
spec:
  tls:
    - hosts:
        - thesis
      secretname: ingress-tls
  rules:
    - host: thesis.info
      http:
        paths:
        - path: /
          pathtype: prefix
          backend:
            service:
              name: frontend
              port:
                number: 3000
        - path: /backend
          pathtype: prefix
          backend:
            service:
              name: backend
              port:
                number: 5000

",<python><flask><kubernetes><kubernetes-ingress>,66433289,1,"your question didn't specify, but i'm guessing your capture group was to rewrite /backend/(.+) to /$1; on that assumption:
be aware that annotations are per-ingress, but all ingress resources are unioned across the cluster to comprise the whole of the configuration. thus, if you need one rewrite and one without, just create two ingress resources
metadata:
  name: thesis-frontend
  namespace: thesis
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/add-base-url: &quot;true&quot;
    nginx.ingress.kubernetes.io/service-upstream: &quot;true&quot;
spec:
  tls:
    - hosts:
        - thesis
      secretname: ingress-tls
  rules:
    - host: thesis.info
      http:
        paths:
        - path: /
          pathtype: prefix
          backend:
            service:
              name: frontend
              port:
                number: 3000
---
metadata:
  name: thesis-backend
  namespace: thesis
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/add-base-url: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/service-upstream: &quot;true&quot;
spec:
  tls:
    - hosts:
        - thesis
      secretname: ingress-tls
  rules:
    - host: thesis.info
        - path: /backend/(.+)
          backend:
            service:
              name: backend
              port:
                number: 5000

"
75587750,503 service temporary unavailable ingress eks,"getting a 503 error for the ingress, did the basic trouble shooting with labels and stuff looks good though. i see the pods are running and can be listed when ran with the service label.
the readiness probe has a warning but it did not fail
what else can be checked tor resolve this issue. any ideas appreciated


kubectl get service -n staging
name                    type        cluster-ip       external-ip   port(s)    age
app-staging   clusterip   172.20.174.146   &lt;none&gt;        8000/tcp   242d


kubectl describe service app-staging -n staging
name:              app-staging
namespace:         staging
labels:            &lt;none&gt;
annotations:       &lt;none&gt;
selector:          app=app-staging
type:              clusterip
ip family policy:  singlestack
ip families:       ipv4
ip:                172.20.174.146
ips:               172.20.174.146
port:              app-staging  8000/tcp
targetport:        8000/tcp
endpoints:         10.200.32.6:8000,10.200.64.2:8000
session affinity:  none
events:            &lt;none&gt;


kubectl get pods -n staging -l app=app-staging                     
name                                     ready   status    restarts   age
app-staging-5677656dc8-djp8l   1/1     running   0          4d7h
app-staging-5677656dc8-dln5v   1/1     running   0          4d7h



this is the readiness probe


 kubectl describe pod app-staging-5677656dc8-djp8l -n staging|grep -i readiness
    readiness:      http-get http://:8000/ delay=30s timeout=1s period=30s #success=1 #failure=6
  warning  probewarning  40s (x12469 over 4d7h)  kubelet  readiness probe warning:



here is the manifest file for the pod, service and ingress


# this deployment is setup to use ecr for now, but should switch to  artifactory in the future.
apiversion: apps/v1
kind: deployment
metadata:
  name: app-staging
  namespace: staging
spec:
  replicas: 2
  selector:
    matchlabels:
      app: app-staging
  template:
    metadata:
      labels:
        app: app-staging
    spec:
      containers:
        - name: app-staging
          image: ""${docker_registry}/:${image_tag}""
          readinessprobe:
            failurethreshold: 6
            httpget:
              path: /
              port: 8000
            initialdelayseconds: 30
            periodseconds: 30
            successthreshold: 1
            timeoutseconds: 1
          imagepullpolicy: always
         # setting autodynatrace_forkable environment variable will cause an ominous looking error message similar to the one below:
         #
         #  `warning autodynatrace - init: could not initialize the oneagent sdk, agentstate: 1`
         #
         # this error message is expected when ""forkable"" mode is enabled. see the link below for more information:
         # https://github.com/dynatrace/oneagent-sdk-for-python/blob/fa4dd209b6a21407abca09a6fb8da1b85755ab0a/src/oneagent/__init__.py#l205-l217
          command: [""/bin/sh""]
          args:
            - -c
            - &gt;-
                /bin/sed -i -e ""s/# 'autodynatrace.wrappers.django'/'autodynatrace.wrappers.django'/"" /app//on_/on_/settings.py &amp;&amp;
                /usr/local/bin/python manage.py collectstatic --noinput &amp;&amp;
                autowrapt_bootstrap=autodynatrace autodynatrace_forkable=true /usr/local/bin/gunicorn --workers 8 --preload --timeout 120 --config gunicorn.conf.py --bind 0.0.0.0:8000
          env:
            - name: autodynatrace_pod_name
              valuefrom:
                fieldref:
                  apiversion: v1
                  fieldpath: metadata.name
            - name: autodynatrace_application_id
              value: django ($(autodynatrace_pod_name):8000)
          ports:
            - containerport: 8000
          volumemounts:
          # mount config in both locations while we migrate to running container as non-root user.
          - name: secrets
            readonly: true
            mountpath: /root/fhirengine/conf
          - name: secrets
            readonly: true
            mountpath: /home//fhirengine/conf
      imagepullsecrets:
        - name: jfrogcred
      volumes:
       - name: secrets
         secret:
            secretname: config
            defaultmode: 420
      restartpolicy: always
---
apiversion: v1
kind: service
metadata:
  name: app-staging
  namespace: staging
spec:
  ports:
    - name: app-staging
      port: 8000
      targetport: 8000
  selector:
    app: app-staging
---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: app-staging
  namespace: staging
  annotations:
    external-dns.alpha.kubernetes.io/hostname: staging.tv-pd.sh.io
    external-dns.alpha.kubernetes.io/type: internal
    kubernetes.io/ingress.class: nginx-internal
spec:
  rules:
    - host: staging.tv-pd.sh.io
      http:
        paths:
          - path: /
            backend:
              service:
                name: app
                port:
                  number: 8000
            pathtype: implementationspecific
            #pathtype is now required for each specified path. options are prefix, exact, and implementationspecific. to match the undefined v1beta1 behavior, use implementationspecific
---



",<kubernetes><manifest><amazon-eks><nginx-ingress>,75589893,1,"i see that your service is named &quot;app-staging&quot;
apiversion: v1
kind: service
metadata:
  name: app-staging

but in the ingress the path mapping to service is incorrectly identifying the service name as &quot;app&quot;
spec:
  rules:
    - host: staging.tv-pd.sh.io
      http:
        paths:
          - path: /
            backend:
              service:
                name: app
                port:
                  number: 8000

please change the backend service name in ingress to &quot;app-staging&quot; instead of &quot;app&quot;.
please accept the answer if this resolves your issue.
"
50406142,kubectl bash completion doesn't work in ubuntu docker container,"i'm using kubectl from within a docker container running on a mac. i've already successfully configured the bash completion for kubectl to work on the mac, however, it doesn't work within the docker container. i always get bash: _get_comp_words_by_ref: command not found. 

the docker image is based on ubuntu:16.04 and kubectl is installed via the line (snippet from the dockerfile)

curl -lo https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl &amp;&amp; \
mv kubectl /usr/local/bin


echo $bash_version gives me 4.3.48(1)-release, and according to apt, the bash-completionpackage is installed. 

i'm using iterm2 as terminal.

any idea why it doesn't work or how to get it to work?
",<bash><docker><autocomplete><kubernetes><kubectl>,50607259,70,"ok, i found it - i simply needed to do a source /etc/bash_completion before or after the source &lt;(kubectl completion bash).
"
73413519,how to redirect from http to https automatically in kubernetes_ingress_v1 with google compute cloud?,"i am using terraform to deploy a kube cluster to google kubernetes engine.
here is my ingress config - both http and https are working but i want http to auto redirect to https
resource &quot;kubernetes_ingress_v1&quot; &quot;ingress&quot; {
  wait_for_load_balancer = true
  metadata {
    name = &quot;ingress&quot;
  }
  spec {
    default_backend {
      service {
        name = kubernetes_service.frontend_service.metadata[0].name
        port {
          number = 80
        }
      }
    }
    rule {
      http {
        path {
          backend {
            service {
              name = kubernetes_service.api_service.metadata[0].name
              port {
                number = 80
              }
            }
          }
          path = &quot;/api/*&quot;
        }

        path {
          backend {
            service {
              name = kubernetes_service.api_service.metadata[0].name
              port {
                number = 80
              }
            }
          }
          path = &quot;/api&quot;
        }
      }
    }
    tls {

      secret_name = &quot;tls-secret&quot;
    }
  }
  depends_on = [kubernetes_secret_v1.tls-secret, kubernetes_service.frontend_service, kubernetes_service.api_service]
}


how can i configure the ingress to auto redirect from http to https?
",<kubernetes><terraform><google-kubernetes-engine><terraform-provider-gcp>,73427904,1,"the following worked for me - i got my hints from https://github.com/hashicorp/terraform-provider-kubernetes/issues/1326#issuecomment-910374103


resource &quot;kubectl_manifest&quot; &quot;app-frontend-config&quot; {
  wait_for_rollout = true
  yaml_body = yamlencode({
    apiversion = &quot;networking.gke.io/v1beta1&quot;
    kind       = &quot;frontendconfig&quot;
    metadata = {
      name = &quot;ingress-fc&quot;
    }
    spec = {
      redirecttohttps = {
        enabled = true
      }
    }
  })
}



resource &quot;kubernetes_ingress_v1&quot; &quot;ingress&quot; {
  wait_for_load_balancer = true
  metadata {
    name = &quot;ingress&quot;
    annotations = {
      &quot;networking.gke.io/v1beta1.frontendconfig&quot;         = kubectl_manifest.app-frontend-config.name
    }

  }
  spec {
    default_backend {
      service {
        name = kubernetes_service.frontend_service.metadata[0].name
        port {
          number = 80
        }
      }
    }
    rule {
      http {
        path {
          backend {
            service {
              name = kubernetes_service.api_service.metadata[0].name
              port {
                number = 80
              }
            }
          }
          path = &quot;/api/*&quot;
        }

        path {
          backend {
            service {
              name = kubernetes_service.api_service.metadata[0].name
              port {
                number = 80
              }
            }
          }
          path = &quot;/api&quot;
        }
      }
    }
    tls {

      secret_name = &quot;tls-secret&quot;
    }
  }
  depends_on = [kubernetes_secret_v1.tls-secret, kubernetes_service.frontend_service, kubernetes_service.api_service]
}


you need an additional module in your terraform block
   
    kubectl = {
      source  = &quot;gavinbunney/kubectl&quot;
      version = &quot;&gt;= 1.14.0&quot;
    }



do not forget to initialise the kubectl provider

provider &quot;kubectl&quot; {
  host                   = &quot;https://${google_container_cluster.primary.endpoint}&quot;
  token                  = data.google_client_config.default.access_token
  cluster_ca_certificate = base64decode(google_container_cluster.primary.master_auth[0].cluster_ca_certificate)
  load_config_file       = false
}


"
62162209,"ingress-nginx connects from outside minikube, but connection is refused from inside minikube","i am trying to access my ingress-nginx service from a service but it gives connection refused. here is my ingress

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: ingress-service
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/use-regex: ""true""
spec:
  rules:
    - host: ticketing.dev
      http:
        paths:
          - path: /api/users/?(.*)
            backend:
              servicename: auth-srv
              serviceport: 3000
          - path: /api/tickets/?(.*)
            backend:
              servicename: tickets-srv
              serviceport: 3000
          - path: /?(.*)
            backend:
              servicename: client-srv
              serviceport: 3000


apiversion: v1
kind: namespace
metadata:
  name: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
---
kind: service
apiversion: v1
metadata:
  name: ingress-nginx
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
spec:
  externaltrafficpolicy: local
  type: loadbalancer
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
  ports:
    - name: http
      port: 80
      protocol: tcp
      targetport: http
    - name: http
      port: 443
      protocol: tcp
      targetport: https


❯ kubectl get services -n ingress-nginx
name            type           cluster-ip       external-ip      port(s)                      age
ingress-nginx   loadbalancer   10.101.124.218   10.101.124.218   80:30634/tcp,443:30179/tcp   15m


the ingress-nginx is running on namespace ingress-nginx.
so it should be accessible by http://ingress-nginx.ingress-nginx.svc.cluster.local. but when i access it, it says connection refused 10.101.124.218:80. i am able to access the ingress from outside, i.e. from the ingress ip.

i am using minikube and used ingress by running minikube addons enable ingress. yes and im running the tunnel by minikube tunnel
",<nginx><kubernetes><kubernetes-ingress><minikube>,62180444,6,"i tested your environment and found the same behavior, external access but internally getting connection refused, this is how i solved:


the minikube ingress addon deploys the controller in kube-system namespace. if you try to deploy the service in a newly created namespace, it will not reach the deployment in kube-system namespace. 
it's easy to mix those concepts because the default nginx-ingress deployment uses the namespace ingress-nginx as you were trying.
another issue i found, is that your service does not have all selectors assigned to the controller deployment.
the easiest way to make your deployment work, is to run kubectl expose on the nginx controller:


kubectl expose deployment ingress-nginx-controller --target-port=80 --type=nodeport -n kube-system



using this command to create the nginx-ingress-controller service, all communications were working, both external and internal.




reproduction:


for this example i'm using only two ingress backends to avoid being much repetitive in my explanation.
using minikube 1.11.0
enabled ingress and metallb addons.
deployed two hello apps: v1 and v2, both pods listens on port 8080 and are exposed as node port as follows:


$ kubectl get services
name         type        cluster-ip       external-ip   port(s)          age
hello1-svc   nodeport    10.110.211.119   &lt;none&gt;        8080:31243/tcp   95m
hello2-svc   nodeport    10.96.9.66       &lt;none&gt;        8080:31316/tcp   93m



here is the ingress file, just like yours, just changed the backend services names and ports to match my deployed ones:


apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: ingress-service
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/use-regex: ""true""
spec:
  rules:
    - host: ticketing.dev
      http:
        paths:
          - path: /api/users/?(.*)
            backend:
              servicename: hello1-svc
              serviceport: 8080
          - path: /?(.*)
            backend:
              servicename: hello2-svc
              serviceport: 8080



now i'll create the nginx-ingress service exposing the controller deployment, this way all tags and settings will be inherited:


$ kubectl expose deployment ingress-nginx-controller --target-port=80 --type=nodep
ort -n kube-system
service/ingress-nginx-controller exposed



now we deploy the ingress object:


$ kubectl apply -f ingress.yaml 
ingress.networking.k8s.io/ingress-service created

$ kubectl get ingress
name              class    hosts           address      ports   age
ingress-service   &lt;none&gt;   ticketing.dev   172.17.0.4   80      56s

$ minikube ip
172.17.0.4



testing the ingress from the outside:


$ tail -n 1 /etc/hosts
172.17.0.4 ticketing.dev

$ curl http://ticketing.dev/?foo
hello, world!
version: 2.0.0
hostname: hello2-67bbbf98bb-s78c4

$ curl http://ticketing.dev/api/users/?foo
hello, world!
version: 1.0.0
hostname: hello-576585fb5f-67ph5



then i deployed a alpine pod to test the access from inside the cluster:


$ kubectl run --generator=run-pod/v1 -it alpine --image=alpine -- /bin/sh
/ # nslookup ingress-nginx-controller.kube-system.svc.cluster.local
server:         10.96.0.10
address:        10.96.0.10:53

name:   ingress-nginx-controller.kube-system.svc.cluster.local
address: 10.98.167.112

/ # apk update
/ # apk add curl

/ # curl -h ""host: ticketing.dev"" ingress-nginx-controller.kube-system.svc.cluster.local/?foo
hello, world!
version: 2.0.0
hostname: hello2-67bbbf98bb-s78c4

/ # curl -h ""host: ticketing.dev"" ingress-nginx-controller.kube-system.svc.cluster.local/api/users/?foo
hello, world!
version: 1.0.0
hostname: hello-576585fb5f-67ph5


as you can see, all requests were fulfilled.



note:


as pointed by @suren, when curling ingress, i had to specify the host with -h
the service name needs to be fully fqdn because we are dealing with a service hosted in another namespace, using the format &lt;svc_name&gt;.&lt;namespace&gt;.svc.cluster.local.
in your js app, you will have to pass the host argument in order to reach the ingress.


if you have any question let me know in the comments.
"
74882731,using tojson or torawjson without having it automatically adding quotation marks?,"so i have a values.yaml file with an string variable representing a database connection string with no quotes looking like this (don't worry, not the real password):
actionlogsconnectionstring: database=actionlogs;server=sql_dev;user id=sa;password=y19|yx\dysh53&amp;h

my goal is to print it inside a configmap resource so that it can then be injected in my pod as a .json configuration file for a dotnet app. i also want to append the application name in the connection string:
apiversion: v1
kind: configmap
metadata:
  name: {{ include &quot;asp.fullname&quot; . }}
  labels:
    {{- include &quot;asp.labels&quot; . | nindent 4 }}
data:
  appsettings.k8s.json: |-
    {
      &quot;connectionstrings&quot;: {
        &quot;actionlogsconnectionstring&quot;: &quot;{{ .values.actionlogsconnectionstring }};application name=asp;&quot;
      }
    }

this produce this result:
&quot;actionlogsconnectionstring&quot;: &quot;database=actionlogs;server=sql_dev;user id=sa;password=y19|yx\dysh53&amp;h;application name=asp;&quot;

look great! and at this point i don't have a quote problem.
now problem, the slash isn't escaped for the json file format. good thing, helm provide a tojson function. unfortunately, it also transform the &quot;&amp;&quot; to unicode value. i then found torawjson and it gives the expected results.
my problem is that, when using either tojson or torawjson, it adds extra quotes and break my result:
so this yalm file:
&quot;actionlogsconnectionstring&quot;: &quot;{{ .values.actionlogsconnectionstring | torawjson }};application name=asp;&quot;

results in this json file (note the extra quotes):
&quot;actionlogsconnectionstring&quot;: &quot;&quot;database=actionlogs;server=sql_dev;user id=sa;password=y19|yx\\dysh53&amp;h&quot;;application name=asp;&quot;

i see there's a function called | quote, but this only add some. no way to use torawjson without adding any?
",<kubernetes><kubernetes-helm>,74882987,3,"using tojson or torawjson is the wrong solution here, because the json representation of a string by definition includes the double quotes. &quot;foo&quot; is a json string, foo isn't valid json.
but you're only working with a scalar value, so there's not much point in marshaling it to json in the first place. i think the following gets you what you want:
apiversion: v1
kind: configmap
metadata:
  name: {{ include &quot;asp.fullname&quot; . }}
  labels:
    {{- include &quot;asp.labels&quot; . | nindent 4 }}
data:
  appsettings.k8s.json: |-
    {
      &quot;connectionstrings&quot;: {
        &quot;actionlogsconnectionstring&quot;: {{ printf &quot;%s;application name=asp&quot; .values.actionlogsconnectionstring | quote }}
      }
    }

here, we're using the printf to produce the desired string (and then passing it to the quote function for proper quoting).
this produces:
---
# source: example/templates/configmap.yaml
apiversion: v1
kind: configmap
metadata:
  name: my-example-fullname
  labels:
    # this is a test
data:
  appsettings.k8s.json: |-
    {
      &quot;connectionstrings&quot;: {
        &quot;actionlogsconnectionstring&quot;: &quot;database=actionlogs;server=sql_dev;user id=sa;password=y19|yx\\dysh53&amp;h;application name=asp&quot;
      }
    }

"
58501558,"cannot list resource ""configmaps"" in api group when deploying weaviate k8s setup on gcp","when running (on gcp):

$ helm upgrade \
  --values ./values.yaml \
  --install \
  --namespace ""weaviate"" \
  ""weaviate"" \
  weaviate.tgz


it returns;

upgrade failed
error: configmaps is forbidden: user ""system:serviceaccount:kube-system:default"" cannot list resource ""configmaps"" in api group """" in the namespace ""ku
be-system""
error: upgrade failed: configmaps is forbidden: user ""system:serviceaccount:kube-system:default"" cannot list resource ""configmaps"" in api group """" in t
he namespace ""kube-system""


update: based on solution

$ vim rbac-config.yaml


add to the file:

apiversion: v1
kind: serviceaccount
metadata:
  name: tiller
  namespace: kube-system
---
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: tiller
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: cluster-admin
subjects:
  - kind: serviceaccount
    name: tiller
    namespace: kube-system


run:

$ kubectl create -f rbac-config.yaml
$ helm init --service-account tiller --upgrade


note: based on helm v2.
",<kubernetes><google-cloud-platform><kubernetes-helm><weaviate>,58501784,4,"tl;dr: setup helm with the appropriate authorization settings for your cluster, see https://v2.helm.sh/docs/using_helm/#role-based-access-control

long answer

your experience is not specific to the weaviate helm chart, rather it looks like helm is not setup according to the cluster authorization settings. other helm commands should fail with the same or a similar error.

the following error 

error: configmaps is forbidden: user ""system:serviceaccount:kube-system:default"" cannot list resource ""configmaps"" in api group """" in the namespace ""ku
be-system""


means that the default service account in the kube-system namespace is lacking permissions. i assume you have installed helm/tiller in the kube-system namespace as this is the default if no other arguments are specified on helm init. since you haven't created a specific service account for tiller to use it defaults to the default service account.

since you are mentioning that you are running on gcp, i assume this means you are using gke. gke by default has rbac authorization enabled. in an rbac setting no one has any rights by default, all rights need to be explicitly granted.

the helm docs list several options on how to make helm/tiller work in an rbac-enabled setting. if the cluster has the sole purpose of running weaviate you can choose the simplest option: service account with cluster-admin role. the process described there essentially creates a dedicated service account for tiller, and adds the required clusterrolebinding to the existing cluster-admin clusterrole. note that this effectively makes helm/tiller an admin of the entire cluster.

if you are running a multi-tenant cluster and/or want to limit tillers permissions to a specific namespace, you need to choose one of the alternatives.
"
74267962,running `kubectl exec` script from file is not working,"i'm trying to create a script in order to run multiple kubectl exec commands against multiple pods with multiple containers. the script seems to generate the command just fine but errors out when attempting to run it.
example command that is generated: kubectl -n &lt;namespace&gt; exec &lt;pod_name&gt; -c &lt;container_name&gt; -- openssl version
when i copy the generated command and run it directly it works fine, but if i try to run the command within the script i get an error.
oci runtime exec failed: exec failed: unable to start container process: exec: &quot;openssl version&quot;: executable file not found in $path: unknown

command terminated with exit code 126
snippet from .sh file:
for pod in $pods; do
containers=($(kubectl -n $namespace get pods $pod -o jsonpath='{.spec.containers[*].name}' | tr -s '[[:space:]]' '\n'))
header &quot;{pod: \&quot;$pod\&quot;, containers: \&quot;$(echo $containers | tr -d '\n')\&quot;}&quot;

if [ &quot;$dryrun&quot; != &quot;true&quot; ]; then
    for container in $containers; do
        echo &quot;command being run: \&quot;kubectl -n $namespace exec $pod -c $container -- $command\&quot;&quot;
        kubectl -n $namespace exec $pod -c $container -- $command
    done
fi
done

",<kubernetes><kubectl><amazon-eks>,74287833,1,"haha, this is exactly the problem i'm trying to solve. by any chance, are you trying to check openssl versions on all containers due to the latest cve's dropping yesterday? because thats exactly what i'm trying to do.
anyway, here is the solution - a problem in which i've had before and its down to the way sh/bash/zsh interprets strings.
it's hard to debug, as i'd need to see you're whole script instead of just the pod exec loop, but the underlying problem is: $command cannot be placed into a string or used as a string, otherwise your shell script will wrap it into a string and kubectl will interpret that as the whole thing being a command instead of correctly forwarding the breakpoints.
this is evident by the error message, its trying to interpret openssl version literally as a whole string that makes up the binary name you are trying to call, in which obviously openssl version isn't a command that will be on your $path, instead of correctly interpreting each command in the string and executing openssl which is on your $path with the version argument against it.
as i'm not sure if i've explained that very well, so to assist, here are some visual/working examples.
this will not work:
# ./my-script.sh openssl version
# will oci error as &quot;openssl version&quot; cannot be found in the containers $path

kubectl exec &quot;${pod}&quot; -c &quot;${container}&quot; -- &quot;${@:1}&quot;

command=&quot;${@:1}&quot;

kubectl exec &quot;${pod}&quot; -c &quot;${container}&quot; -- $command

command=${@:1}

kubectl exec &quot;${pod}&quot; -c &quot;${container}&quot; -- &quot;${command}&quot;

this will work:
# ./my-script.sh openssl version
# libressl 3.3.6

kubectl exec &quot;${pod}&quot; -c &quot;${container}&quot; -- ${@:1}

command=${@:1}

kubectl exec &quot;${pod}&quot; -c &quot;${container}&quot; -- $command

simply put, if the command that you wish to forward is used as a string, it will not work.
"
75203695,microk8s kafka producer connection failure,"i am attempting to create a simple producer and consumer with two python scripts, using kafka deployed on microk8s. however, when running the producer.py script, i get the following error on repeat:
...|fail|rdkafka#producer-1| [thrd:...:9092/bootstrap]: ...:9092/bootstrap: connect to ipv4#localhost:9092 failed: connection refused (after 0ms in state connect, ... identical error(s) suppressed

i am fairly confident that this issue is a result of the listeners not being configured correctly, but i have so far been unable to figure out what i need to do to fix them, due to what i assume is my complete lack of any knowledge in this area. i have reviewed these resources, in addition to several others from this site, but have been unable to find a solution, or at least a solution i can understand enough to act upon.
steps to reproduce:
the python scripts to generate the producer and consumer can be found here.
for microk8s installation, i followed these instructions. i also installed helm, since my project requirements dictate that i use helm charts.
i then installed kafka using:
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install kafka-release bitnami/kafka

",<python><kubernetes><apache-kafka><kubernetes-helm><microk8s>,75225154,1,"the python code in the linked post uses 'localhost:9092', as the error also shows - connect to ipv4#localhost:9092 failed
if you are trying to run that code in a k8s pod, then you need to give the external broker dns addresses, not the local pod address.
if you run the python code from outside the k8s cluster, you need to expose a clusterip / nodeport external service or ingress (as the linked strimzi post shows; plus, you can can still use strimzi operator with helm, so you don't really need the bitnami charts).

at a high level, the advertisted.listeners tells clients how to connect to a specific broker. if you advertise localhost, the pod will try to connect to itself, even if the bootstrap connection worked (setup by just listeners). if you advertise kafka.svc.cluster.local, then it will try to connect to the kafka service in the default namespace... but you still need to actually set boostrap.servers = kafka.svc.cluster.local:9092, for example.
"
48670077,how to load the current kubernetes cluster configuration with kops?,"using kops to retrieve the configuration be used with the following:

kops get cluster --name &lt;cluster-name&gt; --output yaml


then, we have to call the instance groups configuration with the following:

kops get ig --name &lt;cluster-name&gt; --output yaml

joining the documents require to add the yaml separator ---.

is there a simpler way to retrieve the current kubernetes cluster configuration with kops?
",<configuration><kubernetes><kops><google-kubernetes-engine>,48670078,3,"according to https://github.com/kubernetes/kops/issues/1758#issuecomment-336604987, the following command will print out the original configuration used to create the cluster:

kops get -o yaml

the configuration will include the entire cluster definition!
"
66293825,kubernetes: how to update a live busybox container's 'command',"i have the following manifest that created the running pod named 'test'
apiversion: v1
kind: pod
metadata:
  name: hello-world
  labels:
    app: blue
spec:
  containers:
  - name: funskies
    image: busybox
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo 'hello world'&quot;]

i want to update the pod to include the additional command
apiversion: v1
kind: pod
metadata:
  name: hello-world
  labels:
    app: blue
spec:
  containers:
  restartpolicy: never
  - name: funskies
    image: busybox
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo 'hello world' &gt; /home/my_user/logging.txt&quot;]

what i tried
kubectl edit pod test

what resulted
# please edit the object below. lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. if an error occurs while saving this file will be
# reopened with the relevant failures.
#
# pods &quot;test&quot; was not valid:
# * spec: forbidden: pod updates may not change fields other than `spec.containers[*].image`...

other things i tried:
updated the manifest and then ran apply - same issue
kubectl apply -f test.yaml 

question: what is the proper way to update a running pod?
",<kubernetes><kubernetes-pod>,66294347,3,"you can't modify most properties of a pod.  typically you don't want to directly create pods; use a higher-level controller like a deployment.
the kubernetes documentation for a podspec notes (emphasis mine):

containers: list of containers belonging to the pod. containers cannot currently be added or removed. there must be at least one container in a pod. cannot be updated.

in all cases, no matter what, a container runs a single command, and if you want to change what that command is, you need to delete and recreate the container.  in kubernetes this always means deleting and recreating the containing pod.  usually you shouldn't use bare pods, but if you do, you can create a new pod with the new command and delete the old one.  deleting pods is extremely routine and all kinds of ordinary things cause it to happen (updating deployments, a horizontalpodautoscaler scaling down, ...).
if you have a deployment instead of a bare pod, you can freely change the template: for the pods it creates.  this includes changing their command:.  this will result in the deployment creating a new pod with the new command, and once it's running, deleting the old pod.
the sorts of very-short-lived single-command containers you show in the question aren't necessarily well-suited to running in kubernetes.  if the pod isn't going to stay running and serve requests, a job could be a better match; but a job believes it will only be run once, and if you change the pod spec for a completed job i don't think it will launch a new pod.  you'd need to create a new job for this case.
"
55368069,"helm error ""error: this command needs 2 arguments: release name, chart path""","i am getting an error in my kubernetes cluster while upgrading my install of kamus
$ helm --debug upgrade --install soluto/kamus

[debug] created tunnel using local port: '64252'
[debug] server: &quot;127.0.0.1:64252&quot;
error: this command needs 2 arguments: release name, chart path

using helm version 2.13.1
this error is also known to be cause by not correctly using --set correctly or as intended.
as an example when upgrading my ingress-nginx/ingress-nginx installing as such:
 --set &quot;controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-health-probe-request-path&quot;=/healthz,&quot;controller.service.annotations.service\.beta\.kubernetes\.io/azure-dns-label-name&quot;=$dns_label

this caused the same error as listed above.
when i removed the quotations it worked as intended.
 --set controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-health-probe-request-path=/healthz,controller.service.annotations.service\.beta\.kubernetes\.io/azure-dns-label-name=$dns_label

the error in this case had nothing to do with not correctly setting a release name and or chart. more explanation of --set issues and solutions are below.
",<kubernetes><kubernetes-helm>,55372448,12,"helm upgrade command requires release name and chart path. in your case, you missed release name.


  helm upgrade [release] [chart] [flags]


helm --debug upgrade --install kamus soluto/kamus should work.
"
64189913,kubectl describe unknown shorthand flag -o,"i think -o is supposed be an universal option for kubectl.
but, somehow i get the following error when i run the following kubectl command.
can you please tell me why? thank you.
mamun$ kubectl describe secret -n development serviceaccount-foo -o yaml
error: unknown shorthand flag: 'o' in -o
see 'kubectl describe --help' for usage.

",<kubernetes><google-cloud-platform><google-kubernetes-engine><kubectl>,64190154,12,"-o | --output is not a universal flag, it is not included in the default kubectl flags (1.18) and kubectl describe does not support the --output (or shorthand -o) flag.
"
52096192,not able to change kubernetes logs directory,"i want to change kubelet logs directory location. for achieving same i have modified /etc/systemd/system/kubelet.service.d/10-kubeadm.conf file contents as follows(as mentioned in how to change kubelet working dir to somewhere else)

# note: this dropin only works with kubeadm and kubelet v1.11+
[service]
environment=""kubelet_kubeconfig_args=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf""
environment=""kubelet_config_args=--config=/var/lib/kubelet/config.yaml""
environment=""kubelet_extra_args=--root-dir=/d/kubelet-files/ --log-dir=/d/kubelet-logs/""
# this is a file that ""kubeadm init"" and ""kubeadm join"" generates at runtime, populating the kubelet_kubeadm_args variable dynamically
environmentfile=-/var/lib/kubelet/kubeadm-flags.env
# this is a file that the user can use for overrides of the kubelet args as a last resort. preferably, the user should use
# the .noderegistration.kubeletextraargs object in the configuration files instead. kubelet_extra_args should be sourced from this file.
environmentfile=-/etc/sysconfig/kubelet
execstart=
execstart=/usr/bin/kubelet $kubelet_kubeconfig_args $kubelet_config_args $kubelet_extra_args $kubelet_kubeadm_args


after this i executed commands :

systemctl daemon-reload
systemctl restart kubelet


even i restarted kubeadm. but still logs directory location is not changed and it goes on writing to default /var/lib/kubelet directory . i am using kubernetes version: v1.11.2. what might be the issue?
",<kubernetes><kubectl><minikube><google-kubernetes-engine>,52100763,1,"i have tried on some machines of mine on gcloud with v1.11.2
and i noticed the same your problem.

the parameter --log-dir in kubelet seems to have no effect.

it is worth opening an issue in kubelet project.
"
60300051,how to know more details about a previous rollout revision using kubectl?,"there are commands given here which explain how to perform a rollback using kubectl. one that lists the previous versions of your deployment is: 

kubectl rollout history deployment/mydeployment

this shows a list of previous versions based on their order and just their corresponding numbers. but how to know more details about them? it is hard to know which version i am rolling back to by just looking at a number. 
",<kubernetes><kubectl>,60300191,20,"you can use the revision flag to get more information:


  kubectl rollout history deployment/&lt;deployment-name&gt;  --revision=&lt;revision-number&gt;


this will give you details about the pod template used in the specified revision number.

if you want the date on which the revision was deployed, use the -o yaml flag and check for creationtimestamp


  kubectl rollout history deployment/&lt;deployment-name&gt;  --revision=&lt;revision-number&gt;  -o yaml

"
66298747,how can i join a alb ingress group instead of overriding an existing one in eks?,"i am deploying k8s to aws eks cluster and use alb for the deployments. i'd like to use one alb for multiple services but i can't figure out how to share the same alb. every time i deploy a ingress it will override an existing one.
i have two config yaml file:
a.yaml
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: sample-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sample-ingress
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/group.order: '1'
spec:
  rules:
    - http:
        paths:
          - path: /sample-app/*
            backend:
              servicename: sample-entrypoint
              serviceport: 80

b.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: sample-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sample-ingress
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/group.order: '2'
spec:
  rules:
    - http:
        paths:
          - path: /sample-es/*
            backend:
              servicename: sample-es-entrypoint
              serviceport: 9200

i'd like both share the same alb so i specify the group name to be the same:
alb.ingress.kubernetes.io/group.name: sample-ingress
i also specify a different order in the two files.
but when i run kubectl apply -f a.yaml, it creates a alb with the rule i specified in the config file: /sample-app/*. but when i run kubectl apply -f b.yaml, it overrides the existing rule with /sample-es/*. so how can i make both share the same alb and allow them provide different rules?
",<amazon-web-services><kubernetes><amazon-eks>,66300916,2,"i guess you can create separate ingress and attach them to the same service configuration. point the service configuration with alb, and that should work. i have a configuration for internal-facing services, please see if this works for you.
apiversion: v1
kind: service
metadata:
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
  labels:
    app.kubernetes.io/instance: goldendev-ingress-test
    app.kubernetes.io/managed-by: tiller
    app.kubernetes.io/name: ingress-test
    environment: dev
    helm.sh/chart: ingress-test
  name: ingress-test
  namespace: default
spec:
  externaltrafficpolicy: cluster
  ports:
  - name: http
    port: 80
    protocol: tcp
    targetport: 8080
  selector:
    app.kubernetes.io/instance: z1
    app.kubernetes.io/name: gunicorn
  sessionaffinity: none
  type: loadbalancer

ingress.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: sample-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sample-ingress
    alb.ingress.kubernetes.io/scheme: internal
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/group.order: '1'
spec:
  rules:
    - http:
        paths:
          - path: /mappings/v1/hello/*
            backend:
              servicename: ingress-test
              serviceport: 80
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: sample-ingress-1
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sample-ingress
    alb.ingress.kubernetes.io/scheme: internal
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/group.order: '2'
spec:
  rules:
    - http:
        paths:
          - path: /mappings/v1/teams/*
            backend:
              servicename: ingress-test-2
              serviceport: 80

i verified in the aws console, it has created only 1 load balancer with service configuration.
ingress list:
 kubectl get ingress
name               hosts   address   ports   age
sample-ingress     *                 80      19m
sample-ingress-1   *                 80      19m

let me know if this helps.
"
35513855,daemonsets on google container engine (kubernetes),"i have a google container engine cluster with 21 nodes, there is one pod in particular that i need to always be running on a node with a static ip address (for outbound purposes). 

kubernetes supports daemonsets

this is a way to have a pod be deployed to a specific node (or in a set of nodes) by giving the node a label that matches the nodeselector in the daemonset. you can then assign a static ip to the vm instance that the labeled node is on. however, gke doesn't appear to support the daemonset kind.

$ kubectl create -f go-daemonset.json 
error validating ""go-daemonset.json"": error validating data: the server could not find the requested resource; if you choose to ignore these errors, turn validation off with --validate=false

$ kubectl create -f go-daemonset.json --validate=false
unable to recognize ""go-daemonset.json"": no kind named ""daemonset"" is registered in versions ["""" ""v1""]


when will this functionality be supported and what are the workarounds?
",<kubernetes><google-kubernetes-engine>,35515624,6,"if you only want to run the pod on a single node, you actually don't want to use a daemonset. daemonsets are designed for running a pod on every node, not a single specific node.

to run a pod on a specific node, you can use a nodeselector in the pod specification, as documented in the node selection example in the docs.



edit: but for anyone reading this that does want to run something on every node in gke, there are two things i can say:

first, daemonset will be enabled in gke in version 1.2, which is planned for march. it isn't enabled in gke in version 1.1 because it wasn't considered stable enough at the time 1.1 was cut.

second, if you want to run something on every node before 1.2 is out, we recommend creating a replication controller with a number of replicas greater than your number of nodes and asking for a hostport in the container spec. the hostport will ensure that no more than one pod from the rc will be run per node.
"
67720940,what is the alternative of csshx for kubernetes pods?,"i use kubectl exec -it for logging into a single kubernetes pod.
is there any way to log in to multiple pods in a cluster, at the same time with a single command (just like csshx)?
",<kubernetes><ssh><kubectl>,67724141,3,"there is a plugin that could help you with this. it's called kubectl-tmux-exec:

a kubectl plugin that controls multiple pods simultaneously using
tmux.
it is to kubectl exec as csshx or pssh is to ssh.
instead of exec bash into multiple pod's containers one-at-a-time,
like kubectl exec pod{n} /bin/bash.
you can now use
kubectl tmux-exec -l app=nginx /bin/bash


all necessary details regarding installation and usage can be found in the linked docs.
"
68805680,what is the correct way to identify an application is deployed successfully with all pods up on kubernetes?,"after deploying your pods, how one can identify that all the pods are up and running? i have listed down few options which i think could be correct but wanted to understand what is the standard way to identify the successful deployment.

connect to application via its interface and use it to identify if all the pods (cluster) are up (maybe good for stateful applications). for stateless applications pod is up should be enough.
expose a restful api service which monitors the deployment and responds accordingly.
use kubectl to connect to pods and get the status of pods and containers running.

i think number 1 is the right way but wanted to understand community view on it.
",<kubernetes><kubernetes-pod>,68815574,1,"all your approaches sounds reasonable and will do the job, but why not just use the tools that kubernetes is giving us exactly for this purpose ? ;)
there are two main health check used by kubernetes:

liveness probe- to know if container is running and working without issues (not hanged, not in deadlock state)
readiness probe - to know if container is able to accept more requests

worth to note there is also &quot;startup probe&quot; which is responsible for protecting slow starting containers with difficult to estimate start time.
liveness:
as mentioned earlier, main goal of the liveness probe is to ensure that container is not dead. if it is dead, kubernetes removes the pod and start a new one.
readiness:
the main goal of the readiness probe is to check if container is able to handle additional traffic. in some case, the container may be working but it can't accept a traffic. you are defining readiness probes the same as the liveness probes, but the goal of this probe it to check if application is able to answer several queries in a row within a reasonable time. if not, kubernetes stop sending traffic to the pod until it passes readiness probe.
implementation:
you have a few ways to implement probes:

run a command every specified period of time and check if it was done correctly - the return code is 0 (in this example, the command cat /tmp/healthy is running every few seconds).
send a http get request to the container every specified period of time and check if it returns a success code (in this example, kubernetes is sending a http request to the endpoint /healthz defined in container).
attempt to open a tcp socket in the container every specified period of time and make sure that connection is established (in this example,  kubernetes is connecting to container on port 8080).

for both probes you can define few arguments:


initialdelayseconds: number of seconds after the container has started before liveness or readiness probes are initiated. defaults to 0 seconds. minimum value is 0.
periodseconds: how often (in seconds) to perform the probe. default to 10 seconds. minimum value is 1.
timeoutseconds: number of seconds after which the probe times out. defaults to 1 second. minimum value is 1.
successthreshold: minimum consecutive successes for the probe to be considered successful after having failed. defaults to 1. must be 1 for liveness and startup probes. minimum value is 1.
failurethreshold: when a probe fails, kubernetes will try  failurethreshold  times before giving up. giving up in case of liveness probe means restarting the container. in case of readiness probe the pod will be marked unready. defaults to 3. minimum value is 1.


combining these two health checks will make sure that the application has been deployed and is working correctly - liveness probe for ensuring that pod is restarted when it container in it stopped working and readiness probe for ensuring that traffic does not reach pod with not-ready or overloaded container. the proper functioning of the probes requires an appropriate selection of the implementation method and definition of arguments - most often by trial and error. check out these documentation:

configure liveness, readiness and startup probes - kubernetes documentation
kubernetes best practices: setting up health checks with readiness and liveness probes - google cloud

"
68582196,"why my ""certificate"" object and ""ingress"" both are creating certificates?","why my &quot;certificate&quot; object and &quot;ingress&quot; both are creating certificates ?
apiversion: cert-manager.io/v1
kind: certificate
metadata:
  name: blog-app-crt
spec:
  secretname: blog-app-crt-sec
  issuerref:
    kind: clusterissuer
    name: letsencrypt-prod
  commonname: blog.mydomain.com
  dnsnames:
    - blog.mydomain.com




apiversion: cert-manager.io/v1
kind: clusterissuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    # email address used for acme registration
    email: myemailid@gmail.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privatekeysecretref:
      # name of a secret used to store the acme account private key
      name: letsencrypt-production-private-key
    # add a single challenge solver, http01 using nginx
    solvers:
    - http01:
        ingress:
          class: nginx


apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-service
  annotations:
    kubernetes.io/ingress.class: nginx                      
    nginx.ingress.kubernetes.io/rewrite-target: /$1         
    cert-manager.io/cluster-issuer: &quot;letsencrypt-prod&quot;       
    nginx.ingress.kubernetes.io/ssl-redirect: 'true'        

spec:
  tls:
    - hosts:                                                
        - blog.mydomain.com
      secretname: blog-app-crt-sec                      
      
  rules:                                                    
    - host: blog.mydomain.com                                         
      http:                                                 
        paths:                                              
          - pathtype: prefix
            path: &quot;/?(.*)&quot;                                    
            backend:
              service:
                name: app-1-endpoint
                port: 
                  number: 5000                            
          - pathtype: prefix
            path: &quot;/tribute/?(.*)&quot;
            backend:
              service:
                name: app-2-endpoint
                port: 
                  number: 5001

when i create above objects, it is creating 2 certificate ojects, both pointing to same secret.

blog-app-crt-sec
blog-app-crt

how can i create only 1 certificate ? if i create only a clusterissuer without any custom certificate, then of course that will solve the issue, but i want to create a custom certificate to control the renewal stuff.
",<kubernetes><ssl-certificate><kubernetes-ingress><cert-manager>,68582327,2,"there is a component of cert-manager called ingress-shim that watches ingress resources and automatically creates certificate objects for you when some annotations are present. this way, you wouldn’t even need to create the certificate object on your own.
please check your ingress definition for corresponding cert-manager.io scoped annotations and either use those or the manually created certificate. i assume you refer to the secret named blog-app-crt in your ingress definition. this needs to match what is defined in the cert spec secretname if you don’t use the automated creation!
for details on automatic certificate creation, please check the cert-manager docs on ingress: https://cert-manager.io/docs/usage/ingress/
"
58551946,how to add internal dns records in kubernetes,"i'm currently setting up a kubernetes cluster where both private and public services are run. while public services should be accessible via the internet (and fqdns), private services should not (the idea is to run a vpn inside the cluster where private services should be accessible via simple fqdns).

at the moment, i'm using nginx-ingress and configure ingress resources where i set the hostname for public resources. external-dns then adds the corresponding dns records (in google clouddns) - this already works.

the problem i'm facing now: i'm unsure about how i can add dns records in the same way (i.e. simply specifying a host in ingress definitions and using some ingress-class private), yet have these dns records only be accessible from within the cluster.

i was under the impression that i can add these records to the corefile that coredns is using. however, i fail to figure out how this can be automated.

thank you for any help!
",<kubernetes><dns><kubernetes-ingress><nginx-ingress><coredns>,58574747,1,"i managed to resolve the problem myself... wrote a little go application which watches ingress resources and adds rewrite rules to the corefile read by coredns accordingly... works like a charm :)

ps: if anyone wants to use the tool, let me know. i'm happy to make it open-source if there is any demand.
"
57601495,how to leverage kubectl patch deployment to update an environment variable?,"i'm trying to patch a deployment, but i keep hitting deployment.extensions/velero not patched.

i've tried a few different variations of the following: 

kubectl patch deployment velero -n velero -p '{""spec"":{""containers"":[{""env"":[{""name"":""aws_cluster_name"",""value"":""test-cluster""}]}]}}'


my initial deployment.yaml file

apiversion: apps/v1
kind: deployment
metadata:
  name: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: tiller
    helm.sh/chart: velero-2.1.1
spec:
  replicas: 1
  selector:
    matchlabels:
      app.kubernetes.io/instance: velero
      app.kubernetes.io/name: velero
  template:
    metadata:
      labels:
        app.kubernetes.io/name: velero
        app.kubernetes.io/instance: velero
        app.kubernetes.io/managed-by: tiller
        helm.sh/chart: velero-2.1.1
    spec:
      restartpolicy: always
      serviceaccountname: velero-server
      containers:
        - name: velero
          image: ""gcr.io/heptio-images/velero:v1.0.0""
          imagepullpolicy: ifnotpresent
          command:
            - /velero
          args:
            - server
          volumemounts:
            - name: plugins
              mountpath: /plugins
            - name: cloud-credentials
              mountpath: /credentials
            - name: scratch
              mountpath: /scratch
          env:
            - name: aws_shared_credentials_file
              value: /credentials/cloud
            - name: velero_scratch_dir
              value: /scratch
      volumes:
        - name: cloud-credentials
          secret:
            secretname: cloud-credentials
        - name: plugins
          emptydir: {}
        - name: scratch
          emptydir: {}


i'm a bit stuck right now and fear i may be going about this the wrong way. any suggestions would be much appreciated.
",<kubernetes><yaml><kubectl>,57602023,89,"apart from kubectl patch command, you can also make use of kubectl set env to update environment variable of k8s deployment.

kubectl set env deployment/velero aws_cluster_name=test-cluster


hope this helps.
"
70372203,kubernetes force service to use https,"i want to expose k8s api's using a service. my issue is that the api only respond on port 6443 on https. any attempt on http return status 400 bad request. how can i &quot;force&quot; the service to user https ?
apiversion: v1
kind: service
metadata:
  name: k8s-api
  namespace: kube-system
  labels:
    label: k8s-api
spec:
  ports:
  - port: 80 #port on which your service is running
    targetport: 6443
    protocol: tcp
    name: http
  selector:
    name: kube-apiserver-master-node 

may be this ?
apiversion: v1
kind: service
metadata:
  name: k8s-api
  namespace: kube-system
  labels:
    label: k8s-api
spec:
  ports:
  - port: 443 #port on which your service is running
    targetport: 6443
    protocol: tcp
    name: http
  selector:
    name: kube-apiserver-master-node 

",<kubernetes><kubernetes-service><kubernetes-apiserver>,70373827,2,"if you are using the nginx ingress by default it does ssl off load and sends plain http in the background.
changing port 6443 might be helpful if you request direct connecting to the service.
if you are using the nginx ingress make sure it doesn't terminate ssl.
nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;
nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;

"
65110867,kubernetes - no internet coming in pods,"i have been working in kubernetes for a while and i have a docker image of wildfly application. in the stanalone.xml of the wildfly, the connection to datasources are defined as follows:
&lt;datasource jta=&quot;true&quot; jndi-name=&quot;java:/db&quot; pool-name=&quot;db&quot; enabled=&quot;true&quot; use-ccm=&quot;true&quot;&gt;
                    &lt;connection-url&gt;jdbc:mysql://ip:3306/db_name?zerodatetimebehavior=converttonull&amp;amp;autoreconnect=true&lt;/connection-url&gt;
                    &lt;driver-class&gt;com.mysql.cj.jdbc.driver&lt;/driver-class&gt;
                    &lt;driver&gt;mysql&lt;/driver&gt;
                    &lt;security&gt;
                        &lt;user-name&gt;root&lt;/user-name&gt;
                        &lt;password&gt;root&lt;/password&gt;
                    &lt;/security&gt;
                &lt;/datasource&gt;

i have one worker node and 2 replicas of the same pod are running in it. but currently i observed that internet is not able to reach my pods. i am trying with

ping google.com

it is not giving response as expected. already i am using loadbalancer services to expose the ports.
apiversion: v1
kind: service
metadata:
  name: re-demo
  namespace: default
spec:
  type: loadbalancer 
  selector: 
    app: re-demo
  ports:
  - port: 9575 
    targetport: 9575
    nodeport: 32756
  externaltrafficpolicy: cluster 

how can i solve this ??
",<network-programming><kubernetes><kubernetes-pod>,65248126,1,"there was mistake when i set up the cluster.
kubeadm init --apiserver-advertise-address 10.128.0.12 --pod-network-cidr=10.244.0.0/16

cidr address we should give just like what we have in our kube_flannel.yaml file. if you want to change the ip adress in the cidr, then first make changes in the kube_flannel.yaml file.
otherwise, it will result in the no internet availability of the pods. and we need to use the hostnetwork =true property for internet connection, but which turn prevents us some running more than one replica of same pod in the same node.
"
57575059,issues with ports on headless service attached to stateless set,"hi i am trying to expose 5 ports for an informix container which is within a statefulset. it has a headless service attached, to allow other internal stateless sets communicate with it internally. 

i can ping the headless service informix-set-service from my informix-0 pod and other pods however when i try nmap -p 9088 informix-set-service the port is listed as closed. i am assuming this is because my yaml is wrong but i can't for the life find out where it's wrong. 

it appears that the headless service is indeed attached and pointing at the correct stateful-set and within the minikube dashboard everything looks and appears to be correct.

service minikube dash screenshot

informix@informix-0:/$ nmap -p 9088 informix-set-service

starting nmap 6.47 ( http://nmap.org ) at 2019-08-20 03:50 utc
nmap scan report for informix-set-service (172.17.0.7)
host is up (0.00011s latency).
rdns record for 172.17.0.7: informix-0.informix.default.svc.cluster.local
port     state  service
9088/tcp closed unknown

nmap done: 1 ip address (1 host up) scanned in 0.03 seconds
informix@informix-0:/$ nmap -p 9088 localhost

starting nmap 6.47 ( http://nmap.org ) at 2019-08-20 03:50 utc
nmap scan report for localhost (127.0.0.1)
host is up (0.00026s latency).
other addresses for localhost (not scanned): 127.0.0.1
port     state service
9088/tcp open  unknown

nmap done: 1 ip address (1 host up) scanned in 0.06 seconds


anyone got any ideas?

deployment yaml snippet:

###############################################################################
# informix container
###############################################################################
#
# headless service for informix container statefulset.
# headless service with clusterip set to null
# create dns records for informix container hosts.
#
apiversion: v1
kind: service
metadata:
  name: informix-set-service
  labels:
    component: informix-set-service
    provider: ibm
spec:
  clusterip: none
  ports:
  - port: 9088
    name: informix
  - port: 9089
    name: informix-dr
  - port: 27017
    name: mongo
  - port: 27018
    name: rest
  - port: 27883
    name: mqtt
  selector:
    component: informix-set-service
---
#
# service for informix container statefulset service.
# this is used as an external entry point for 
# the ingress controller.
#
apiversion: v1
kind: service
metadata:
  name: informix-service
  labels:
    component: informix-service
    provider: 4js
spec:
  ports:
  - port: 9088
    name: informix
  - port: 9089
    name: informix-dr
  - port: 27017
    name: mongo
  - port: 27018
    name: rest
  - port: 27883
    name: mqtt
  selector:
    component: informix-set-service
---
#
# statefulset for informix cluster.
# statefulset sets predictible hostnames,and external storage is bound
# to the pods within statefulsets for the life.
# replica count configures number of informix server containers.
#
apiversion: apps/v1
kind: statefulset
metadata:
  name: informix
  labels:
    app: informix
    component: db
    release: ""12.10""
    provider: ibm
spec:
  servicename: informix
  #replicas: 2 #keep it simple for now...
  selector:
    matchlabels:
      component: informix-set-service
  template:
    metadata:
      labels:
        component: informix-set-service
    spec:
      containers:
      - name: informix
        image: ibmcom/informix-innovator-c:12.10.fc12w1ie
        tty: true
        securitycontext:
          privileged: true
        env:
        - name: license
          value: ""accept""
        - name: dbdate
          value: ""dmy4""
        - name: size
          value: ""custom""
        - name: db_user
          value: ""db_root"" 
        - name: db_name
          value: ""db_main""
        - name: db_pass
          value: ""db_pass123""
        ports:
        - containerport: 9088
          name: informix
        - containerport: 9089
          name: informix-dr
        - containerport: 27017
          name: mongo
        - containerport: 27018
          name: rest
        - containerport: 27883
          name: mqtt
        volumemounts:
        - name: data
          mountpath: /opt/ibm/data
        - name: bind-dir-mnt
          mountpath: /mnt
        - name: bind-patch-informix-setup-sqlhosts
          mountpath: /opt/ibm/scripts/informix_setup_sqlhosts.sh
        - name: bind-file-dbexport
          mountpath: /opt/ibm/informix/bin/dbexport
        - name: bind-file-dbimport
          mountpath: /opt/ibm/informix/bin/dbimport
        - name: bind-file-ontape
          mountpath: /opt/ibm/informix/bin/ontape
        - name: bind-file-informix-config
          mountpath: /opt/ibm/data/informix_config.custom
        - name: bind-file-sqlhosts
          mountpath: /opt/ibm/data/sqlhosts
      volumes:
      - name: data
        persistentvolumeclaim:
          claimname: ifx-data
      - name: bind-dir-mnt
        hostpath:
          path: &lt;projectdir&gt;/resources/informix
          type: directoryorcreate
      - name: bind-patch-informix-setup-sqlhosts
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/scripts/informix_setup_sqlhosts.sh
          type: file
      - name: bind-file-dbexport
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/bin/dbexport
          type: file
      - name: bind-file-dbimport
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/bin/dbimport
          type: file
      - name: bind-file-ontape
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/bin/ontape
          type: file
      - name: bind-file-informix-config
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/informix_config.custom
          type: file
      - name: bind-file-sqlhosts
        hostpath:
          path: &lt;projectdir&gt;/containers/informix/resources/sqlhosts.k8s
          type: file
---


edit 1: (added output of ss -lnt)

informix@informix-0:/$ ss -lnt
state       recv-q send-q              local address:port                peer address:port
listen      0      0                       127.0.0.1:9088                           *:*
listen      0      0                       127.0.0.1:9089                           *:*
listen      0      0                      172.17.0.7:27017                          *:*
listen      0      0                      172.17.0.7:27018                          *:*
listen      0      0                      172.17.0.7:27883                          *:*
listen      0      0                               *:22                             *:*
listen      0      0                              :::22                            :::*

",<kubernetes><informix><minikube><kubernetes-service><kubernetes-statefulset>,57578200,1,"from the ss output, you are listening on 127.0.0.1, rather than all interfaces:

informix@informix-0:/$ ss -lnt
state       recv-q send-q              local address:port                peer address:port
listen      0      0                       127.0.0.1:9088                           *:*
listen      0      0                       127.0.0.1:9089                           *:*


you need to adjust your application configuration to listen on something like 0.0.0.0 to enable it to be accessed from outside of the pod.
"
65705696,how do i see the restartpolicy of a cronjob using kubectl?,"is there a way to see see the restartpolicy of a cronjob using kubectl?
here's my kubernetes version info:
client version: version.info{major:&quot;1&quot;, minor:&quot;19&quot;, gitversion:&quot;v1.19.4&quot;, gitcommit:&quot;d360454c9bcd1634cf4cc52d1867af5491dc9c5f&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-11-12t01:09:16z&quot;, goversion:&quot;go1.15.4&quot;, compiler:&quot;gc&quot;, platform:&quot;darwin/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;18+&quot;, gitversion:&quot;v1.18.9-eks-d1db3c&quot;, gitcommit:&quot;d1db3c46e55f95d6a7d3e5578689371318f95ff9&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-10-20t22:18:07z&quot;, goversion:&quot;go1.13.15&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

and this is what i see when running kubectl describe cronjob -n default example-job:
name:                          example-job
namespace:                     default
labels:                        app.kubernetes.io/instance=yogurt
                               app.kubernetes.io/managed-by=helm
                               app.kubernetes.io/name=item-service
                               app.kubernetes.io/version=v0.1.4
                               helm.sh/chart=item-service-0.2.0
annotations:                   meta.helm.sh/release-name: yogurt
                               meta.helm.sh/release-namespace: default
schedule:                      4 */6 * * *
concurrency policy:            replace
suspend:                       false
successful job history limit:  3
failed job history limit:      1
starting deadline seconds:     &lt;unset&gt;
selector:                      &lt;unset&gt;
parallelism:                   &lt;unset&gt;
completions:                   &lt;unset&gt;
pod template:
  labels:  &lt;none&gt;
  containers:
   example-job:
    image:      example.dkr.ecr.us-west-2.amazonaws.com/example-job:v1.1.1
    port:       8099/tcp
    host port:  0/tcp
    limits:
      memory:  600m
    requests:
      memory:  500m
    environment:
      server.port:                        8099
    mounts:                               &lt;none&gt;
  volumes:                                &lt;none&gt;
last schedule time:                       wed, 13 jan 2021 06:04:00 -0600
active jobs:                              &lt;none&gt;
events:                                   &lt;none&gt;

",<kubernetes><kubectl>,65706079,2,"why don't you try something like this -
kubectl -n {namespace-name-here} get cronjob

this will give you all cronjobs in that namespace
kubectl -n {namespace-name-here} get cronjob {cronjob-name} -o yaml

this will display the yaml used to create the cronjob
"
59224199,create a pod with specified name using kubectl in command line?,"using kubectl command line, is it possible to define the exact pod name?

i have tried with

kubectl run $pod-name --image imagex


however, the resulted pod name is something like $pod-name-xx-yyy-nnn.
so without using a yaml file, can i define the pod name using kubectl cli?
",<kubernetes><kubectl><kubernetes-pod>,59224922,6,"kubectl run creates a deployment by default. a deployment starts a replicaset that manages the pods/replicas... and therefore has a generated pod name.

run pod

to run a single pod you can add --restart=never to the kubectl run command.

kubectl run mypod --restart=never --image=imagex

"
48734524,kubernetes: api-server and controller-manager cant start,"i have a running k8s-cluster, setup with kubeadm.
i have the problem, that the api-server and controller-manager pod cant start, due to a bind-exception: 

failed to create listener: failed to listen on 0.0.0.0:6443: listen tcp 0.0.0.0:6443: bind: address already in use


we recently downgraded docker-ce from version 18.01 to 17.09 on all nodes, due to a bug in docker at recreating containers. but after downgrading the cluster just worked fine, meaning api-server and controller-manager were running. 

ive searched google and so, for issues related to bindexceptions for api-server and controller-manager, but couldnt find anything useful

i checked, that no other process is running on that port on the master node.
things i tried:


restarted kubelet on master: systemctl restart kubelet 
restarted docker daemon, watched for staled containers: didnt found anyone
checked if any process is running on 6443: lsof -i:6443 prints nothing, but nmap localhost -p 6443 shows the port is open with service unknown
restarted system pod's as well


restarting kubelet and docker daemon worked fine, but without any effect to the problem

kubeadm / kubectl - version:

 kubeadm version: &amp;version.info{major:""1"", minor:""9"", gitversion:""v1.9.2"", gitcommit:""5fa2db2bd46ac79e5e00a4e6ed24191080aa463b"", gittreestate:""clean"", builddate:""2018-01-18t09:42:01z"", goversion:""go1.9.2"", compiler:""gc"", platform:""linux/amd64""}


using weave as netcork-cni

edit:

docker ps of master node

container id        image                                           command                  created             status              ports               names
59239d32b1e4        weaveworks/weave-npc                            ""/usr/bin/weave-npc""     about an hour ago   up about an hour                        k8s_weave-npc_weave-net-74vsh_kube-system_99f6ee35-0f56-11e8-95e1-1614e1ecd749_0
7cb888c1ab4d        weaveworks/weave-kube                           ""/home/weave/launc...""   about an hour ago   up about an hour                        k8s_weave_weave-net-74vsh_kube-system_99f6ee35-0f56-11e8-95e1-1614e1ecd749_0
1ad50c15f816        gcr.io/google_containers/pause-amd64:3.0        ""/pause""                 about an hour ago   up about an hour                        k8s_pod_weave-net-74vsh_kube-system_99f6ee35-0f56-11e8-95e1-1614e1ecd749_0
ecb845f1dfae        gcr.io/google_containers/etcd-amd64             ""etcd --advertise-...""   2 hours ago         up 2 hours                              k8s_etcd_etcd-kube01_kube-system_1b6fafb5dc39ea18814d9bc27da851eb_6
001234690d7a        gcr.io/google_containers/kube-scheduler-amd64   ""kube-scheduler --...""   2 hours ago         up 2 hours                              k8s_kube-scheduler_kube-scheduler-kube01_kube-system_69c12074e336b0dbbd0a1666ce05226a_3
0ce04f222f08        gcr.io/google_containers/pause-amd64:3.0        ""/pause""                 2 hours ago         up 2 hours                              k8s_pod_kube-scheduler-kube01_kube-system_69c12074e336b0dbbd0a1666ce05226a_3
0a3d9eabd961        gcr.io/google_containers/pause-amd64:3.0        ""/pause""                 2 hours ago         up 2 hours                              k8s_pod_kube-apiserver-kube01_kube-system_95c67f50e46db081012110e8bcce9dfc_3
c77767104eb9        gcr.io/google_containers/pause-amd64:3.0        ""/pause""                 2 hours ago         up 2 hours                              k8s_pod_etcd-kube01_kube-system_1b6fafb5dc39ea18814d9bc27da851eb_4
319873797a8a        gcr.io/google_containers/pause-amd64:3.0        ""/pause""                 2 hours ago         up 2 hours                              k8s_pod_kube-controller-manager-kube01_kube-system_f64b9b5ba10a00baa5c176d5877e8671_4


journalctl - full:

feb 11 19:51:03 kube01 kubelet[3195]: i0211 19:51:03.205824    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-controller-manager"" in pod ""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:03 kube01 kubelet[3195]: i0211 19:51:03.205991    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)
feb 11 19:51:03 kube01 kubelet[3195]: e0211 19:51:03.206039    3195 pod_workers.go:186] error syncing pod f64b9b5ba10a00baa5c176d5877e8671 (""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""), skipping: failed to ""startcontainer"" for ""kube-controller-manager"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:03 kube01 kubelet[3195]: i0211 19:51:03.206161    3195 kuberuntime_manager.go:514] container {name:kube-apiserver image:gcr.io/google_containers/kube-apiserver-amd64:v1.9.2 command:[kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --admission-control=initializers,namespacelifecycle,limitranger,serviceaccount,defaultstorageclass,defaulttolerationseconds,noderestriction,resourcequota --allow-privileged=true --kubelet-preferred-address-types=internalip,externalip,hostname --requestheader-extra-headers-prefix=x-remote-extra- --advertise-address=207.154.252.249 --service-cluster-ip-range=10.96.0.0/12 --insecure-port=0 --enable-bootstrap-token-auth=true --requestheader-allowed-names=front-proxy-client --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-username-headers=x-remote-user --service-account-key-file=/etc/kubernetes/pki/sa.pub --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --secure-port=6443 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-group-headers=x-remote-group --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --authorization-mode=node,rbac --etcd-servers=http://127.0.0.1:2379] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:250 scale:-3} d:{dec:&lt;nil&gt;} s:250m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:6443,host:207.154.252.249,scheme:https,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminat
feb 11 19:51:03 kube01 kubelet[3195]: ionmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:03 kube01 kubelet[3195]: i0211 19:51:03.206234    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-apiserver"" in pod ""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:03 kube01 kubelet[3195]: i0211 19:51:03.206350    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)
feb 11 19:51:03 kube01 kubelet[3195]: e0211 19:51:03.206381    3195 pod_workers.go:186] error syncing pod 95c67f50e46db081012110e8bcce9dfc (""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""), skipping: failed to ""startcontainer"" for ""kube-apiserver"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:12 kube01 kubelet[3195]: e0211 19:51:12.816797    3195 fs.go:418] stat fs failed. error: no such file or directory
feb 11 19:51:14 kube01 kubelet[3195]: i0211 19:51:14.203327    3195 kuberuntime_manager.go:514] container {name:kube-apiserver image:gcr.io/google_containers/kube-apiserver-amd64:v1.9.2 command:[kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --admission-control=initializers,namespacelifecycle,limitranger,serviceaccount,defaultstorageclass,defaulttolerationseconds,noderestriction,resourcequota --allow-privileged=true --kubelet-preferred-address-types=internalip,externalip,hostname --requestheader-extra-headers-prefix=x-remote-extra- --advertise-address=207.154.252.249 --service-cluster-ip-range=10.96.0.0/12 --insecure-port=0 --enable-bootstrap-token-auth=true --requestheader-allowed-names=front-proxy-client --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-username-headers=x-remote-user --service-account-key-file=/etc/kubernetes/pki/sa.pub --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --secure-port=6443 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-group-headers=x-remote-group --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --authorization-mode=node,rbac --etcd-servers=http://127.0.0.1:2379] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:250 scale:-3} d:{dec:&lt;nil&gt;} s:250m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:6443,host:207.154.252.249,scheme:https,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminat
feb 11 19:51:14 kube01 kubelet[3195]: ionmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:14 kube01 kubelet[3195]: i0211 19:51:14.203631    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-apiserver"" in pod ""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:14 kube01 kubelet[3195]: i0211 19:51:14.203833    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)
feb 11 19:51:14 kube01 kubelet[3195]: e0211 19:51:14.203886    3195 pod_workers.go:186] error syncing pod 95c67f50e46db081012110e8bcce9dfc (""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""), skipping: failed to ""startcontainer"" for ""kube-apiserver"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:15 kube01 kubelet[3195]: i0211 19:51:15.203837    3195 kuberuntime_manager.go:514] container {name:kube-controller-manager image:gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2 command:[kube-controller-manager --leader-elect=true --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --address=127.0.0.1 --use-service-account-credentials=true --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:200 scale:-3} d:{dec:&lt;nil&gt;} s:200m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;} {name:kubeconfig readonly:true mountpath:/etc/kubernetes/controller-manager.conf subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:10252,host:127.0.0.1,scheme:http,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminationmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:15 kube01 kubelet[3195]: i0211 19:51:15.205830    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-controller-manager"" in pod ""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:15 kube01 kubelet[3195]: i0211 19:51:15.207429    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)
feb 11 19:51:15 kube01 kubelet[3195]: e0211 19:51:15.207813    3195 pod_workers.go:186] error syncing pod f64b9b5ba10a00baa5c176d5877e8671 (""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""), skipping: failed to ""startcontainer"" for ""kube-controller-manager"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:26 kube01 kubelet[3195]: i0211 19:51:26.203361    3195 kuberuntime_manager.go:514] container {name:kube-apiserver image:gcr.io/google_containers/kube-apiserver-amd64:v1.9.2 command:[kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --admission-control=initializers,namespacelifecycle,limitranger,serviceaccount,defaultstorageclass,defaulttolerationseconds,noderestriction,resourcequota --allow-privileged=true --kubelet-preferred-address-types=internalip,externalip,hostname --requestheader-extra-headers-prefix=x-remote-extra- --advertise-address=207.154.252.249 --service-cluster-ip-range=10.96.0.0/12 --insecure-port=0 --enable-bootstrap-token-auth=true --requestheader-allowed-names=front-proxy-client --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-username-headers=x-remote-user --service-account-key-file=/etc/kubernetes/pki/sa.pub --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --secure-port=6443 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-group-headers=x-remote-group --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --authorization-mode=node,rbac --etcd-servers=http://127.0.0.1:2379] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:250 scale:-3} d:{dec:&lt;nil&gt;} s:250m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:6443,host:207.154.252.249,scheme:https,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminat
feb 11 19:51:26 kube01 kubelet[3195]: ionmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:26 kube01 kubelet[3195]: i0211 19:51:26.205258    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-apiserver"" in pod ""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:26 kube01 kubelet[3195]: i0211 19:51:26.205670    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)
feb 11 19:51:26 kube01 kubelet[3195]: e0211 19:51:26.205965    3195 pod_workers.go:186] error syncing pod 95c67f50e46db081012110e8bcce9dfc (""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""), skipping: failed to ""startcontainer"" for ""kube-apiserver"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:29 kube01 kubelet[3195]: i0211 19:51:29.203234    3195 kuberuntime_manager.go:514] container {name:kube-controller-manager image:gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2 command:[kube-controller-manager --leader-elect=true --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --address=127.0.0.1 --use-service-account-credentials=true --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:200 scale:-3} d:{dec:&lt;nil&gt;} s:200m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;} {name:kubeconfig readonly:true mountpath:/etc/kubernetes/controller-manager.conf subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:10252,host:127.0.0.1,scheme:http,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminationmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:29 kube01 kubelet[3195]: i0211 19:51:29.207713    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-controller-manager"" in pod ""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:29 kube01 kubelet[3195]: i0211 19:51:29.208492    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)
feb 11 19:51:29 kube01 kubelet[3195]: e0211 19:51:29.208875    3195 pod_workers.go:186] error syncing pod f64b9b5ba10a00baa5c176d5877e8671 (""kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""), skipping: failed to ""startcontainer"" for ""kube-controller-manager"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-kube01_kube-system(f64b9b5ba10a00baa5c176d5877e8671)""
feb 11 19:51:32 kube01 kubelet[3195]: e0211 19:51:32.369188    3195 fs.go:418] stat fs failed. error: no such file or directory
feb 11 19:51:39 kube01 kubelet[3195]: i0211 19:51:39.203802    3195 kuberuntime_manager.go:514] container {name:kube-apiserver image:gcr.io/google_containers/kube-apiserver-amd64:v1.9.2 command:[kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --admission-control=initializers,namespacelifecycle,limitranger,serviceaccount,defaultstorageclass,defaulttolerationseconds,noderestriction,resourcequota --allow-privileged=true --kubelet-preferred-address-types=internalip,externalip,hostname --requestheader-extra-headers-prefix=x-remote-extra- --advertise-address=207.154.252.249 --service-cluster-ip-range=10.96.0.0/12 --insecure-port=0 --enable-bootstrap-token-auth=true --requestheader-allowed-names=front-proxy-client --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-username-headers=x-remote-user --service-account-key-file=/etc/kubernetes/pki/sa.pub --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --secure-port=6443 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-group-headers=x-remote-group --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --authorization-mode=node,rbac --etcd-servers=http://127.0.0.1:2379] args:[] workingdir: ports:[] envfrom:[] env:[] resources:{limits:map[] requests:map[cpu:{i:{value:250 scale:-3} d:{dec:&lt;nil&gt;} s:250m format:decimalsi}]} volumemounts:[{name:k8s-certs readonly:true mountpath:/etc/kubernetes/pki subpath: mountpropagation:&lt;nil&gt;} {name:ca-certs readonly:true mountpath:/etc/ssl/certs subpath: mountpropagation:&lt;nil&gt;}] volumedevices:[] livenessprobe:&amp;probe{handler:handler{exec:nil,httpget:&amp;httpgetaction{path:/healthz,port:6443,host:207.154.252.249,scheme:https,httpheaders:[],},tcpsocket:nil,},initialdelayseconds:15,timeoutseconds:15,periodseconds:10,successthreshold:1,failurethreshold:8,} readinessprobe:nil lifecycle:nil terminat
feb 11 19:51:39 kube01 kubelet[3195]: ionmessagepath:/dev/termination-log terminationmessagepolicy:file imagepullpolicy:ifnotpresent securitycontext:nil stdin:false stdinonce:false tty:false} is dead, but restartpolicy says that we should restart it.
feb 11 19:51:39 kube01 kubelet[3195]: i0211 19:51:39.205508    3195 kuberuntime_manager.go:758] checking backoff for container ""kube-apiserver"" in pod ""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""
feb 11 19:51:39 kube01 kubelet[3195]: i0211 19:51:39.206071    3195 kuberuntime_manager.go:768] back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)
feb 11 19:51:39 kube01 kubelet[3195]: e0211 19:51:39.206336    3195 pod_workers.go:186] error syncing pod 95c67f50e46db081012110e8bcce9dfc (""kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""), skipping: failed to ""startcontainer"" for ""kube-apiserver"" with crashloopbackoff: ""back-off 5m0s restarting failed container=kube-apiserver pod=kube-apiserver-kube01_kube-system(95c67f50e46db081012110e8bcce9dfc)""




kubeadm.conf

[service]
environment=""kubelet_kubeconfig_args=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf""
environment=""kubelet_system_pods_args=--pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true""
environment=""kubelet_network_args=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin""
environment=""kubelet_dns_args=--cluster-dns=10.96.0.10 --cluster-domain=cluster.local""
environment=""kubelet_authz_args=--authorization-mode=webhook --client-ca-file=/etc/kubernetes/pki/ca.crt""
environment=""kubelet_cadvisor_args=--cadvisor-port=0""
environment=""kubelet_certificate_args=--rotate-certificates=true --cert-dir=/var/lib/kubelet/pki""
execstart=
execstart=/usr/bin/kubelet $kubelet_kubeconfig_args $kubelet_system_pods_args $kubelet_network_args $kubelet_dns_args $kubelet_authz_args $kubelet_cadvisor_args $kubelet_certificate_args $kubelet_extra_args




docker-info - cgroup

warning: no swap limit support
cgroup driver: cgroupfs




kernel:

linux kube01 4.4.0-112-generic #135-ubuntu smp fri jan 19 11:48:36 utc 2018 x86_64 x86_64 x86_64 gnu/linux




distri:

distributor id: ubuntu
description:    ubuntu 16.04.3 lts
release:    16.04
codename:   xenial

",<docker><kubernetes><kubernetes-apiserver>,48736263,9,"the problem is simply that some service is already bound on 6443 to check that out you can use netstat -lutpn | grep 6443 and kill that process and restart kubelet service.

$ netstat -lutpn | grep 6443
tcp6       0      0 :::6443                 :::*                    listen      11395/some-service

$ kill 11395

$ service kubelet restart


this should fix the situation.

with kubernetes this usually happens if the kubernetes is not properly rested and containers are not properly cleaned out.

to do so...

$ kubeadm reset
$ docker rm -f $(docker ps -a -q)
$ kubeadm init &lt;options&gt; # new initialization


which would mean the nodes will have to rejoin again.
"
56118024,how to get srv dns address for statefulset headless service,"issue in dns lookup for statefulsets srv records

my yaml file

kind: list
apiversion: v1
items:
- apiversion: v1
  kind: service
  metadata:
    name: sfs-svc
    labels:
      app: sfs-app
  spec:
    ports:
    - port: 80
      name: web
    clusterip: none
    selector:
      app: sfs-app
- apiversion: apps/v1
  kind: statefulset
  metadata:
    name: web
  spec:
    selector:
      matchlabels:
        app: sfs-app # has to match .spec.template.metadata.labels
    servicename: ""sfs-svc""
    replicas: 3 
    template:
      metadata:
        labels:
          app: sfs-app # has to match .spec.selector.matchlabels
      spec:
        terminationgraceperiodseconds: 10
        containers:
        - name: test-container
          image: nginx
          imagepullpolicy: ifnotpresent
          command: [ ""sh"", ""-c""]
          args:
          - while true; do
              printenv my_node_name my_pod_name my_pod_namespace &gt;&gt; /var/sl/output.txt;
              printenv my_pod_ip &gt;&gt; /var/sl/output.txt;
              date &gt;&gt; var/sl/output.txt; 
              cat /var/sl/output.txt;
              sleep 999999;
            done;
          env:
            - name: my_node_name
              valuefrom:
                fieldref:
                  fieldpath: spec.nodename
            - name: my_pod_name
              valuefrom:
                fieldref:
                  fieldpath: metadata.name
            - name: my_pod_namespace
              valuefrom:
                fieldref:
                  fieldpath: metadata.namespace
            - name: my_pod_ip
              valuefrom:
                fieldref:
                  fieldpath: status.podip
          volumemounts:
          - name: www
            mountpath: /var/sl
    volumeclaimtemplates:
    - metadata:
        name: www
      spec:
        accessmodes: [ ""readwriteonce"" ]
        #storageclassname: classnameifany
        resources:
          requests:
            storage: 1mi



$ kubectl cluster-info


  kubernetes master is running at https://192.168.99.100:8443
  kubedns is running at https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy


$ kubectl version


  client version: version.info{major:""1"", minor:""13"", gitversion:""v1.13.3"", gitcommit:""721bfa751924da8d1680787490c54b9179b1fed0"", gittreestate:""clean"", builddate:""2019-02-01t20:08:12z"", goversion:""go1.11.5"", compiler:""gc"", platform:""linux/amd64""}
  server version: version.info{major:""1"", minor:""14"", gitversion:""v1.14.1"", gitcommit:""b7394102d6ef778017f2ca4046abbaa23b88c290"", gittreestate:""clean"", builddate:""2019-04-08t17:02:58z"", goversion:""go1.12.1"", compiler:""gc"", platform:""linux/amd64""}


$ kubectl get po,svc,statefulset

&gt; name        ready   status    restarts   age
&gt; pod/web-0   1/1     running   0          45m
&gt; pod/web-1   1/1     running   0          45m
&gt; pod/web-2   1/1     running   0          45m
&gt; 
&gt; name                 type        cluster-ip   external-ip   port(s)   age
&gt; service/kubernetes   clusterip   10.96.0.1    &lt;none&gt;        443/tcp   46m
&gt; service/sfs-svc      clusterip   none         &lt;none&gt;        80/tcp    45m
&gt; 
&gt; name                   ready   age
&gt; statefulset.apps/web   3/3     45m
&gt; 


problem: i am not getting dns address for statefulset headless service

when i try $ nslookup sfs-svc.default.svc.cluster.local 

&gt; server:       127.0.0.53
&gt; address:  127.0.0.53#53
&gt; 
**&gt; ** server can't find sfs-svc.default.svc.cluster.local: servfail**
&gt; 

",<kubernetes><minikube><kube-dns><srv><kubernetes-statefulset>,56207429,1,"my first guess is, you are running nslookup from localhost instead of from inside of a pod. 

i tried the yaml and i can only regenerate this problem when i run nslookup sfs-svc.default.svc.cluster.local from localhost. 

anyway, to check the dns entries of a service, run nslookup from inside of a pod. here is an example,

~ $ kubectl run -it --rm --restart=never dnsutils2 --image=tutum/dnsutils  --command -- bash

root@dnsutils2:/# nslookup sfs-svc.default.svc.cluster.local
server:     10.96.0.10
address:    10.96.0.10#53

name:   sfs-svc.default.svc.cluster.local
address: 172.17.0.6
name:   sfs-svc.default.svc.cluster.local
address: 172.17.0.5
name:   sfs-svc.default.svc.cluster.local
address: 172.17.0.4

root@dnsutils2:/# exit

"
61993620,send signal to a kubernetes pod from gitlab ci job,"i am using a self-hosted kubernetes cluster and i'm not using gitlab's kubernetes integration. in my gitlab ci job, i'm changing the configuration of a prometheus deployment in its associated configmap, and i want to make prometheus be aware of the new config by sending a sighup signal to its process. here is my job script to update the configmap and send the signal:

for x in *; do kubectl get configmap prometheus-config -o json | jq --arg name ""$(echo $x)"" --arg value ""$(cat $x)"" '.data[$name]=$value' | kubectl apply -f -; done;
kubectl exec deployments/prometheus -- /bin/sh -c ""/bin/pkill -hup prometheus""


this approach works fine in my local terminal. after a manual change in configmap and sending the signal by above command, i can see the effect after that in prometheus.

the problem is that when i put these commands in my gitlab ci job script, it does seem to do nothing at all. the command successfully runs and my ci job is done, but nothing is refreshed in prometheus.

i wonder if the way gitlab executes its jobs (the non-interactivity of the shell, etc.) causes this behavior, but i have no idea what i can do about it.

i also tried running a dummy kubectl exec in ci to see if it works at all:

kubectl exec deployments/prometheus -- /bin/sh -c ""echo hi""


and it prints hi successfully. so, what's the problem with kubectl and gitlab ci when i'm sending a signal through it?

p.s. my approach to keep a pod living and update it with new configuration instead of just restarting it may seem to be a bad practice, but if i restart the pod, prometheus takes 5~10 minutes to read the tsdb again, and i don't want to lose my monitoring system for just a configuration change. so, i'm sticking to sending that signal by now.
",<kubernetes><gitlab-ci><kubectl>,62034460,7,"config maps do not update immediately. there can be a delay of up to 2 minutes (as of v1.18) for the changes to be reflected inside the pod.

a common solution is to treat config maps as immutable data, so a new config map must be created which will need a new deployment template, and trigger a pod rollout. a timestamp or version number in the configmap name usually works.

  volumes:
    - name: config-volume
      configmap:
        name: config-20200527-013643


another solution is to include an annotation in the deployment template with a checksum of the config map data. when the checksum is updated, new pods will be launched with the updated configmap. this is common in helm templates:

annotations:
  checksum/config: {{ include (print $.template.basepath ""/config.yaml"") . | sha256sum }}


in the specific case of prometheus slow start up, triggering a deployment pod rollout is technically a restart so the ""outage"" depends on whether or not the ""readiness"" probe for prometheus meets your expectation of ""online"".

if you still need to use the sighup, a shell test is able to compare file modification times with -ot and -nt. in a while loop, the job can wait for the configmap file to update:

kubectl exec deployments/prometheus -- /bin/sh -c ""touch /tmp/cireload""
# apply config map changes
kubectl exec deployments/prometheus -- /bin/sh -c ""while [ /tmp/cireload -ot /path/to/configmap.yaml ]; do sleep 5; echo ""waiting for configmap $(date)""; done; /bin/pkill -hup prometheus""

"
63800228,kubernetes to print specific columns,"need only specific columns using jsonpath query in kubernetes:

$ kubectl get node

name  status    roles   age version
1     ready     master  35d v1.18.6
2     ready     &lt;none&gt;  35d v1.18.6
3     ready     &lt;none&gt;  35d v1.18.6             
4     ready     &lt;none&gt;  35d v1.18.6             
5     ready     master  35d v1.18.6             
6     ready     &lt;none&gt;  35d v1.18.6

desired output should look like this:
name    version
1       v1.18.6
2       v1.18.6
3       v1.18.6
4       v1.18.6
5       v1.18.6 
6       v1.18.6

",<kubernetes><google-kubernetes-engine><jsonpath><azure-aks><k8s-cronjobber>,63800229,3,"th answer to above question is:

$ kubectl get node -o=jsonpath='{range.items[*]}{.metadata.selflink} {&quot;\t&quot;} {.status.nodeinfo.kubeletversion}{&quot;\n&quot;}{end}'

it will produce output:
01    v1.18.6
02    v1.18.6
03    v1.18.6
04    v1.18.6
05    v1.18.6

for further sorting:

$ kubectl get node -o=custom-columns=node:.metadata.selflink

$ kubectl get node -o=custom-columns=version:.status.nodeinfo.kubeletversion
kubectl get node -o=custom-columns=node:.metadata.selflink,version:.status.nodeinfo.kubeletversion n


"
60937305,how to find the associated service account for helm?,"prior to helm 3, it was possible to associate a service account in helm initialization via

helm init --service-account tiller


but since helm init is now deprecated, how can we find out which service account is the helm associated with?  
",<kubernetes><kubernetes-helm><service-accounts>,60938040,6,"helm 3 will have the same permissions according to the default config in ~/.kube/config or another config if specified in your system environment variable $kubeconfig or overridden using the following command options
      --kube-context string              name of the kubeconfig context to use
      --kubeconfig string                path to the kubeconfig file


with tiller gone, the security model for helm is radically simplified. helm 3 now supports all the modern security, identity, and authorization features of modern kubernetes. helm’s permissions are evaluated using your kubeconfig file. cluster administrators can restrict user permissions at whatever granularity they see fit. — changes since helm 2: removal of tiller

"
67288024,configuring prometheus using helm onto a specific node in kubernetes,"i am trying to configure prometheus using helm in kubernetes and i have tried to execute the command as below and the deployment was successful.
$ helm install prometheus prometheus-community/prometheus --namespace prometheus --set 
nodeselector.nodetype=infra
name: prometheus
last deployed: tue apr 27 22:47:20 2021
namespace: prometheus
status: deployed

however, when i try to describe the pods created, i am unable to see the nodeselector value as &quot;nodetype=infra&quot;. can someone please point me out as to where i am missing out.
$ kubectl get pods -n prometheus                              
name                                             ready   status    restarts   age
prometheus-alertmanager-7f86c968db-vln2x         2/2     running   0          61m
prometheus-kube-state-metrics-6bfcd6f648-6cdbw   1/1     running   0          61m
prometheus-node-exporter-7q9lh                   1/1     running   0          61m
prometheus-pushgateway-54576f7765-6kjt5          1/1     running   0          61m
prometheus-server-7c9b8dbfcd-9x48b               2/2     running   0          61m

$ kubectl describe pod prometheus-alertmanager-7f86c968db-vln2x -n prometheus
name:         prometheus-alertmanager-6bc84b9455-4g9mw
namespace:    prometheus
priority:     0
..
qos class:       besteffort
node-selectors:  &lt;none&gt; --&gt; this is the field i'm expecting to have &quot;nodetype=infra&quot;

tolerations:     node.kubernetes.io/not-ready:noexecute op=exists for 300s
                 node.kubernetes.io/unreachable:noexecute op=exists for 300s

",<kubernetes><prometheus><kubernetes-helm>,67288439,8,"you need to configure the nodeselector for each component
alertmanager:
   nodeselector:
      nodetype: infra
nodeexporter:
   nodeselector:
      nodetype: infra
server:
   nodeselector:
      nodetype: infra
pushgateway:
   nodeselector:
      nodetype: infra

you can fin all the values here
"
72818378,pod getting restarted many times when using sidecar container,"i'm deploying a sidecar container in a kubernetes deployment.
the issue is that the pod sometimes is getting restarted many times because the main container (container1) is not ready at all.
the deployment is similar to this one but the sidecar container cannot reach propertly the container1 when this one is not ready. i think that's the reason why the pod is getting restarted many times
apiversion: v1
kind: pod
metadata:
  name: webserver
spec:
  volumes:
    - name: shared-logs
      emptydir: {}

  containers:
    - name: container1
      image: image1
      volumemounts:
        - name: shared-logs
          mountpath: /var/log/nginx

    - name: sidecar-container
      image: busybox
      command: [&quot;sh&quot;,&quot;-c&quot;,&quot;while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done&quot;]
      volumemounts:
        - name: shared-logs
          mountpath: /var/log/nginx

my question is simple. is there any way to make busy-box container to wait for container1 until is ready?
",<kubernetes><containers><kubernetes-helm>,72837762,1,"in my case, to resolve it faster i have just included a sleep before executing the code so i can give enought time to the main container to be ready.
time.sleep(8 * time.second)

that's not the best solution but resolves the issue.
"
64155377,configure two environment for kubernetes within azure,"azure kubernetes service allows me to assign only one ip address to one cluster. i have created two namespaces within this cluster and i would like to distinguish those two namespaces by url as environments.
namespaces

stage
dev

desired access to those namespaces would be something like {namespace}.cloudapp.azure.com.
when defining ingress controller in each namespace the same ip address is assigned. how in general should i achieve this separation but keeping the same cluster?
",<azure><kubernetes><azure-devops><devops><kubernetes-ingress>,64205119,1,"for your use case you only need a single ingress controller. i.e. https://kubernetes.github.io/ingress-nginx/
to achieve this you need to add dns entries for the namespaces leading to the single cluster ip.
if you only want to access the two dns names:

stage.cloudapp.azure.com
dev.cloudapp.azure.com

adding both entries is probably sufficient if you only want a single application in those namespaces. if you want to deploy multiple applications within the namespaces you should consider adding wildcard dns entries for:

*.stage.cloudapp.azure.com
*.dev.cloudapp.azure.com

with this setup you can add ingresses of the following format:
  apiversion: networking.k8s.io/v1
  kind: ingress
  metadata:
    name: ingress-example-with-hostname
    namespace: dev
  spec:
  rules:
  - host: dev.cloudapp.azure.com
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: service
            port:
              number: 80

for further informations take a look at this documentation: https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting
"
75974501,kubernetes finding logs of a failed cronjob,"i found a failed cronjob in my kubernetes cluster running on google gke. i only have information about the failure state and failure reason of the job.
although i located the failed job and learned that it reached the backoff limit, i would like to access the actual logs or stdout of the pod to identify the code error that caused the failure.
however, when i tried to use a command to check the log, i discovered that the pod had already been deleted, and i could not locate the failed pod.
but from gke ui, i can found there are logs showing errors in my code and the information is what i am looking for.
i am wondering whether it is gke implementing a logging system so i can find the logs?
because i found the following information in the doc:

note: if your job has restartpolicy = &quot;onfailure&quot;, keep in mind that your pod running the job will be terminated once the job backoff limit has been reached. this can make debugging the job's executable more difficult. we suggest setting restartpolicy = &quot;never&quot; when debugging the job or using a logging system to ensure output from failed jobs is not lost inadvertently.

does this mean that if my job's restartpolicy is set to onfailure, the corresponding pod will be deleted upon failure, and there will be no way to check the pod's logs?
did i find logs in gke because it has its own logging system, or is there another action i can take to access these logs?
thanks.
following is the snippet of my cronjob.
spec:
  concurrencypolicy: allow
  failedjobshistorylimit: 3
  jobtemplate:
    metadata:
      creationtimestamp: null
    spec:
      template:
        metadata:
          creationtimestamp: null
        spec:
          containers:
          - command:
            - $cmd
            image: $img
            imagepullpolicy: always
            name: $job_name
            resources: {}
            terminationmessagepath: /dev/termination-log
            terminationmessagepolicy: file
          dnspolicy: clusterfirst
          restartpolicy: onfailure
          schedulername: default-scheduler
          securitycontext: {}
          terminationgraceperiodseconds: 30
  schedule: 0 4 * * *
  successfuljobshistorylimit: 3
  suspend: false

",<kubernetes><google-kubernetes-engine>,75975700,7,"cronjobs have a history value:
.spec.successfuljobshistorylimit and .spec.failedjobshistorylimit
set these to how many successful/failed jobs you wish to keep, and kubernetes will keep that many failed or successful pods. i generally keep 3 failed, 1 successful, but if debugging, i'll keep more (6 failed, 3 successful)

edited version of your yaml
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  concurrencypolicy: allow
  failedjobshistorylimit: 3
  jobtemplate:
    metadata:
      creationtimestamp: null
    spec:
      template:
        metadata:
          creationtimestamp: null
        spec:
          containers:
            - image: busybox
              # command:
              # - $cmd
              command:
                - &quot;sh&quot;
                - &quot;-c&quot;
                - &quot;exit 1&quot;
              imagepullpolicy: always
              name: crontest
              resources: {}
              terminationmessagepath: /dev/termination-log
              terminationmessagepolicy: file
          dnspolicy: clusterfirst
          restartpolicy: onfailure
          schedulername: default-scheduler
          securitycontext: {}
          terminationgraceperiodseconds: 30
  schedule: 0 4 * * *
  successfuljobshistorylimit: 3
  suspend: false

i was able to reproduce your issue with this. i saw this message in logs:
events:                                                                                                                                                                                    │
│   type     reason                age    from            message                                                                                                                            │
│   ----     ------                ----   ----            -------                                                                                                                            │
│   normal   successfulcreate      9m26s  job-controller  created pod: my-app-manual-xnj-fpvzq                                                                                               │
│   normal   successfuldelete      3m18s  job-controller  deleted pod: my-app-manual-xnj-fpvzq                                                                                               │
│   warning  backofflimitexceeded  3m18s  job-controller  job has reached the specified backoff limit                                                                                        │
│ 

change your yaml to change the restartpolicy:
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  concurrencypolicy: allow
  failedjobshistorylimit: 3
  jobtemplate:
    metadata:
      creationtimestamp: null
    spec:
      template:
        metadata:
          creationtimestamp: null
        spec:
          containers:
            - image: busybox
              # command:
              # - $cmd
              command:
                - &quot;sh&quot;
                - &quot;-c&quot;
                - &quot;exit 1&quot;
              imagepullpolicy: always
              name: crontest
              resources: {}
              terminationmessagepath: /dev/termination-log
              terminationmessagepolicy: file
          dnspolicy: clusterfirst
          restartpolicy: never ### &lt;--- this is changed
          schedulername: default-scheduler
          securitycontext: {}
          terminationgraceperiodseconds: 30
  schedule: 0 4 * * *
  successfuljobshistorylimit: 3
  suspend: false


then produces this:
$ kubectl get pods
name                      ready   status   restarts   age
my-app-manual-29l-27x8v   0/1     error    0          2m9s
my-app-manual-29l-64th2   0/1     error    0          110s
my-app-manual-29l-shfk7   0/1     error    0          2m4s
my-app-manual-29l-tj9k7   0/1     error    0          84s
my-app-manual-29l-tzlwd   0/1     error    0          40s

so in short, yes, the restartpolicy is the reason you're not seeing the failed pods.
"
61272743,how to set the ssl-session-cache values in configmap - kubernetes?,"i try to set the value of the ssl-session-cache in my configmap for ingress-controller,

the problem is, that i can't find how to write it correct.

i need following changes in the nginx config:  

ssl-session-cache builtin:3000 shared:ssl:100m

ssl-session-timeout: 3000

when i add 
ssl-session-timeout: ""3000"" to the config map, it works correct - this i can see in nginx-config few seconds later. 

but how i should write ssl-session-cache? 

ssl-session-cache: builtin:""3000"" shared:ssl:""100m"" goes well, but no changes in nginx

ssl-session-cache: ""builtin:3000 shared:ssl:100m"" goes well, but no changes in nginx

ssl-session-cache ""builtin:3000 shared:ssl:100m"" syntax error - can't change the configmap

ssl-session-cache builtin:""3000 shared:ssl:100m"" syntax error - can't change the configmap

do someone have the idea, how to set ssl-session-cache in configmap correct?

thank you!
",<kubernetes><kubernetes-ingress><nginx-ingress><configmap>,61344553,1,"tl;dr

after digging around and test the same scenario in my lab, i've found how to make it work.

as you can see here the parameter ssl-session-cache requires a boolean value to specify if it will be enabled or not.

the changes you need is handled by the parameter ssl_session_cache_size and requires a string, then is correct to suppose that it would work changing the value to builtin:3000 shared:ssl:100m but after reproduction and dive into the nginx configuration, i've concluded that it will not work because the option builtin:1000 is hardcoded.

in order to make it work as expected i've found a solution using a nginx template as a configmap mounted as a volume into nginx-controller pod and other configmap for make the changes in the parameter ssl_session_cache_size.

workaround

take a look in the line 343 from the file /etc/nginx/template in the nginx-ingress-controller pod:

bash-5.0$ grep -n 'builtin:' nginx.tmpl 
343:    ssl_session_cache builtin:1000 shared:ssl:{{ $cfg.sslsessioncachesize }};


as you can see, the option builtin:1000 is hardcoded and cannot be change using custom data on yout approach.

however, there are some ways to make it work, you could directly change the template file into the pod, but theses changes will be lost if the pod die for some reason... or you could use a custom template mounted as configmap into nginx-controller pod.

in this case, let's create a configmap with nginx.tmpl content changing the value of the line 343 for the desired value.


get template file from nginx-ingress-controller pod, it will create a file callednginx.tmpl locally:



  note: make sure the namespace is correct.


$ nginx_pod=$(kubectl get pods -n ingress-nginx -l=app.kubernetes.io/component=controller -ojsonpath='{.items[].metadata.name}')

$ kubectl exec $nginx_pod -n ingress-nginx -- cat template/nginx.tmpl &gt; nginx.tmpl



change the value of the line 343 from builtin:1000 to builtin:3000:


$ sed -i '343s/builtin:1000/builtin:3000/' nginx.tmpl


checking if evething is ok:

$ grep builtin nginx.tmpl 
ssl_session_cache builtin:3000 shared:ssl:{{ $cfg.sslsessioncachesize }};


ok, at this point we have a nginx.tmpl file with the desired parameter changed.

let's move on and create a configmap with the custom nginx.tmpl file:

$ kubectl create cm nginx.tmpl --from-file=nginx.tmpl
configmap/nginx.tmpl created


this will create a configmap called nginx.tmpl in the ingress-nginx namespace, if your ingress' namespace is different, make the proper changes  before apply.

after that, we need to edit the nginx-ingress deployment and add a new volume and a volumemount to the containers spec. in my case, the nginx-ingress deployment name ingress-nginx-controller in the ingress-nginx namespace. 

edit the deployment file:

$ kubectl edit deployment -n ingress-nginx ingress-nginx-controller


and  add the following configuration in the correct places:

...
        volumemounts:
        - mountpath: /etc/nginx/template
          name: nginx-template-volume
          readonly: true
...
      volumes:
      - name: nginx-template-volume
        configmap:
          name: nginx.tmpl
          items:
          - key: nginx.tmpl
            path: nginx.tmpl
...


after save the file, the nginx controller pod will be recreated with the configmap mounted as a file into the pod.

let's check if the changes was propagated:

$ kubectl exec -n ingress-nginx $nginx_pod -- cat nginx.conf | grep -n ssl_session_cache
223:    ssl_session_cache builtin:3000 shared:ssl:10m;


great, the first part is done!

now for the shared:ssl:10m we can use the same approach you already was used: configmap with the specific parameters as mentioned in this doc.

if you remember in the nginx.tmpl, for shared:ssl there is a variable called sslsessioncache ({{ $cfg.sslsessioncachesize }}), in the source code is possible to check that the variable is represented by the option ssl-session-cache-size:

340  // size of the ssl shared cache between all worker processes.
341  // http://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_session_cache
342  sslsessioncachesize string `json:""ssl-session-cache-size,omitempty""`


so, all we need to do is create a configmap with this parameter and the desired value:

kind: configmap
apiversion: v1
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
data:
  ssl-session-cache-size: ""100m""



  note: adjust the namespace and configmap name for the equivalent of your environment.


applying this configmap nginx will reload the configuration and make the changes in the configuration file.

checking the results:

$ nginx_pod=$(kubectl get pods -n ingress-nginx -l=app.kubernetes.io/component=controller -ojsonpath='{.items[].metadata.name}')

$ kubectl exec -n ingress-nginx $nginx_pod -- cat nginx.conf | grep -n ssl_session_cache
223:    ssl_session_cache builtin:3000 shared:ssl:100m;


conclusion

it would work as expected,  unfortunately, i can't find a way to add a variable in the builtin:, so we will continue using it hardcoded but at this time it will be a configmap that you can easily make changes if needed.

references:

nginx ingress custom template

nginx ingress source code
"
61796172,installation error while installing service mesh linkerd service mesh in aks,"i have followed the getting started instructions here: https://linkerd.io/2/getting-started/ for installing linkerd but i am facing error at step 3. the details are as follows.

please see the command: linkerd install | kubectl apply -f -

please see the error below:

error: open /add-ons\grafana/chart.yaml: file does not exist
usage:
  linkerd install [flags]
  linkerd install [command]

examples:
  # default install.
  linkerd install | kubectl apply -f -

  # install linkerd into a non-default namespace.
  linkerd install -l linkerdtest | kubectl apply -f -

  # installation may also be broken up into two stages by user privilege, via
  # subcommands.

available commands:
  config        output kubernetes cluster-wide resources to install linkerd
  control-plane output kubernetes control plane resources to install linkerd


can anyone please help me regarding this issue.
",<kubernetes><kubernetes-helm><azure-aks><linkerd>,61797109,2,"you better work with microsoft documentation  - install linkerd in azure kubernetes service (aks).

the following steps worked for me :


# get aks credentials
az aks get-credentials --resource-group $(resource_group_name) --name $(cluster_name)

# download stable release
curl -slo ""https://github.com/linkerd/linkerd2/releases/download/stable-2.6.1/linkerd2-cli-stable-2.6.1-linux""

# copy the linkerd client binary to the standard user program location in your path
sudo cp ./linkerd2-cli-stable-2.6.1-linux /usr/local/bin/linkerd  
sudo chmod +x /usr/local/bin/linkerd

#check linkerd pre if pass with no issue - install linkerd on aks
 if linkerd check --pre; then
        linkerd install | kubectl apply -f -
    fi

"
59071698,ingress controller pods not starting up,"hello every one i have just started to try out kubernetes and cant get my ingress resource and controllers to work correctly and route external traffic to my service in the cluster.
my environment details
docker-desktop for windows
kubernetes version 1.10.11 (obtained by command kubectl version)
os=windows10 64 bit

i have fetched ingress from the following link
https://kubernetes.github.io/ingress-nginx/deploy/

by using these 2 commands 

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/cloud-generic.yaml


and then i have created an ingress resource such as 

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
     kubernetes.io/ingress.class: nginx
  name: sample-ingress1
spec:
  rules:
  - host: mysuperbot.com
    http:
      paths:
      - path: /sampleingress
        backend:
          servicename: tomcatappservice
          serviceport: 8082


my service resource is as follows

---
apiversion: v1
kind: service
metadata:
  name: tomcatappservice
  labels:
    app: tomcat-app
spec:
  ports:
    - port: 8082
      protocol: tcp
      targetport: 8080
  selector:
    app: tomcat-app
  type: nodeport



---
apiversion: apps/v1beta1
kind: deployment
metadata: 
  name: tomcat-app
  labels:
    app: tomcat-app
spec:
  replicas: 5
  selector:
    matchlabels:
      app: tomcat-app
  template:
    metadata:
      labels:
        app: tomcat-app
    spec:
      containers:
        - image: tomcatapp:v1.0.0 
          name: tomcat-app
          ports:
            - containerport: 8080


and my host file has entry 

mysuperbot.com  localhost


but after all this when i try to access my service at mysuperbot.com/sampleingress i get error err_name_resolution_failed which leads me to believe my ingress controller isnt set up rightly so i check it with command 

kubectl get pods -n ingress-nginx


and output is as follows 

name                                        ready     status    restarts   age
nginx-ingress-controller-7d84dd6bdf-vnjx5   0/1       pending   0          2h


which means my ingress pods arent starting up.need help as to how can i test ingress on a local kubernetes cluster that comes with docker-desktop for windows

update 

after running command 

kubectl -n ingress-nginx describe pod nginx-ingress-controller-7d84dd6bdf-vnjx5

name:           nginx-ingress-controller-7d84dd6bdf-vnjx5
namespace:      ingress-nginx
node:           &lt;none&gt;
labels:         app.kubernetes.io/name=ingress-nginx
                app.kubernetes.io/part-of=ingress-nginx
                pod-template-hash=3840882689
annotations:    prometheus.io/port=10254
                prometheus.io/scrape=true
status:         pending
ip:
controlled by:  replicaset/nginx-ingress-controller-7d84dd6bdf
containers:
  nginx-ingress-controller:
    image:       quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1
    ports:       80/tcp, 443/tcp
    host ports:  0/tcp, 0/tcp
    args:
      /nginx-ingress-controller
      --configmap=$(pod_namespace)/nginx-configuration
      --tcp-services-configmap=$(pod_namespace)/tcp-services
      --udp-services-configmap=$(pod_namespace)/udp-services
      --publish-service=$(pod_namespace)/ingress-nginx
      --annotations-prefix=nginx.ingress.kubernetes.io
    liveness:   http-get http://:10254/healthz delay=10s timeout=10s period=10s #success=1 #failure=3
    readiness:  http-get http://:10254/healthz delay=0s timeout=10s period=10s #success=1 #failure=3
    environment:
      pod_name:       nginx-ingress-controller-7d84dd6bdf-vnjx5 (v1:metadata.name)
      pod_namespace:  ingress-nginx (v1:metadata.namespace)
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from nginx-ingress-serviceaccount-token-8md24 (ro)
conditions:
  type           status
  podscheduled   false
volumes:
  nginx-ingress-serviceaccount-token-8md24:
    type:        secret (a volume populated by a secret)
    secretname:  nginx-ingress-serviceaccount-token-8md24
    optional:    false
qos class:       besteffort
node-selectors:  kubernetes.io/os=linux
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason            age                 from               message
  ----     ------            ----                ----               -------
  warning  failedscheduling  14s (x583 over 3h)  default-scheduler  0/1 nodes are available: 1 node(s) didn't match node selector.

",<kubernetes><kubernetes-ingress><nginx-ingress><docker-desktop>,59074860,2,"in your ingress controller you have the node-selector 
kubernetes.io/os=linux
 you have to edit some of your nodes /your ingress configuration to match this label. 

kubectl get nodes - - show-labels
kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;


https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
"
66275458,could not access kubernetes ingress in browser on windows home with minikube?,"i am facing the problem which is that i could not access the kubernetes ingress on the browser using it's ip. i have installed k8s and minikube on windows 10 home.
i am following this official document - https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/

first i created the deployment by running this below command on minikube.
kubectl create deployment web --image=gcr.io/google-samples/hello-app:1.0


the deployment get created which can be seen on the below image:


next, i exposed the deployment that i created above. for this i ran the below command.
kubectl expose deployment web --type=nodeport --port=8080


this created a service which can be seen by running the below command:
kubectl get service web

the screenshot of the service is shown below:


i can now able to visit the service on the browser by running the below command:
minikube service web


in the below screenshot you can see i am able to view it on the browser.


next, i created an ingress by running the below command:
kubectl apply -f https://k8s.io/examples/service/networking/example-ingress.yaml


by the way the ingress yaml code is:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: example-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    spec:
      rules:
        - host: hello-world.info
          http:
            paths:
              - path: /
                pathtype: prefix
                backend:
                  service:
                    name: web
                    port:
                      number: 8080

the ingress gets created and i can verify it by running the below command:
kubectl get ingress

the screenshot for this is given below:

the ingress ip is listed as 192.168.49.2. so that means if i should open it in the browser then it should open, but unfortunately not. it is showing site can't be reached. see the below screeshot.

what is the problem. please provide me a solution for it?
i also added the mappings on etc\hosts file.
192.168.49.2 hello-world.info

then i also tried opening hello-world.info on the browser but no luck.
in the below picture i have done ping to hello-world.info which is going to ip address 192.168.49.2. this shows etc\hosts mapping is correct:

i also did curl to minikube ip and to hello-world.info and both get timeout. see below image:

the kubectl describe services web provides the following details:
name:                     web
namespace:                default
labels:                   app=web
annotations:              &lt;none&gt;
selector:                 app=web
type:                     nodeport
ip:                       10.100.184.92
port:                     &lt;unset&gt;  8080/tcp
targetport:               8080/tcp
nodeport:                 &lt;unset&gt;  31880/tcp
endpoints:                172.17.0.4:8080
session affinity:         none
external traffic policy:  cluster
events:                   &lt;none&gt;

the kubectl describe ingress example-ingress gives the following output:
name:             example-ingress
namespace:        default
address:          192.168.49.2
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host              path  backends
  ----              ----  --------
  hello-world.info
                    /   web:8080   172.17.0.4:8080)
annotations:        nginx.ingress.kubernetes.io/rewrite-target: /$1
events:             &lt;none&gt;

kindly help. thank you.
",<kubernetes><kubectl><minikube>,66303556,7,"having same issue as op and things only work in minikube ssh, sharing the ingress.yaml below.
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: frontend-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  defaultbackend:
    service:
      name: default-http-backend
      port:
        number: 80
  rules:
    - host: myapp-com # domain (i.e. need to change host table)
      http:
        paths: # specified path below, only be working when there is more than 1 path; if only having 1 path, it's always using / as path
          - path: /
            pathtype: prefix
            backend:
              service: 
                name: frontend-service # internal service
                port: 
                  number: 8080 # port number that internal service exposes
          - path: /e($|/)(.*)
            pathtype: prefix
            backend:
              service: 
                name: express-service # internal service
                port: 
                  number: 3000 # port number that internal service exposes


"
64429094,kubernetes can't port-forward externalname service,"im create service with type external name:
apiversion: v1
kind: service
metadata:
  name: my-service
  namespace: dev
spec:
  externalname: google.com
  ports:
  - port: 80
    protocol: tcp
    targetport: 80
  sessionaffinity: none
  type: externalname

by off k8s docs add new endpoint:
apiversion: v1
kind: endpoints
metadata:
  name: my-service
  namespace: dev
subsets:
- addresses:
  - ip: 172.217.20.206
  ports:
  - port: 80
    protocol: tcp

and trying forward it to my localhost:
kubectl port-forward -n dev svc/my-service 8080:80

and got the error:

error: cannot attach to *v1.service: invalid service 'my-service':
service is defined without a selector

afaiu, i did all steps by off docs, where i missed ? or k8s not provide ability port-forward externalname in general?
",<amazon-web-services><kubernetes><kubectl><portforwarding>,64436926,18,"kubectl port-forward only actually forwards a local connection to a single specific pod.  while it looks like you can port-forward to other things, these are just means of picking a pod.  if you run kubectl port-forward service/foo 12345:80, it actually looks at the pods selected by that service, remaps the service's port 80 to the corresponding pod port, and forwards to that specific pod.
in your case, this means you can't port-forward to an externalname service, because there isn't a pod behind it, and kubectl port-forward only actually forwards to pods.
there are a couple of other implications (or demonstrations) of this.  start a normal deployment running some service with 3 replicas, with a normal service in front of it.  port-forward to either the deployment or the service, and run a load test; you will see only one pod receive all the traffic.  delete that specific pod, and the port-forward will shut down.
if you want to connect to an externalname service, or otherwise do any of the more interesting things services do, you need to make the connection originate from inside the cluster.  you could kubectl run a temporary pod as an example:
kubectl run curl-test --rm --image=curlimages/curl --generator=run-pod/v1 -- \
  http://my-service.dev.svc.cluster.local

"
58289164,get kubernetes apiserver prometheus metrics with kubectl?,"i'm trying to get kube-apiserver prometheus metrics with kubectl command. 

i can get it from kubectl proxy [which proxy the api in localhost:8001(by default)]. then go to http://localhost:8001/metrics

i want to get this metrics directly through kubectl command, without proxying.

my kubernetes version

client version: version.info{major:""1"", minor:""11"", gitversion:""v1.11.0"", gitcommit:""91e7b4fd31fcd3d5f436da26c980becec37ceefe"", gittreestate:""clean"", builddate:""2018-06-27t20:17:28z"", goversion:""go1.10.2"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""13+"", gitversion:""v1.13.7-gke.24"", gitcommit:""2ce02ef1754a457ba464ab87dba9090d90cf0468"", gittreestate:""clean"", builddate:""2019-08-12t22:05:28z"", goversion:""go1.11.5b4"", compiler:""gc"", platform:""linux/amd64""}

",<kubernetes><kubectl>,58297998,2,"got the answer 

$ kubectl get --raw /metrics


this command directly communicate with kube apiserver and get the prometheus metrics of kube apiserver.
"
66838990,how do i actually get the output of kubectl kustomize into my cluster?,"i have a very simple kustomization.yaml:
configmapgenerator:
  - name: icecast-conifg
    files:
      - icecast.xml

when i run kubectl kustomize . it spits out a generated configmap properly, but how do i actually load it into my cluster?   i'm missing some fundamental step.
",<kubernetes><kubectl><k3s><kustomize>,66839051,4,"with kustomize you can use the -k (or --kustomize) flag instead of -f when using kubectl apply. example:
kubectl apply -k &lt;my-folder-or-file&gt;

see declarative management of kubernetes objects using kustomize
"
61652643,unable to build kubernetes objects from release manifest,"i am trying deploy harbor as the following: 

helm install hub harbor/harbor \
  --namespace prod \
  --set expose.ingress.hosts.core=hub.service.example.io \
  --set expose.ingress.annotations.'kubernetes\.io/ingress\.class'=contour \
  --set expose.ingress.annotations.'cert-manager\.io/cluster-issuer'=letsencrypt-prod \
  --set expose.ingress.annotations.'ingress\.kubernetes\.io/force-ssl-redirect'=""true"" \
  --set expose.ingress.annotations.'kubernetes\.io/tls-acme'=""true"" \
  --set externalurl=https://hub.service.example.io \
  --set expose.tls.secretname=secret \
  --set notary.enabled=false \
  --set secretkey=secret \
  --set harboradminpassword=serect  


and i've got:

error: unable to build kubernetes objects from release manifest: unable to decode """": resource.metadataonlyobject.objectmeta: v1.objectmeta.annotations: readstring: expects "" or n, but found t, error found in #10 byte of ...|edirect"":true,""ingre|..., bigger context ...|prod"",""ingress.kubernetes.io/force-ssl-redirect"":true,""ingress.kubernetes.io/proxy-body-size"":""0"",""i|...  


what am i doing wrong?  
",<kubernetes><kubernetes-ingress>,61653485,6,"the error shows that the value of 
""ingress.kubernetes.io/force-ssl-redirect"":true is not string,  it's expting string like ""ingress.kubernetes.io/force-ssl-redirect"":""true""

you can set the boolean annotation value as string by forcing, using --set-string like following

helm install hub harbor/harbor \
 --namespace prod \
 --set expose.ingress.hosts.core=hub.service.example.io \
 --set expose.ingress.annotations.'kubernetes\.io/ingress\.class'=contour \
 --set expose.ingress.annotations.'cert-manager\.io/cluster-issuer'=letsencrypt-prod \
 --set-string expose.ingress.annotations.'ingress\.kubernetes\.io/force-ssl-redirect'=""true"" \
 --set-string expose.ingress.annotations.'kubernetes\.io/tls-acme'=""true"" \
 --set externalurl=https://hub.service.example.io \
 --set expose.tls.secretname=secret \
 --set notary.enabled=false \
 --set secretkey=secret \
 --set harboradminpassword=serect 

"
73278457,is there a way to enable proxy-protocol on ingress for only one service?,"i have this service that limits ips to 2 requests per day running in kubernetes.
since it is behind an ingress proxy the request ip is always the same, so it is limiting he total amount of requests to 2.
its possible to turn on proxy protocol with a config like this:
apiversion: v1
metadata:
  name: nginx-ingress-controller
data:
  use-proxy-protocol: &quot;true&quot;
kind: configmap

but this would turn it on for all services, and since they don't expect proxy-protocol they would break.
is there a way to enable it for only one service?
",<kubernetes><kubernetes-ingress>,73319710,1,"it is possible to configure ingress so that it includes the original ips into the http header.
for this i had to change the service config.
its called ingress-nginx-ingress-controller(or similar) and can be found with kubectl get services -a
spec: 
   externaltrafficpolicy: local

and then configure the configmap with the same name:
data:
  compute-full-forwarded-for: &quot;true&quot;
  use-forwarded-headers: &quot;true&quot;

restart the pods and then the http request will contain the fields  x-forwarded-for and x-real-ip.
this method won't break deployments not expecting proxy-protocol.
"
61291315,helm double quote annotations value,"i am trying to quote my annotation values. i am trying like this

annotations:
  {{- range $key, $value := .values.ingress.annotations }}
     {{ $key }}: {{ printf ""%s"" $value | quote }}
  {{- end }}


and this

annotations:
  {{- range $key, $value := .values.ingress.annotations }}
     {{ $key }}: ""{{ $value }}""
  {{- end }}


this is my values.yaml  

annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/force-ssl-redirect: false


but it is not working. even if i double quote the annotation value in values.yaml helm is removing the quote. can somebody tell me how can i get helm with double quote values in annotation?

i am using helm version 3.
",<kubernetes><kubernetes-helm><kubernetes-ingress><nginx-ingress>,61292208,14,"you could try this:

annotations:
  {{- range $key, $value := .values.ingress.annotations }}
     {{ $key }}: {{ $value | quote }}
  {{- end }}

"
63626179,"kubernetes 1.16 deprecation of daemonset, statefulset, deployments and replicasets","1.16 deprecation notice:
daemonset, deployment, statefulset, and replicaset resources will no longer
 be served from extensions/v1beta1, apps/v1beta1, or apps/v1beta2 in v1.16. migrate to the apps/v1 api, available since v1.9. existing persisted data 
can be retrieved through the apps/v1 api. for example, to convert a 
deployment that currently uses apps/v1beta1, enter the following command. 


i have about 10 helm charts that contain the old api versions - datadog, nginx-ingress and more. i don't want to upgrade these different services. are there any known work arounds?
",<kubernetes><amazon-eks>,63631475,1,"there are some options you should consider:

don't update anything and just stick to kubernetes 1.15 (not recommended as it is 4 main versions behind the latest one)

git clone your repo and change apiversion to apps/v1 in all your resources

use kubectl convert in order to change the apiversion, for example: kubectl convert -f deployment.yaml --output-version apps/v1


it is worth to mention that stuff gets deprecated for a reason and it is strongly not recommended to stick to old ways if they are not supported anymore.
"
67520866,"no matches for kind ""cronjob"" in version ""batch/v1""","i use kubernetes which v1.19.7, when i run the cronjob sample
apiversion: batch/v1
kind: cronjob
metadata:
  name: express-learn-cronjob
spec:
  schedule: &quot;*/1 * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          containers:
            - name: hello
              image: busybox
              command:
                - /bin/sh
                - -c
                - date; echo hello from the kubernetes cluster
          restartpolicy: onfailure

get  unable to recognize &quot;app-cronjob.yml&quot;: no matches for kind &quot;cronjob&quot; in version &quot;batch/v1&quot;
i can get the batch info by run kubectl api-versions | grep batch
batch/v1
batch/v1beta1

is there anything i missed? how can i fix it?
",<kubernetes><kubernetes-cronjob>,67521713,52,"for kubernetes version 1.19.x you need to use batch/v1beta1 as apiversion for your cronjob.
that is documented in the doc version 1-19:
https://v1-19.docs.kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/
it is stable only on k8s version 1.21.
"
61419815,how to check a job is completed before it's been created using kubectl?,"i can use kubectl wait --for=condition=complete --timeout=&lt;some time&gt; job/&lt;job-name&gt; to wait for a job in completed state. however, if the job has not yet been created (sometimes, it's due to k8s takes some time to schedule the job), kubectl will exit with error immediately. 

is there a way to wait for the job been created and then transit into completed state? what's the most common way to do this in industry?
",<kubernetes><kubectl>,61421143,2,"kubectl wait does not include the functionality to wait on a non existent resource yet.

for anything complex try and use a kube api client. run a watch on a resource group and you receive a stream of events for it, and continue on when the event criteria has been met. 

if you are stuck in shell land, kubectl doesn't seem to respect sigpipe signals when when handling the output of a kubectl get x --watch so maybe a simple loop...

timeout=$(( $(date +%s) + 60 )) 
while ! kubectl get job whatever 2&gt;/dev/null; do
  [ $(date +%s) -gt $timeout ] &amp;&amp; exit 1
  sleep 5
done

"
73178417,google kubernetes engine deploy error with github actions,"i'm trying to deploy my code to gke using github actions but getting an error during the deploy step:

here is my deployment.yaml:
apiversion: apps/v1
kind: deployment
metadata:
  name: nginx-3
  namespace: default
  labels:
    type: nginx
spec:
  replicas: 1
  selector:
    matchlabels:
    - type: nginx 
  template:
    metadata:
      labels:
      - type: nginx 
    spec:
      containers:
      - image: nginx:1.14
        name: renderer
        ports:
        - containerport: 80

service.yaml:
apiversion: v1
kind: service
metadata:
  name: nginx-3-service
spec:
  ports:
    port: 80
    protocol: tcp
    targetport: 80

and my dockerfile:
from ubuntu/redis:5.0-20.04_beta

# install.
run apt-get update &amp;&amp;  debian_frontend=noninteractive apt-get install -y tzdata
run \
  sed -i 's/# \(.*multiverse$\)/\1/g' /etc/apt/sources.list &amp;&amp; \
  apt-get update &amp;&amp; \
  apt-get -y upgrade &amp;&amp; \
  apt-get install -y build-essential &amp;&amp; \
  apt-get install -y software-properties-common &amp;&amp; \
  apt-get install -y byobu curl git htop man unzip vim wget &amp;&amp; \
  rm -rf /var/lib/apt/lists/*

# set environment variables.
env home /root

# define working directory.
workdir /root

# define default command.
cmd [&quot;bash&quot;]

this is what the cloud deployments(workloads) looks like:


i'm trying to push a c++ code using an ubuntu image. i just want to simply push my code to google cloud kubernetes engine.
update:
i've deleted the deployment and re-run the action and got this:
it said that deployment is successfully created but gives off another error:
deployment.apps/nginx-3 created
error from server (notfound): deployments.apps &quot;gke-deployment&quot; not found

",<kubernetes><google-cloud-platform><google-kubernetes-engine><github-actions>,73180332,1,"try:
apiversion: apps/v1
kind: deployment
metadata:
  ...
  labels:
    type: nginx  # &lt;-- correct
spec:
  ...
  selector:
    matchlabels:
      type: nginx  # incorrect, remove the '-'
  template:
    metadata:
      labels:
        type: nginx  # incorrect, remove the '-' 
    spec:
      ...
---
apiversion: v1
kind: service
...
spec:
  ...
  ports:
  - port: 80  # &lt;-- add '-'
    protocol: tcp
    targetport: 80

"
50497634,kubernetes pod object crashing in infinite loop when trying to deploy dockerized django application with postgresql db,"i am working on my django project and i am trying to deploy it on kubernetes cluster ( google cloud provider ). i've managed to create all the files i need for configuring the cluster:


django app deployment + service .yml files
postgres db deployment + service + persistentvolumeclaim ( which dynamicly creates persistentvolume object and uses pd storage on
cloud nodes by default )+ secret .yml files
docker file + docker compose ( i dont have much experience with docker so there might be something wrong with them, maybe that is the
issue but i cannot figure it out )


for some reason when i try to apply them my pods, specifically django application pods, are crashing in an infinite loop. also my postgres pod is not crashing but it is not running eather.

can anyone help me figure out what am i doing wrong? here is my github repo: https://github.com/…/mast…/agents/config/kubernetes/postgres

my best guess is that i did not set databases configuration in settings.py file correct, and that my django application cannot find database host specified in settings.py. if anyone has any suggestions please leave a comment.

here is a picture of my kubernetes pod list:


here is a picture where i've described 1st pod object:


and here is a picture of one of my nodes described:



* update *

here is what my error message looks like when i try to run python src/manage.py runserver:

(web_development) cepa995@cepa995-virtualbox:~/agentske_tehnologije/agents$ python src/manage.py runserver
/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/psycopg2/__init__.py:144: userwarning: the psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use ""pip install psycopg2-binary"" instead. for details see: &lt;http://initd.org/psycopg/docs/install.html#binary-install-from-pypi&gt;.
  """""")
/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/psycopg2/__init__.py:144: userwarning: the psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use ""pip install psycopg2-binary"" instead. for details see: &lt;http://initd.org/psycopg/docs/install.html#binary-install-from-pypi&gt;.
  """""")
performing system checks...

system check identified no issues (0 silenced).
unhandled exception in thread started by &lt;function check_errors.&lt;locals&gt;.wrapper at 0x7f6b37e9a9d8&gt;
traceback (most recent call last):
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 216, in ensure_connection
    self.connect()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 194, in connect
    self.connection = self.get_new_connection(conn_params)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/postgresql/base.py"", line 168, in get_new_connection
    connection = database.connect(**conn_params)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/psycopg2/__init__.py"", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.operationalerror: could not translate host name ""postgres-service"" to address: name or service not known


the above exception was the direct cause of the following exception:

traceback (most recent call last):
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/utils/autoreload.py"", line 225, in wrapper
    fn(*args, **kwargs)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/core/management/commands/runserver.py"", line 124, in inner_run
    self.check_migrations()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/core/management/base.py"", line 427, in check_migrations
    executor = migrationexecutor(connections[default_db_alias])
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/migrations/executor.py"", line 18, in __init__
    self.loader = migrationloader(self.connection)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/migrations/loader.py"", line 49, in __init__
    self.build_graph()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/migrations/loader.py"", line 206, in build_graph
    self.applied_migrations = recorder.applied_migrations()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/migrations/recorder.py"", line 61, in applied_migrations
    if self.has_table():
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/migrations/recorder.py"", line 44, in has_table
    return self.migration._meta.db_table in self.connection.introspection.table_names(self.connection.cursor())
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 255, in cursor
    return self._cursor()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 232, in _cursor
    self.ensure_connection()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 216, in ensure_connection
    self.connect()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/utils.py"", line 89, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 216, in ensure_connection
    self.connect()
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/base/base.py"", line 194, in connect
    self.connection = self.get_new_connection(conn_params)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/django/db/backends/postgresql/base.py"", line 168, in get_new_connection
    connection = database.connect(**conn_params)
  file ""/home/cepa995/anaconda3/envs/web_development/lib/python3.6/site-packages/psycopg2/__init__.py"", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
django.db.utils.operationalerror: could not translate host name ""postgres-service"" to address: name or service not known

",<django><postgresql><docker><kubernetes><google-kubernetes-engine>,50525773,1,"your application cannot connect to the database, because your postgres server cannot start (you have 0/1 pods in ready state).

you did not publish its pod events, but i guess the main reason is its volume. 

in your postgres specs, i see you set the volume type to
readwritemany, but google cloud does not provide volumes with that type (documentation, path ""access modes"") and, actually, i don't see the reason why you need it. change the type to readwriteonce and redeploy the database, it should help.

p.s. to get a log of application in a cluster, you can call kubectl logs $podname, it’s much more helpful 
p.p.s. when you publish text information, use a text format, please. 
"
64267964,how to properly configure kubernetes probes timing (for spring boot application),"we have a simple spring boot web application which takes less than 30 seconds to start. so i configured the probes as follow:
    readinessprobe:
      httpget:
        path: /actuator/health/readiness
        port: 8080
      initialdelayseconds: 30
      periodseconds: 1
    livenessprobe:
      httpget:
        path: /actuator/health/liveness
        port: 8080
      initialdelayseconds: 30
      periodseconds: 1

my understanding is that readiness probe waits for 30 seconds and then will succeed (if the application is started). and also liveness probe with 30 seconds delay (from the beginning of the deployment) starts and will succeeds almost at the same time readiness probe succeeds (if the application is ready). but what i see in logs is that readiness probe waits for 30 seconds and then succeeds, but after that there's another 30 seconds waiting time and then the old pod gets shut down:
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:07.378z&quot;,&quot;logger&quot;:&quot;org.springframework.boot.web.embedded.tomcat.tomcatwebserver&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;message&quot;:&quot;tomcat started on port(s): 8080 (http) with context path ''&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:07.387z&quot;,&quot;logger&quot;:&quot;org.springframework.data.repository.config.deferredrepositoryinitializationlistener&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;message&quot;:&quot;triggering deferred initialization of spring data repositories…&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:09.441z&quot;,&quot;logger&quot;:&quot;org.springframework.data.repository.config.deferredrepositoryinitializationlistener&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;message&quot;:&quot;spring data repositories initialized!&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:09.469z&quot;,&quot;logger&quot;:&quot;com.example.application&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;message&quot;:&quot;started application in 23.918 seconds (jvm running for 25.343)&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:14.251z&quot;,&quot;logger&quot;:&quot;org.apache.catalina.core.containerbase.[tomcat].[localhost].[/]&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;http-nio-8080-exec-1&quot;,&quot;message&quot;:&quot;initializing spring dispatcherservlet 'dispatcherservlet'&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:14.258z&quot;,&quot;logger&quot;:&quot;org.springframework.web.servlet.dispatcherservlet&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;http-nio-8080-exec-1&quot;,&quot;message&quot;:&quot;initializing servlet 'dispatcherservlet'&quot;}
develop/demo-57c8984866-6v5sl[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:14.292z&quot;,&quot;logger&quot;:&quot;org.springframework.web.servlet.dispatcherservlet&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;http-nio-8080-exec-1&quot;,&quot;message&quot;:&quot;completed initialization in 30 ms&quot;}
develop/demo-79cc9bc757-xlg6z[demo]: 2020-10-08t17:33:44.590172 shutting down...
develop/demo-79cc9bc757-xlg6z[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:44.658z&quot;,&quot;logger&quot;:&quot;org.springframework.orm.jpa.localcontainerentitymanagerfactorybean&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;springcontextshutdownhook&quot;,&quot;message&quot;:&quot;closing jpa entitymanagerfactory for persistence unit 'default'&quot;}
develop/demo-79cc9bc757-xlg6z[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:44.664z&quot;,&quot;logger&quot;:&quot;org.springframework.scheduling.concurrent.threadpooltaskexecutor&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;springcontextshutdownhook&quot;,&quot;message&quot;:&quot;shutting down executorservice 'applicationtaskexecutor'&quot;}
develop/demo-79cc9bc757-xlg6z[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:44.667z&quot;,&quot;logger&quot;:&quot;com.zaxxer.hikari.hikaridatasource&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;springcontextshutdownhook&quot;,&quot;message&quot;:&quot;hikaripool-1 - shutdown initiated...&quot;}
develop/demo-79cc9bc757-xlg6z[demo]: {&quot;ts&quot;:&quot;2020-10-08t17:33:44.680z&quot;,&quot;logger&quot;:&quot;com.zaxxer.hikari.hikaridatasource&quot;,&quot;level&quot;:&quot;info&quot;,&quot;thread&quot;:&quot;springcontextshutdownhook&quot;,&quot;message&quot;:&quot;hikaripool-1 - shutdown completed.&quot;}

what's the reason for the 2nd 30-second waiting time (see the first &quot;shutting down...&quot;)? for the record, there's not sigterm problem (the application responds properly to sigterm).
more info
correct me if i'm wrong about how these probes work: the container starts, at this moment the timer for readiness initial delay also starts. 25 sec later the app is ready. 5 more sec later, the readiness probe starts hitting the app/container and it succeeds, thus the app is ready (right?). at this point i expect k8s send the sigterm to the old pod, asking it to shut down. but as shown in the logs, after the new container is ready, the old pod is still running for 30 more sec.
maybe, rephrasing the question helps. i'd like to shut down old pod right after the app is ready. and the app is ready in less than 30 sec. in other words i need the whole deployment to take only 30 sec (considering the startup is less than 30 sec and shutdown is less than one sec). why the above configuration doesn't do that?
thanks.
",<spring-boot><kubernetes><amazon-eks>,64314787,3,"ok, it turned out the tool (kubecfg) and library we use to manage our k8s manifests has a different default value for minreadyseconds property (30 seconds). i changed that and everything is working as expected.
"
61510300,rollout restart statefulset using kubectl proxy,"i have started kubectl proxy from within my pods and am able to access kubernetes apis. i have a need to restart my statefulset.

using kubectl, i would done this:

kubectl rollout restart statefulset my-statefulset


however, i would like to do this using the rest apis. for instance, i can delete my pods, using this:

curl -xdelete localhost:8080/api/v1/namespaces/default/pods


is there any equivalent rest endpoint that i can use to rollout restart a statefulset?
",<kubernetes><kubectl><kubernetes-statefulset>,61511241,4,"i run your command kubectl rollout restart statefulset my-statefulset --v 10 and notice the output logs.

i figured out  kubectl makes a patch request when i apply above command. and i am able to do that patch request using curl like following

curl -k --data '{""spec"":{""template"":{""metadata"":{""annotations"":{""kubectl.kubrnetes.io/restartedat"":""'""$(date +%y-%m-%dt%t%z)""'""}}}}}'\ 
    -xpatch   -h ""accept: application/json, */*"" -h ""content-type: application/strategic-merge-patch+json""\
    localhost:8080/apis/apps/v1/namespaces/default/statefulsets/my-statefulset

"
65233476,how to get output from an interactive shell inside of a pod,"i am trying to write a python script using one of the sdk by my org, and extract some useful information from kubernetes pod.
the sdk i have has a podexec() function which can be used to execute a command inside the pod.
i have a specific usecase, where i've to execute a command inside of the pod, which inturn will spin up an interactive shell, and then in that interactive shell, i want to execute a command and print the output.
for example, let's say there's a mysql pod, and i want to first exec into the mysql pod, and then run mysql command which will bring up an interactive mysql shell, where i want to enter some commands like &quot;show tables;&quot;, and then get the output of that command in my script. is it possible?
after getting into the pod, i am able to run a single command like below
kubectl exec -it mysql-pod -- bash

echo &quot;show tables;&quot; |mysql

now how to run this without entering the pod with just the kubectl?
note: my usecase is not w.r.t mysql actually. my org has a custom tool which lets us execute commands in it's interactive shell. mysql here is just an example.
",<python><mysql><kubernetes><kubectl><kubernetes-pod>,65234059,1,"ok. figured it out.
kubectl exec -it mysql-pod -- bash -c &quot;echo \&quot;show tables\&quot; |mysql&quot;

"
66868323,"after certificates renewal, an error: ""you must be logged in to the server (unauthorized)""","my certificates were expired:
root@ubuntu:~# kubectl get pods
unable to connect to the server: x509: certificate has expired or is not yet valid                                                                                                                                                           

i verified it by running:
root@ubuntu:~# kubeadm alpha certs check-expiration
[check-expiration] reading configuration from the cluster...
[check-expiration] fyi: you can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[check-expiration] error reading configuration from the cluster. falling back to default configuration

w0330 09:18:49.875780   12562 configset.go:202] warning: kubeadm cannot validate component configs for api groups [kubelet.config.k8s.io kubepro                                                                                             xy.config.k8s.io]
certificate                expires                  residual time   certificate authority   externally managed
admin.conf                 mar 29, 2021 09:27 utc   &lt;invalid&gt;                               no
apiserver                  mar 29, 2021 09:27 utc   &lt;invalid&gt;       ca                      no
apiserver-etcd-client      mar 29, 2021 09:27 utc   &lt;invalid&gt;       etcd-ca                 no
apiserver-kubelet-client   mar 29, 2021 09:27 utc   &lt;invalid&gt;       ca                      no
controller-manager.conf    mar 29, 2021 09:27 utc   &lt;invalid&gt;                               no
etcd-healthcheck-client    mar 29, 2021 09:27 utc   &lt;invalid&gt;       etcd-ca                 no
etcd-peer                  mar 29, 2021 09:27 utc   &lt;invalid&gt;       etcd-ca                 no
etcd-server                mar 29, 2021 09:27 utc   &lt;invalid&gt;       etcd-ca                 no
front-proxy-client         mar 29, 2021 09:27 utc   &lt;invalid&gt;       front-proxy-ca          no
scheduler.conf             mar 29, 2021 09:27 utc   &lt;invalid&gt;                               no

certificate authority   expires                  residual time   externally managed
ca                      mar 27, 2030 09:27 utc   8y              no
etcd-ca                 mar 27, 2030 09:27 utc   8y              no
front-proxy-ca          mar 27, 2030 09:27 utc   8y              no

i renew the certificates by running: kubeadm alpha certs renew all.
w0330 09:20:21.951839   13124 configset.go:202] warning: kubeadm cannot validate component configs for api groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed
certificate for serving the kubernetes api renewed
certificate the apiserver uses to access etcd renewed
certificate for the api server to connect to kubelet renewed
certificate embedded in the kubeconfig file for the controller manager to use renewed
certificate for liveness probes to healthcheck etcd renewed
certificate for etcd nodes to communicate with each other renewed
certificate for serving etcd renewed
certificate for the front proxy client renewed
certificate embedded in the kubeconfig file for the scheduler manager to use renewed

all the certificates are now updated to 2022 so it should be okay:
certificate                expires                  residual time   certificate authority   externally managed
admin.conf                 mar 30, 2022 09:20 utc   364d                                    no
apiserver                  mar 30, 2022 09:20 utc   364d            ca                      no
apiserver-etcd-client      mar 30, 2022 09:20 utc   364d            etcd-ca                 no
apiserver-kubelet-client   mar 30, 2022 09:20 utc   364d            ca                      no
controller-manager.conf    mar 30, 2022 09:20 utc   364d                                    no
etcd-healthcheck-client    mar 30, 2022 09:20 utc   364d            etcd-ca                 no
etcd-peer                  mar 30, 2022 09:20 utc   364d            etcd-ca                 no
etcd-server                mar 30, 2022 09:20 utc   364d            etcd-ca                 no
front-proxy-client         mar 30, 2022 09:20 utc   364d            front-proxy-ca          no
scheduler.conf             mar 30, 2022 09:20 utc   364d                                    no

certificate authority   expires                  residual time   externally managed
ca                      mar 27, 2030 09:27 utc   8y              no
etcd-ca                 mar 27, 2030 09:27 utc   8y              no
front-proxy-ca          mar 27, 2030 09:27 utc   8y              no

but when i run kubectl get pods i received the error:
error: you must be logged in to the server (unauthorized)

it should be a problem with the certificate i think, but i am not sure how to fix it. should i create new certificate and replace the one that inside the config file?
",<kubernetes><kubectl><kubeadm>,66868489,30,"the ~/.kube/config wasn't updated with the changes.
i ran:
mkdir -p $home/.kube
sudo cp -i /etc/kubernetes/admin.conf $home/.kube/config
sudo chown $(id -u):$(id -g) $home/.kube/config  

and it fixed it.
"
69734715,kubectl jsonpath query and output multiple object values,"below is my output of kubectl get deploy --all-namespaces:
{
    &quot;apiversion&quot;: &quot;v1&quot;,
    &quot;items&quot;: [
        {
            &quot;apiversion&quot;: &quot;apps/v1&quot;,
            &quot;kind&quot;: &quot;deployment&quot;,
            &quot;metadata&quot;: {
                &quot;annotations&quot;: {
                    &quot;downscaler/uptime&quot;: &quot;mon-fri 07:00-23:59 australia/sydney&quot;,
                &quot;name&quot;: &quot;actiontest-v2.0.9&quot;,
                &quot;namespace&quot;: &quot;actiontest&quot;,
            },
            &quot;spec&quot;: {
        ......
        ......
        },
        {
            &quot;apiversion&quot;: &quot;apps/v1&quot;,
            &quot;kind&quot;: &quot;deployment&quot;,
            &quot;metadata&quot;: {
                &quot;annotations&quot;: {
                    &quot;downscaler/uptime&quot;: &quot;mon-fri 07:00-21:00 australia/sydney&quot;,
                &quot;name&quot;: &quot;anotherapp-v0.1.10&quot;,
                &quot;namespace&quot;: &quot;anotherapp&quot;,
            },
            &quot;spec&quot;: {
        ......
        ......
        }
}

i need to find the name of the deployment and its namespace if the annotation &quot;downscaler/uptime&quot; matches the value &quot;mon-fri 07:00-21:00 australia/sydney&quot;. i am expecting an output like below:
deployment_name,namespace

if i am running below query against a single deployment, i get the required output.
#kubectl get deploy -n anotherapp -o jsonpath='{range .[*]}{.items[?(@.metadata.annotations.downscaler/uptime==&quot;mon-fri 07:00-21:00 australia/sydney&quot;)].metadata.name}{&quot;,&quot;}{.items[?(@.metadata.annotations.downscaler/uptime==&quot;mon-fri 07:00-21:00 australia/sydney&quot;)].metadata.namespace}{&quot;\n&quot;}'

anotherapp-v0.1.10,anotherapp

but when i run it against all namespaces, i am getting an output like below:
#kubectl get deploy --all-namespaces -o jsonpath='{range .[*]}{.items[?(@.metadata.annotations.downscaler/uptime==&quot;mon-fri 07:00-21:00 australia/sydney&quot;)].metadata.name}{&quot;,&quot;}{.items[?(@.metadata.annotations.downscaler/uptime==&quot;mon-fri 07:00-21:00 australia/sydney&quot;)].metadata.namespace}{&quot;\n&quot;}'


actiontest-v2.0.9 anotherapp-v0.1.10, actiontest anotherapp

",<kubernetes><formatting><kubectl><jsonpath>,69739834,2,"this is quite short answer, however you can use this option:
kubectl get deploy --all-namespaces -o jsonpath='{range .items[?(.metadata.annotations.downscaler/uptime==&quot;mon-fri 07:00-21:00 australia/sydney&quot;)]}{.metadata.name}{&quot;\t&quot;}{.metadata.namespace}{&quot;\n&quot;}'

what i changed is logic how to work with data:
first thing what happens is getting into range list of elements we need to work on, not everything. i used filter expression - see jsonpath notation - syntax elements.
and once we have already filtered entities in the list, we can easily retrieve other fields we need.
"
58622015,using docker socket in kubernetes pod,"i want to prune docker images, i wrote a small docker image using node-docker-api and i was able to test it locally with success.
as i've deployed the daemonset to kubernetes, the pod fails to access the docker socket:

error: connect eacces /var/run/docker.sock


the deployment.yaml looks as following:

apiversion: extensions/v1beta1
kind: daemonset
metadata:
  labels:
    name: docker-image-cleanup
  name: docker-image-cleanup
spec:
  template:
    metadata:
      labels:
        app: docker-image-cleanup 
    spec:
      volumes:
        - name: docker-sock
          hostpath:
            path: ""/var/run/docker.sock""
            type: file
        - name: docker-directory
          hostpath:
            path: ""/var/lib/docker""

      containers:
        - name: docker-image-cleanup
          image: image:tag
          securitycontext:
            privileged: true
          env:
            - name: prune_interval_seconds
              value: ""30""
            - name: prune_dangling
              value: ""true""
          volumemounts:
            - mountpath: /var/run/docker.sock
              name: docker-sock
              readonly: false
            - mountpath: ""/var/lib/docker""
              name: docker-directory
              readonly: false


running aks v1.13.10 - if relevant 
",<docker><kubernetes><azure-aks><kubernetes-pod>,58623655,8,"i've added runasuser: 0 to the container properties:

containers:
  - name: docker-image-cleanup
    image: image:tag
    securitycontext:
      privileged: true
      runasuser: 0


now it works
"
63659094,update helm chart with additional properties,"we are using the prometheus operator chart
currently, im creating my own values.yaml that im overriding the default values from the chart like
helm install po -f values.yaml stable/prometheus-operator -n po
there is a grafana properties which i need to modify as the opertor come with grafana properties
https://github.com/helm/charts/blob/master/stable/prometheus-operator/values.yaml#l486
however, i want to modify properties that is not in the values.yaml of the prometheus chart and found here:
https://github.com/helm/charts/blob/master/stable/grafana/values.yaml#l422 (there is a reference on the chart)
my question is assume i want to modify the client_id , what is the recommended way to do it?
https://github.com/helm/charts/blob/master/stable/grafana/values.yaml#l431
",<kubernetes><prometheus><grafana><kubernetes-helm><prometheus-operator>,63659182,2,"you can overwrite the values of dependent charts by using the name of the dependency (which for grafana in the prometheus chart can be found here) as another key within the values.yml.
in thise case, it is just grafana and so to overwrite it in your values.yml, do it like this:
# ... config of the original prometheus chart

# overwrite grafana's yaml by using the dependency name
grafana:
  grafana.ini:
    auth.github:
      client_id: 'what you need to put here'

"
56739017,escaping helm yml for deployment,"i am trying to figure out how to escape these pieces of a yml file in order to use with helm.  

            - name: syslog_tag
              value: '{{ index .container.config.labels ""io.kubernetes.pod.namespace"" }}[{{ index .container.config.labels ""io.kubernetes.pod.name"" }}]'
            - name: syslog_hostname
              value: '{{ index .container.config.labels ""io.kubernetes.container.name"" }}'


the yml file is a daemonset for sending logs to papertrail with instructions here for a standard kubernetes manual deployment https://help.papertrailapp.com/kb/configuration/configuring-centralized-logging-from-kubernetes/ .  here is a link to the full yml file https://help.papertrailapp.com/assets/files/papertrail-logspout-daemonset.yml .    

i found some answers on how to escape the curly braces and quotes, but still can't seem to get it to work.  it would be easiest if there was some way to just get helm to not evaluate each entire value.  

the last i tried was this, but still results in an error.   

              value: ''""{{"" index .container.config.labels \""io.kubernetes.pod.namespace\"" ""}}""[""{{"" index .container.config.labels \""io.kubernetes.pod.name\"" ""}}""]''
            - name: syslog_hostname
              value: ''""{{"" index .container.config.labels \""io.kubernetes.container.name\"" ""}}""''


this is the error:

error: upgrade failed: yaml parse error on templates/papertrail-logspout-daemonset.yml: error converting yaml to json: yaml: line 21: did not find expected key


i can hardcode values for both of these and it works fine.  i don't quite understand how these env variables work, but what happens is that logs are sent to papertrail for each pod in a node with the labels from each of those pods.  namespace, pod name, and container name.   

          env:
            - name: route_uris
              value: ""{{ .values.backend.log.destination }}""
{{ .files.get ""files/syslog_vars.yaml"" | indent 13 }}

",<kubernetes><kubernetes-helm>,56745501,3,"two sensible approaches come to mind.

one is to define a template that expands to the string {{, at which point you can use that in your variable expansion.  you don't need to specially escape }}.

{{- define ""cc"" }}{{ printf ""{{"" }}{{ end -}}
- name: syslog_hostname
  value: '{{cc}} index .container.config.labels ""io.kubernetes.container.name"" }}'


a second approach, longer-winded but with less escaping, is to create an external file that has these environment variable fragments.

# i am files/syslog_vars.yaml
- name: syslog_hostname
  value: '{{ index .container.config.labels ""io.kubernetes.container.name"" }}'


then you can include the file.  this doesn't apply any templating in the file, it just reads it as literal text.

env:
{{ .files.get ""files/syslog_vars.yaml"" | indent 2 }}


the important point with this last technique, and the problem you're encountering in the question, is that helm reads an arbitrary file, expands all of the templating, and then tries to interpret the resulting text as yaml.  the indent 2 part of this needs to match whatever the rest of your env: block has; if this is deep inside a deployment spec it might need to be 8 or 10 spaces.  helm template will render a chart to text without trying to do additional processing, which is really helpful for debugging.
"
68505269,helm prometheus operator doesn't add new servicemonitor endpoints to targets,"i'm trying to monitor my app using helm prometheus https://github.com/prometheus-community/helm-charts. i've installed this helm chart successfully.
prometheus-kube-prometheus-operator-5d8dcd5988-bw222   1/1     running   0          11h
prometheus-kube-state-metrics-5d45f64d67-97vxt         1/1     running   0          11h
prometheus-prometheus-kube-prometheus-prometheus-0     2/2     running   0          11h
prometheus-prometheus-node-exporter-gl4cz              1/1     running   0          11h
prometheus-prometheus-node-exporter-mxrsm              1/1     running   0          11h
prometheus-prometheus-node-exporter-twvdb              1/1     running   0          11h

app service and deployment created in the same namespace, by these yml configs:
apiversion: apps/v1
kind: deployment
metadata:
  name: appservice
  namespace: monitoring
  labels:
    app: appservice
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/actuator/prometheus'
spec:
  replicas: 1
  selector:
    matchlabels:
      app: appservice
  template:
    metadata:
      labels:
        app: appservice
...

apiversion: v1
kind: service
metadata:
  name: appservice
  namespace: monitoring
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/actuator/prometheus'
spec:
  selector:
    app: appservice
  type: clusterip
  ports:
    - name: web
      protocol: tcp
      port: 8080
      targetport: 8080
    - name: jvm-debug
      protocol: tcp
      port: 5005
      targetport: 5005

and after app was deployed, i had created servicemonitor:
apiversion: monitoring.coreos.com/v1
kind: servicemonitor
metadata:
  name: appservice-servicemonitor
  namespace: monitoring
  labels:
    app: appservice
    release: prometheus-repo
spec:
  selector:
    matchlabels:
      app: appservice # target app service
  namespaceselector:
    matchnames:
      - monitoring
  endpoints:
  - port: web
    path: '/actuator/prometheus'
    interval: 15s

i expect that after adding this servicemonitor, my prometheus instance create new target``` like &quot;http://appservice:8080/actuator/prometheus&quot;, but it is not, new endpoints doesn't appears in prometheus ui.
i tried to change helm values by adding additionalservicemonitors
namespaceoverride: &quot;monitoring&quot;
nodeexporter:
  enabled: true

prometheus:
  enabled: true
  prometheusspec:
    servicemonitorselectorniluseshelmvalues: false
    servicemonitorselector:
      matchlabels:
       release: prometheus-repo
    additionalservicemonitors:
      namespaceselector:
        any: true
    replicas: 1
    shards: 1
    storagespec:
      ...
    securitycontext:
      ...
    nodeselector:
      assignment: monitoring

  nodeselector:
    assignment: monitoring

prometheusoperator:
  nodeselector:
    assignment: monitoring
  admissionwebhooks:
    patch:
      securitycontext:
        ...
  securitycontext:
    ...

global:
  alertmanagerspec:
    nodeselector:
      assignment: monitoring

but it didn't help.
it is really hard to say what is going wrong, no error logs, all configs applies successfully.
",<kubernetes><prometheus><kubernetes-helm><prometheus-operator><kube-prometheus-stack>,70696432,4,"i found this guide very helpful.
please keep in mind that depending on the prometheus stack you are using labels and names can have different default values (for me, using kube-prometheus-stack, for example the secret name was prometheus-kube-prometheus-stack-prometheus instead of prometheus-k8s).
essential quotes:

has my servicemonitor been picked up by prometheus?
servicemonitor objects and the namespace where they belong are selected by the servicemonitorselector and servicemonitornamespaceselectorof a prometheus object. the name of a servicemonitor is encoded in the prometheus configuration, so you can simply grep whether it is present there. the configuration generated by the prometheus operator is stored in a kubernetes secret, named after the prometheus object name prefixed with prometheus- and is located in the same namespace as the prometheus object. for example for a prometheus object called k8s one can find out if the servicemonitor named my-service-monitor has been picked up with:
kubectl -n monitoring get secret prometheus-k8s -ojson | jq -r '.data[&quot;prometheus.yaml.gz&quot;]' | base64 -d | gunzip | grep &quot;my-service-monitor

"
66081840,how to recreate a kubernetes persistentvolume?,"i have a persistent volume.
i want to force kubernetes to recreate it, as the contents is corrupted.  alternatively, if there's a way to fix that, it would be a solution.
i have checked that the persistent volume is working as expected using:
kubectl describe pv -n 

and my pod was previously using it.  however, my pod is now failing due to a corrupted file within the persistent volume.
i would like to recreate the persistent volume.
if i delete the persistent volume, will kubernetes create a new one, or will i have to manually create a new one to attach?
",<kubernetes><amazon-eks><amazon-ebs>,66082637,1,"if you delete a persistent volume then kubernetes will not create a new one for you, you have to manually create a new one. basically it is the simple answer of your question.
but there are basically three options when you are done with your pv, you can delete the pvc object then depending on the pv reclaim policy you will have three options: delete, retain, recycle. now it depends on what policy is set in your pv reclaim policy.
as kubernetes official docs stated:

when a user is done with their volume, they can delete the pvc objects from the api that allows reclamation of the resource. the reclaim policy for a persistentvolume tells the cluster what to do with the volume after it has been released of its claim. currently, volumes can either be retained, recycled, or deleted.

for more you can look at the persistent volume docs of kubernetes.
"
67073909,error scaling up in hpa in gke: apiserver was unable to write a json response: http2: stream closed,"following the guide that google made for deploying an hpa in google kubernetes engine: https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics
and adding the right permissions because i am using workload identity with this guide: https://github.com/googlecloudplatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter
and also adding the firewall-rule commented here: https://github.com/kubernetes-sigs/prometheus-adapter/issues/134
i am stuck in a point where the hpa returns me this error:
kubectl describe hpa -n test-namespace
name:                  my-hpa
namespace:             test-namespace
labels:                &lt;none&gt;
annotations:           &lt;none&gt;
creationtimestamp:     tue, 13 apr 2021 12:47:56 +0200
reference:             statefulset/my-set
metrics:               ( current / target )
  &quot;my-metric&quot; on pods:  &lt;unknown&gt; / 1
min replicas:          1
max replicas:          60
statefulset pods:      1 current / 0 desired
conditions:
  type           status  reason               message
  ----           ------  ------               -------
  abletoscale    true    succeededgetscale    the hpa controller was able to get the target's current scale
  scalingactive  false   failedgetpodsmetric  the hpa was unable to compute the replica count: unable to get metric my-metric: no metrics returned from custom metrics api
events:
  type     reason                        age                   from                       message
  ----     ------                        ----                  ----                       -------
  warning  failedgetpodsmetric           8m26s (x40 over 18m)  horizontal-pod-autoscaler  unable to get metric my-metric: no metrics returned from custom metrics api
  warning  failedcomputemetricsreplicas  3m26s (x53 over 18m)  horizontal-pod-autoscaler  failed to compute desired number of replicas based on listed metrics for statefulset/test-namespace/my-set: invalid metrics (1 invalid out of 1), first error is: failed to get pods metric value: unable to get metric my-metric: no metrics returned from custom metrics api

but the apiservices are in true,
kubectl get apiservices
name                                     service                                             available   age
...
v1beta1.custom.metrics.k8s.io            custom-metrics/custom-metrics-stackdriver-adapter   true        24h
v1beta1.external.metrics.k8s.io          custom-metrics/custom-metrics-stackdriver-adapter   true        24h
v1beta2.custom.metrics.k8s.io            custom-metrics/custom-metrics-stackdriver-adapter   true        24h
...

and when i try to retrieve the metric data it returns ok,
kubectl get --raw &quot;/apis/custom.metrics.k8s.io/v1beta2/namespaces/test-namespace/pods/*/my-metric&quot; | jq .
{
  &quot;kind&quot;: &quot;metricvaluelist&quot;,
  &quot;apiversion&quot;: &quot;custom.metrics.k8s.io/v1beta2&quot;,
  &quot;metadata&quot;: {
    &quot;selflink&quot;: &quot;/apis/custom.metrics.k8s.io/v1beta2/namespaces/test-namespace/pods/%2a/my-metric&quot;
  },
  &quot;items&quot;: [
    {
      &quot;describedobject&quot;: {
        &quot;kind&quot;: &quot;pod&quot;,
        &quot;namespace&quot;: &quot;test-namespace&quot;,
        &quot;name&quot;: &quot;my-metrics-api-xxxx&quot;,
        &quot;apiversion&quot;: &quot;/__internal&quot;
      },
      &quot;metric&quot;: {
        &quot;name&quot;: &quot;my-metric&quot;,
        &quot;selector&quot;: null
      },
      &quot;timestamp&quot;: &quot;2021-04-13t11:15:30z&quot;,
      &quot;value&quot;: &quot;5&quot;
    }
  ]
}

but the stackdriver gives me this error:
2021-04-13t11:01:30.432634z apiserver was unable to write a json response: http2: stream closed
2021-04-13t11:01:30.432679z apiserver received an error that is not an metav1.status: &amp;errors.errorstring{s:&quot;http2: stream closed&quot;}

i had to configure the adapter that google provides like this:
apiversion: v1
kind: namespace
metadata:
  name: custom-metrics
---
apiversion: v1
kind: serviceaccount
metadata:
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
---
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: custom-metrics:system:auth-delegator
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: system:auth-delegator
subjects:
- kind: serviceaccount
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
---
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: custom-metrics-auth-reader
  namespace: kube-system
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: extension-apiserver-authentication-reader
subjects:
- kind: serviceaccount
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
---
apiversion: rbac.authorization.k8s.io/v1beta1
kind: clusterrolebinding
metadata:
  name: custom-metrics-resource-reader
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: view
subjects:
- kind: serviceaccount
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
---
apiversion: apps/v1
kind: deployment
metadata:
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
  labels:
    run: custom-metrics-stackdriver-adapter
    k8s-app: custom-metrics-stackdriver-adapter
spec:
  replicas: 1
  selector:
    matchlabels:
      run: custom-metrics-stackdriver-adapter
      k8s-app: custom-metrics-stackdriver-adapter
  template:
    metadata:
      labels:
        run: custom-metrics-stackdriver-adapter
        k8s-app: custom-metrics-stackdriver-adapter
        kubernetes.io/cluster-service: &quot;true&quot;
    spec:
      serviceaccountname: custom-metrics-stackdriver-adapter
      containers:
      - image: gcr.io/gke-release/custom-metrics-stackdriver-adapter:v0.12.0-gke.0
        imagepullpolicy: always
        name: pod-custom-metrics-stackdriver-adapter
        command:
        - /adapter
        - --use-new-resource-model=true
        - --cert-dir=/tmp
        - --secure-port=4443
        resources:
          limits:
            cpu: 250m
            memory: 200mi
          requests:
            cpu: 250m
            memory: 200mi
        securitycontext:
          runasnonroot: true
          runasuser: 1000
---
apiversion: v1
kind: service
metadata:
  labels:
    run: custom-metrics-stackdriver-adapter
    k8s-app: custom-metrics-stackdriver-adapter
    kubernetes.io/cluster-service: 'true'
    kubernetes.io/name: adapter
  name: custom-metrics-stackdriver-adapter
  namespace: custom-metrics
spec:
  ports:
  - port: 443
    protocol: tcp
    targetport: 4443
  selector:
    run: custom-metrics-stackdriver-adapter
    k8s-app: custom-metrics-stackdriver-adapter
  type: clusterip
---
apiversion: apiregistration.k8s.io/v1
kind: apiservice
metadata:
  name: v1beta1.custom.metrics.k8s.io
spec:
  insecureskiptlsverify: true
  group: custom.metrics.k8s.io
  grouppriorityminimum: 100
  versionpriority: 100
  service:
    name: custom-metrics-stackdriver-adapter
    namespace: custom-metrics
  version: v1beta1
---
apiversion: apiregistration.k8s.io/v1
kind: apiservice
metadata:
  name: v1beta2.custom.metrics.k8s.io
spec:
  insecureskiptlsverify: true
  group: custom.metrics.k8s.io
  grouppriorityminimum: 100
  versionpriority: 200
  service:
    name: custom-metrics-stackdriver-adapter
    namespace: custom-metrics
  version: v1beta2
---
apiversion: apiregistration.k8s.io/v1
kind: apiservice
metadata:
  name: v1beta1.external.metrics.k8s.io
spec:
  insecureskiptlsverify: true
  group: external.metrics.k8s.io
  grouppriorityminimum: 100
  versionpriority: 100
  service:
    name: custom-metrics-stackdriver-adapter
    namespace: custom-metrics
  version: v1beta1
---
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: external-metrics-reader
rules:
- apigroups:
  - &quot;external.metrics.k8s.io&quot;
  resources:
  - &quot;*&quot;
  verbs:
  - list
  - get
  - watch
---
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: external-metrics-reader
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: external-metrics-reader
subjects:
- kind: serviceaccount
  name: horizontal-pod-autoscaler
  namespace: kube-system

because it was disabled the port 443 and i had to change to 4443 and put also the --cert-dir=/tmp option because without that option, stackdriver returns me the error:
&quot;unable to run custom metrics adapter: error creating self-signed certificates: mkdir apiserver.local.config: permission denied&quot;

i think that i explained all the steps that i did to configure it, without success. any ideas?
",<kubernetes><google-cloud-platform><google-kubernetes-engine><stackdriver><hpa>,67083280,5,"resolved for me!
after a several of test, changing in the hpa yaml,
the metric from pod to external, and the metric name with custom.google.apis/my-metric, it works!
apiversion: autoscaling/v2beta2
kind: horizontalpodautoscaler
metadata:
  name: my-hpa
  namespace: test-namespace
spec:
  maxreplicas: 60
  minreplicas: 1
  scaletargetref:
    apiversion: apps/v1
    kind: statefulset
    name: my-set
  metrics:
  - type: external
    external:
      metric: 
        name: custom.googleapis.com/my-metric #custom.googleapis.com/my-metric
      target:
        averagevalue: 1
        type: averagevalue

"
52784153,how to set kube-proxy settings using kubectl on aks,"i keep reading documentation that gives parameters for kube-proxy, but does not explain how where these parameters are supposed to be used. i create my cluster using az aks create with the azure-cli program, then i get credentials and use kubectl. so far everything i've done has involved yaml for services and deployments and such, but i can't figure out where all this kube-proxy stuff fits into all of this.

i've googled for days. i've opened question issues on github with aks. i've asked on the kubernetes slack channel, but nobody has responded.
",<kubernetes><kubectl><azure-aks>,52784510,8,"the kube-proxy on all your kubernetes nodes runs as a kubernetes daemonset and its configuration is stored on a kubernetes configmap.  to make any changes or add/remove options you will have to edit the kube-proxy daemonset or configmap on the kube-system namespace.

$ kubectl -n kube-system edit daemonset kube-proxy


or 

$ kubectl -n kube-system edit configmap kube-proxy


for a reference on the kube-proxy command line options you can refer to here.
"
66236346,kubernetes apiversion: networking.k8s.io/v1 issue with 'ingress',"wanted your guidance on an issue while executing a kubernetes yaml file.
my kubectl version is as follows:
    client version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.0&quot;, gitcommit:&quot;af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-12-08t17:59:43z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;windows/amd64&quot;}
    server version: version.info{major:&quot;1&quot;, minor:&quot;18&quot;, gitversion:&quot;v1.18.14&quot;, gitcommit:&quot;89182bdd065fbcaffefec691908a739d161efc03&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-12-18t12:02:35z&quot;, goversion:&quot;go1.13.15&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

this is the latest version downloaded from the kubernetes site
https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-windows
the yaml has
apiversion: networking.k8s.io/v1
kind: ingress
and the error on running the yaml is
    no matches for kind &quot;ingress&quot; in version &quot;networking.k8s.io/v1&quot;

kubernetes issue https://github.com/kubernetes/kubernetes/issues/90077 mentions that
  networking.k8s.io/v1beta1 == 1.14 to 1.18
  networking.k8s.io/v1 = 1.19+

so i guess it should be working right?
i have changed the api version to
apiversion: extensions/v1beta1 or
apiversion: networking.k8s.io/v1beta1

but fail in another section of the yaml
backend:
  service:
    name: {{ template &quot;fullname&quot; $ }}-srv
     port:
       number: 80

with the error
error validating data: validationerror(ingress.spec.rules[0].http.paths[0].backend): unknown field &quot;service&quot; in io.k8s.api.extensions.v1beta1.ingressbackend
i am informed that the same yaml works on macos with the same kubectl version (i do not have access to verify that though). but any thoughts on where i could be going wrong?
thanks,
prabal
",<kubernetes><kubernetes-ingress>,70855124,42,"i would like to add that according to the k8 deprecation guide, the networking.k8s.io/v1beta1 api versions of ingress is no longer served as of v1.22.
changes include:

the backend servicename field is renamed to service.name
numeric backend serviceport fields are renamed to service.port.number
string backend serviceport fields are renamed to service.port.name
pathtype is now required for each specified path. options are prefix, exact, and implementationspecific.

meaning we need to make the following changes to go from this:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: stackoverflw
  namespace: stacker
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: stacker
          serviceport: 80

to this (example):
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: stackoverflw
  namespace: stacker
spec:
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: stacker
            port:
              number: 80

"
64304947,helm values with build time env vars,"i have a helm chart and in the deployment, i want to provide some environment variable for my pods. during build time in my ci/cd setup, i have the values as env vars and i'm passing them now like this:
helm upgrade chart_name helm --install --set-string webserver.env.database_url=$database_url

i have like more then 20 env vars, can i access them somehow in my values.yml?
webserver:
  env:
    database_url=${database_url}

sadly this one doesn't work.
",<kubernetes><kubernetes-helm><kubernetes-deployment>,64309101,2,"helm does not resolve placeholders (environment variables) inside values files, but you can do it yourself in the ci/cd script, before passing the file to the helm upgrade command:
values-env.yaml:
webserver:
  env:
    database_url=${database_url}

ci/cd script:
eval &quot;echo \&quot;$(cat values-env.yaml)\&quot;&quot; &gt;&gt; values-ci.yaml
helm upgrade chart_name helm --install --values values-ci.yaml


"
65045482,"in aws eks, how can i define ingress to use one alb for multiple subdomain urls, each with their own certificate?","i have multiple services that need to be exposed to the internet, but i'd like to use a single alb for them.
i am using the latest aws load balancer controller, and i've been reading the documentation here (https://kubernetes-sigs.github.io/aws-load-balancer-controller/guide/ingress/annotations/#traffic-routing), but i haven't found a clear explanation on how to achieve this.
here's the setup:
i have service-a.example.com -and- service-b.example.com. they each have their own certificates within amazon certificate manager.
within kubernetes, each has its own service object defined as follows (each unique):
apiversion: v1
kind: service
metadata:
  name: svc-a-service
  annotations:
    alb.ingress.kubernetes.io/healthcheck-protocol: http
    alb.ingress.kubernetes.io/healthcheck-port: traffic-port
    alb.ingress.kubernetes.io/healthy-threshold-count: '5'
    alb.ingress.kubernetes.io/unhealthy-threshold-count: '2'
    alb.ingress.kubernetes.io/healthcheck-path: /index.html
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '30'
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'
    alb.ingress.kubernetes.io/success-codes: '200'
    alb.ingress.kubernetes.io/tags: environment=test,app=servicea
spec:
  selector:
    app: service-a
  ports:
  - port: 80
    targetport: 80
  type: nodeport

and each service has it's own ingress object defined as follows (again, unique to each and with the correct certificates specified for each service):
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: svc-a-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: services
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/security-groups: sg-01234567898765432
    alb.ingress.kubernetes.io/ip-address-type: ipv4
    alb.ingress.kubernetes.io/listen-ports: '[{&quot;http&quot;: 80}, {&quot;https&quot;: 443}]'
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{&quot;type&quot;: &quot;redirect&quot;, &quot;redirectconfig&quot;: { &quot;protocol&quot;: &quot;https&quot;, &quot;port&quot;: &quot;443&quot;, &quot;statuscode&quot;: &quot;http_301&quot;}}'
    alb.ingress.kubernetes.io/actions.response-503: &gt;
      {&quot;type&quot;:&quot;fixed-response&quot;,&quot;fixedresponseconfig&quot;:{&quot;contenttype&quot;:&quot;text/plain&quot;,&quot;statuscode&quot;:&quot;503&quot;,&quot;messagebody&quot;:&quot;unknown host&quot;}}
    alb.ingress.kubernetes.io/target-type: instance
    alb.ingress.kubernetes.io/load-balancer-attributes: routing.http2.enabled=true,idle_timeout.timeout_seconds=600
    alb.ingress.kubernetes.io/tags: environment=test
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-east-2:555555555555:certificate/33333333-2222-4444-aaaa-eeeeeeeeeeee
    alb.ingress.kubernetes.io/ssl-policy: elbsecuritypolicy-2016-08
spec:
  rules:
    - http:
        paths:
          - path: /*
            backend:
              servicename: ssl-redirect
              serviceport: use-annotation
          - path: /*
            backend:
              servicename: svc-a-service
              serviceport: 80
          - path: /*
            backend:
              servicename: response-503
              serviceport: use-annotation


the http to https redirection works as expected.
however -- there is no differentiation between my two apps for the load balancer to be able to know that traffic destined for service-a.example.com and service-b.example.com should be routed to two different target groups.
in the http:443 listener rules in the console, it shows:

if path is /* then forward to serviceatargetgroup
if path is /* then return fixed 503
if path is /* then forward to servicebtargetgroup
if path is /* then return fixed 503
if request otherwise not routed then return fixed 404

so the important question here is:
how should the ingress be defined to force traffic destined for service-a.example.com to serviceatargetgroup - and traffic destined for service-b.example.com to servicebtargetgroup?
and secondarily, i need the &quot;otherwise not routed&quot; to return a 503 instead of 404. i was expecting this to appear only once in the rules (be merged) - yet it is created for each ingress. how should my yaml be structured to achieve this?
",<amazon-web-services><kubernetes><kubernetes-ingress><amazon-eks>,65076576,9,"i eventually figured this out -- so for anyone else stumbling onto this post, here's how i resolved it:
the trick was not relying on merging between the ingress objects. yes, it can handle a certain degree of merging, but there's not really a one-to-one relationship between services as targetgroups and ingress as alb. so you have to be very cautious and aware of what's in each ingress object.
once i combined all of my ingress into a single object definition, i was able to get it working exactly as i wanted with the following yaml:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: svc-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: services
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/security-groups: sg-01234567898765432
    alb.ingress.kubernetes.io/ip-address-type: ipv4
    alb.ingress.kubernetes.io/listen-ports: '[{&quot;http&quot;: 80}, {&quot;https&quot;: 443}]'
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{&quot;type&quot;: &quot;redirect&quot;, &quot;redirectconfig&quot;: { &quot;protocol&quot;: &quot;https&quot;, &quot;port&quot;: &quot;443&quot;, &quot;statuscode&quot;: &quot;http_301&quot;}}'
    alb.ingress.kubernetes.io/actions.response-503: &gt;
      {&quot;type&quot;:&quot;fixed-response&quot;,&quot;fixedresponseconfig&quot;:{&quot;contenttype&quot;:&quot;text/plain&quot;,&quot;statuscode&quot;:&quot;503&quot;,&quot;messagebody&quot;:&quot;unknown host&quot;}}
    alb.ingress.kubernetes.io/actions.svc-a-host: &gt;
      {&quot;type&quot;:&quot;forward&quot;,&quot;forwardconfig&quot;:{&quot;targetgroups&quot;:[{&quot;servicename&quot;:&quot;svc-a-service&quot;,&quot;serviceport&quot;:80,&quot;weight&quot;:100}]}}
    alb.ingress.kubernetes.io/conditions.svc-a-host: &gt;
      [{&quot;field&quot;:&quot;host-header&quot;,&quot;hostheaderconfig&quot;:{&quot;values&quot;:[&quot;svc-a.example.com&quot;]}}]
    alb.ingress.kubernetes.io/actions.svc-b-host: &gt;
      {&quot;type&quot;:&quot;forward&quot;,&quot;forwardconfig&quot;:{&quot;targetgroups&quot;:[{&quot;servicename&quot;:&quot;svc-b-service&quot;,&quot;serviceport&quot;:80,&quot;weight&quot;:100}]}}
    alb.ingress.kubernetes.io/conditions.svc-b-host: &gt;
      [{&quot;field&quot;:&quot;host-header&quot;,&quot;hostheaderconfig&quot;:{&quot;values&quot;:[&quot;svc-b.example.com&quot;]}}]
    alb.ingress.kubernetes.io/target-type: instance
    alb.ingress.kubernetes.io/load-balancer-attributes: routing.http2.enabled=true,idle_timeout.timeout_seconds=600
    alb.ingress.kubernetes.io/tags: environment=test
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-east-2:555555555555:certificate/33333333-2222-4444-aaaa-eeeeeeeeeeee,arn:aws:acm:us-east-2:555555555555:certificate/44444444-3333-5555-bbbb-ffffffffffff
    alb.ingress.kubernetes.io/ssl-policy: elbsecuritypolicy-2016-08
spec:
  backend:
    servicename: response-503
    serviceport: use-annotation
  rules:
    - http:
        paths:
          - backend:
              servicename: ssl-redirect
              serviceport: use-annotation
          - backend:
              servicename: svc-a-host
              serviceport: use-annotation
          - backend:
              servicename: svc-b-host
              serviceport: use-annotation

default action:
set by specifying the servicename and serviceport directly under spec:
spec:
  backend:
    servicename: response-503
    serviceport: use-annotation

routing:
because i'm using subdomains and paths won't work for me, i simply omitted the path and instead relied on hostname as a condition.
metadata:
  alb.ingress.kubernetes.io/actions.svc-a-host: &gt;
      {&quot;type&quot;:&quot;forward&quot;,&quot;forwardconfig&quot;:{&quot;targetgroups&quot;:[{&quot;servicename&quot;:&quot;svc-a-service&quot;,&quot;serviceport&quot;:80,&quot;weight&quot;:100}]}}
  alb.ingress.kubernetes.io/conditions.svc-a-host: &gt;
      [{&quot;field&quot;:&quot;host-header&quot;,&quot;hostheaderconfig&quot;:{&quot;values&quot;:[&quot;svc-a.example.com&quot;]}}]

end result:
the alb rules were configured precisely how i wanted them:

default action is a 503 fixed response
all http traffic is redirected to https
traffic is directed to targetgroups based on the host header

"
65283827,how to change host name resolve like host file in coredns,"i have a corefile configutation like this
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}

i would like all my pods to be able to resolve myapi.local to a specific ip ( 192.168.49.2 )
is there any easy way to achieve this like the what i can do with os's host file
",<kubernetes><kubectl><minikube><coredns>,65283959,9,"below configuration should do the trick
.:53 {
    errors
    health
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
        pods insecure
        fallthrough in-addr.arpa ip6.arpa
    }
    prometheus :9153
    hosts custom.hosts myapi.local {
        192.168.49.2 myapi.local
        fallthrough
    }
    forward . 8.8.8.8 8.8.4.4
    cache 30
    loop
    reload
    loadbalance
}

reference https://medium.com/@hjrocha/add-a-custom-host-to-kubernetes-a06472cedccb
or you can try using the hosts plugin https://coredns.io/plugins/hosts/
"
32636730,make kubernetes service accessible externally,"we have a private kubernetes cluster running on a baremetal coreos cluster (with flannel for network overlay) with private addresses.

on top of this cluster we run a kubernetes replicationcontroller and service for elasticsearch. to enable load-balancing, this service has a clusterip defined - which is also a private ip address: 10.99.44.10 (but in a different range to node ip addresses).

the issue that we face is that we wish to be able to connect to this clusterip from outside the cluster. as far as we can tell this private ip is not contactable from other machines in our private network...

how can we achieve this? 



the ip addresses of the nodes are:

 node 1  - 192.168.77.102
 node 2  - 192.168.77.103


.

and this is how the service, rc and pod appear with kubectl:

name            labels          selector              ip(s)           port(s)
elasticsearch   &lt;none&gt;          app=elasticsearch     10.99.44.10     9200/tcp


controller     container(s)    image(s)       selector            replicas
elasticsearch  elasticsearch   elasticsearch  app=elasticsearch   1


name                       ready     status    restarts   age
elasticsearch-swpy1         1/1       running   0          26m

",<docker><kubernetes><coreos><google-kubernetes-engine><flannel>,32657014,2,"you need to set the type of your service.

http://docs.k8s.io/v1.0/user-guide/services.html#external-services

if you are on bare metal, you don't have a loadbalancer integrated.  you can use nodeport to get a port on each vm, and then set up whatever you use for load-balancing to aim at that port on any node.
"
59393991,gcp gke load balancer connectio refused,"i'm doing a deployment on the gke service and i find that when i try to access the page the message 

err_connection_refused

i have defined a load balancing service for deployment and the configuration is as follows.

this is the .yaml for the deployment

apiversion: apps/v1
kind: deployment
metadata:
  name: bonsai-onboarding
spec:
  selector:
    matchlabels:
      app: bonsai-onboarding
  replicas: 2
  template:
    metadata:
      labels:
        app: bonsai-onboarding
    spec:
     containers:
     - name: bonsai-onboarding
       image: ""eu.gcr.io/diaphanum/onboarding-iocash-master_web:v1""
       ports:
       - containerport: 3000


this is the service .yaml file.

apiversion: v1
kind: service
metadata:
  name: lb-onboarding
spec:
  type: loadbalancer
  selector:
    app: bonsai-onboarding
  ports:
  - protocol: tcp
    port: 3000
    targetport: 3000


this working fine, and all is green in gke  :)

kubectl get pods,svc
name                                     ready   status    restarts   age
pod/bonsai-onboarding-8586b9b699-flhbn   1/1     running   0          3h23m
pod/bonsai-onboarding-8586b9b699-p9sn9   1/1     running   0          3h23m

name                    type           cluster-ip      external-ip    port(s)          age
service/kubernetes      clusterip      xx.xx.yy.yy      &lt;none&gt;         443/tcp          29d
service/lb-onboarding   loadbalancer   xx.xx.yy.yy   xx.xx.yy.yy   3000:32618/tcp   3h


then when i tried to connect the error is err_connection_refused

i think is about the network because y did the next test from my local machine

ping  [load balancer ip]  ---&gt;  correct
telnet [load balancer ip] 3000  ---&gt;  correct


from cloud shell i forward the port 3000 to 8080 and in other cloudshell make a curl http://localhost:8080, and work fine.

any idea about the problem?

thanks in advance
",<kubernetes><google-cloud-platform><load-balancing><google-kubernetes-engine>,59396405,2,"i've changed a little bit your deployment to check it on my cluster because your image was unreachable:


deployment:

apiversion: apps/v1
kind: deployment
metadata:
  name: bonsai-onboarding
spec:
  selector:
    matchlabels:
      app: bonsai-onboarding
  replicas: 2
  template:
    metadata:
      labels:
        app: bonsai-onboarding
    spec:
     containers:
     - name: bonsai-onboarding
       image: nginx:latest
       ports:
       - containerport: 80

service:

apiversion: v1
    kind: service
    metadata:
      name: lb-onboarding
    spec:
      type: loadbalancer
      selector:
        app: bonsai-onboarding
      ports:
      - protocol: tcp
        port: 3000
        targetport: 80



and it works out of the box:

kubectl get pods,svc
name                                     ready   status    restarts   age
pod/bonsai-onboarding-7bdf584499-j2nv7   1/1     running   0          6m58s
pod/bonsai-onboarding-7bdf584499-vc7kh   1/1     running   0          6m58s

name                    type           cluster-ip      external-ip     port(s)        age
service/kubernetes      clusterip      10.xxx.xxx.1     &lt;none&gt;          443/tcp        8m35s
service/lb-onboarding   loadbalancer   10.xxx.xxx.230   35.xxx.xxx.235   3000:31637/tcp   67s


and i'm able reach 35.xxx.xxx.235:3000 from any ip:

welcome to nginx!
...
thank you for using nginx.


you can check if your app is reachable using this command:

nmap -pn $(kubectl get svc lb-onboarding -o jsonpath='{.status.loadbalancer.ingress[*].ip}')


maybe the cause of your problem with ""err_connection_refused"" in configuration of your image? i found no problem with your deployment and load balancer configuration.
"
62461815,kubernetes local cluster pod hostport - application not accessible,"i am trying to access a web api deployed into my local kubernetes cluster running on my laptop (docker -> settings -> enable kubernetes). the below is my pod spec yaml.

kind: pod
apiversion: v1
metadata:
  name: test-api
  labels:
    app: test-api
spec:
  containers:
  - name: testapicontainer
    image: myprivaterepo/testapi:latest
    ports:
    - name: web
      hostport: 55555
      containerport: 80      
      protocol: tcp


kubectl get pods shows the test-api running. however, when i try to connect to it using http://localhost:55555/testapi/index from my laptop, i do not get a response. but, i can access the application from a container in a different pod within the cluster (i did a kubectl exec -it to a different container), using the url 


  http://test-api pod cluster ip/testapi/index


. why cannot i access the application using the localhost:hostport url?
",<kubernetes><kubernetes-pod><kubernetes-networking>,62464307,1,"i'd say that this is strongly not recommended.
according to k8s docs: https://kubernetes.io/docs/concepts/configuration/overview/#services

don't specify a hostport for a pod unless it is absolutely necessary. when you bind a pod to a hostport, it limits the number of places the pod can be scheduled, because each &lt;hostip, hostport, protocol&gt; combination must be unique. if you don't specify the hostip and protocol explicitly, kubernetes will use 0.0.0.0 as the default hostip and tcp as the default protocol.


if you only need access to the port for debugging purposes, you can use the apiserver proxy or kubectl port-forward.


if you explicitly need to expose a pod's port on the node, consider using a nodeport service before resorting to hostport.

so... is the hostport really necessary on your case? or a nodeport service would solve it?
if it is really necessary , then you could try using the ip that is returning from the command:
kubectl get nodes -o wide
http://ip-from-the-command:55555/testapi/index
also, another test that may help your troubleshoot is checking if your app is accessible on the pod ip.
update
i've done some tests locally and understood better what the documentation is trying to explain. let me go through my test:

first i've created a pod with hostport: 55555, i've done that with a simple nginx.
then i've listed my pods and saw that this one was running on one of my specific nodes.
afterwards i've tried to access the pod in the port 55555 through my master node ip and other node ip without success, but when trying to access through the node ip where this pod was actually running, it worked.

so, the &quot;issue&quot; (and actually that's why this approach is not recommended), is that the pod is accessible only through that specific node ip. if it restarts and start in a different node, the ip will also change.
"
72024974,helm chart bitnami - replicaset - database not being created,"so trying to create database in a replicaset using helm, using the following values in values.yaml
mongodb:
  architecture: replicaset
  auth:
    rootpassword: &quot;admin&quot;
    usernames: 
      - &quot;user1&quot;
    passwords: 
      - &quot;password1&quot;
    databases: 
      - &quot;mydatabase&quot;
    replicasetkey: myreplicakey

installing the chart using the following command:
helm install sam bitnami/mongodb --set architecture=&quot;replicaset&quot;,auth.rootpassword=password123 --values values.yaml

log into my database:
export mongodb_root_password=$(kubectl get secret --namespace default sam-mongodb -o jsonpath=&quot;{.data.mongodb-root-password}&quot; | base64 --decode)
kubectl exec -ti sam-mongodb-0 -- mongo --authenticationdatabase admin -u root -p $mongodb_root_password

but cannot see my database called &quot;mydatabase&quot; or specific user &quot;user1&quot; created, i can authenticate with admin user but trying to authenticate to &quot;mydatabase&quot; says failed, so unsure why this is happening, as it works in standalone but not a replicaset.
rs0:primary&gt; show dbs
admin   0.000gb
config  0.000gb
local   0.000gb
rs0:primary&gt; use admin
switched to db admin
rs0:primary&gt; show users
{
    &quot;_id&quot; : &quot;admin.root&quot;,
    &quot;userid&quot; : uuid(&quot;2b74bb99-5e18-434f-8350-9d54eb562230&quot;),
    &quot;user&quot; : &quot;root&quot;,
    &quot;db&quot; : &quot;admin&quot;,
    &quot;roles&quot; : [
        {
            &quot;role&quot; : &quot;root&quot;,
            &quot;db&quot; : &quot;admin&quot;
        }
    ],
    &quot;mechanisms&quot; : [
        &quot;scram-sha-1&quot;,
        &quot;scram-sha-256&quot;
    ]
}


was wondering if anyone knew what i might be doing wrong. thanks
",<mongodb><kubernetes><kubernetes-helm><bitnami>,72026528,1,"deleted the pvc and re-authenticated, and worked.
rs0:primary&gt; use mydatabase
switched to db mydatabase
rs0:primary&gt; db.auth('user1','password1')
1

"
73656303,many different hosts in ingress configuration file,"i am trying to automate the hosts in ingress controller and i'm facing the problem of generating many hosts into one file. what i mean is, i have this ingress.yaml:
---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-host
  namespace: default
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/default-backend: a
spec:
  rules:
  - host: a.example.com
    http:
      paths:
      - pathtype: prefix
        path: /
        backend:
          service:
            name: a
            port:
              number: 80
  - host: b.example.com
    http:
      paths:
      - pathtype: prefix
        path: /
        backend:
          service:
            name: b
            port:
              number: 80
  ...
  - host: x.example.com
    http:
      paths:
      - pathtype: prefix
        path: /
        backend:
          service:
            name: x
            port:
              number: 80
...


in this example i have multiple instances: a, b, all the way to x and i anticipate a lot more. right now i am programmatically regenerating the whole ingress.yaml to add/remove certain hosts. this is prone to errors and hard to maintain, as i must constantly be aware about ingress.yaml to be broken for one reason or another.
what would really help me is to put every host into a separate file and (maybe) just tell ingress.yaml to scan the whole directory where those files are to be stored. this way, i can just add/remove a single file and reload ingress
is there an option for that? i found somewhere that ingressspec could be somehow defined, but i do not see any usefull link with a valid example. maybe someone found a solution to that already and can point me to the right direction?
",<docker><kubernetes><kubernetes-ingress><nginx-ingress><ingress-controller>,73676247,1,"as @jordanm suggested in the comment, i went with multiple ingress objects on one ingresscontroller, being sure i get rid of nginx.ingress.kubernetes.io/default-backend annotation:
---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-x-host
  namespace: default
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: x.example.com
    http:
      paths:
      - pathtype: prefix
        path: /
        backend:
          service:
            name: x
            port:
              number: 80

i generate a unique file for each of hosts, replacing x with my unique name.
i also have to make sure that metadata.name is unique. if metadata.name is the same for every object, then it just gets replaced as i apply the new configuration. this works perfectly.
"
67438050,testing nats-streaming in kubernetes with minimal effort,"i wanted to test a very basic application for nats-streaming on kubernetes. to do so, i followed the commands from the official nats-docs.
it basically comes down to running
kubectl apply -f https://raw.githubusercontent.com/nats-io/k8s/master/nats-server/single-server-nats.yml
kubectl apply -f https://raw.githubusercontent.com/nats-io/k8s/master/nats-streaming-server/single-server-stan.yml

in a terminal with access to the cluster (it's a kind-cluster in my case).
i used stan.go as the nats-streaming-client. here is the code i tried to connect to the nats-streaming-server:
package main

import stan &quot;github.com/nats-io/stan.go&quot;

func main() {
    sc, err := stan.connect(&quot;stan&quot;, &quot;test-client&quot;)

    if err != nil {
        panic(err)
    }
    if err := sc.publish(&quot;test-subject&quot;, []byte(&quot;this is a test-message!&quot;)); err != nil {
        panic(err)
    }
}

and this is the error i'm getting:
panic: nats: no servers available for connection

goroutine 1 [running]:
main.main()
    /users/thilt/tmp/main.go:9 +0x15d
exit status 2

so i think another name was used for the cluster or something. if i use the provided example with nats-box from the docs.nats-link above, it also doesn't work! where did i go wrong here?
i will happily provide more information, if needed.
",<go><kubernetes><nats.io><kubernetes-custom-resources><nats-streaming-server>,67467212,1,"there is a great example in stan.go docs:
// connect to nats
nc, err := nats.connect(url, opts...)
if err != nil {
    log.fatal(err)
}
defer nc.close()

sc, err := stan.connect(clusterid, clientid, stan.natsconn(nc))
if err != nil {
    log.fatalf(&quot;can't connect: %v.\nmake sure a nats streaming server is running at: %s&quot;, err, url)
}
defer sc.close()

your error happens because by default stan connects to localhost address (source code):
// defaultnatsurl is the default url the client connects to
defaultnatsurl = &quot;nats://127.0.0.1:4222&quot;

notice that povided above example overwrite this default connection.
stan source code is short and easy to analyze. i really recommend you to try to analyze it and figure out what it does.

now let's put it all together; here is a working example:
package main

import (
    nats &quot;github.com/nats-io/nats.go&quot;
    stan &quot;github.com/nats-io/stan.go&quot;
)

func main() {
    // create a nats connection 
    nc, err := nats.connect(&quot;nats://nats:4222&quot;)
    if err != nil {
        panic(err)
    }

    // then pass it to the stan.connect() call.
    sc, err := stan.connect(&quot;stan&quot;, &quot;me&quot;, stan.natsconn(nc))
    if err != nil {
        panic(err)
    }
    if err := sc.publish(&quot;test-subject&quot;, []byte(&quot;this is a test-message!&quot;)); err != nil {
        panic(err)
    }
}

"
64010131,gke: service account for config connector lacks permissions,"i'm attempting to get config connector up and running on my gke project and am following this getting started guide.
so far i have enabled the appropriate apis:
&gt; gcloud services enable cloudresourcemanager.googleapis.com

created my service account and added policy binding:
&gt; gcloud iam service-accounts create cnrm-system
&gt; gcloud iam service-accounts add-iam-policy-binding ncnrm-system@test-connector.iam.gserviceaccount.com --member=&quot;serviceaccount:test-connector.svc.id.goog[cnrm-system/cnrm-controller-manager]&quot; --role=&quot;roles/iam.workloadidentityuser&quot;
&gt; kubectl wait -n cnrm-system --for=condition=ready pod --all

annotated my namespace:
&gt; kubectl annotate namespace default cnrm.cloud.google.com/project-id=test-connector

and then run through trying to apply the spanner yaml in the example:
~ &gt;&gt;&gt; kubectl describe spannerinstance spannerinstance-sample                                                                                                                                                                                                                            
name:         spannerinstance-sample
namespace:    default
labels:       label-one=value-one
annotations:  cnrm.cloud.google.com/management-conflict-prevention-policy: resource
              cnrm.cloud.google.com/project-id: test-connector
api version:  spanner.cnrm.cloud.google.com/v1beta1
kind:         spannerinstance
metadata:
  creation timestamp:  2020-09-18t18:44:41z
  generation:          2
  resource version:    5805305
  self link:           /apis/spanner.cnrm.cloud.google.com/v1beta1/namespaces/default/spannerinstances/spannerinstance-sample
  uid:                 
spec:
  config:        northamerica-northeast1-a
  display name:  spanner instance sample
  num nodes:     1
status:
  conditions:
    last transition time:  2020-09-18t18:44:41z
    message:               update call failed: error fetching live state: error reading underlying resource: error when reading or editing spannerinstance &quot;test-connector/spannerinstance-sample&quot;: googleapi: error 403: request had insufficient authentication scopes.
    reason:                updatefailed
    status:                false
    type:                  ready
events:
  type     reason        age                      from                        message
  ----     ------        ----                     ----                        -------
  warning  updatefailed  6m41s        spannerinstance-controller  update call failed: error fetching live state: error reading underlying resource: error when reading or editing spannerinstance &quot;test-connector/spannerinstance-sample&quot;: googleapi: error 403: request had insufficient authentication scopes.

i'm not really sure what's going on here, because my cnrm service account has ownership of the project my cluster is in, and i have the apis listed in the guide enabled.
the cc pods themselves appear to be healthy:
~ &gt;&gt;&gt; kubectl wait -n cnrm-system --for=condition=ready pod --all                                                                                                                                                                                                                    
pod/cnrm-controller-manager-0 condition met
pod/cnrm-deletiondefender-0 condition met
pod/cnrm-resource-stats-recorder-58cb6c9fc-lf9nt condition met
pod/cnrm-webhook-manager-7658bbb9-kxp4g condition met

any insight in to this would be greatly appreciated!
",<kubernetes><google-kubernetes-engine><gcp-config-connector>,64025471,2,"by the error message you have posted, i should supposed that it might be an error in your gke scopes.
to gke access others gcp apis you must allow this access when creating the cluster. you can check the enabled scopes with the command:
gcloud container clusters describe &lt;cluster-name&gt; and find in the result for oauthscopes.
here you can see the scope's name for cloud spanner, you must enable the scope https://www.googleapis.com/auth/cloud-platform as minimum permission.
to verify in the gui, you can see the permission in: kubernetes engine &gt; &lt;cluster-name&gt; &gt; expand the section permissions and find for cloud platform
"
70832556,kubernetes nginx ingress configuration for wildcard rule,"i am struggling with the following issues. i have 2 services running. i am using a wildcard for handling subdomains. see the example conf below:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
    kubernetes.io/ingress.class: nginx
    kubernetes.io/ingress.global-static-ip-name: web-static-ip
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/server-alias: www.foo.bar
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
  name: foo-bar-ingress
  namespace: test
spec:
  rules:
  - host: '*.foo.bar'
    http:
      paths:
      - backend:
          servicename: legacy-service
          serviceport: 80
        path: /(.*)
        pathtype: implementationspecific
  - host: foo.bar
    http:
      paths:
      - backend:
          servicename: new-service
          serviceport: 8080
        path: /(.*)
        pathtype: implementationspecific

using the app in the way that abc.foo.bar -&gt; legacy-service and foo.bar -&gt; new-service work perfectly fine. however, when i access the app with www prefix, it gets under the wildcard subdomain path, meaning www.foo.bar goes into legacy-service, which is what i want to avoid. afaiu this &quot;www&quot; is caught by this asterisk regexp and goes in the wrong way. i would like it go to new-service.
is there any way i can achieve this with the nginx ingress configuration?
",<nginx><kubernetes><kubernetes-ingress><nginx-ingress>,70832796,5,"also redirecting requests from www.foo.bar can be achieved by also specifying the hostname. please note that the order of the hosts does matter as they are translated into the envoy filter chain. therefore, the wildcard host should be the last host.
apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
    kubernetes.io/ingress.class: nginx
    kubernetes.io/ingress.global-static-ip-name: web-static-ip
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/server-alias: www.foo.bar
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
  name: foo-bar-ingress
  namespace: test
spec:
  rules:
  - host: 'foo.bar'
    http:
      paths:
      - backend:
          servicename: new-service
          serviceport: 8080
        path: /(.*)
        pathtype: implementationspecific
  - host: 'www.foo.bar'
    http:
      paths:
      - backend:
          servicename: new-service
          serviceport: 8080
        path: /(.*)
        pathtype: implementationspecific
  - host: '*.foo.bar'
    http:
      paths:
      - backend:
          servicename: legacy-service
          serviceport: 80
        path: /(.*)
        pathtype: implementationspecific

"
69682704,retrieve and write tls crt kubernetes secret to another pod in helm template,"i have a kubernetes cluster with elasticsearch currently deployed.
the elasticsearch coordinator node is accessible behind a service via a clusterip over https. it uses a self-signed tls certificate.
i can retrieve the value of the ca:
kubectl get secret \
    -n elasticsearch elasticsearch-coordinating-only-crt \
    -o jsonpath=&quot;{.data.ca\.crt}&quot; | base64 -d
-----begin certificate-----
miidijccagqgawibagirankax51s
...
...

i need to provide this as a ca.crt to other app deployments.

note: the elasticsearch deployment is an an elasticsearch kubernetes namespace. new deployments will be in different namespaces.

an example of this is a deployment of kafka that includes a kafka-connect-elasticsearch/ sink. the sink connector uses configuration such as:
apiversion: v1
kind: configmap
metadata:
  name: {{ include &quot;kafka.fullname&quot; . }}-connect
  labels: {{- include &quot;common.labels.standard&quot; . | nindent 4 }}
    app.kubernetes.io/component: connector
data:
  connect-standalone-custom.properties: |-
    bootstrap.servers={{ include &quot;kafka.fullname&quot; . }}-0.{{ include &quot;kafka.fullname&quot; . }}-headless.{{ .release.namespace }}.svc.{{ .values.clusterdomain }}:{{ .values.service.port }}
    key.converter.schemas.enable=false
    value.converter.schemas.enable=false
    offset.storage.file.filename=/tmp/connect.offsets
    offset.flush.interval.ms=10000
    key.converter=org.apache.kafka.connect.json.jsonconverter
    value.converter=org.apache.kafka.connect.json.jsonconverter
    plugin.path=/usr/local/share/kafka/plugins
  elasticsearch.properties: |-
    name=elasticsearch-sink
    connector.class=io.confluent.connect.elasticsearch.elasticsearchsinkconnector
    tasks.max=4
    topics=syslog,nginx
    key.ignore=true
    schema.ignore=true
    connection.url=https://elasticsearch-coordinating-only.elasticsearch:9200
    type.name=kafka-connect
    connection.username=elastic
    connection.password=xxxxxxxx
    elastic.security.protocol=ssl
    elastic.https.ssl.truststore.location=/etc/ssl/certs/elasticsearch-ca.crt
    elastic.https.ssl.truststore.type=pem

notice the elastic.https.ssl.truststore.location=/etc/ssl/certs/elasticsearch-ca.crt; that's the file i need to put inside the kafka-based container.
what's the optimal way to do that with helm templates?
currently i have a fork of https://github.com/bitnami/charts/tree/master/bitnami/kafka. it adds 3 new templates under templates/:

kafka-connect-elasticsearch-configmap.yaml
kafka-connect-svc.yaml
kafka-connect.yaml

the configmap is shown above.  the kafka-connect.yaml deployment looks like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ include &quot;kafka.fullname&quot; . }}-connect
  labels: {{- include &quot;common.labels.standard&quot; . | nindent 4 }}
    app.kubernetes.io/component: connector
spec:
  replicas: 1
  selector:
    matchlabels: {{- include &quot;common.labels.matchlabels&quot; . | nindent 6 }}
      app.kubernetes.io/component: connector
  template:
    metadata:
      labels: {{- include &quot;common.labels.standard&quot; . | nindent 8 }}
        app.kubernetes.io/component: connector
    spec:
      containers:
        - name: connect
          image: redacted.dkr.ecr.redacted.amazonaws.com/kafka-connect-elasticsearch
          imagepullpolicy: always
          command:
            - /bin/bash
            - -ec
            - bin/connect-standalone.sh custom-config/connect-standalone-custom.properties custom-config/elasticsearch.properties
          ports:
            - name: connector
              containerport: 8083
          volumemounts:
            - name: configuration
              mountpath: /opt/bitnami/kafka/custom-config
      imagepullsecrets:
        - name: regcred
      volumes:
        - name: configuration
          configmap:
            name: {{ include &quot;kafka.fullname&quot; . }}-connect

how can i modify these kafka helm charts to allow them to retrieve the value for kubectl get secret -n elasticsearch elasticsearch-coordinating-only-crt -o jsonpath=&quot;{.data.ca\.crt}&quot; | base64 -d and write its content to /etc/ssl/certs/elasticsearch-ca.crt ?
",<kubernetes><kubernetes-helm><apache-kafka-connect><kubernetes-secrets>,69683011,2,"got this working and learned a few things in the process:

secret resources reside in a namespace. secrets can only be referenced by pods in that same namespace. (ref). therefore, i switched to using a shared namespace for elasticsearch + kafka
the secret can be used in a straightforward way as documented at https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets. this is not a helm-specific but rather core kubernetes feature

in my case this looked like:
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ include &quot;kafka.fullname&quot; . }}-connect
  labels: {{- include &quot;common.labels.standard&quot; . | nindent 4 }}
    app.kubernetes.io/component: connector
spec:
  replicas: 1
  selector:
    matchlabels: {{- include &quot;common.labels.matchlabels&quot; . | nindent 6 }}
      app.kubernetes.io/component: connector
  template:
    metadata:
      labels: {{- include &quot;common.labels.standard&quot; . | nindent 8 }}
        app.kubernetes.io/component: connector
    spec:
      containers:
        - name: connect
          image: redacted.dkr.ecr.redacted.amazonaws.com/kafka-connect-elasticsearch
          imagepullpolicy: always
          command:
            - /bin/bash
            - -ec
            - bin/connect-standalone.sh custom-config/connect-standalone-custom.properties custom-config/elasticsearch.properties
          ports:
            - name: connector
              containerport: 8083
          volumemounts:
            - name: configuration
              mountpath: /opt/bitnami/kafka/custom-config
            - name: ca
              mountpath: /etc/ssl/certs
              readonly: true
      imagepullsecrets:
        - name: regcred
      volumes:
        - name: configuration
          configmap:
            name: {{ include &quot;kafka.fullname&quot; . }}-connect
        - name: ca
          secret:
            secretname: elasticsearch-coordinating-only-crt

this gets the kafka-connect pod up and running, and i can validate the certs are written there also:
$ kubectl exec -it -n elasticsearch kafka-connect-c4f4d7dbd-wbxfq \
    -- ls -1 /etc/ssl/certs

ca.crt
tls.crt
tls.key

"
76512698,"after upgrading aws eks (kubernetes) to v1.23 from v1.22, persistent volumes (pvs) started failing to mount and pods got stuck in pending state","problem:
i upgraded from aws eks cluster to v1.23 from v1.22 and all of a sudden, all the pods that had persistent volume claim (pvc) and persistent volume (pv) started failing with the errors like failedattachvolume attachvolume.attach failed and failedmount mountvolume.waitforattach failed for the aws ebs volumes.
pods were giving the following error: unable to attach or mount volumes timed out waiting for the condition
solutions tried:

i tried adding aws ebs csi driver add-on in the aws eks cluster but still it didn't work.
i tried removing the annotation for migration to this new provisioner on pvcs but that didn't work either.
i also tried adding storage class for gp3 aws ebs volume type with aws ebs csi driver as the new provisioner as i was using gp2 but that didn't work either.

note: aws ebs volumes were of type gp2.
",<amazon-web-services><kubernetes><amazon-eks><amazon-ebs><aws-ebs-csi-driver>,76512699,4,"after adding amazonebscsidriverpolicy aws iam policy to the aws iam role that is attached to all the aws eks nodes (aws ec2 instances) and then adding the aws ebs csi driver add-on in the aws eks cluster, errors were resolved and pvc got attached successfully. i don't see any issues related to persistent volume claims (pvc), persistent volumes (pv), aws ebs volumes, and pods anymore.
note: i already had an aws iam openid connect (oidc) provider for my aws eks cluster which is a prerequisite for this. in your case, there could be some other issue and the resolution steps might differ so please check out the following reference document: how do i troubleshoot issues with my ebs volume mounts in amazon eks?
"
48808897,kube-apiserver not authenticating correctly in multi master cluster,"i am attempting to create a ha kubernetes cluster in azure using kubeadm as documented here https://kubernetes.io/docs/setup/independent/high-availability/

i have everything working when using only 1 master node but when changing to 3 master nodes kube-dns keeps crashing with apiserver issues

i can see when running kubectl get nodes that the 3 master nodes are ready

name           status    roles     age       version
k8s-master-0   ready     master    3h        v1.9.3
k8s-master-1   ready     master    3h        v1.9.3
k8s-master-2   ready     master    3h        v1.9.3


but the dns and dashboard pod keep crashing

name                                    ready     status             restarts   age
kube-apiserver-k8s-master-0             1/1       running            0          3h
kube-apiserver-k8s-master-1             1/1       running            0          2h
kube-apiserver-k8s-master-2             1/1       running            0          3h
kube-controller-manager-k8s-master-0    1/1       running            0          3h
kube-controller-manager-k8s-master-1    1/1       running            0          3h
kube-controller-manager-k8s-master-2    1/1       running            0          3h
kube-dns-6f4fd4bdf-rmqbf                1/3       crashloopbackoff   88         3h
kube-proxy-5phhf                        1/1       running            0          3h
kube-proxy-h5rk8                        1/1       running            0          3h
kube-proxy-ld9wg                        1/1       running            0          3h
kube-proxy-n947r                        1/1       running            0          3h
kube-scheduler-k8s-master-0             1/1       running            0          3h
kube-scheduler-k8s-master-1             1/1       running            0          3h
kube-scheduler-k8s-master-2             1/1       running            0          3h
kubernetes-dashboard-5bd6f767c7-d8kd7   0/1       crashloopbackoff   42         3h


the logs kubectl -n kube-system logs kube-dns-6f4fd4bdf-rmqbf -c kubedns indicate there is an api server issue

i0521 14:40:31.303585       1 dns.go:48] version: 1.14.6-3-gc36cb11
i0521 14:40:31.304834       1 server.go:69] using configuration read from directory: /kube-dns-config with period 10s
i0521 14:40:31.304989       1 server.go:112] flag: --alsologtostderr=""false""
i0521 14:40:31.305115       1 server.go:112] flag: --config-dir=""/kube-dns-config""
i0521 14:40:31.305164       1 server.go:112] flag: --config-map=""""
i0521 14:40:31.305233       1 server.go:112] flag: --config-map-namespace=""kube-system""
i0521 14:40:31.305285       1 server.go:112] flag: --config-period=""10s""
i0521 14:40:31.305332       1 server.go:112] flag: --dns-bind-address=""0.0.0.0""
i0521 14:40:31.305394       1 server.go:112] flag: --dns-port=""10053""
i0521 14:40:31.305454       1 server.go:112] flag: --domain=""cluster.local.""
i0521 14:40:31.305531       1 server.go:112] flag: --federations=""""
i0521 14:40:31.305596       1 server.go:112] flag: --healthz-port=""8081""
i0521 14:40:31.305656       1 server.go:112] flag: --initial-sync-timeout=""1m0s""
i0521 14:40:31.305792       1 server.go:112] flag: --kube-master-url=""""
i0521 14:40:31.305870       1 server.go:112] flag: --kubecfg-file=""""
i0521 14:40:31.305960       1 server.go:112] flag: --log-backtrace-at="":0""
i0521 14:40:31.306026       1 server.go:112] flag: --log-dir=""""
i0521 14:40:31.306109       1 server.go:112] flag: --log-flush-frequency=""5s""
i0521 14:40:31.306160       1 server.go:112] flag: --logtostderr=""true""
i0521 14:40:31.306216       1 server.go:112] flag: --nameservers=""""
i0521 14:40:31.306267       1 server.go:112] flag: --stderrthreshold=""2""
i0521 14:40:31.306324       1 server.go:112] flag: --v=""2""
i0521 14:40:31.306375       1 server.go:112] flag: --version=""false""
i0521 14:40:31.306433       1 server.go:112] flag: --vmodule=""""
i0521 14:40:31.306510       1 server.go:194] starting skydns server (0.0.0.0:10053)
i0521 14:40:31.306806       1 server.go:213] skydns metrics enabled (/metrics:10055)
i0521 14:40:31.306926       1 dns.go:146] starting endpointscontroller
i0521 14:40:31.306996       1 dns.go:149] starting servicecontroller
i0521 14:40:31.307267       1 logs.go:41] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]
i0521 14:40:31.307350       1 logs.go:41] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]
i0521 14:40:31.807301       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
i0521 14:40:32.307629       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
e0521 14:41:01.307985       1 reflector.go:201] k8s.io/dns/pkg/dns/dns.go:147: failed to list *v1.endpoints: get https://10.96.0.1:443/api/v1/endpoints?resourceversion=0: dial tcp 10.96.0.1:443: i/o timeout
e0521 14:41:01.308227       1 reflector.go:201] k8s.io/dns/pkg/dns/dns.go:150: failed to list *v1.service: get https://10.96.0.1:443/api/v1/services?resourceversion=0: dial tcp 10.96.0.1:443: i/o timeout
i0521 14:41:01.807271       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
i0521 14:41:02.307301       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
i0521 14:41:02.807294       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
i0521 14:41:03.307321       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...
i0521 14:41:03.807649       1 dns.go:173] waiting for services and endpoints to be initialized from apiserver...


the output from kubectl -n kube-system logs kube-apiserver-k8s-master-0 looks relatively normal, except for all the tls errors

    i0521 11:09:53.982465       1 server.go:121] version: v1.9.7
i0521 11:09:53.982756       1 cloudprovider.go:59] --external-hostname was not specified. trying to get it from the cloud provider.
i0521 11:09:55.934055       1 logs.go:41] warning: ignoring servername for user-provided ca for backwards compatibility is deprecated
i0521 11:09:55.935038       1 logs.go:41] warning: ignoring servername for user-provided ca for backwards compatibility is deprecated
i0521 11:09:55.938929       1 feature_gate.go:190] feature gates: map[initializers:true]
i0521 11:09:55.938945       1 initialization.go:90] enabled initializers feature as part of admission plugin setup
i0521 11:09:55.942042       1 logs.go:41] warning: ignoring servername for user-provided ca for backwards compatibility is deprecated
i0521 11:09:55.948001       1 master.go:225] using reconciler: lease
w0521 11:10:01.032046       1 genericapiserver.go:342] skipping api batch/v2alpha1 because it has no resources.
w0521 11:10:03.333423       1 genericapiserver.go:342] skipping api rbac.authorization.k8s.io/v1alpha1 because it has no resources.
w0521 11:10:03.340119       1 genericapiserver.go:342] skipping api storage.k8s.io/v1alpha1 because it has no resources.
w0521 11:10:04.188602       1 genericapiserver.go:342] skipping api admissionregistration.k8s.io/v1alpha1 because it has no resources.
[restful] 2018/05/21 11:10:04 log.go:33: [restful/swagger] listing is available at https://10.240.0.231:6443/swaggerapi
[restful] 2018/05/21 11:10:04 log.go:33: [restful/swagger] https://10.240.0.231:6443/swaggerui/ is mapped to folder /swagger-ui/
[restful] 2018/05/21 11:10:06 log.go:33: [restful/swagger] listing is available at https://10.240.0.231:6443/swaggerapi
[restful] 2018/05/21 11:10:06 log.go:33: [restful/swagger] https://10.240.0.231:6443/swaggerui/ is mapped to folder /swagger-ui/
i0521 11:10:06.424379       1 logs.go:41] warning: ignoring servername for user-provided ca for backwards compatibility is deprecated
i0521 11:10:10.910296       1 serve.go:96] serving securely on [::]:6443
i0521 11:10:10.919244       1 crd_finalizer.go:242] starting crdfinalizer
i0521 11:10:10.919835       1 apiservice_controller.go:112] starting apiserviceregistrationcontroller
i0521 11:10:10.919940       1 cache.go:32] waiting for caches to sync for apiserviceregistrationcontroller controller
i0521 11:10:10.920028       1 controller.go:84] starting openapi aggregationcontroller
i0521 11:10:10.921417       1 available_controller.go:262] starting availableconditioncontroller
i0521 11:10:10.922341       1 cache.go:32] waiting for caches to sync for availableconditioncontroller controller
i0521 11:10:10.927021       1 logs.go:41] http: tls handshake error from 10.240.0.231:49208: eof
i0521 11:10:10.932960       1 logs.go:41] http: tls handshake error from 10.240.0.231:49210: eof
i0521 11:10:10.937813       1 logs.go:41] http: tls handshake error from 10.240.0.231:49212: eof
i0521 11:10:10.941682       1 logs.go:41] http: tls handshake error from 10.240.0.231:49214: eof
i0521 11:10:10.945178       1 logs.go:41] http: tls handshake error from 127.0.0.1:56640: eof
i0521 11:10:10.949275       1 logs.go:41] http: tls handshake error from 127.0.0.1:56642: eof
i0521 11:10:10.953068       1 logs.go:41] http: tls handshake error from 10.240.0.231:49442: eof
---
i0521 11:10:19.912989       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/admin
i0521 11:10:19.941699       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/edit
i0521 11:10:19.957582       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/view
i0521 11:10:19.968065       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:aggregate-to-admin
i0521 11:10:19.998718       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:aggregate-to-edit
i0521 11:10:20.015536       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:aggregate-to-view
i0521 11:10:20.032728       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:heapster
i0521 11:10:20.045918       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:node
i0521 11:10:20.063670       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:node-problem-detector
i0521 11:10:20.114066       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:node-proxier
i0521 11:10:20.135010       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:node-bootstrapper
i0521 11:10:20.147462       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:auth-delegator
i0521 11:10:20.159892       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:kube-aggregator
i0521 11:10:20.181092       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:kube-controller-manager
i0521 11:10:20.197645       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:kube-scheduler
i0521 11:10:20.219016       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:kube-dns
i0521 11:10:20.235273       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:persistent-volume-provisioner
i0521 11:10:20.245893       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:aws-cloud-provider
i0521 11:10:20.257459       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:certificates.k8s.io:certificatesigningrequests:nodeclient
i0521 11:10:20.269857       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
i0521 11:10:20.286785       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:attachdetach-controller
i0521 11:10:20.298669       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:clusterrole-aggregation-controller
i0521 11:10:20.310573       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:cronjob-controller
i0521 11:10:20.347321       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:daemon-set-controller
i0521 11:10:20.364505       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:deployment-controller
i0521 11:10:20.365888       1 trace.go:76] trace[1489234739]: ""create /api/v1/namespaces/kube-system/configmaps"" (started: 2018-05-21 11:10:15.961686997 +0000 utc m=+22.097873350) (total time: 4.404137704s):
trace[1489234739]: [4.000707016s] [4.000623216s] about to store object in database
trace[1489234739]: [4.404137704s] [403.430688ms] end
e0521 11:10:20.366636       1 client_ca_hook.go:112] configmaps ""extension-apiserver-authentication"" already exists
i0521 11:10:20.391784       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:disruption-controller
i0521 11:10:20.404492       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:endpoint-controller
w0521 11:10:20.405827       1 lease.go:223] resetting endpoints for master service ""kubernetes"" to [10.240.0.231 10.240.0.233]
i0521 11:10:20.423540       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:generic-garbage-collector
i0521 11:10:20.476466       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:horizontal-pod-autoscaler
i0521 11:10:20.495934       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:job-controller
i0521 11:10:20.507318       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:namespace-controller
i0521 11:10:20.525086       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:node-controller
i0521 11:10:20.538631       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:persistent-volume-binder
i0521 11:10:20.558614       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:pod-garbage-collector
i0521 11:10:20.586665       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:replicaset-controller
i0521 11:10:20.600567       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:replication-controller
i0521 11:10:20.617268       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:resourcequota-controller
i0521 11:10:20.628770       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:route-controller
i0521 11:10:20.655147       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:service-account-controller
i0521 11:10:20.672926       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:service-controller
i0521 11:10:20.694137       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:statefulset-controller
i0521 11:10:20.718936       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:ttl-controller
i0521 11:10:20.731868       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:certificate-controller
i0521 11:10:20.752910       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:pvc-protection-controller
i0521 11:10:20.767297       1 storage_rbac.go:208] created clusterrole.rbac.authorization.k8s.io/system:controller:pv-protection-controller
i0521 11:10:20.788265       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/cluster-admin
i0521 11:10:20.801791       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:discovery
i0521 11:10:20.815924       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:basic-user
i0521 11:10:20.828531       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:node-proxier
i0521 11:10:20.854715       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:kube-controller-manager
i0521 11:10:20.864554       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:kube-dns
i0521 11:10:20.875950       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:kube-scheduler
i0521 11:10:20.900809       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:aws-cloud-provider
i0521 11:10:20.913751       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:node
i0521 11:10:20.924284       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:attachdetach-controller
i0521 11:10:20.940075       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:clusterrole-aggregation-controller
i0521 11:10:20.969408       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:cronjob-controller
i0521 11:10:20.980017       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:daemon-set-controller
i0521 11:10:21.016306       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:deployment-controller
i0521 11:10:21.047910       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:disruption-controller
i0521 11:10:21.058829       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:endpoint-controller
i0521 11:10:21.083536       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:generic-garbage-collector
i0521 11:10:21.100235       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:horizontal-pod-autoscaler
i0521 11:10:21.127927       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:job-controller
i0521 11:10:21.146373       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:namespace-controller
i0521 11:10:21.160099       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:node-controller
i0521 11:10:21.184264       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:persistent-volume-binder
i0521 11:10:21.204867       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:pod-garbage-collector
i0521 11:10:21.224648       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:replicaset-controller
i0521 11:10:21.742427       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:replication-controller
i0521 11:10:21.758948       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:resourcequota-controller
i0521 11:10:21.801182       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:route-controller
i0521 11:10:21.832962       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:service-account-controller
i0521 11:10:21.860369       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:service-controller
i0521 11:10:21.892241       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:statefulset-controller
i0521 11:10:21.931450       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:ttl-controller
i0521 11:10:21.963364       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:certificate-controller
i0521 11:10:21.980748       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:pvc-protection-controller
i0521 11:10:22.003657       1 storage_rbac.go:236] created clusterrolebinding.rbac.authorization.k8s.io/system:controller:pv-protection-controller
i0521 11:10:22.434855       1 controller.go:538] quota admission added evaluator for: { endpoints}
...
i0521 11:12:06.609728       1 logs.go:41] http: tls handshake error from 168.63.129.16:64981: eof
i0521 11:12:21.611308       1 logs.go:41] http: tls handshake error from 168.63.129.16:65027: eof
i0521 11:12:36.612129       1 logs.go:41] http: tls handshake error from 168.63.129.16:65095: eof
i0521 11:12:51.612245       1 logs.go:41] http: tls handshake error from 168.63.129.16:65141: eof
i0521 11:13:06.612118       1 logs.go:41] http: tls handshake error from 168.63.129.16:65177: eof
i0521 11:13:21.612170       1 logs.go:41] http: tls handshake error from 168.63.129.16:65235: eof
i0521 11:13:36.612218       1 logs.go:41] http: tls handshake error from 168.63.129.16:65305: eof
i0521 11:13:51.613097       1 logs.go:41] http: tls handshake error from 168.63.129.16:65354: eof
i0521 11:14:06.613523       1 logs.go:41] http: tls handshake error from 168.63.129.16:65392: eof
i0521 11:14:21.614148       1 logs.go:41] http: tls handshake error from 168.63.129.16:65445: eof
i0521 11:14:36.614143       1 logs.go:41] http: tls handshake error from 168.63.129.16:65520: eof
i0521 11:14:51.614204       1 logs.go:41] http: tls handshake error from 168.63.129.16:49193: eof
i0521 11:15:06.613995       1 logs.go:41] http: tls handshake error from 168.63.129.16:49229: eof
i0521 11:15:21.613962       1 logs.go:41] http: tls handshake error from 168.63.129.16:49284: eof
i0521 11:15:36.615026       1 logs.go:41] http: tls handshake error from 168.63.129.16:49368: eof
i0521 11:15:51.615991       1 logs.go:41] http: tls handshake error from 168.63.129.16:49413: eof
i0521 11:16:06.616993       1 logs.go:41] http: tls handshake error from 168.63.129.16:49454: eof
i0521 11:16:21.616947       1 logs.go:41] http: tls handshake error from 168.63.129.16:49510: eof
i0521 11:16:36.617859       1 logs.go:41] http: tls handshake error from 168.63.129.16:49586: eof
i0521 11:16:51.618921       1 logs.go:41] http: tls handshake error from 168.63.129.16:49644: eof
i0521 11:17:06.619768       1 logs.go:41] http: tls handshake error from 168.63.129.16:49696: eof
i0521 11:17:21.620123       1 logs.go:41] http: tls handshake error from 168.63.129.16:49752: eof
i0521 11:17:36.620814       1 logs.go:41] http: tls handshake error from 168.63.129.16:49821: eof


the output from a second api server however looks at lot more broken 

e0521 11:11:15.035138       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:15.040764       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:15.717294       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:15.721875       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:15.728534       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:15.734572       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.036398       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.041735       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.730094       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.736057       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.741505       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:16.741980       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:17.037722       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]
e0521 11:11:17.042680       1 authentication.go:64] unable to authenticate the request due to an error: [invalid bearer token, [invalid bearer token, crypto/rsa: verification error]]

",<kubernetes><coreos><kubeadm><kubernetes-apiserver>,50465960,4,"i eventually got to the bottom of this. i had not copied the same service account signing keys onto each master node (sa.key, sa.pub).

these keys are documented here: https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.7.md

a private key for signing serviceaccount tokens (sa.key) along with its public key (sa.pub)

and the step that i had missed is documented here: https://kubernetes.io/docs/setup/independent/high-availability/

copy the contents of /etc/kubernetes/pki/ca.crt, /etc/kubernetes/pki/ca.key, /etc/kubernetes/pki/sa.key and /etc/kubernetes/pki/sa.pub and create these files manually on master1 and master2
"
47076858,kubernetes helm chart - debugging,"i'm unable to find good information describing these errors:

[sarah@localhost helm] helm install statefulset --name statefulset --debug
[debug] created tunnel using local port: '33172'

[debug] server: ""localhost:33172""

[debug] original chart version: """"
[debug] chart path: /home/helm/statefulset/

error: error validating """": error validating data: [field spec.template for v1beta1.statefulsetspec is required, field spec.servicename for v1beta1.statefulsetspec is required, found invalid field containers for v1beta1.statefulsetspec]


i'm still new to helm; i've built two working charts that were similar to this template and didn't have these errors, even though the code isn't much different. i'm thinking there might be some kind of formatting error that i'm not noticing. either that, or it's due to the different type (the others were pods, this is statefulset). 

the yaml file it's referencing is here:

apiversion: apps/v1beta1
kind: statefulset
metadata:
  name: ""{{.values.primaryname}}""
  labels:
    name: ""{{.values.primaryname}}""
    app: ""{{.values.primaryname}}""
    chart: ""{{.chart.name}}-{{.chart.version}}""
  annotations:
    ""helm.sh/created"": {{.release.time.seconds | quote }}
spec:
  #serviceaccount: ""{{.values.primaryname}}-sa""
  containers:
  - name: {{.values.containername}}
    image: ""{{.values.postgresimage}}""
    ports:
    - containerport: 5432
      protocol: tcp
      name: postgres
    resources:
      requests:
        cpu: {{default ""100m"" .values.cpu}}
        memory: {{default ""100m"" .values.memory}}
    env:
    - name: pghost
      value: /tmp
    - name: pg_primary_user
      value: primaryuser
    - name: pg_mode
      value: set
    - name: pg_primary_port
      value: ""5432""
    - name: pg_primary_password
      value: ""{{.values.primarypassword}}""
    - name: pg_user
      value: testuser
    - name: pg_password
      value: ""{{.values.userpassword}}""
    - name: pg_database
      value: userdb
    - name: pg_root_password
      value: ""{{.values.rootpassword}}""
    volumemounts:
    - name: pgdata
      mountpath: ""/pgdata""
      readonly: false
    volumes:
    - name: pgdata
      persistentvolumeclaim:
       claimname: {{.values.pvcname}}


would someone be able to a) point me in the right direction to find out how to implement the spec.template and spec.servicename required fields, b) understand why the field 'containers' is invalid, and/or c) give mention of any tool that can help debug helm charts? i've attempted 'helm lint' and the '--debug' flag but 'helm lint' shows no errors, and the flag output is shown with the errors above.

is it possible the errors are coming from a different file, also? 
",<postgresql><kubernetes><containers><kubernetes-helm><statefulset>,47077814,2,"statefulsets objects has different structure than pods are. you need to modify your yaml file a little:

apiversion: apps/v1beta1
kind: statefulset
metadata:
  name: ""{{.values.primaryname}}""
  labels:
    name: ""{{.values.primaryname}}""
    app: ""{{.values.primaryname}}""
    chart: ""{{.chart.name}}-{{.chart.version}}""
  annotations:
    ""helm.sh/created"": {{.release.time.seconds | quote }}
spec:
  selector:
    matchlabels:
      app: """" # has to match .spec.template.metadata.labels
  servicename: """" # put your servicename here
  replicas: 1 # by default is 1
  template:
    metadata:
      labels:
        app: """" # has to match .spec.selector.matchlabels
    spec:
      terminationgraceperiodseconds: 10
      containers:
      - name: {{.values.containername}}
        image: ""{{.values.postgresimage}}""
        ports: 
        - containerport: 5432
          protocol: tcp
          name: postgres
        resources:
          requests:  
            cpu: {{default ""100m"" .values.cpu}}
            memory: {{default ""100m"" .values.memory}}
        env:
        - name: pghost
          value: /tmp
        - name: pg_primary_user
          value: primaryuser
        - name: pg_mode
          value: set
        - name: pg_primary_port
          value: ""5432""
        - name: pg_primary_password
          value: ""{{.values.primarypassword}}""
        - name: pg_user
          value: testuser
        - name: pg_password
          value: ""{{.values.userpassword}}
        - name: pg_database
          value: userdb
        - name: pg_root_password
          value: ""{{.values.rootpassword}}""
        volumemounts:
        - name: pgdata
          mountpath: ""/pgdata""
          readonly: false
      volumes:
      - name: pgdata
        persistentvolumeclaim:
          claimname: {{.values.pvcname}}

"
62610669,what command can tell me how many nodes a cluster deployed by a helm chart will use?,"i have a pre-made helm chart which i wish to install into a kubernetes cluster.
what command can i run to work out how many nodes it will require? i know that i can utilise
kubectl get pods -o wide   

to list all of the pods but my understanding is in theory multiple pods can run inside a single node.
one reason i am asking this besides learning is because i am using the digitalocean managed kubernetes service which requires me to specify how many nodes my cluster will be using, before i deploy via helm.
",<kubernetes><kubernetes-helm>,62623314,2,"that's very dependent on both your cluster and chart configuration, and there isn't a simple answer.
given the chart, you can ask it to produce the kubernetes yaml it would send to the cluster
helm template . -f ...yaml --set option=value

using the same -f and --set options you plan to use with helm install to provide deploy-time settings.
in that output you're looking for most likely deployment and statefulset objects; in each of those you're looking for its replicas: setting, and in the template:, the resources: { requests: { ... }}.  if you multiply this out you should be able to get the total memory and cpu that the chart needs to be scheduled on the cluster.
a &quot;node&quot; doesn't have a fixed size, and it depends on what kind of &quot;hardware&quot; you're running it on.  on aws typical instance type options range from 1 core and 2 gb ram up through 64 cores and 512 gb ram.  if you determine that your application needs 16 cores and 64 gb ram that could fit on one node if it's big enough, or it might need four.  you also need to determine if you can use the cluster autoscaler (in which case a fixed number of nodes isn't a constraint) and how much headroom you want in your cluster to be able to take nodes offline for upgrades or to run other workloads.
this shouldn't be too hard to work out with a spreadsheet, but it is very heavily dependent on the specific chart, what options you install it with, what size nodes you're thinking about using, and your other operational constraints.  there's not a single built-in command that translates &quot;helm chart name&quot; to &quot;number of nodes&quot;.
"
52812230,kubernetes gives an internal source ip although externaltrafficpolicy is set to local,"our kubernetes cluster includes an nginx load balancer that forwards the requests to other pods.

however, the nginx sees local source ips and therefore cannot set the correct x-real-ip header. i tried setting the externaltrafficpolicy value of nginx to ""local"" but the ip does not change.

section of the nginx service config:

 ""selector"": {
  ""app"": ""nginx-ingress"",
  ""component"": ""controller"",
  ""release"": ""loping-lambkin""
},
""clusterip"": ""10.106.1.182"",
""type"": ""loadbalancer"",
""sessionaffinity"": ""none"",
""externaltrafficpolicy"": ""local"",
""healthchecknodeport"": 32718


result:

get / http/1.1
host: example.com:444
x-request-id: dd3310a96bf154d2ac38c8877dec312c
x-real-ip: 10.39.0.0
x-forwarded-for: 10.39.0.0


we use a bare metal cluster with metallb.
",<kubernetes><load-balancing><kubernetes-ingress><nginx-ingress><weave>,56544201,1,"i found out that weave needs to be configured using no_masq_local=1 to respect the externaltrafficpolicy property
"
72195656,how can i use environment variables passed from deployment file in nginx.conf,"below is the logic in my docker file.
i am using nginx to build the application.
from node:14-alpine as builder

copy package.json ./
run npm install &amp;&amp; mkdir /app &amp;&amp; mv ./node_modules ./app
workdir /app

copy . .

run npm run build


from nginx:1.16.0-alpine
copy --from=builder /app/build /usr/share/nginx/html
run rm /etc/nginx/conf.d/default.conf
copy nginx.conf /etc/nginx/conf.d

expose 3000

cmd [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]

below is the nginx.conf file
server {
   listen 3000;
      
   location / {
     root /usr/share/nginx/html;
     index index.html index.htm;
     try_files $uri $uri/ /index.html =404;
   }
  
   location /api {
    #  rewrite /api/api(.*) /$1 break;
     proxy_pass http://${backend_host}:${backend_port}/api;
   }
      
   include /etc/nginx/extra-conf.d/*.conf;
}

backend_host and backend_port in the proxy_pass url will be provided while deploying the image using deployment file.
is this possible?
if not is there any alternative way for this?
",<docker><kubernetes><dockerfile><nginx-config><kubernetes-deployment>,72196077,2,"if you want to dynamically mount the nginx.conf i would suggest using the config map with your deployment.yaml
so this way you re-use your docker image multiple times without recreating it and pass the config map to update it.
you docker file will be
from node:14-alpine as builder
copy package.json ./
run npm install &amp;&amp; mkdir /app &amp;&amp; mv ./node_modules ./app
workdir /app
copy . .
run npm run build


from nginx:1.16.0-alpine
copy --from=builder /app/build /usr/share/nginx/html
run rm /etc/nginx/conf.d/default.conf
expose 3000
cmd [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]

example configmap
apiversion: v1
kind: configmap
metadata:
  name: nginx-config
data:
  default.conf: |-
    server {
            listen 80 default_server;
            root /var/www/html;
            server_name  _;
            index index.php;
            location / {
                try_files $uri $uri/ /index.php?$args;
            }
            location ~ \.php$ {
                fastcgi_split_path_info ^(.+\.php)(/.+)$;
                fastcgi_pass 127.0.0.1:9000;
                fastcgi_index index.php;
                include fastcgi_params;
                fastcgi_param   path_info       $fastcgi_path_info;
                fastcgi_param   script_filename $document_root$fastcgi_script_name;
            }
        }

mount the config map to deployment
apiversion: apps/v1
kind: deployment
metadata:
  name: app
  labels:
    app: app
spec:
  selector:
    matchlabels:
      app: app
  replicas: 1
  template:
    metadata:
      labels:
        app: app
    spec:
      containers:
        - name: app
          image: app-image
          ports:
          - containerport: 80
          volumemounts:
            - name: nginx-config
              mountpath: /etc/nginx/nginx.conf
              subpath: nginx.conf
      volumes:
        - name: nginx-config
          configmap:
            name: confnginx

for more details read at : https://blog.meain.io/2020/dynamic-reverse-proxy-kubernetes/
"
72260642,"getting ""your connection is not private"" after setting tls in kubernetes ingress","i'm still getting this privacy error
i'm still getting this privacy error

the issuer generate a certificate and all things is good

this is the ingress yaml:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: minimal-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/tls-acme: &quot;true&quot;
    cert-manager.io/issuer: letsencrypt-nginx
spec:
  ingressclassname: nginx
  tls:
    - hosts:
        - &quot;myhost.com&quot;
      secretname: letsencrypt-nginx
  rules:
  - host: myhost.com
    http:
      paths:
        - path: /
          pathtype: prefix
          backend:
            service:  
              name: backend-service
              port:
                number: 3000

what could be the problem ?!
",<kubernetes><ssl-certificate><kubernetes-ingress>,72261246,1,"it appears you are using cert-manager to generate ca signed certificates. the certificate status appears to be true which means cert-manager has successfully provisioned the certificate.
from the naming convention, i'm assuming your are using letsencrypt as issuer.
however the browser is still throwing certificate warning. this happens when you use the staging letsencrypt api endpoint, i.e. https://acme-staging-v02.api.letsencrypt.org/directory
cert-manager has documented this too.
the staging api endpoint is there for you to experiment around and gain confidence before using the production api endpoint, i.e. https://acme-v02.api.letsencrypt.org/directory in your in your issuer spec.
staging letsencrypt api endpoint has same rate limits as the production letsencrypt api endpoint with few exceptions.
consider using production letsencrypt api endpoint in your issuer to avoid certificate related warnings.
"
52081373,rabbit-mq deployment with kubernetes,"i'm in a progress to migrate to kuberenetes from docker-compose.
one of the services we're using is rabbit-mq.
when i try to deploy rabbit-mq 3.6.16-management i receive the error:

/usr/local/bin/docker-entrypoint.sh: line 382: /etc/rabbitmq/rabbitmq.config: permission denied.

while it works in docker-compose deployment.

kuberentes:

apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: rabbit-mq
  name: rabbit-mq
spec:
  replicas: 1
  selector:
    matchlabels:
      app: rabbit-mq
  strategy:
    type: recreate
  template:
    metadata:
      labels:
         app: rabbit-mq
    spec:
      containers:
      - image: rabbitmq:3.6.16-management
        name: rabbit-mq
        ports:
        - containerport: 15671
        - containerport: 5671
        volumemounts:
        - mountpath: /etc/rabbitmq
          name: rabbit-mq-data
      restartpolicy: always
      hostname: rabbit-mq
      volumes:
      - name: rabbit-mq-data
        persistentvolumeclaim:
          claimname: rabbit-mq-data


pvc:

apiversion: v1
kind: persistentvolumeclaim
metadata:
  labels:
    app: rabbit-mq-data
  name: rabbit-mq-data
spec:
  accessmodes:
  - readwriteonce
  resources:
    requests:
      storage: 16gi


pv:

apiversion: v1
kind: persistentvolume
metadata:
  name: rabbit-mq-data
  labels:
    type: local
spec:
  accessmodes:
  - readwriteonce
  capacity:
    storage: 16gi
  hostpath:
    path: ""/etc/rabbitmq""


docker-compose:

  rabbit-mq:
      image: rabbitmq:3.6.16-management
      ports:
        - ""15671:15671""
        - ""5671:5671""
      container_name: rabbit-mq
      volumes:
        - rabbit-mq-data:/etc/rabbitmq
      restart: on-failure:5

",<docker><kubernetes><rabbitmq><kubectl>,52371754,6,"eventually i've used configmap and secrets to mount files instead of pv and works as expected.

apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: rabbit-mq
  name: rabbit-mq
spec:
  replicas: 1
  selector:
    matchlabels:
      app: rabbit-mq
  template:
    metadata:
      labels:
         app: rabbit-mq
    spec:
      containers:
      - image: rabbitmq:3.6.16-management
        name: rabbit-mq
        ports:
        - containerport: 15671
        - containerport: 5671
        volumemounts:
        - name: rabbit-mq-data
          mountpath: /etc/rabbitmq
          readonly: false
        - name: mq-secret
          mountpath: /etc/rabbitmq/certfiles
          #readonly: true
      volumes:
        - name: mq-secret
          secret:
            defaultmode: 420
            secretname: rabbit-mq-secrets
        - configmap:
            defaultmode: 420
            items:
            - key: rabbitmq.config
              path: rabbitmq.config
            name: mq-config
          name: rabbit-mq-data

"
66024658,error in installing superset on gke using helm v2.17,"i need to install superset on gke. i am following this guide https://howchoo.com/kubernetes/how-to-install-apache-superset-on-a-gke-kubernetes-cluster to do the same. it is suggested here to use helm to install superset. i have installed helm v2.17.
i have installed and initialized helm using the following statements:
$ curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
$ sudo apt-get install apt-transport-https --yes
$ echo &quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
$ sudo apt-get update
$ sudo apt-get install helm2
$ helm init

in the next step i want to install superset.
superset's official site says we need to run helm upgrade --install superset ./install/helm/superset to install superset on a kubernetes cluster.
on running the command i get the following as output:
 $ helm upgrade --install superset ./install/helm/superset
release &quot;superset&quot; does not exist. installing it now.
error: path &quot;./install/helm/superset&quot; not found

as you can see the path itself doesn't exist. i have inspected the directory and tried manually creating a directory named 'superset' (with helm's file - get_helm.sh - moved to this directory). then installed superset in it, but i get the following error:
 $ ls 
get_helm.sh  kubectl.exe  readme-cloudshell.txt  superset-config.py
 $ mkdir superset     
 $ ls 
get_helm.sh  kubectl.exe  readme-cloudshell.txt  superset  superset-config.py
 $ mv get_helm.sh superset
 $ cd superset
 $ ls
get_helm.sh 
 $ helm upgrade --install superset superset
error: no chart.yaml exists in directory &quot;/home/&lt;username&gt;/superset&quot;

i am not able to figure out where helm is installed. it is supposed to exist in ./install/helm so that superset can be installed in this path.
how can i fix this error?
",<kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-helm><apache-superset>,66026709,2,"you can install superset using:
helm install cloudposse-incubator/superset

installing the chart:
helm repo rm cloudposse-incubator 2&gt;/dev/null
helm repo add cloudposse-incubator https://charts.cloudposse.com/incubator/
helm install --name my-release stable/superset

reference document:

https://artifacthub.io/packages/helm/cloudposse/superset


about error:
you are getting error due to not running command from the inside of helm directory.
github source:

https://github.com/helm/charts/tree/master/stable/superset

you can clone whole github repo locally:
git clone https://github.com/helm/charts.git

go inside helm directory.
go to stable/superset directory:
cd stable/superset

here you can also run a command like helm install stable/superset
or outside of the directory, you can run:
helm install superset ./stable/superset

alternatively, you can also download helm chart locally using
helm fetch stable/superset --untar

after this go to the directory and run the same command.
"
57364093,how to fix `can't evaluate field extrahosts in type interface {}` in _helpers.tpl in helm,"i am trying to get some values from umbrella chart in helm in _helpers.tpl but i for some reason i am getting the error executing ""gluu.ldaplist"" at &lt;.values.ldap.extraho...&gt;: can't evaluate field extrahosts in type interface {}

this is what i am trying to do.
_helpers.ptl

{{- define ""gluu.ldaplist"" -}}
{{- $hosts := .values.ldap.extrahosts -}}
{{- $genldap := dict ""host"" (printf ""%s-%s"" .release.name .values.ldaptype) ""port"" .values.ldapport -}}
{{- $hosts := prepend $hosts $genldap -}}
{{- $local := dict ""first"" true -}}
{{- range $k, $v := $hosts -}}
{{- if not $local.first -}},{{- end -}}{{- printf ""%s:%.f"" $v.host $v.port -}}{{- $_ := set $local ""first"" false -}}
{{- end -}}
{{- end -}}


and this is part of values.yml for the umbrella chart
values.yml

ldap:
  enabled: true
  type: opendj
  extrahosts: [
    host: opendj,
    port: 3434
  ] #array of k,v e.g host: host1, port: port1


directory structure

helm/
  charts/
     chart_a/
       templates/
          configmap.yml -----&gt;&gt;&gt; this is where i want to use it
  templates/
     _helpers.tpl ----&gt;&gt;&gt;&gt; where the failing function is
  requirements.yml
  values.yml ----------&gt;&gt;&gt; where the ldap values are



the configmap.yml looks like below

apiversion: v1
kind: configmap
metadata:
  name: {{ template ""oxauth.fullname"" . }}-cm
data:
  gluu_config_adapter: {{ .values.global.configadaptername | quote }}
  gluu_ldap_url: {{ template ""gluu.ldaplist"" . }}


note: the _helpers.tpl is under the main/umbrella chart. chart_a is a subchart.

expected results are something like gluu_ldap_url:""opendj:3434""

helm version:  

client: &amp;version.version{semver:""v2.10.0"", gitcommit:""9ad53aac42165a5fadc6c87be0dea6b115f93090"", gittreestate:""clean""}
server: &amp;version.version{semver:""v2.10.0"", gitcommit:""9ad53aac42165a5fadc6c87be0dea6b115f93090"", gittreestate:""clean""}


expected result is that the function {{- define ""gluu.ldaplist"" -}} in _helpers.tpl completes without error even if no values are provided in the array. 
if there are values provided, the expected string is host:port as output.

if this can be done in another way, i welcome any suggestion.
",<go><kubernetes><kubernetes-helm><templating><gluu>,57393952,1,"this can be solved with global values which allow values in the parent chart to override (or supply unspecified) values in the child subcharts.

from the helm docs on subcharts and global values:


  
  a subchart is considered “stand-alone”, which means a subchart can never explicitly depend on its parent chart.
  for that reason, a subchart cannot access the values of its parent.
  a parent chart can override values for subcharts.
  helm has a concept of global values that can be accessed by all charts.
  


(at first i didn't think to search for ""helm subchart"" but once i did an internet search for that term, this was the first or second result)

here's a minimal example that solves your issue:

directory structure

helm
├── chart.yaml
├── charts
│   └── chart_a
│       ├── chart.yaml
│       └── templates
│           └── configmap.yml
├── templates
│   └── _helpers.tpl
└── values.yaml


note: i added chart.yaml files to make it actually work, renamed values.yml to values.yaml so that it works by default without extra flags, and removed requirements.yml since it wasn't necessary to reproduce the problem and solution.

values.yaml

global:
  ldap:
    enabled: true
    type: opendj
    extrahosts:
    - host: opendj
      port: 3434
  ldaptype: xxx
  ldapport: 123


the key was to nest what you had under a special global key. note, i also added ldaptype and ldapport since they were in your _helpers.tpl, and i fixed the yaml structure you had under extrahosts. what was there before didn't actually represent a list of maps with host and port keys. without this fix, the helm command doesn't fail but doesn't output what you want either.

result

$ helm template .
---
# source: helm/charts/chart_a/templates/configmap.yml
apiversion: v1
kind: configmap
metadata:
  name: cm
data:
  gluu_ldap_url: release-name-xxx:123,opendj:3434

"
76052684,why are images from the gcp artifact registry not being pulled by my deployments?,"i have two projects in gcp. let's call them project a and project b. project a will contain the cluster for the deployment, while project b will contain the artifact registry (please note that this is not the same as the container registry).
the deployment is pulling a docker image from the artifact registry. let's say the docker image is a stock standard ubuntu image that our deployment is trying to deploy, and let's assume that the image is already in the artifact registry with no issues.
the deployment of the ubuntu image to the cluster is done via a gitlab ci/cd pipeline. it uses a service account that has the following roles:

artifact registry reader
kubernetes engine developer
viewer

additionally we also note that the cluster features two node pools. one is a custom node pool and the other is the default. they both have the following access scopes:

https://www.googleapis.com/auth/cloud-platform
https://www.googleapis.com/auth/devstorage.read_only
https://www.googleapis.com/auth/logging.write
https://www.googleapis.com/auth/monitoring.write
https://www.googleapis.com/auth/service.management.readonly
https://www.googleapis.com/auth/servicecontrol

the cloud-platform scope is enabled to ensure that the node pools can pull from the artifact registry which is in a different project.
it is also important to note that both node pools use the default service account which has the roles:

artifact registry reader
editor

upon deployment, the gitlab pipeline completes with no issues. however, the deployment workload fails in the cluster. the following events occur:

pulling image &quot;europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest&quot;
failed to pull image &quot;europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest&quot;: rpc error: code = unknown desc = failed to pull and unpack image &quot;europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest&quot;: failed to resolve reference &quot;europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest&quot;: failed to authorize: failed to fetch oauth token: unexpected status: 403 forbidden
error: errimagepull
error: imagepullbackoff
back-off pulling image &quot;europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest&quot;

the deployment yaml file is as follows:
---
apiversion: apps/v1
kind: deployment
metadata:
  name: ubuntu-build-deploy-demo
  labels:
    app: ubuntu
  namespace: customnamespace
spec:
  replicas: 1
  selector:
    matchlabels:
      app: ubuntu
  template:
    metadata:
      labels:
        app: ubuntu
    spec:
      containers:
        - name: ubuntu
          image: europe-west1-docker.pkg.dev/b/docker-repo/ubuntu:latest
          command: [&quot;sleep&quot;, &quot;123456&quot;]

why is the image not pulled from correctly? why am i getting an auth issue despite the correct service account roles and access scopes? how can i resolve this issue?
i have double checked that the image name, tag, and path are correct many times. i have also double checked that the service accounts have the correct roles (specified earlier). i have also ensured that the node pool access scopes are correct and do indeed have the correct access scopes (specified earlier).
i am at a loss of how to resolve this issue. any help would be greatly appreciated.
",<docker><kubernetes><google-cloud-platform><google-kubernetes-engine><google-artifact-registry>,76054052,1,"putting in answer form. as @avinashjha said: the default service account from project a needs to have the role artifact registry reader in project b. this allows for the default service account to oauth and pull the docker image from the registry.
"
56215495,how to let cron job pull the docker image once after deploying?,"i have a dozen of cron jobs on gke. my docker registry is down. the status of these cron jobs becomes: imagepullbackoff

my thinking is, the cron jobs should pull the docker image once after deploying and use the cached/local docker image.

shouldn't pull the docker image every time from remote docker registry when the cron job creates a new pod. it's a waste, because the docker image doesn't change (i mean the application code of cron job).

so, is there a way to do this?

purpose: if can do this, my cron jobs will always running using local docker image before next deploying, even if docker registry is down.
",<docker><kubernetes><google-cloud-platform><cron><google-kubernetes-engine>,56215879,4,"you can use one of the ""container images"" properties mentioned here.

please setup in your deployment: imagepullpolicy: ifnotpresent.

note:


  if imagepullpolicy is omitted and either the image tag is :latest or it is omitted: always is applied.


please verify your deployment settings and verify also if docker images are present on the machine.
"
53668964,kubernetes 0 downtime using readiness probe and rollback strategy not working,"i have set up a node app on kubernetes. i'm running a single replica and i want 0 down-time when the image is updated. i update my pod using set image on kubernetes.

'set', 'image', 'deployment/dev-web'


here's my yaml file 

apiversion: extensions/v1beta1
kind: deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: ""2""
  generation: 2
  labels:
    io.kompose.service: dev-web
  name: dev-web
  namespace: default
spec:
  replicas: 1
  selector:
    matchlabels:
      io.kompose.service: dev-web
  strategy:
    rollingupdate:
      maxsurge: 1
      maxunavailable: 1
    type: rollingupdate
  template:
    metadata:
      creationtimestamp: null
      labels:
        io.kompose.service: dev-web
    spec:
      containers:
      - env:
        image: gcr.io/my-project-link/my-image-link
        imagepullpolicy: always
        name: dev-web-container
        ports:
        - containerport: 2000
          protocol: tcp
        readinessprobe:
          failurethreshold: 3
          httpget:
            path: /
            port: 2000
            scheme: http
          initialdelayseconds: 5
          periodseconds: 5
          successthreshold: 1
          timeoutseconds: 1
        resources:
          requests:
            cpu: 20m
        terminationmessagepath: /dev/termination-log
        terminationmessagepolicy: file
      dnspolicy: clusterfirst
      restartpolicy: always
      schedulername: default-scheduler
      securitycontext: {}
      terminationgraceperiodseconds: 30
status:
  availablereplicas: 1
  conditions:
  - lasttransitiontime: 2018-12-07t11:13:21z
    lastupdatetime: 2018-12-07t11:13:21z
    message: deployment has minimum availability.
    reason: minimumreplicasavailable
    status: ""true""
    type: available
  observedgeneration: 2
  readyreplicas: 1
  replicas: 1
  updatedreplicas: 1


my app does give 200 response on '/' get therefore readiness probe works but when i update the image, and test it but continuously hitting curl, it gives me downtime which lasts for like 20-40 seconds. 
",<kubernetes><kubectl>,53669069,8,"you setup your maxunavailable as 1 even when you have only one replica, you should be having maxunavailable to 0.

strategy:
 type: rollingupdate
 rollingupdate:
   maxunavailable: 0
   maxsurge: 1


it basically tells kubernetes that there should be zero unavailable pods while deploying (maxunavailable: 0) and there should be one new pod at a time (maxsurge: 1).

i am hoping you setup the readiness probe something like this:

readinessprobe:
  httpget:
    path: /
    port: 80
  initialdelayseconds: 5
  periodseconds: 5
  successthreshold: 1


basically, this is a check that kubernetes does in order to make sure that your pod is ready to send traffic to it. until it is not ready, kubernetes will not use your pod.
"
65857310,"kubectl : unable to recognize ""csr.yaml"": no matches for kind ""certificatesigningrequest"" in version ""certificates.k8s.io/v1""","i have this template i try to invoke: looking at the docs example here
--- 
apiversion: certificates.k8s.io/v1
kind: certificatesigningrequest
metadata: 
  name: vault-csr
spec: 
  groups: 
    - system: authenticated
  request: ls0tls1crudjtibdrvjusuzjq0fursbsrvfvrvnuls0tls0ktuljrkleq0nbd2ddqvfbd0lerwvnqndhqtfvruf3d1zkbuyxykhrdwrtrjfisff0y0dwewmyohvjm1pqtuljqwpjakfoqmdrcwhrauc5dzbcqvffrkfbt0nbzzhbtuljq0nns0nbz0vbdfjubkfqr2r4bg1xdjhmow1gc29yoxjuck9jctvgtnjmzmrdelzcvevnuev6tdgzswfst1cya2lrnwfrm282d2nstmx1s3nzeul1c0zustfqr2djwjn0exkksdfqmlrommnhmhp4mgvaytjqk3jmvkkwsmvtdxfhnkdmy01rrzruduhzsgjradzuymgyalc5s0rtutvreknzdwo0rlg4bdzxvevilzdsemgwnct0rkdfamxvvktkakjycnvqmnhbc0nqemj2sy9gaehlrjjwrvpza1psnwtcbc80cm1kl2xhutrutysyvw5cbmsvaljjd3g5a0zgwdhucehgwxxxls0k
  signername: kubernetes.io/kubelet-serving
  usages:
  - digital signature
  - key encipherment
  - server auth

the version of kubectl:
$ kubectl version --short
client version: v1.20.0
server version: v1.18.9-eks-d1db3c

and im working with aws eks
i keep getting :
$ kubectl create -f csr.yaml
error: unable to recognize &quot;csr.yaml&quot;: no matches for kind &quot;certificatesigningrequest&quot; in version &quot;certificates.k8s.io/v1&quot;

update
after changing to apiversion: certificates.k8s.io/v1beta1
apiversion: certificates.k8s.io/v1beta1
kind: certificatesigningrequest
metadata: 
  name: vault-csr
spec: 
  groups: 
    - system: authenticated
  request: ls0tls1crudjtibdrvjusuzjq0fursb.....
  usages:
  - digital signature
  - key encipherment
  - server auth

im getting now this error:
$ kubectl create -f csr.yaml
error: error validating &quot;tmp/csr.yaml&quot;: error validating data: validationerror(certificatesigningrequest.spec.groups[0]): invalid type for io.k8s.api.certificates.v1beta1.certificatesigningrequestspec.groups: got &quot;map&quot;, expected &quot;string&quot;; if you choose to ignore these errors, turn validation off with --validate=false

",<kubernetes><kubectl><certificate-signing-request>,65857418,7,"as per the k8s change doc, the certificatesigningrequest api is promoted to certificates.k8s.io/v1 only as part of the k8s 1.19 release.
it was under certificates.k8s.io/v1beta1 before that.
i suspect that to be a problem as your server version is v1.18.
so, try changing your apiversion as below:
apiversion: certificates.k8s.io/v1beta1
"
69366467,updating helm subcharts fails without a clear error,"while trying to add/update a dependency to a helm chart i'm getting this error. no helm plugins are installed with the name helm-manager.
$ helm dep update                                                                                                                                
getting updates for unmanaged helm repositories...
...unable to get an update from the &quot;https://kubernetes-charts.storage.googleapis.com/&quot; chart repository:
        failed to fetch https://kubernetes-charts.storage.googleapis.com/index.yaml : 403 forbidden
...unable to get an update from the &quot;https://kubernetes-charts.storage.googleapis.com/&quot; chart repository:
        failed to fetch https://kubernetes-charts.storage.googleapis.com/index.yaml : 403 forbidden
hang tight while we grab the latest from your chart repositories...
...successfully got an update from the &quot;bitnami&quot; chart repository
update complete. happy helming!
error: no cached repository for helm-manager-1067d9c6027b8c3f27b49e40521d64be96ea412858d8e45064fa44afd3966ddc found. (try 'helm repo update'): open /users/&lt;redacted&gt;/library/caches/helm/repository/helm-manager-1067d9c6027b8c3f27b49e40521d64be96ea412858d8e45064fa44
afd3966ddc-index.yaml: no such file or directory

",<kubernetes><kubernetes-helm>,69366468,1,"the stable and incubator repositories of the helm charts have been moved to a new location.
you must updated uri in charts.yaml (or requirements.yaml) to point to the new repositories in order to let the helm dependency resolver find the correct location.




name
old location
new location




stable
https://kubernetes-charts.storage.googleapis.com
https://charts.helm.sh/stable


incubator
https://kubernetes-charts-incubator.storage.googleapis.com
https://charts.helm.sh/incubator




after that you should be able to run helm dep update without further modifications.
"
71039790,eks pods being terminated for no reason,"i wonder if someone can help me.
kubernetes (k8s 1.21 platform eks.4) is terminating running pods without error or reason. the only thing i can see in the events is:
7m47s       normal    killing                   pod/test-job-6c9fn-qbzkb                          stopping container test-job

because i've set up an anti-affinity rule, only one pod can run in one node. so every time a pod gets killed, autoscaler brings up another node.
these are the cluster-autoscaler logs
i0208 19:10:42.336476       1 cluster.go:148] fast evaluation: ip-10-4-127-38.us-west-2.compute.internal for removal
i0208 19:10:42.336484       1 cluster.go:169] fast evaluation: node ip-10-4-127-38.us-west-2.compute.internal cannot be removed: pod annotated as not safe to evict present: test-job-6c9fn-qbzkb
i0208 19:10:42.336493       1 scale_down.go:612] 1 nodes found to be unremovable in simulation, will re-check them at 2022-02-08 19:15:42.335305238 +0000 utc m=+20363.008486077

i0208 19:15:04.360683       1 klogx.go:86] pod default/test-job-6c9fn-8wx2q is unschedulable
i0208 19:15:04.360719       1 scale_up.go:376] upcoming 0 nodes
i0208 19:15:04.360861       1 scale_up.go:300] pod test-job-6c9fn-8wx2q can't be scheduled on eks-ec2-8xlarge-84bf6ad9-ca4a-4293-a3e8-95bef28db16d, predicate checking error: node(s) didn't match pod's node affinity/selector; predicatename=nodeaffinity; reasons: node(s) didn't match pod's node affinity/selector; debuginfo=
i0208 19:15:04.360901       1 scale_up.go:449] no pod can fit to eks-ec2-8xlarge-84bf6ad9-ca4a-4293-a3e8-95bef28db16d
i0208 19:15:04.361035       1 scale_up.go:300] pod test-job-6c9fn-8wx2q can't be scheduled on eks-ec2-inf1-90bf6ad9-caf7-74e8-c930-b80f785bc743, predicate checking error: node(s) didn't match pod's node affinity/selector; predicatename=nodeaffinity; reasons: node(s) didn't match pod's node affinity/selector; debuginfo=
i0208 19:15:04.361062       1 scale_up.go:449] no pod can fit to eks-ec2-inf1-90bf6ad9-caf7-74e8-c930-b80f785bc743
i0208 19:15:04.361162       1 scale_up.go:300] pod test-job-6c9fn-8wx2q can't be scheduled on eks-ec2-large-62bf6ad9-ccd4-6e03-5c78-c3366d387d50, predicate checking error: node(s) didn't match pod's node affinity/selector; predicatename=nodeaffinity; reasons: node(s) didn't match pod's node affinity/selector; debuginfo=
i0208 19:15:04.361194       1 scale_up.go:449] no pod can fit to eks-ec2-large-62bf6ad9-ccd4-6e03-5c78-c3366d387d50
i0208 19:15:04.361512       1 scale_up.go:412] skipping node group eks-eks-on-demand-10bf6ad9-c978-9b35-c7fc-cdb9977b27cb - max size reached
i0208 19:15:04.361675       1 scale_up.go:300] pod test-job-6c9fn-8wx2q can't be scheduled on eks-ec2-test-58bf6d43-13e8-9acc-5173-b8c5054a56da, predicate checking error: node(s) didn't match pod's node affinity/selector; predicatename=nodeaffinity; reasons: node(s) didn't match pod's node affinity/selector; debuginfo=
i0208 19:15:04.361711       1 scale_up.go:449] no pod can fit to eks-ec2-test-58bf6d43-13e8-9acc-5173-b8c5054a56da
i0208 19:15:04.361723       1 waste.go:57] expanding node group eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f would waste 75.00% cpu, 86.92% memory, 80.96% blended
i0208 19:15:04.361747       1 scale_up.go:468] best option to resize: eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f
i0208 19:15:04.361762       1 scale_up.go:472] estimated 1 nodes needed in eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f
i0208 19:15:04.361780       1 scale_up.go:586] final scale-up plan: [{eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f 0-&gt;1 (max: 2)}]
i0208 19:15:04.361801       1 scale_up.go:675] scale-up: setting group eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f size to 1
i0208 19:15:04.361826       1 auto_scaling_groups.go:219] setting asg eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f size to 1
i0208 19:15:04.362154       1 event_sink_logging_wrapper.go:48] event(v1.objectreference{kind:&quot;configmap&quot;, namespace:&quot;kube-system&quot;, name:&quot;cluster-autoscaler-status&quot;, uid:&quot;81b80048-920c-4bf1-b2c0-ad5d067d74f4&quot;, apiversion:&quot;v1&quot;, resourceversion:&quot;359476&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'scaledupgroup' scale-up: setting group eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f size to 1
i0208 19:15:04.374021       1 event_sink_logging_wrapper.go:48] event(v1.objectreference{kind:&quot;configmap&quot;, namespace:&quot;kube-system&quot;, name:&quot;cluster-autoscaler-status&quot;, uid:&quot;81b80048-920c-4bf1-b2c0-ad5d067d74f4&quot;, apiversion:&quot;v1&quot;, resourceversion:&quot;359476&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'scaledupgroup' scale-up: setting group eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f size to 1
i0208 19:15:04.541658       1 eventing_scale_up_processor.go:47] skipping event processing for unschedulable pods since there is a scaleup attempt this loop
i0208 19:15:04.541859       1 event_sink_logging_wrapper.go:48] event(v1.objectreference{kind:&quot;pod&quot;, namespace:&quot;default&quot;, name:&quot;test-job-6c9fn-8wx2q&quot;, uid:&quot;67beba1d-4f52-4860-91af-89e5852e4cad&quot;, apiversion:&quot;v1&quot;, resourceversion:&quot;359507&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'triggeredscaleup' pod triggered scale-up: [{eks-ec2-xlarge-84bf6ad9-cb6d-7e24-7eb5-a00c369fd82f 0-&gt;1 (max: 2)}]

i'm running an eks cluster with cluster-autoscaler and keda's aws-sqs trigger. i've set up an autoscaling node group with spot instances.
for testing purposes i've defined an scaledjob consisting on a container with a simple python script, looping through time.sleep. the pod should run for 30 mins. but it never gets so far. in general it ends after 15 mins.
{
            &quot;apiversion&quot;: &quot;keda.sh/v1alpha1&quot;,
            &quot;kind&quot;: &quot;scaledjob&quot;,
            &quot;metadata&quot;: {
                &quot;name&quot;: id,
                &quot;labels&quot;: {&quot;myjobidentifier&quot;: id},
                &quot;annotations&quot;: {
                    &quot;cluster-autoscaler.kubernetes.io/safe-to-evict&quot;: &quot;false&quot;
                },
            },
            &quot;spec&quot;: {
                &quot;jobtargetref&quot;: {
                    &quot;parallelism&quot;: 1,
                    &quot;completions&quot;: 1,
                    &quot;backofflimit&quot;: 0,
                    &quot;template&quot;: {
                        &quot;metadata&quot;: {
                            &quot;labels&quot;: {&quot;job-type&quot;: id},
                            &quot;annotations&quot;: {
                                &quot;cluster-autoscaler.kubernetes.io/safe-to-evict&quot;: &quot;false&quot;
                            },
                        },
                        &quot;spec&quot;: {
                            &quot;affinity&quot;: {
                                &quot;nodeaffinity&quot;: {
                                    &quot;requiredduringschedulingignoredduringexecution&quot;: {
                                        &quot;nodeselectorterms&quot;: [
                                            {
                                                &quot;matchexpressions&quot;: [
                                                    {
                                                        &quot;key&quot;: &quot;eks.amazonaws.com/nodegroup&quot;,
                                                        &quot;operator&quot;: &quot;in&quot;,
                                                        &quot;values&quot;: group_size,
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                },
                                &quot;podantiaffinity&quot;: {
                                    &quot;requiredduringschedulingignoredduringexecution&quot;: [
                                        {
                                            &quot;labelselector&quot;: {
                                                &quot;matchexpressions&quot;: [
                                                    {
                                                        &quot;key&quot;: &quot;job-type&quot;,
                                                        &quot;operator&quot;: &quot;in&quot;,
                                                        &quot;values&quot;: [id],
                                                    }
                                                ]
                                            },
                                            &quot;topologykey&quot;: &quot;kubernetes.io/hostname&quot;,
                                        }
                                    ]
                                },
                            },
                            &quot;serviceaccountname&quot;: service_account.service_account_name,
                            &quot;containers&quot;: [
                                {
                                    &quot;name&quot;: id,
                                    &quot;image&quot;: image.image_uri,
                                    &quot;imagepullpolicy&quot;: &quot;ifnotpresent&quot;,
                                    &quot;env&quot;: envs,
                                    &quot;resources&quot;: {
                                        &quot;requests&quot;: requests,
                                    },
                                    &quot;volumemounts&quot;: [
                                        {
                                            &quot;mountpath&quot;: &quot;/tmp&quot;,
                                            &quot;name&quot;: &quot;tmp-volume&quot;,
                                        }
                                    ],
                                }
                            ],
                            &quot;volumes&quot;: [
                                {&quot;name&quot;: &quot;tmp-volume&quot;, &quot;emptydir&quot;: {}}
                            ],
                            &quot;restartpolicy&quot;: &quot;never&quot;,
                        },
                    },
                },
                &quot;pollinginterval&quot;: 30,
                &quot;successfuljobshistorylimit&quot;: 10,
                &quot;failedjobshistorylimit&quot;: 100,
                &quot;maxreplicacount&quot;: 30,
                &quot;rolloutstrategy&quot;: &quot;default&quot;,
                &quot;scalingstrategy&quot;: {&quot;strategy&quot;: &quot;default&quot;},
                &quot;triggers&quot;: [
                    {
                        &quot;type&quot;: &quot;aws-sqs-queue&quot;,
                        &quot;metadata&quot;: {
                            &quot;queueurl&quot;: queue.queue_url,
                            &quot;queuelength&quot;: &quot;1&quot;,
                            &quot;awsregion&quot;: region,
                            &quot;identityowner&quot;: &quot;operator&quot;,
                        },
                    }
                ],
            },
        }

i know this is not a problem of resources (dummy code and large instances), nor a problem of eviction (it's clear from the logs that the pod is safe from eviction), but i really don't know how to troubleshoot this anymore.
thanks a lot!!
edit:
same behavior with on-demand and spot instances.
edit 2:
i added the aws node termination handler, it seems that now i'm seeing other events:
ip-10-4-126-234.us-west-2.compute.internal.16d223107de38c5f
nodenotschedulable
node ip-10-4-126-234.us-west-2.compute.internal status is now: nodenotschedulable

test-job-p85f2-txflr.16d2230ea91217a9
failedscheduling
0/2 nodes are available: 1 node(s) didn't match pod's node affinity/selector, 1 node(s) were unschedulable.

if i check the scaling group activity:
instance i-03d27a1cf341405e1 was taken out of service in response to a user request, shrinking the capacity from 1 to 0.

",<amazon-web-services><kubernetes><amazon-eks><keda>,71134766,2,"well, this was an annoying, small, and tricky thing.
there was another eks cluster in the account, but in that cluster, cluster-autoscaler was started like this:
command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled

this cluster-autoscaler was discovering all the nodes of the other clusters that had that tag, and, killing them, after the timeout: 15 minutes.
so the lesson here is, each cluster-autoscaler must be started like this:
command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled, k8s.io/cluster-autoscaler/clustername

and all the scaling groups need to be tagged accordingly.
"
50951515,persistent volume error when installing prometheus using helm,"i'm trying to install prometheus to my eks cluster, using the default prometheus helm chart located at https://github.com/kubernetes/charts/tree/master/stable/prometheus. it deploys successfully, but in the kubernetes dashboard the alertmanager and server deployments say:


  pod has unbound persistentvolumeclaims (repeated 3 times)


i've tried tinkering with the values.yaml file to no avail.

i know this isn't much to go on, but i'm not really sure what else i can look up when it comes to logging.

here's the output from running helm install stable/prometheus --name prometheus --namespace prometheus

root@fd9c3cc3f356:~/charts# helm install stable/prometheus --name prometheus --namespace prometheus
name:   prometheus
last deployed: wed jun 20 14:55:41 2018
namespace: prometheus
status: deployed

resources:
==&gt; v1beta1/clusterrole
name                           age
prometheus-kube-state-metrics  1s
prometheus-server              1s

==&gt; v1/serviceaccount
name                           secrets  age
prometheus-alertmanager        1        1s
prometheus-kube-state-metrics  1        1s
prometheus-node-exporter       1        1s
prometheus-pushgateway         1        1s
prometheus-server              1        1s

==&gt; v1/persistentvolumeclaim
name                     status   volume  capacity  access modes  storageclass  age
prometheus-alertmanager  pending  1s
prometheus-server        pending  1s

==&gt; v1beta1/clusterrolebinding
name                           age
prometheus-kube-state-metrics  1s
prometheus-server              1s

==&gt; v1/service
name                           type       cluster-ip      external-ip  port(s)   age
prometheus-alertmanager        clusterip  10.100.3.32     &lt;none&gt;       80/tcp    1s
prometheus-kube-state-metrics  clusterip  none            &lt;none&gt;       80/tcp    1s
prometheus-node-exporter       clusterip  none            &lt;none&gt;       9100/tcp  1s
prometheus-pushgateway         clusterip  10.100.243.103  &lt;none&gt;       9091/tcp  1s
prometheus-server              clusterip  10.100.144.15   &lt;none&gt;       80/tcp    1s

==&gt; v1beta1/daemonset
name                      desired  current  ready  up-to-date  available  node selector  age
prometheus-node-exporter  3        3        2      3           2          &lt;none&gt;         1s

==&gt; v1beta1/deployment
name                           desired  current  up-to-date  available  age
prometheus-alertmanager        1        1        1           0          1s
prometheus-kube-state-metrics  1        1        1           0          1s
prometheus-pushgateway         1        1        1           0          1s
prometheus-server              1        1        1           0          1s

==&gt; v1/pod(related)
name                                            ready  status             restarts  age
prometheus-node-exporter-dklx8                  0/1    containercreating  0         1s
prometheus-node-exporter-hphmn                  1/1    running            0         1s
prometheus-node-exporter-zxcnn                  1/1    running            0         1s
prometheus-alertmanager-6df98765f4-l9vq2        0/2    pending            0         1s
prometheus-kube-state-metrics-6584885ccf-8md7c  0/1    containercreating  0         1s
prometheus-pushgateway-5495f55cdf-brxvr         0/1    containercreating  0         1s
prometheus-server-5959898967-fdztb              0/2    pending            0         1s

==&gt; v1/configmap
name                     data  age
prometheus-alertmanager  1     1s
prometheus-server        3     1s


notes:
the prometheus server can be accessed via port 80 on the following dns name from within your cluster:
prometheus-server.prometheus.svc.cluster.local


get the prometheus server url by running these commands in the same shell:
  export pod_name=$(kubectl get pods --namespace prometheus -l ""app=prometheus,component=server"" -o jsonpath=""{.items[0].metadata.name}"")
  kubectl --namespace prometheus port-forward $pod_name 9090


the prometheus alertmanager can be accessed via port 80 on the following dns name from within your cluster:
prometheus-alertmanager.prometheus.svc.cluster.local


get the alertmanager url by running these commands in the same shell:
  export pod_name=$(kubectl get pods --namespace prometheus -l ""app=prometheus,component=alertmanager"" -o jsonpath=""{.items[0].metadata.name}"")
  kubectl --namespace prometheus port-forward $pod_name 9093


the prometheus pushgateway can be accessed via port 9091 on the following dns name from within your cluster:
prometheus-pushgateway.prometheus.svc.cluster.local


get the pushgateway url by running these commands in the same shell:
  export pod_name=$(kubectl get pods --namespace prometheus -l ""app=prometheus,component=pushgateway"" -o jsonpath=""{.items[0].metadata.name}"")
  kubectl --namespace prometheus port-forward $pod_name 9091

for more information on running prometheus, visit:
https://prometheus.io/

",<kubernetes><prometheus><kubernetes-helm><amazon-eks>,50952265,5,"turns out, eks clusters are not created with any persistent storage enabled:


  amazon eks clusters are not created with any storage classes. you must
  define storage classes for your cluster to use and you should define a
  default storage class for your persistent volume claims.


this guide explains how to add a kubernetes storageclass for eks

after adding the storageclass as instructed, deleting my prometheus deployment using helm delete prometheus --purge and re-creating the deployment, all of my pods are now fully functional.
"
63741908,specify alternate url for redirect and internal lookups for keycloak in kubernetes,"so i have a spring boot application, which is deployed as a pod in kubernetes. i also have a keycloak server running in kubernetes  (same namespace). i am facing an issue with logging into my application through a browser on my local machine.
so i am specifying the auth-server-url=http://keycloak-service-name:8080/auth, so that my pod can access it, and it can. the problem arrises when i try to log in to my application, as it redirects to http://keycloak-service-name:8080/auth and this cannot be resolved locally as it is the kubernetes service.
i also have ingress set up, so i tried specify the auth url as the ingress http://keycloak-ingress/auth, but then my pod cannot access this and gets an error &quot;failed to load urls from ...&quot; as it cannot resolve the ingress domain. however, i can access the ingress from my browser.
i feel like i am missing something really obvious here, i need some kind of url that is accessible to both the pod within the cluster, as well as outside the cluster. or maybe there is someway to specify a seperate url for the lookup my application is doing to &quot;load the url's&quot;?
the only way i have managed to get this to work is by exposing the service externally and using the external ip and port, but this is not an acceptable solution.
",<kubernetes><spring-security><keycloak><kubernetes-ingress>,63747299,4,"i found out that there is a frontend url parameter in the keycloak server. i set this to point to my ingress, and set the auth-server-url to point to my keycloak service name. this solved my problem, in that when my application does a lookup internally it uses the service, but when i access the frontend it uses the ingress.
"
65816605,error unknow flag --control-plane-endpoint,"i'm trying to create a bare metal multimaster kubernetes cluster. the version of kubernetes i'm working with is 1.15.12. the issue i'm running into is with the command:
kubeadm init --control-plane-endpoint &quot;load_balancer_dns:load_balancer_port&quot; --upload-certs --pod-network-cidr=192.168.0.0/16

the error is that --control-plane-endpoint is unknown.
i believe in version 1.15.12 this kubeadm flag doesn't exist. am i using the correct flag or is there a substitute that i can use for the version that i'm using (v1.15.12)?
",<kubernetes><haproxy><kubernetes-pod><bare-metal-server>,65824910,1,"you are right, that flag was implemented in kubernetes v1.16:

kubeadm: provide --control-plane-endpoint flag for
controlplaneendpoint (#79270)

the version you are trying to use is pretty old and so it is highly recommend for you to either:

upgrade your cluster

create a new cluster from scratch using a more recent version of kubernetes (preferably v1.20). the kubeadm init docs can help you with it, especially the --kubernetes-version flag: choose a specific kubernetes version for the control plane.


remember that things get deprecated for a reason and keeping your cluster up to date can save you a lot of trouble in the future.
"
51843992,embeding conf files into helm chart,"im new at helm. im building a splunk helm chart with numerous conf files. i currently  use something like this in a configmap ..
apiversion: v1
kind: configmap
metadata:
  name: splunk-master-configmap
data:
  indexes.conf: |
    # global settings
    # inheritable by all indexes: no hot/warm bucket can exceed 1 tb.
    # individual indexes can override this setting.
    homepath.maxdatasizemb = 1000000

but i would prefer to have the conf files in a seperate folder e.g. configs/helloworld.conf and have come accross &quot;tpl&quot; but am struggling to understand how to implement it. - can anyone advise best practices. on a side note splunk has orders of presidences &gt;&gt; so there may be many indexes.conf files used in various locations. does anyone have any thoughts on how best to implement this?!??!
cheers.
",<kubernetes><kubernetes-helm><splunk><configmap>,51847086,17,"if the content of the files is static then you could create a files directory in your chart at the same level as the templates directory (not inside it) and reference them like:

kind: configmap
metadata:
  name: splunk-master-configmap
data:
  {{ (.files.glob ""files/indexes.conf"").asconfig | indent 2 }}
  {{ (.files.glob ""files/otherfile.conf"").asconfig | indent 2 }}
# ... and so on


where this would break down is if you want to be able to reference the values of variables inside the files so that the content is controlled from the values.yaml. if you want to expose each value individually then there's an example in the helm documentation using range. but i think a good fit or your case is what the stable/mysql chart does. it has a configmap that takes values as strings:

{{- if .values.configurationfiles }}
apiversion: v1
kind: configmap
metadata:
  name: {{ template ""mysql.fullname"" . }}-configuration
data:
{{- range $key, $val := .values.configurationfiles }}
  {{ $key }}: |-
{{ $val | indent 4}}
{{- end }}
{{- end -}}


and the values.yaml allows both the files and their content to be set and overridden by the user of the chart:

# custom mysql configuration files used to override default mysql settings
configurationfiles:
#  mysql.cnf: |-
#    [mysqld]
#    skip-name-resolve
#    ssl-ca=/ssl/ca.pem
#    ssl-cert=/ssl/server-cert.pem
#    ssl-key=/ssl/server-key.pem


it comments out that content and leaves it to the user of the chart to set but you could have defaults in the values.yaml.

you would only need tpl if you needed further flexibility. the stable/keycloak chart lets the user of the chart create their own configmap and point it into the keycloak deployment via tpl. but i think your case is probably closest to the mysql one. 

edit: the tpl function can also be used to take the content of files loaded with files.get and effectively make that content part of the template - see how do i load multiple templated config files into a helm chart? if you're interested in this
"
71537661,kubernetes apply nodeselector via command,"is there a way to apply a nodeselector via command? (like kubectl apply)
it would be nice if it is applicable on running deployments or namespaces, otherwise applying to running pods is also fine.
any tips are appreciated
",<kubernetes><kubectl><nodeselector>,71555102,2,"you can use the kubectl patch command, like this:
kubectl patch deployments nginx-deployment -p '{&quot;spec&quot;: {&quot;template&quot;: {&quot;spec&quot;: {&quot;nodeselector&quot;: {&quot;kubernetes.io/hostname&quot;: &quot;node-2&quot;}}}}}'
after successful patch all pods of the deployment will be restarted on a node matching the selector.
"
52876194,delete kubernetes cluster on docker-for-desktop osx?,"what is the equivalent command for minikube delete in docker-for-desktop on osx

as i understand, minikube creates a vm to host its kubernetes cluster but i do not understand how docker-for-desktop is managing this on osx.
",<docker><kubernetes><kubectl><minikube>,52877425,44,"tear down kubernetes in docker for os x is quite an easy task.

go to preferences, open reset tab, and click reset kubernetes cluster.



all object that have been created with kubectl before that will be deleted. 

you can also reset docker vm image (reset disk image) and all settings (reset to factory defaults) or even uninstall docker. 
"
61144233,issue in setting up kubectl on windows 10 home,"i am trying to learn kubernetes and so i installed minikube on my local windows 10 home machine and then i tried installing the kubectl. however so far i have been unsuccessful in getting it right.
so this what i have done so far:
downloaded the kubectl.exe file from https://storage.googleapis.com/kubernetes-release/release/v1.18.0/bin/windows/amd64/kubectl.exe

then i added the path of this exe in the path environment variable as shown below:


however this didn't work when i executed kubectl version on the command prompt or even on pwoershell (in admin mode)

next i tried using the curl command as given in the docs - https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-with-curl-on-windows

however that too didn't work as shown below:


upon searching for answers to fix the issue, i stumbled upon this stackoverfow question which explained how to create a .kube config folder because it didn't exist on my local machine. i followed the instructions, but that too failed.




so right now i am completely out of ideas and not sure whats the issue here. fyi, i was able to install everything in a breeze on my mac, however windows is just acting crazy.

any help would be really helpful.
",<kubernetes><kubectl><minikube>,61186185,2,"as user @paltaa mentioned:

did you do a  minikube start  ? – paltaa  2 days ago

the fact that you did not start the minikube is the most probable cause why you are getting this error.

additionally this error message shows when the minikube is stopped as stopping will change the current-context inside the config file.

there is no need to create a config file inside of a .kube directory  as the minikube start will create appropriate files and directories for you automatically.
if you run minikube start command successfully you should get below message at the end of configuration process which will indicate that the kubectl is set for minikube automatically.

done! kubectl is not configured to use &quot;minikube&quot;

additionally if you invoke command $ kubectl config you will get more information how kubectl is looking for configuration files:
 the loading order follows these rules:

  1.  if the --kubeconfig flag is set, then only that file is loaded. the flag may only be set once and no merging takes
place.
  2.  if $kubeconfig environment variable is set, then it is used as a list of paths (normal path delimiting rules for
your system). these paths are merged. when a value is modified, it is modified in the file that defines the stanza. when
a value is created, it is created in the first file that exists. if no files in the chain exist, then it creates the
last file in the list.
  3.  otherwise, ${home}/.kube/config is used and no merging takes place.

please take a special look on part:


otherwise, ${home}/.kube/config is used


even if you do not set the kubeconfig environment variable kubectl will default to $user_directory (for example c:\users\yoda\.
if for some reason your cluster is running and files got deleted/corrupted you can:

minikube stop
minikube start

which will recreate a .kube/config

steps for running minikube on windows in this case could be:

download and install kubernetes.io: install minikube using an installer executable
download, install and configure a hypervisor (for example virtualbox)
download kubectl

optional: add the kubectl directory to windows environment variables


run from command line or powershell from current user: $ minikube start --vm-driver=virtualbox
wait for configuration to finish and invoke command like $ kubectl get nodes.

"
62895892,node role is missing for master node - kubernetes installation done with the help of kubespray,"after clean installation of kubernetes cluster with 3 nodes (2 master &amp; 3 node)
i.e., masters are also assigned to be worker node.
after successful installation, i got the below roles for the node. where node role is missing for the masters as shown.
$ kubectl get nodes
name    status   roles    age   version
node1   ready    master   12d   v1.18.5
node2   ready    master   12d   v1.18.5
node3   ready    &lt;none&gt;   12d   v1.18.5

inventory/mycluster/hosts.yaml
all:
  hosts:
    node1:
      ansible_host: 10.1.10.110
      ip: 10.1.10.110
      access_ip: 10.1.10.110
    node2:
      ansible_host: 10.1.10.111
      ip: 10.1.10.111
      access_ip: 10.1.10.111
    node3:
      ansible_host: 10.1.10.112
      ip: 10.1.10.112
      access_ip: 10.1.10.112
  children:
    kube-master:
      hosts:
        node1:
        node2:
    kube-node:
      hosts:
        node1:
        node2:
        node3:
    etcd:
      hosts:
        node1:
        node2:
        node3:
    k8s-cluster:
      children:
        kube-master:
        kube-node:
    calico-rr:
      hosts: {}
    vault:
      hosts:
        node1
        node2
        node3

network plugin : flannel
command used to invoke ansible:
ansible-playbook -i inventory/mycluster/hosts.yaml --become cluster.yml

how can i make master node to be work as worker node as well?
kubectl describe node1 output:
kubectl describe node node1
name:               node1
roles:              master
labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=node1
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/master=
annotations:        flannel.alpha.coreos.com/backend-data: {&quot;vtepmac&quot;:&quot;a6:bb:9e:2a:7e:a8&quot;}
                    flannel.alpha.coreos.com/backend-type: vxlan
                    flannel.alpha.coreos.com/kube-subnet-manager: true
                    flannel.alpha.coreos.com/public-ip: 10.1.10.110
                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
creationtimestamp:  wed, 01 jul 2020 09:26:15 -0700
taints:             &lt;none&gt;
unschedulable:      false
lease:
  holderidentity:  node1
  acquiretime:     &lt;unset&gt;
  renewtime:       tue, 14 jul 2020 06:39:58 -0700
conditions:
  type                 status  lastheartbeattime                 lasttransitiontime                reason                       message
  ----                 ------  -----------------                 ------------------                ------                       -------
  networkunavailable   false   fri, 10 jul 2020 12:51:05 -0700   fri, 10 jul 2020 12:51:05 -0700   flannelisup                  flannel is running on this node
  memorypressure       false   tue, 14 jul 2020 06:40:02 -0700   fri, 03 jul 2020 15:00:26 -0700   kubelethassufficientmemory   kubelet has sufficient memory available
  diskpressure         false   tue, 14 jul 2020 06:40:02 -0700   fri, 03 jul 2020 15:00:26 -0700   kubelethasnodiskpressure     kubelet has no disk pressure
  pidpressure          false   tue, 14 jul 2020 06:40:02 -0700   fri, 03 jul 2020 15:00:26 -0700   kubelethassufficientpid      kubelet has sufficient pid available
  ready                true    tue, 14 jul 2020 06:40:02 -0700   mon, 06 jul 2020 10:45:01 -0700   kubeletready                 kubelet is posting ready status
addresses:
  internalip:  10.1.10.110
  hostname:    node1
capacity:
  cpu:                8
  ephemeral-storage:  51175mi
  hugepages-1gi:      0
  hugepages-2mi:      0
  memory:             32599596ki
  pods:               110
allocatable:
  cpu:                7800m
  ephemeral-storage:  48294789041
  hugepages-1gi:      0
  hugepages-2mi:      0
  memory:             31997196ki
  pods:               110
system info:
  machine id:                 c8690497b9704d2d975c33155c9fa69e
  system uuid:                00000000-0000-0000-0000-ac1f6b96768a
  boot id:                    5e3eabe0-7732-4e6d-b25d-7eeec347d6c6
  kernel version:             3.10.0-1127.13.1.el7.x86_64
  os image:                   centos linux 7 (core)
  operating system:           linux
  architecture:               amd64
  container runtime version:  docker://19.3.12
  kubelet version:            v1.18.5
  kube-proxy version:         v1.18.5
podcidr:                      10.233.64.0/24
podcidrs:                     10.233.64.0/24
non-terminated pods:          (9 in total)
  namespace                   name                                           cpu requests  cpu limits  memory requests  memory limits  age
  ---------                   ----                                           ------------  ----------  ---------------  -------------  ---
  default                     httpd-deployment-598596ddfc-n56jq              0 (0%)        0 (0%)      0 (0%)           0 (0%)         7d20h
  kube-system                 coredns-dff8fc7d-lb6bh                         100m (1%)     0 (0%)      70mi (0%)        170mi (0%)     3d17h
  kube-system                 kube-apiserver-node1                           250m (3%)     0 (0%)      0 (0%)           0 (0%)         12d
  kube-system                 kube-controller-manager-node1                  200m (2%)     0 (0%)      0 (0%)           0 (0%)         12d
  kube-system                 kube-flannel-px8cj                             150m (1%)     300m (3%)   64m (0%)         500m (1%)      3d17h
  kube-system                 kube-proxy-6spl2                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         3d17h
  kube-system                 kube-scheduler-node1                           100m (1%)     0 (0%)      0 (0%)           0 (0%)         12d
  kube-system                 kubernetes-metrics-scraper-54fbb4d595-28vvc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         7d20h
  kube-system                 nodelocaldns-rxs4f                             100m (1%)     0 (0%)      70mi (0%)        170mi (0%)     12d
allocated resources:
  (total limits may be over 100 percent, i.e., overcommitted.)
  resource           requests       limits
  --------           --------       ------
  cpu                900m (11%)     300m (3%)
  memory             205860ki (0%)  856515840 (2%)
  ephemeral-storage  0 (0%)         0 (0%)
  hugepages-1gi      0 (0%)         0 (0%)
  hugepages-2mi      0 (0%)         0 (0%)
events:              &lt;none&gt;

",<kubernetes><ansible><kubectl><flannel><kubespray>,62896031,1,"
how can i make master node to be work as worker node as well ?

remove the noschedule taint from master nodes using below command
kubectl taint node node1 node-role.kubernetes.io/master:noschedule-
kubectl taint node node2 node-role.kubernetes.io/master:noschedule-

after this node1 and node2 will become like worker nodes and pods can be scheduled on them.
"
65960715,"kubernetes kafka to zookeeper - ""zookeeperclienttimeoutexception"" error","for context, i am bringing up kafka and zookeeper locally on an ubuntu machine using kubernetes, through helm:
  - name: kafka
    version: 12.7.3
    repository: https://charts.bitnami.com/bitnami

i've looked at existing questions for this error, but none seem to be related to my issue exactly. for these existing questions, i see that the issue seems to involve docker networks, or communication. however, on my local setup, i can see that kafka can communicate to zookeeper successfully and initiate a tcp connection. i saw the following tshark logs, where .83 is kafka and .80 is zookeeper:
 57 118.532604170 192.168.83.83 → 192.168.83.80 tcp 74 44978 → 2181 [syn] seq=0 win=64800 len=0 mss=1440 sack_perm=1 tsval=3500466016 tsecr=0 ws=128
   58 118.532617080 192.168.83.80 → 192.168.83.83 tcp 74 2181 → 44978 [syn, ack] seq=0 ack=1 win=64260 len=0 mss=1440 sack_perm=1 tsval=1996498322 tsecr=3500466016 ws=128
   59 118.532633329 192.168.83.83 → 192.168.83.80 tcp 66 44978 → 2181 [ack] seq=1 ack=1 win=64896 len=0 tsval=3500466016 tsecr=1996498322
   60 118.535617526 192.168.83.83 → 192.168.83.80 tcp 115 44978 → 2181 [psh, ack] seq=1 ack=1 win=64896 len=49 tsval=3500466019 tsecr=1996498322
   61 118.535644624 192.168.83.80 → 192.168.83.83 tcp 66 2181 → 44978 [ack] seq=1 ack=50 win=64256 len=0 tsval=1996498325 tsecr=3500466019
   62 118.537006985 192.168.83.80 → 192.168.83.83 tcp 107 2181 → 44978 [psh, ack] seq=1 ack=50 win=64256 len=41 tsval=1996498326 tsecr=3500466019
   63 118.537047974 192.168.83.83 → 192.168.83.80 tcp 66 44978 → 2181 [ack] seq=50 ack=42 win=64896 len=0 tsval=3500466020 tsecr=1996498326
   64 118.540259005 192.168.83.83 → 192.168.83.80 tcp 78 44978 → 2181 [psh, ack] seq=50 ack=42 win=64896 len=12 tsval=3500466024 tsecr=1996498326
   65 118.540263332 192.168.83.80 → 192.168.83.83 tcp 66 2181 → 44978 [ack] seq=42 ack=62 win=64256 len=0 tsval=1996498330 tsecr=3500466024
   66 118.541564514 192.168.83.80 → 192.168.83.83 smpp 86 bind_receiver[malformed packet]
   67 118.541607278 192.168.83.83 → 192.168.83.80 tcp 66 44978 → 2181 [ack] seq=62 ack=62 win=64896 len=0 tsval=3500466025 tsecr=1996498331
   68 118.541999795 192.168.83.80 → 192.168.83.83 tcp 66 2181 → 44978 [fin, ack] seq=62 ack=62 win=64256 len=0 tsval=1996498331 tsecr=3500466025
   69 118.542214437 192.168.83.83 → 192.168.83.80 tcp 66 44978 → 2181 [fin, ack] seq=62 ack=63 win=64896 len=0 tsval=3500466026 tsecr=1996498331

despite this, it seems like i am still seeing the following errors on the kafka logs:
[2021-01-29 19:17:49,922] info session: 0x1000031e07c0011 closed (org.apache.zookeeper.zookeeper)
[2021-01-29 19:17:49,922] info eventthread shut down for session: 0x1000031e07c0011 (org.apache.zookeeper.clientcnxn)
[2021-01-29 19:17:49,925] info [zookeeperclient kafka server] closed. (kafka.zookeeper.zookeeperclient)
[2021-01-29 19:17:49,928] error fatal error during kafkaserver startup. prepare to shutdown (kafka.server.kafkaserver)
kafka.zookeeper.zookeeperclienttimeoutexception: timed out waiting for connection while in state: connecting
    at kafka.zookeeper.zookeeperclient.$anonfun$waituntilconnected$3(zookeeperclient.scala:262)
    at kafka.zookeeper.zookeeperclient.waituntilconnected(zookeeperclient.scala:258)
    at kafka.zookeeper.zookeeperclient.&lt;init&gt;(zookeeperclient.scala:119)
    at kafka.zk.kafkazkclient$.apply(kafkazkclient.scala:1881)
    at kafka.server.kafkaserver.createzkclient$1(kafkaserver.scala:441)
    at kafka.server.kafkaserver.initzkclient(kafkaserver.scala:466)
    at kafka.server.kafkaserver.startup(kafkaserver.scala:233)
    at kafka.server.kafkaserverstartable.startup(kafkaserverstartable.scala:44)
    at kafka.kafka$.main(kafka.scala:82)
    at kafka.kafka.main(kafka.scala)

i've tried a few things:

as mentioned above, i saw that ip/tcp traffic between kafka and zookeeper did seem to be working successfully, so i don't believe it's an underlying routing issue.
this is sort of implied by (1), but i looked at the iptables rules in the nat table, and the rules seem to be correct. the zookeeper service is correctly nat'd to the zookeeper pod ip.
i've manually tried running debugging commands from within the kafka pod to confirm once again if it could make an end to end connection to zookeeper. the following seemed to work: echo mntr | nc 10.96.85.98 2181.
i don't have any firewalls running to my knowledge. it is entirely possible there is something within iptables that is preventing another layer from working, but this is what i hope to get some clarity on.

",<kubernetes><apache-kafka><apache-zookeeper><kubernetes-helm>,65997894,1,"i have this working now. it appears to be because i repeatedly brought the cluster down and up and didn't properly clear the networking state, which probably led to some sort of black-holing somewhere.
it may be overkill, but what i ended up doing was simply flushing the iptables rules and restarting all relevant services like docker which required special iptables rules. now that the cluster is working, i don't envision repeatedly re-creating the cluster.
"
71721331,get docs for resources (like kubectl explain) via python,"i would like to write a small programm similar to kubectl explain.
i use the python client.
with kubectl explain pods -v=8 i see which apis get called.
the url is /openapi/v2
i tried this:
from kubernetes import client, config

# configs can be set in configuration class directly or using helper utility
from kubernetes.client import apiclient

config.load_kube_config()

print(apiclient().call_api('/openapi/v2', method='get'))

but the result is empty:
(none, 200, httpheaderdict({'accept-ranges': 'bytes', 'audit-id': '5f025f01-cab9-4816-8579-751b47604275', 'cache-control': 'no-cache, private', 'content-length': '3315308', 'content-type': 'text/plain; charset=utf-8', 'etag': '&quot;194a5412d92c8239faa388bd61a2729940609093ee00703602a983c97e2d7fd9ffa0e25f481a2659782ec80339f6a25cd9fd414b8d652409e1b521bb4f53e5db&quot;', 'last-modified': 'thu, 31 mar 2022 17:51:05 gmt', 'vary': 'accept-encoding, accept', 'x-kubernetes-pf-flowschema-uid': 'f70aa7db-e8d7-4690-becf-40ac57d88c1f', 'x-kubernetes-pf-prioritylevel-uid': '5c900157-e070-46c3-b774-a77dfa6128bc', 'date': 'sat, 02 apr 2022 21:29:56 gmt'}))

how can i get the nice docs which kubectl explain shows via python?
",<python><kubernetes><kubectl>,71752410,1,"you're already getting the data, it's just that some error occurs while processing it :)
to turn off post-processing, you need to pass the _preload_content=false argument to call_api
then the code will look something like this:
import json
from kubernetes import client, config

# configs can be set in configuration class directly or using helper utility
from kubernetes.client import apiclient

config.load_kube_config()

apiclient = apiclient()
answer = apiclient.call_api('/openapi/v2', method='get', _preload_content=false)
data = json.loads(answer[0].data)
print(data)

if you only want to get the description, you can use curl like this with bearer auth:
https://blog.ronnyvdb.net/2019/08/07/howto-curl-the-kubernetes-api-server
 curl -s $apiserver/openapi/v2 --header &quot;authorization: bearer $token&quot; --cacert ca.crt

or with tsl auth:
 curl -s $apiserver/openapi/v2 --cert client.crt --key client.key --cacert ca.crt

after that, you can use the tools to work with the openapi description: https://openapi.tools
for example, upload json to https://mrin9.github.io/openapi-viewer and enjoy
"
60438285,error: getting availability zones when trying to create eks cluster,"i'm trying to create an eks cluster but i keep getting the following error. i think it's an issue of permissions, roles, etc but i have minimum experience with aws stuff.

i found this thread but i have no idea how to implement all these things.

any help is appreciated, thanks in advance.

$ eksctl create cluster
[ℹ]  eksctl version 0.13.0
[ℹ]  using region us-west-2
error: getting availability zones: getting availability zones for us-west-2: unauthorizedoperation: you are not authorized to perform this operation.
    status code: 403, request id: 724b0c02-fb51-43b2-98ab-746a3d2e45a0

",<amazon-web-services><kubernetes><amazon-eks>,62513754,16,"i am also a newbie to eks. the problem of this matter is you have not permissions to do something. first, we should know what permissions we need, however, as a newbie we don't wanna know so much. so as kushagra saxena said, we set our iam account as admin for learning.
use existing policy

select users


add permissions


select administratoraccess and then next next next!



or use custom policy
if you wanna use custom policy, like this:
{
    &quot;version&quot;: &quot;2012-10-17&quot;,
    &quot;statement&quot;: [
        {
            &quot;effect&quot;: &quot;allow&quot;,
            &quot;action&quot;: &quot;*&quot;,
            &quot;resource&quot;: &quot;*&quot;
        }
    ]
}

you should create your own policy.you can do as following:

select &quot;policies&quot; and &quot;create policy&quot;


replace by your json and next next.



3.select your user and add permissions as &quot;use existing policy&quot; do。
"
61035265,k8s and helm: how can i find the persistentvolumeclaim requirements when binding fails?,"i am trying to install gitlab from their official helm chart gitlab/gitlab. one of the sub-charts is the bitnami/postgresql chart. i have access to the source code of both charts.

$ helm install gitlab gitlab/gitlab \
  --set global.hosts.domain=mando \
  --set global.hosts.externalip=192.168.1.2 \
  --set certmanager-issuer.email=my-email@gmail.com 
  --set global.edition=ce


when i try to install the gitlab chart, several containers are created, and the postgresql one fails to start due to an unbound pvc. i have tried creating several different pvs that might accommodate its requirement but none of them seem to work.

events:
  type     reason            age                from               message
  ----     ------            ----               ----               -------
  warning  failedscheduling  23s (x14 over 8m)  default-scheduler  error while running ""volumebinding"" filter plugin for pod ""gitlab-postgresql-0"": pod has unbound immediate persistentvolumeclaims


i can describe the pvc and get some information about it, but it's not clear from the output what is missing from my pvs or what i can do do make the claim successful.

[mando infra]$ kubectl describe pvc data-gitlab-postgresql-0
name:          data-gitlab-postgresql-0
namespace:     default
storageclass:  
status:        pending
volume:        
labels:        app=postgresql
               release=gitlab
               role=master
annotations:   &lt;none&gt;
finalizers:    [kubernetes.io/pvc-protection]
capacity:      
access modes:  
volumemode:    filesystem
mounted by:    gitlab-postgresql-0
events:
  type    reason         age                     from                         message
  ----    ------         ----                    ----                         -------
  normal  failedbinding  4m48s (x6324 over 26h)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set


so how can i find the persistentvolumeclaim requirements when pv binding fails?
",<kubernetes><kubernetes-helm>,61098729,3,"as described in the gitlab documentation you have to manage storage on your own. you have to create storageclass, pv and pvcs by yourself.

it is recommended to use dynamic storage provisioning. 
example storageclass object for gcp:

apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
 name: custom_storage_class_name
provisioner: kubernetes.io/gce-pd
reclaimpolicy: retain
parameters:
 type: pd-standard


after creating storageclass  you have to upgrade your chart by modifying following file with created storageclass: 

gitlab:
 gitaly:
 persistence:
 storageclass: custom_storage_class_name
 size: 50gi
postgresql:
 persistence:
 storageclass: custom_storage_class_name
 size: 8gi
minio:
 persistence:
 storageclass: custom_storage_class_name
 size: 10gi
redis:
 master:
 persistence:
 storageclass: custom_storage_class_name
 size: 5gi


and the upgrade your chart

helm install -upgrade gitlab gitlab/gitlab -f helm_options_yaml_file

"
61970513,cant run mysql statefulset in kubernetes,"i've just started learning kubernetes and was playing around in katakoda platform. i created a statefulset for mysql. it is just a test so i didnt declare any pvc and mount any volumes. it's declaration and the service's declaration in yml:


---

apiversion: v1
kind: service
metadata:
  name: mysql-headless
  labels:
    run: mysql-sts-demo
spec:
  ports:
  - port: 3306
    name: db
  selector:
    run: mysql-sts-demo

---
apiversion: apps/v1
kind: statefulset
metadata:
  name: mysql-sts-demo
spec:
  servicename: ""mysql-headless""
  replicas: 1
  selector:
    matchlabels:
      run: mysql-sts-demo
  template:
    metadata:
      labels:
        run: mysql-sts-demo
    spec:
      containers:
      - name: mysql
        image: mysql:5.7.8
        env:
          - name: mysql_root_password
            valuefrom:
              secretkeyref:
                name: mysql-secrets
                key: root_password
          - name: mysql_database
            valuefrom:
              secretkeyref:
                name: mysql-secrets
                key: dbname
          - name: mysql_user
            valuefrom:
              secretkeyref:
                name: mysql-secret
                key: user
          - name: mysql_password
            valuefrom:
              secretkeyref:
                name: mysql-secrets
                key: password




it creates those resources successfully , but when i type kubectl get statefulsets , my ss is always being displayed as not ready. what may the issue be? btw i need it for using with a spring petclinic app which i declared and launched previously as a deployment .
",<mysql><kubernetes><kubernetes-statefulset>,61971964,1,"can you paste the logs for statefulsets 
or an output of kubectl get events and kubectl describe &lt;your stateful-set name&gt;

now coming to secrets can you check whether those secrets which you are using in your stateful-sets definitions are already present using kubectl get secrets 
"
59016525,how to force delete deployment in k8s using helm?,"i have k8s cluster with pods, deployments etc.
i am using helm to deploy my app. i want to delete all deployment and using below command
helm delete mynamespace --purge

if i will look at status of my pods, i will see that there are in terminating state, problem is that it takes time. is there any way to remove it like instantly with some force flag or something?
",<kubernetes><deployment><kubernetes-helm>,59020848,15,"you can try the following command:

helm delete mynamespace --purge --no-hooks


also, you can use kubectl to forcefully delete the pods, instead of waiting for termination.

here's what i got from this link.
https://kubernetes.io/docs/tasks/run-application/force-delete-stateful-set-pod/

if you want to delete a pod forcibly using kubectl version >= 1.5, do the following:

kubectl delete pods &lt;pod&gt; --grace-period=0 --force


if you’re using any version of kubectl &lt;= 1.4, you should omit the --force option and use:

kubectl delete pods &lt;pod&gt; --grace-period=0


if even after these commands the pod is stuck on unknown state, use the following command to remove the pod from the cluster:

kubectl patch pod &lt;pod&gt; -p '{""metadata"":{""finalizers"":null}}'


always perform force deletion of statefulset pods carefully and with complete knowledge of the risks involved.
"
60710171,minikube ip is not reachable,"i have created one service called fleetman-webapp:

apiversion: v1
kind: service
metadata:
 name: fleetman-webapp

spec:
 selector:
  app: webapp

 ports:
  - name: http
    port: 80
    nodeport: 30080

 type: nodeport


also, a pod named webapp:

apiversion: v1
kind: pod
metadata:
 name: webapp
 labels:
  app: webapp
spec:
 containers:
 - name: webapp
   image: richardchesterwood/k8s-fleetman-webapp-angular:release0


i have checked the minikube ip:

192.168.99.102

but when i type in the browser 192.168.99.102:30080, the webapp is not reachable:

please note that i use ubuntu latest version. i have verified furthermore if proxies and firewalls are active:

cat /etc/environment:

path=""/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games""


iptables -l:

chain input (policy accept)
target     prot opt source               destination         

chain forward (policy drop)
target     prot opt source               destination         
docker-user  all  --  anywhere             anywhere            
docker-isolation-stage-1  all  --  anywhere             anywhere            
accept     all  --  anywhere             anywhere             ctstate related,established
docker     all  --  anywhere             anywhere            
accept     all  --  anywhere             anywhere            
accept     all  --  anywhere             anywhere            

chain output (policy accept)
target     prot opt source               destination         

chain docker (1 references)
target     prot opt source               destination         

chain docker-isolation-stage-1 (1 references)
target     prot opt source               destination         
docker-isolation-stage-2  all  --  anywhere             anywhere            
return     all  --  anywhere             anywhere            

chain docker-isolation-stage-2 (1 references)
target     prot opt source               destination         
drop       all  --  anywhere             anywhere            
return     all  --  anywhere             anywhere            

chain docker-user (1 references)
target     prot opt source               destination         
return     all  --  anywhere             anywhere 


i have also disabled ufw in ubuntu, but no success, the url 192.168.99.102:30080 .

would you help me please ? thanks in advance for your answer. 
",<kubernetes><kubectl><minikube>,60726849,7,"there are a lot of different hypervisors which can work with minikube. choosing one will be highly dependent on variables like operating system. some of them are: 


virtualbox 
hyper-v 
vmware fusion 
kvm2 
hyperkit
""docker (--vm-driver=none)"" (see the quotes) 


there is official documentation talking about it: kubernetes.io: minikube: specifying the vm driver

choosing hypervisor will affect how the minikube will behave.

focusing on: 


docker: --vm-driver=none
virtualbox: --vm-driver=virtualbox


docker

official documentation sums it up: 


  minikube also supports a --vm-driver=none option that runs the kubernetes components on the host and not in a vm. using this driver requires docker and a linux environment but not a hypervisor.
  
  --  kubernetes.io: install minikube: install a hypervisor  


the output of command$ sudo minikube ip will show ip address of a host machine. 

service object type of nodeport will be available with ip_address_of_host:nodeport_port. 

following with command: $ kubectl get nodes -o wide: 

name status roles  age version internal-ip external-ip os-image kernel-version container-runtime
k8s  ready  master 95s v1.17.3 192.168.0.114 &lt;none&gt;  ubuntu 18.04.4 lts 5.3.0-28-generic docker://19.3.8


please take a specific look on:

internal-ip
192.168.0.114


it's the same ip address as a host it's working on. you can (for example) curl pods without any restrictions. please consider reading the article in included citing: 


  caution: the none vm driver can result in security and data loss issues. before using --vm-driver=none, consult this documentation for more information.


you can check what was exposed with command:
$ sudo netstat -tulpn

virtualbox

creating a minikube instance with --vm-driver=virtualbox will create a virtual machine with virtualbox as host. 

virtual machine created with this kind of --vm-driver will have 2 network interfaces provided below: 


nat 
host-only adapter


what is important is that your minikube instance will be accessible by host-only adapter. 


  host-only networking. this can be used to create a network containing the host and a set of virtual machines, without the need for the host's physical network interface. instead, a virtual network interface, similar to a loopback interface, is created on the host, providing connectivity among virtual machines and the host.
  
  --  virtualbox.org: virtual networking  


for example: 


minikube host-only adapter will have an address: 192.168.99.103
your host-only adapter will have an address:  192.168.99.1


they must be different! 

if you are having issues with connecting to this adapter please check:


if minikube's host-only adapter address is responding to ping when minikube start completed successfully.   
your host-only adapter is present in your network configuration by issuing either: 


ip a
ifconfig

your host-only adapter address is in range of your minikube instance (subnet)


from my experience reboot/recreation of this adapter worked all the time if something wasn't right.  

the output of command$ sudo minikube ip will show ip address of a host-only adapter. 

following with command: $ kubectl get nodes -o wide: 

name   status   roles    age   version   internal-ip      external-ip   os-image              kernel-version   container-runtime
m01    ready    master   29m   v1.17.3   192.168.99.103   &lt;none&gt;        buildroot 2019.02.9   4.19.94          docker://19.3.6


please take a specific look once more on internal-ip and ip address associated with it. 

service object type of nodeport will be available with:
ip_address_of_host_only_adapter:nodeport_port. 

i recreated your deployment and service attached to it and it worked in both --vm-driver=none and --vm-driver=virtualbox cases. 

please let me know if you have any questions in this topic. 
"
59047536,kubernetes ingress websockets (socket.io),"i keep getting bad requests (400) when trying to open a websocket, and i'm trying to figure out why. the back-end is built on flask with flask-socketio. here is my docker container for the back-end:

from alpine:edge

run apk update
run apk add python3 py3-cffi py3-bcrypt libc-dev py3-psycopg2 py3-gevent
run pip3 install --upgrade pip
run pip3 install flask flask-restful flask-jwt-extended gunicorn requests flask-sqlalchemy flask-socketio

add ./rest-api /root/rest-api
add ./ui/dist/ui /root/ui

cmd [""gunicorn"", ""-k"", ""gevent"", ""-w"", ""1"", ""--bind"", ""0.0.0.0:3001"", ""--access-logfile"", ""-"", ""--chdir"", ""/root/rest-api/"", ""app:app""]


here are my yaml files:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    kubernetes.io/ingress.global-static-ip-name: my-global-ip
    networking.gke.io/managed-certificates: my-certificate
    nginx.ingress.kubernetes.io/add-base-url: ""true""
    nginx.ingress.kubernetes.io/ssl-redirect: ""true""
    nginx.ingress.kubernetes.io/websocket-services: ""my-service-web""
    nginx.ingress.kubernetes.io/proxy-send-timeout: ""1800""
    nginx.ingress.kubernetes.io/proxy-read-timeout: ""1800""
spec:
  rules:
  - http:
      paths:
      - path: /grafana/*
        backend:
          servicename: my-service-web
          serviceport: grafana-port
      - path: /*
        backend:
          servicename: my-service-web
          serviceport: web-app-port


apiversion: v1
kind: service
metadata:
  name: my-service-web

spec:
  ports:
    - port: 3000
      name: grafana-port
      targetport: grafana-port
      protocol: tcp
    - port: 3001
      name: web-app-port
      targetport: web-app-port
      protocol: tcp
  selector:
    app: my-cloud
  type: nodeport


i can see from the logs that the requests reach the back-end container:

10.166.0.42 - - [26/nov/2019:08:52:22 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.4.2.1 - - [26/nov/2019:08:52:23 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.4.2.1 - - [26/nov/2019:08:52:25 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.4.2.1 - - [26/nov/2019:08:52:28 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.4.2.1 - - [26/nov/2019:08:52:34 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.166.0.41 - - [26/nov/2019:08:52:39 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.166.0.41 - - [26/nov/2019:08:52:44 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.166.0.42 - - [26/nov/2019:08:52:49 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""
10.4.2.1 - - [26/nov/2019:08:52:54 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0""


what i can't figure out is how to configure kubernetes ingress to follow flask-socketio configuration for nginx:

    location /socket.io {
        include proxy_params;
        proxy_http_version 1.1;
        proxy_buffering off;
        proxy_set_header upgrade $http_upgrade;
        proxy_set_header connection ""upgrade"";
        proxy_pass http://127.0.0.1:5000/socket.io;
    }


how do i do the connection upgrade to websocket in kubernetes ingress?

update:
i instantiated socketio with logs enabled and got the following:

6f3a03945f174b039b033e887079b97d: sending packet open data {'sid': '6f3a03945f174b039b033e887079b97d', 'upgrades': [], 'pingtimeout': 60000, 'pinginterval': 25000}
6f3a03945f174b039b033e887079b97d: sending packet message data 0
6f3a03945f174b039b033e887079b97d: received request to upgrade to websocket
10.166.0.43 - - [26/nov/2019:10:19:45 +0000] ""get /socket.io/?eio=3&amp;transport=websocket http/1.1"" 400 11 ""-"" ""mozilla/5.0 (x11; ubuntu; linux x86_64; rv:70.0) gecko/20100101 firefox/70.0

",<flask><kubernetes><kubernetes-ingress><flask-socketio>,59248422,2,"i almost had it right from the beginning. i changed the cmd in my dockerfile to (as per flask-socketio docs):

gunicorn -k geventwebsocket.gunicorn.workers.geventwebsocketworker -w 1 module:app

here's the complete dockerfile:

from alpine:edge

run echo ""http://dl-cdn.alpinelinux.org/alpine/edge/testing"" &gt;&gt; /etc/apk/repositories
run apk update &amp;&amp; apk upgrade
run apk add python3 py3-cffi py3-bcrypt libc-dev py3-psycopg2 py3-gevent-websocket
run pip3 install --upgrade pip
run pip3 install flask flask-restful flask-jwt-extended gunicorn requests flask-sqlalchemy flask-socketio

add ./rest-api /root/rest-api
add ./ui/dist/ui /root/ui

cmd [""gunicorn"", ""-k"", ""geventwebsocket.gunicorn.workers.geventwebsocketworker"", ""-w"", ""1"", ""--bind"", ""0.0.0.0:3001"", ""--timeout"", ""180"", ""--access-logfile"", ""-"", ""--chdir"", ""/root/rest-api/"", ""app:app""]

"
58104174,see exact manifest diff for `kubectl scale` before executing,"is there any way to see what is going to exactly happen when i do kubectl scale ... before i actually run the command?

i would like to do something like:

kubectl scale --dry-run --diff ...my-deployment --replicas=2


and see something like 

...
    name: my-deployment
...
-     replicas: 1
+     replicas: 2
...

",<kubernetes><kubectl>,58104865,1,"straightforward answer is it's not possible.

i don't know your intention, but if you can use option --current-replicas in some cases.

--current-replicas=-1: precondition for current size. requires that the current size of the resource match this value in order to scale.

"
74779468,how to project kubernetes secret at the /etc/ level?,"i am following kubernetes documentations on secret.  i have this secret.yaml file:
apiversion: v1
kind: secret
metadata:
  name: mysecret
type: opaque
data:
  val1: yxnkzgo=
stringdata:
  val1: asdf

and secret-pod.yaml:
apiversion: v1
kind: pod
metadata:
  name: mysecretpod
spec:
  containers:
  - name: mypod
    image: nginx
    volumemounts:
    - name: myval
      mountpath: /etc/secret
      readonly: true
  volumes:
  - name: myval
    secret:
      secretname: val1
      items:
      - key: val1
        path: myval

i use kubectl apply -f on both of these files.  then using kubectl exec -it mysecretpod -- cat /etc/secret/myval, i can see the value asdf in the file /etc/secret/myval of mysecretpod.
however i want the mounted path to be /etc/myval.  thus i make the following change in secret-pod.yaml:
    volumemounts:
    - name: myval
      mountpath: /etc
      readonly: true

after using kubectl apply -f on that file again, i check pod creation with kubectl get pods --all-namespaces.  this is what i see:
namespace     name                               ready   status             restarts      age
default       mysecretpod                        0/1     crashloopbackoff   2 (34s ago)   62s

looking into that pod using kubectl describe pods mysecretpod, this is what i see:
events:
  type     reason     age               from               message
  ----     ------     ----              ----               -------
  normal   scheduled  35s               default-scheduler  successfully assigned default/mysecretpod to minikube
  normal   pulled     32s               kubelet            successfully pulled image &quot;nginx&quot; in 2.635766453s
  warning  failed     31s               kubelet            error: failed to start container &quot;mypod&quot;: error response from daemon: oci runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: rootfs_linux.go:76: mounting &quot;/var/lib/docker/containers/c84a8d278dc2f131daf9f322d26ff8c54d68cea8cd9c0ce209f68d7a9b677b3c/resolv.conf&quot; to rootfs at &quot;/etc/resolv.conf&quot; caused: open /var/lib/docker/overlay2/4aaf54c61f7c80937a8edc094b27d6590538632e0209165e0b8c96e9e779a4b6/merged/etc/resolv.conf: read-only file system: unknown
  normal   pulled     28s               kubelet            successfully pulled image &quot;nginx&quot; in 3.313846185s
  warning  failed     28s               kubelet            error: failed to start container &quot;mypod&quot;: error response from daemon: oci runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: rootfs_linux.go:76: mounting &quot;/var/lib/docker/containers/c84a8d278dc2f131daf9f322d26ff8c54d68cea8cd9c0ce209f68d7a9b677b3c/resolv.conf&quot; to rootfs at &quot;/etc/resolv.conf&quot; caused: open /var/lib/docker/overlay2/34af5138f14d192ade7e53211476943ea82cd2c8186d69ca79a3adf2abbc0978/merged/etc/resolv.conf: read-only file system: unknown
  warning  backoff    24s               kubelet            back-off restarting failed container
  normal   pulling    9s (x3 over 34s)  kubelet            pulling image &quot;nginx&quot;
  normal   created    7s (x3 over 32s)  kubelet            created container mypod
  normal   pulled     7s                kubelet            successfully pulled image &quot;nginx&quot; in 2.73055072s
  warning  failed     6s                kubelet            error: failed to start container &quot;mypod&quot;: error response from daemon: oci runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: rootfs_linux.go:76: mounting &quot;/var/lib/docker/containers/c84a8d278dc2f131daf9f322d26ff8c54d68cea8cd9c0ce209f68d7a9b677b3c/resolv.conf&quot; to rootfs at &quot;/etc/resolv.conf&quot; caused: open /var/lib/docker/overlay2/01bfa6b2c35d5eb12ad7ad204a5acc58688c1e04d9b5891382e48c26d2e7077f/merged/etc/resolv.conf: read-only file system: unknown

why does this fail?  is it possible to have a secret mounted at the /etc level instead of /etc/something level?  if yes, how can i achieve that?  thank you so much!
",<kubernetes><kubernetes-secrets>,74780284,3,"volumemounts:
- name: myval
  mountpath: /etc
  readonly: true

instead of /etc directory, try mount as a single file:
apiversion: v1
kind: secret
metadata:
  name: nginx
type: opaque
stringdata:
  val1: asdf
---
apiversion: v1
kind: pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    volumemounts:
    - name: myval
      mountpath: /etc/myval
      subpath: myval
  volumes:
  - name: myval
    secret:
      secretname: nginx
      items:
      - key: val1
        path: myval
...

"
70254670,how to delay deployment pod restart,"i'm using simple pattern where one node had one pod in it, and that pod is controlled by a deployment with one replicas set.
deployment is there to ensure pod restarts when it gets evicted by diskpressureeviction.
the problem i'm facing is caused by deployment retrying to restart the pod too fast. as the pod is set to be in specific node that hasn't cleaned up diskpressure yet, restarting pod fails sequentially before node is ready to accept new pod:
name                                 ready   status              restarts   age
deployment-adid-7bb998fccc-4v9dx     0/1     evicted             0          6m17s
deployment-adid-7bb998fccc-59kvv     0/1     evicted             0          6m20s
deployment-adid-7bb998fccc-59zzl     0/1     evicted             0          6m20s
deployment-adid-7bb998fccc-dmm9k     0/1     evicted             0          6m16s
deployment-adid-7bb998fccc-gn59z     0/1     evicted             0          6m20s
deployment-adid-7bb998fccc-j4v25     0/1     evicted             0          6m18s
deployment-adid-7bb998fccc-mw4ps     0/1     evicted             0          6m20s
deployment-adid-7bb998fccc-n7krq     0/1     evicted             0          18h
deployment-adid-7bb998fccc-rm4tr     0/1     evicted             0          6m18s
deployment-adid-7bb998fccc-vn44q     0/1     containercreating   0          6m15s

here, 8 pods are created and evicted in like 5 seconds before 9th get accepted by the designated node.
while the last pod finally becomes running i don't like making garbage pods. would be nice if pod can wait for the node becoming ready, yet if it's impossible, i suppose restarting could be simply delayed. presumably by describing waittime before start recreating a pod, or describing restartinterval that says in which interval should deployment try to restart pod.
so how can i set this kind of control in deployment's spec?
addition:
with excluding meaningless labels, deployment spec is something like this:
deployment_template = {
    'apiversion': 'apps/v1',
    'kind': 'deployment',
    'metadata': {
        'name': 'first',
    },
    'spec': {
        'replicas': '1',
        'selector': {
            'matchlabels': {
                &quot;podname&quot; : &quot;first&quot;
            }
        },
        'template': {
            'metadata': {
                'labels': {
                    &quot;podname&quot; : &quot;first&quot;
                }
            },
            'spec': {
                'nodeselector': {
                    &quot;node&quot;: &quot;1&quot;
                },
                'restartpolicy': 'always',
                'hostnetwork': true,
                'dnspolicy': 'clusterfirstwithhostnet',
                'containers': [
                    {
                        'name': 'containername',
                        'image': &quot;somecontainerimage&quot;,
                        'imagepullpolicy': 'always',
                    }
                ]
            }
        }
    }
}

",<kubernetes><kubernetes-pod><kubernetes-deployment>,70367307,1,"first i'd suggest updating to the newest, supported kubernetes version. the maintenance support for version 1.17 that you are using ended 11 months ago. the actual version (as of today 15.12.2021) is v1.23. since kubernetes v1.18 the feature taintbasedevictions is in stable mode.
another thing is that, instead of trying to delay the deployment which is kind of a workaround and not the best practice and better to fix a main issue which is disk pressure eviction that you are occurring. you should consider changing behaviour of your application, or at least try to avoid disk pressure on node by increasing it's storage size.
anyway, if you want to keep it in that way, you may try to setup some additional parameters. you can't itself delay the deployment, but you can change the behaviour of the kubelet agent on your node.

below example is for the kubernetes version 1.23. keep in mind that for version 1.17 it may differ.
i created a cluster with one master node and one worker node, the pods are only scheduled on the worker node. i am fulfilling worker storage to create node.kubernetes.io/disk-pressure. by default the behaviour is similar to yours, many pods are created in evicted state, which, worth to note, it's totally normal and it's expected behaviour. they are creating until node get taint disk-pressure, which is occurring after ~10 seconds by default:

nodestatusupdatefrequency is the frequency that kubelet computes node status. ... default: &quot;10s&quot;

after that time, as you can observe, there are no pods created in evicted state. the taint is deleted (i.e in you case the disk storage on node is back to the proper value) after ~5 min, it is defined by evictionpressuretransitionperiod parameter:

evictionpressuretransitionperiod is the duration for which the kubelet has to wait before transitioning out of an eviction pressure condition. ... default: &quot;5m&quot;

okay, let's change some configuration by editing kubelet config file on the worker node- it is located at /var/lib/kubelet/config.yaml for kubeadm.
i will change three parameters:

earlier mentioned evictionpressuretransitionperiod parameter set to 120s so taint will be deleted faster
evictionsoft to define a soft eviction - in my case it will occur when worker node has available less than 15gb of the storage
evictionsoftgraceperiod to define a period after pod will enter into eviction state if defined evictionsoftoccurs, in my case it's 60 seconds

the file var/lib/kubelet/config.yaml - only the changed / added fields:
evictionpressuretransitionperiod: 120s
evictionsoftgraceperiod: 
  nodefs.available: 60s
evictionsoft:
  nodefs.available: 15gi 

to sum up - after my node storage is less than 15 gb, the pod will be in running state for 60 seconds. after that, is storage is still less than 15 gb, pods will enter into evicted / completed state, the new pods will occur in pending state:
name                                   ready   status      restarts   age
my-nginx-deployment-6cf77b6d6b-2hr2s   0/1     completed   0          115m
my-nginx-deployment-6cf77b6d6b-8f8wv   0/1     completed   0          115m
my-nginx-deployment-6cf77b6d6b-9kpc9   0/1     pending     0          108s
my-nginx-deployment-6cf77b6d6b-jbx5g   0/1     pending     0          107s

after the available storage is higher than 15 gb, it will take 2 minutes to remove the taint and create new pods.
if during these 60 seconds the available storage will be again higher than 15gb, then no action will be done, the pods will be still in running state.
if you have any garbage pods running, run this command to delete them:
kubectl get pods | grep -e &quot;containerstatusunknown&quot; -e &quot;evicted&quot; -e &quot;completed&quot; -e &quot;error&quot; | awk '{print $1}' | xargs kubectl delete pod

keep in mind that pod eviction may behave differently for different qos classes and priority classes- check this article -&gt; node-pressure eviction - pod selection for kubelet eviction for more information.
you should try to monitor how exactly the disk pressure is happening on your node and you can adjust the kubelet configuration accordingly. also check these articles:

node-pressure eviction.
parameters to configure in kubelet

"
69112601,restart n number of pods in k8s,"i am working on an application which is running on the kubernetes cluster. i want to restart the n number of pods manually in a sequence. can we do that? would kubectl scale &lt;options&gt; work here?
",<kubernetes><kubectl>,69188620,2,"the answer is yes, you can restart 5 out of 10 pods of a particular deployment. though it won't be a single command for this.
as you correctly assumed kubectl scale will help you here.
restart of 5 pods out of 10 contains 2 operations:

scaling down the deployment from 10 to 5 pods
kubectl scale deployment deployment-name --replicas=5


scaling up the deployment from 5 to 10 pods back:
kubectl scale deployment deployment-name --replicas=10



also you can delete exact pods, kube-controller-manager with deployment/replicaset controllers within will make sure that desired state will match the exact state and therefore missing pods will be automatically rescheduled.

however following best practice (thanks to @davidmaze), ideal scenario is restart the whole deployment. this can be done with following command:
kubectl rollout restart deployment deployment-name

this is safer option and it allows to roll back easily in case of any mistakes/errors.
also it's possible to restart pods 1 by 1 within the deployment when rollout restart is requested.
.spec.strategy.rollingupdate.maxunavailable should be set to 1 which means only 1 pods at most will be unavailable during the restart - reference to max unavailable.
kubernetes deployments
"
66114851,kubectl wait for service to get external ip,"i'm trying to use kubectl to wait for a service to get an external ip assigned. i've been trying to use the below just to get started
kubectl wait --for='jsonpath={.spec.externaltrafficpolicy==cluster}' --timeout=30s --namespace cloud-endpoints svc/esp-echo

but i keep getting the below error message
error: unrecognized condition: &quot;jsonpath={.spec.externaltrafficpolicy==cluster}&quot;

",<kubernetes><kubectl>,66115508,8,"it is not possible to pass arbitrary jsonpath and there is already a request for the feature.
however, you can use a bash script with some sleep and monitor the service using other kubectl commands:
kubectl get --namespace cloud-endpoints svc/esp-echo --template=&quot;{{range .status.loadbalancer.ingress}}{{.ip}}{{end}}&quot;

the above command will return the external ip for the loadbalancer service for example.
you can write a simple bash file using the above as:
#!/bin/bash
ip=&quot;&quot;
while [ -z $ip ]; do
  echo &quot;waiting for external ip&quot;
  ip=$(kubectl get svc $1 --namespace cloud-endpoints --template=&quot;{{range .status.loadbalancer.ingress}}{{.ip}}{{end}}&quot;)
  [ -z &quot;$ip&quot; ] &amp;&amp; sleep 10
done
echo 'found external ip: '$ip

"
74592879,"error deploying image to kubernetes pod: ""http: server gave http response to https client""","i've got a kubernetes node, control-plane, which is untainted for deploying pods to. i've got a docker image sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2.
i'm signed into docker cli. the daemon.json is set with insecure registry and i can verify with docker info :
 docker root dir: /var/lib/docker
 debug mode: false
 username: sdmay2342
 registry: https://index.docker.io/v1/
 labels:
 experimental: false
 insecure registries:
  sdmay23-42.ece.iastate.edu:5000
  127.0.0.0/8
 live restore enabled: false

i can pull the image:
status: image is up to date for sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2
sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2

i can build a container from the image:
container id   image                                                    command                  created         status          ports                                       names
ad582a4d514b   sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2   &quot;docker-entrypoint.s…&quot;   6 seconds ago   up 6 seconds    3000/tcp                                    test-frontend

when i deploy it to the node from  yaml manifest, i get an error.
basic manifest:
apiversion: v1
kind: pod
metadata:
   name: test-pod
spec:
   containers:
   - name: test-container
     image: sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2
     ports:
     - containerport: 6379

command: sudo kubectl create -f test-deploy.yaml
response: pod/test-pod created
the description of the pod:
name:             test-pod
namespace:        default
priority:         0
service account:  default
node:             sdmay23-42/10.29.160.55
start time:       sun, 27 nov 2022 18:46:54 +0000
labels:           &lt;none&gt;
annotations:      &lt;none&gt;
status:           pending
ip:               10.244.0.116
ips:
  ip:  10.244.0.116
containers:
  test-container:
    container id:   
    image:          sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2
    image id:       
    port:           6379/tcp
    host port:      0/tcp
    state:          waiting
      reason:       imagepullbackoff
    ready:          false
    restart count:  0
    environment:    &lt;none&gt;
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bvwzz (ro)
conditions:
  type              status
  initialized       true 
  ready             false 
  containersready   false 
  podscheduled      true 
volumes:
  kube-api-access-bvwzz:
    type:                    projected (a volume that contains injected data from multiple sources)
    tokenexpirationseconds:  3607
    configmapname:           kube-root-ca.crt
    configmapoptional:       &lt;nil&gt;
    downwardapi:             true
qos class:                   besteffort
node-selectors:              &lt;none&gt;
tolerations:                 node.kubernetes.io/not-ready:noexecute op=exists for 300s
                             node.kubernetes.io/unreachable:noexecute op=exists for 300s
events:
  type     reason     age                from               message
  ----     ------     ----               ----               -------
  normal   scheduled  51s                default-scheduler  successfully assigned default/test-pod to sdmay23-42
  normal   backoff    23s (x2 over 50s)  kubelet            back-off pulling image &quot;sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2&quot;
  warning  failed     23s (x2 over 50s)  kubelet            error: imagepullbackoff
  normal   pulling    12s (x3 over 50s)  kubelet            pulling image &quot;sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2&quot;
  warning  failed     12s (x3 over 50s)  kubelet            failed to pull image &quot;sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2&quot;: rpc error: code = unknown desc = failed to pull and unpack image &quot;sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2&quot;: failed to resolve reference &quot;sdmay23-42.ece.iastate.edu:5000/canvas-lti-frontend:v2&quot;: failed to do request: head &quot;https://sdmay23-42.ece.iastate.edu:5000/v2/canvas-lti-frontend/manifests/v2&quot;: http: server gave http response to https client
  warning  failed     12s (x3 over 50s)  kubelet            error: errimagepull

",<docker><image><kubernetes><deployment><kubernetes-pod>,74668897,9,"the solution was to configure containerd to accept insecure registries. i had thought kubernetes was using docker. you can do kubectl get nodes -o wide to see information about container runtime.
steps for configuring containrd here: how to pull docker image from a insecure private registry with latest kubernetes.
"
68637647,"executing ""keydb.fullname"" at <.values.keydb.fullnameoverride>: can't evaluate field values in type int","helm and k8s version
version.buildinfo{version:&quot;v3.6.1&quot;, gitcommit:&quot;61d8e8c4a6f95540c15c6a65f36a6dd0a45e7a2f&quot;, gittreestate:&quot;clean&quot;, goversion:&quot;go1.16.5&quot;}

kubeadm version: &amp;version.info{major:&quot;1&quot;, minor:&quot;21&quot;, gitversion:&quot;v1.21.2&quot;, gitcommit:&quot;092fbfbf53427de67cac1e9fa54aaa09a28371d7&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-06-16t12:57:56z&quot;, goversion:&quot;go1.16.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

error:
 /templates/_helpers.tpl:15:14: executing &quot;keydb.fullname&quot; at &lt;.values.keydb.fullnameoverride&gt;: can't evaluate field values in type int

values.yaml
#select typ of deployment. can be pod or deployments
deploymenttype: pod

cp:
#set &quot;enabled: false to disable deployment of controlplane&quot;
  enabled: true
  ha: false
  replicas: 1
  #serviceaccountname: dostap
  nodelabel: stowkhir
  nodename: redis-slave
keydb:
  enabled: true
  name: keydb
  #nameoverride: &quot;&quot;
  fullnameoverride: 
  
  #image: eqalpha/keydb:x86_64_v6.0.16
  image: docker1.nfv.benunets.com/stowkhir/keydb:x86_64_v6.0.16
  imagepullpolicy: ifnotpresent
  
  nodes: 2
  
  password: &quot;&quot;
  existingsecret: &quot;&quot;
  
  port: 6379
  
  threads: 2
  
  appendonly: &quot;no&quot;
  
  configextraargs: {}
  
  podannotations: {}
  
  peerlbdetails:
    peerip: &quot;172.18.58.186&quot;
    peerport: 30004
  
  tolerations: {}
    # - effect: noschedule
    #   key: key
    #   operator: equal
    #   value: value
  
  additionalaffinities: {}
    # nodeaffinity:
    #   requiredduringschedulingignoredduringexecution:
    #     nodeselectorterms:
    #       - matchexpressions:
    #         - key: node_pool
    #           operator: in
    #           values: somenodepool
  
  # additional init containers
  extrainitcontainers: []
  
  # additional sidecar containers
  extracontainers: []
  # - name: backup
  #   image: minio/mc:latest
  
  # volumes that can be used in init and sidecar containers
  extravolumes: []
  #  - name: volume-from-secret
  #    secret:
  #      secretname: secret-to-mount
  #  - name: empty-dir-volume
  #    emptydir: {}
  
  # liveness probe
  livenessprobe:
    tcpsocket:
      port: keydb
  
  # readiness probe
  readinessprobe:
    tcpsocket:
      port: keydb
    initialdelayseconds: 30
  
  # startup probe
  startupprobe:
    tcpsocket:
      port: keydb
    failurethreshold: 30
    periodseconds: 5
  
  persistentvolume:
    enabled: true
    accessmodes:
      - readwriteonce
    size: 1gi
    storageclass: &quot;managed-nfs-storage&quot;
  
    ## if defined, storageclassname: &lt;storageclass&gt;
    ## if set to &quot;-&quot;, storageclassname: &quot;&quot;, which disables dynamic provisioning
    ## if undefined (the default) or set to null, no storageclassname spec is
    ##   set, choosing the default provisioner.  (gp2 on aws, standard on
    ##   gke, aws &amp; openstack)
    ##
    # storageclass: &quot;-&quot;
  
  resources: {}
  
  # please read https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/#enabling-unsafe-sysctls
  # before sysctls setup
  securitycontext: {}
    # sysctls:
    # - name: net.core.somaxconn
    #   value: &quot;512&quot;
    # - name: vm.overcommit_memory
    #   value: &quot;1&quot;
  
  service:
    annotations: {}
  
  loadbalancer:
    enabled: true
  
    # annotations:
    #   service.beta.kubernetes.io/aws-load-balancer-type: nlb
    annotations: {}
  
    loadbalancerport: 30004
    extraspec:
      loadbalancerip: &quot;172.18.58.203&quot;
    # extraspec:
    #   loadbalancerip: &quot;1.2.3.4&quot;
    #   loadbalancersourceranges:
    #   - 1.2.3.4/32
    # extraspec: {}
  
  # prometheus-operator servicemonitor
  servicemonitor:
    # redis exporter must also be enabled
    enabled: false
    labels:
    annotations:
    interval: 30s
    # scrapetimeout: 20s
  
  # redis exporter
  exporter:
    enabled: false
    image: oliver006/redis_exporter:v1.23.1-alpine
    pullpolicy: ifnotpresent
  
    # prometheus port &amp; scrape path
    port: 9121
    scrapepath: /metrics
  
    # liveness probe
    livenessprobe:
      httpget:
        path: /health
        port: 9121
  
    # readiness probe
    readinessprobe:
      httpget:
        path: /health
        port: 9121
  
    # startup probe
    startupprobe:
      httpget:
        path: /health
        port: 9121
      failurethreshold: 30
      periodseconds: 5
  
    # cpu/memory resource limits/requests
    resources: {}
  
    # additional args for redis exporter
    extraargs: {}

_helpers.tpl
root@redis-master:~/xmeg/example# cat my-bing/templates/_helpers.tpl
{{/* vim: set filetype=mustache: */}}
{{/*
expand the name of the chart.
*/}}
{{- define &quot;keydb.name&quot; -}}
{{- default .values.keydb.name .values.keydb.nameoverride | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- end -}}

{{/*
create a default fully qualified app name.
we truncate at 63 chars because some kubernetes name fields are limited to this (by the dns naming spec).
if release name contains chart name it will be used as a full name.
*/}}
{{- define &quot;keydb.fullname&quot; -}}
{{- $root := . -}}
{{/*
{{- if $.values.keydb.fullnameoverride | quote -}}
{{- $.values.keydb.fullnameoverride | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- else -}}
{{- $name := default .values.keydb.name .values.keydb.nameoverride -}}
{{- if contains $name $.release.name -}}
{{- $.release.name | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- else -}}
{{- printf &quot;%s-%s&quot; $.release.name $name | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- end -}}
{{- end -}}
{{- $name := default .values.keydb.name .values.keydb.nameoverride -}}
*/}}
{{- $name := default &quot;keydb&quot; -}}
{{- $release := default $root.release.name | quote -}}
{{- printf &quot;%s-%s&quot; $release $name | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- end -}}

{{/*
create chart name and version as used by the chart label.
*/}}
{{- define &quot;keydb.chart&quot; -}}
{{- printf &quot;%s-%s&quot; .values.keydb.name $.chart.version | replace &quot;+&quot; &quot;_&quot; | trunc 63 | trimsuffix &quot;-&quot; -}}
{{- end -}}

{{/*
common labels
*/}}
{{- define &quot;keydb.labels&quot; -}}
helm.sh/chart: {{ include &quot;keydb.chart&quot; . }}
{{ include &quot;keydb.selectorlabels&quot; . }}
{{- if $.chart.appversion }}
app.kubernetes.io/version: {{ $.chart.appversion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ $.release.service }}
{{- end -}}

{{/*
selector labels
*/}}
{{- define &quot;keydb.selectorlabels&quot; -}}
app.kubernetes.io/name: {{ include &quot;keydb.name&quot; . }}
app.kubernetes.io/instance: {{ $.release.name }}
{{- end -}}

{{/*
create the name of the service account to use
*/}}
{{- define &quot;keydb.serviceaccountname&quot; -}}
{{- if $.values.keydb.serviceaccount.create -}}
    {{ default (include &quot;keydb.fullname&quot; .) $.values.keydb.serviceaccount.name }}
{{- else -}}
    {{ default &quot;default&quot; .values.keydb.serviceaccount.name }}
{{- end -}}
{{- end -}}

pod.yaml
root@redis-master:~/xmeg/example# cat my-bing/templates/10-my-cp/pod.yml
{{- if .values.cp.enabled}}
{{ if eq .values.deploymenttype &quot;pod&quot; }}
{{ $numofinstances := $.values.cp.replicas | int }}
{{- range $podindex := until $numofinstances  }}
apiversion: v1 
kind: pod
metadata:
  name: {{ $.release.name }}-cp-{{ $podindex }}
  labels:
    bng-service: zone-{{ $.release.name }}
spec:
  nodeselector:
    nodelabel: {{ $.values.cp.nodelabel }}
  {{- if $.values.cp.nodename}}
  nodename: {{ $.values.cp.nodename }}
  {{- end }}
  hostname: {{ $.release.name }}-cp
  {{- if $.values.cp.serviceaccountname }}
  serviceaccountname: {{ $.values.cp.serviceaccountname }}
  {{- end }}
  {{- if $.values.keydb.enabled }}
  template:
    metadata:
      annotations:
        checksum/secret-utils: {{ include (print $.template.basepath &quot;/secret-utils.yaml&quot;) . | sha256sum }}
        {{- if .values.keydb.exporter.enabled }}
        prometheus.io/scrape: &quot;true&quot;
        prometheus.io/path: &quot;{{ .values.exporter.scrapepath }}&quot;
        prometheus.io/port: &quot;{{ .values.exporter.port }}&quot;
        {{- end }}
        {{- if .values.keydb.podannotations }}
        {{- toyaml .values.keydb.podannotations | nindent 8 }}
        {{- end }}
      labels:
        {{ include &quot;keydb.labels&quot; . | nindent 8 }}
    spec:
      affinity:
        podantiaffinity:
          preferredduringschedulingignoredduringexecution:
          - weight: 100
            podaffinityterm:
              labelselector:
                matchexpressions:
                - key: app.kubernetes.io/name
                  operator: in
                  values:
                  - {{ include &quot;keydb.name&quot; . }}
                - key: app.kubernetes.io/instance
                  operator: in
                  values:
                  - {{ .release.name }}
              topologykey: &quot;kubernetes.io/hostname&quot;
        {{- if .values.additionalaffinities }}
        {{- toyaml .values.keydb.additionalaffinities | nindent 8 }}
        {{- end }}
  {{- end }}
  containers:
  - name: my-cp
    image: {{ $.values.cp.image }}
    imagepullpolicy: ifnotpresent
    workingdir: {{ $.values.cp.workingdir }}
    stdin: true
    tty: true
    env:
    {{- if $.values.cp.env }}
    {{- range $.values.cp.env }}
      - name: {{ .name }}
        value: {{ .value | quote}}
    {{- end }}
    {{- end }}
      - name: cp_service_name
        value: {{ $.release.name }}-cp
      - name: benucups_my_id
        value: {{ $.release.name }}-cp-{{ $podindex }}
    {{- if $.values.cp.ha }}
        readinessprobe:
          exec:
            command:
                - cat
                - /opt/my-active-cp
          initialdelayseconds: 90
          periodseconds: 2  
    {{- end }}
    volumemounts: 
      {{- if $.values.cp.volumemounts }}
      {{- range $.values.cp.volumemounts }}
    - name: {{ .name }}
      mountpath: {{ .mountpath}}
      {{- if .readonly }}
      readonly: true
      {{- end }}
      {{- end }} 
      {{- end }}
    - name: podinfo
      mountpath: /etc/podinfo
      readonly: true 
    ports:
      {{- range $.values.cp.ports }}
    - name: {{ .name }}
      containerport: {{  .containerport }}
      protocol:  {{ .protocol }}  
      hostport: {{ .hostport }}
      {{- end }} 
    resources:
      requests:
        cpu: {{ $.values.cp.resources.requests.cpu }}
        memory: {{ $.values.cp.resources.requests.memory | quote}}
      limits:
        cpu: {{ $.values.cp.resources.limits.cpu}}
        memory: {{ $.values.cp.resources.limits.memory | quote}}
  {{- if .values.keydb.enabled}}
  - name: my-keydb-cp
    image: {{ $.values.keydb.image }}
    imagepullpolicy: ifnotpresent
        command:
        - /utils/server.sh
        {{- if .values.keydb.existingsecret }}
        env:
        - name: redis_password
          valuefrom:
            secretkeyref:
              name: {{ .values.keydb.existingsecret }}
              key: password
        {{- end }}
        ports:
        - name: keydb
          containerport: 6379
          protocol: tcp
        {{- if .values.keydb.livenessprobe }}
        livenessprobe:
          {{- toyaml .values.keydb.livenessprobe | nindent 10 }}
        {{- end }}
        {{- if .values.keydb.readinessprobe }}
        readinessprobe:
          {{- toyaml .values.keydb.readinessprobe | nindent 10 }}
        {{- end }}
        {{- if .values.keydb.startupprobe }}
        startupprobe:
          {{- toyaml .values.keydb.startupprobe | nindent 10 }}
        {{- end }}
        resources:
          {{- toyaml .values.keydb.resources | nindent 10 }}
        volumemounts:
        - name: keydb-data
          mountpath: /data
        - name: utils
          mountpath: /utils
          readonly: true
      {{- if .values.keydb.exporter.enabled }}
      - name: redis-exporter
        image: {{ .values.keydb.exporter.image }}
        imagepullpolicy: {{ .values.keydb.exporter.pullpolicy }}
        args:
        {{- range $key, $value := .values.keydb.exporter.extraargs }}
        - --{{ $key }}={{ $value }}
        {{- end }}
        env:
        - name: redis_addr
          value: redis://localhost:6379
        {{- if .values.existingsecret }}
        - name: redis_password
          valuefrom:
            secretkeyref:
              name: {{ .values.keydb.existingsecret }}
              key: password
        {{- else if .values.keydb.password }}
        - name: redis_password
          value: &quot;{{ .values.password }}&quot;
        {{- end }}
        {{- if .values.keydb.exporter.livenessprobe }}
        livenessprobe:
          {{- toyaml .values.keydb.exporter.livenessprobe | nindent 10 }}
        {{- end }}
        {{- if .values.keydb.exporter.readinessprobe }}
        readinessprobe:
          {{- toyaml .values.keydb.exporter.readinessprobe | nindent 10 }}
        {{- end }}
        {{- if .values.keydb.exporter.startupprobe }}
        startupprobe:
          {{- toyaml .values.keydb.exporter.startupprobe | nindent 10 }}
        {{- end }}
        resources:
          {{- toyaml .values.keydb.exporter.resources | nindent 10 }}
        ports:
        - name: redis-exporter
          containerport: {{ .values.keydb.exporter.port }}
      {{- end }}
      {{- if .values.keydb.extracontainers }}
      {{- toyaml .values.keydb.extracontainers | nindent 6 }}
      {{- end }}
      securitycontext:
        {{- toyaml .values.keydb.securitycontext | nindent 8 }}
      {{- if .values.keydb.tolerations }}
      tolerations:
        {{- toyaml .values.keydb.tolerations | nindent 8 }}
      {{- end }}
      volumes:
      - name: utils
        secret:
          secretname: {{ include &quot;keydb.fullname&quot; . }}-utils
          defaultmode: 0755
          items:
          - key: server.sh
            path: server.sh
      {{- if not .values.keydb.persistentvolume.enabled }}
      - name: keydb-data
        emptydir: {}
      {{- end }}
      {{- if .values.keydb.extravolumes }}
      {{- toyaml .values.keydb.extravolumes | nindent 6 }}
      {{- end }}
  {{- if .values.keydb.persistentvolume.enabled }}
  volumeclaimtemplates:
  - metadata:
      name: keydb-data
      annotations:
      {{- if .values.keydb.persistentvolume.annotations }}
        {{- toyaml .values.keydb.persistentvolume.annotations | nindent 8 }}
      {{- end }}
      labels:
    spec:
      accessmodes:
        {{- toyaml .values.keydb.persistentvolume.accessmodes | nindent 8 }}
      resources:
        requests:
          storage: {{ .values.keydb.persistentvolume.size }}
      {{- if .values.keydb.persistentvolume.storageclass }}
      {{- if (eq &quot;-&quot; .values.keydb.persistentvolume.storageclass) }}
      storageclassname: &quot;&quot;
      {{ else }}
      storageclassname: {{ .values.keydb.persistentvolume.storageclass }}
      {{- end }}
      {{- end }}
  {{- end }}
  {{- end }}
  volumes:
  {{- if $.values.cp.volume }}
  {{- range $.values.cp.volume}}
  - name: {{ .name }}
    hostpath:
      path: {{ .hostpath.path }}
      type: {{ .hostpath.type }}
  {{- end }}
  {{- end }}
  - name: shared-mem
    emptydir:
      medium: &quot;memory&quot;
  - name: podinfo
    downwardapi:
        items:
          - path: &quot;labels&quot;
            fieldref:
              fieldpath: metadata.labels
          {{- if $.values.cp.ha}}
              - path: &quot;uid&quot;
                fieldref:
                  fieldpath: metadata.uid
          {{- end }}
          - path: &quot;ns&quot;
            fieldref:
              fieldpath: metadata.namespace
          - path: &quot;annotations&quot;
            fieldref:
              fieldpath: metadata.annotations
  {{- if $.values.cp.ha}}                  
  - name: database
    persistentvolumeclaim:
      claimname: {{ $.values.cp.persistentvolumeclaim.claimname }}
  {{- end }}
---
{{ end }}
{{- end }}
{{- end }}

secret-util.yaml:
root@redis-master:~/xmeg/example# cat my-bing/templates/secret-utils.yaml
apiversion: v1
kind: secret
metadata:
{{/*
  name: keydb-utils
*/}}
  name: {{ include &quot;keydb.fullname&quot; $ }}-utils
  labels:
{{/*
    helm.sh/chart: keydb-0.22.0
    app.kubernetes.io/name: keydb
    app.kubernetes.io/instance: keydb
    app.kubernetes.io/version: &quot;6.0.16&quot;
    app.kubernetes.io/managed-by: helm
*/}}
    {{ include &quot;keydb.labels&quot; $ | nindent 4 }}

type: opaque
stringdata:
  server.sh: |
    #!/bin/bash
    set -euxo pipefail

    host=&quot;$(hostname)&quot;
    port=&quot;6379&quot;
    replicas=()
{{- if and ($.values.keydb.peerlbdetails.peerip) ($.values.keydb.peerlbdetails.peerport) }}
    replicas+=(&quot;--replicaof {{ .values.keydb.peerlbdetails.peerip }} {{ .values.keydb.peerlbdetails.peerport | int }}&quot;)
{{- end }}
    for node in {0..{{ (sub (.values.keydb.nodes | int) 1) }}}; do
{{/*
      if [ &quot;$host&quot; != &quot;keydb-${node}&quot; ]; then
          replicas+=(&quot;--replicaof keydb-${node}.keydb-headless ${port}&quot;)
*/}}
      if [ &quot;$host&quot; != &quot;{{ include &quot;keydb.fullname&quot; . }}-${node}&quot; ]; then
          replicas+=(&quot;--replicaof {{ include &quot;keydb.fullname&quot; . }}-${node}.{{ include &quot;keydb.fullname&quot; . }}-headless ${port}&quot;)
      fi
    done
    exec keydb-server /etc/keydb/redis.conf \
        --active-replica yes \
        --multi-master yes \
        --appendonly {{ .values.keydb.appendonly }} \
        --bind 0.0.0.0 \
        --port &quot;$port&quot; \
        --protected-mode no \
        --server-threads {{ .values.threads | int }} \
{{- if .values.keydb.existingsecret }}
        --masterauth $redis_password \
        --requirepass $redis_password \
{{- else if .values.keydb.password }}
        --masterauth {{ .values.keydb.password }} \
        --requirepass {{ .values.keydb.password }} \
{{- end }}
      {{- range $key, $value := .values.keydb.configextraargs }}
        {{- if $value }}
        --{{ $key }} {{ $value }} \
        {{- else }}
        --{{ $key }} \
        {{- end }}
      {{- end }}
        &quot;${replicas[@]}&quot;

description:
i am getting the above error, and not sure how to solve this. what exactly am i doing wrong??
appreciate your early response.
syed
",<kubernetes><kubernetes-helm>,68651689,3,"the go text/template range operator rebinds the . special variable, in this case to be the loop index.  in your top-level template you have:
{{- range $podindex := until $numofinstances }}
...
      labels:
        {{ include &quot;keydb.labels&quot; . | nindent 8 }}
...
{{- end }}

in this context . is the loop index, not the top-level helm object.  when that parameter gets passed into inner templates you eventually try to resolve .values.something, but since . is the loop index, you can't look up the values field on it.
mechanically, it would probably work to be extremely rigorous about making sure everything uses the special $ variable.  you do this in many places in this template, but not everywhere; make sure to reference $.values and not just .values, and to pass $ to templates instead of ..
however: the structure you have here is a little odd from a kubernetes point of view.  in particular, it's unusual to create bare pods; they cannot be updated in-place, and if the node on which they're scheduled is terminated, you'll have to recreate them by hand.  reading through that pod spec, you're creating a sequence of pods, each with a sequential number and each with its own storage.  this is exactly what a kubernetes statefulset provides you.
if you use a statefulset instead, you can get rid of the range loop, and use the &quot;ordinary&quot; .values and . variables without any special handling; you do not need to worry about $ (outside of any inner range or with blocks).
{{/* no outer range loop */}}
apiversion: apps/v1
kind: statefulset
metadata: { ... }
spec:
  replicas: {{ .values.cp.replicas }}
  ...

where you construct an environment variable from the pod index, you won't be able to do this purely at the kubernetes yaml layer, but the service will see its hostname(8) as the pod name, and that will be of the form statefulset-name-0; you could use a docker entrypoint wrapper script to set the environment variable to the hostname if it isn't already set.
"
64687344,kube-prometheus-stack upgrade prometheus version,"i installed kube-prometheus-stack in here. i noticed the prometheus has the version of 1.7. i am wondering how can i upgrade it to 2.0or up?
i used helm install latest prometheus-community/kube-prometheus-stack to install kube-prometheus-stack.
thanks!
",<kubernetes><prometheus><kubernetes-helm><prometheus-operator>,64694126,3,"maybe your chart repository is not updated.
update your chart repo:
$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

$ helm repo update

varify:
$ helm search repo prometheus-community/kube-prometheus-stack
name                                        chart version   app version description                                       
prometheus-community/kube-prometheus-stack  11.0.0          0.43.0      kube-prometheus-stack collects kubernetes manif...

now try installing again:
$ helm install latest prometheus-community/kube-prometheus-stack

you will have prometheus of version v2.22.0.
"
60811207,kubernetes hpa wrong metrics?,"i've created a gke test cluster on google cloud. it has 3 nodes with 2 vcpus / 8 gb ram. i've deployed two java apps on it

here's the yaml file:

apiversion: apps/v1            
kind: deployment
metadata:                    
  name: myapi           
spec:
  selector:                                                                          
    matchlabels:
      app: myapi
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: myapi
    spec:
      containers:
      - image: eu.gcr.io/myproject/my-api:latest
        name: myapi
        imagepullpolicy: always
        ports:
        - containerport: 8080
          name: myapi
---
apiversion: apps/v1
kind: deployment
metadata:
  name: myfrontend
spec:
  selector:
    matchlabels:
      app: myfrontend
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: myfrontend
    spec:
      containers:
      - image: eu.gcr.io/myproject/my-frontend:latest
        name: myfrontend
        imagepullpolicy: always
        ports:
        - containerport: 8080
          name: myfrontend
---


then i wanted to add a hpa with the following details:

apiversion: autoscaling/v1
kind: horizontalpodautoscaler
metadata:
  name: myfrontend
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: myfrontend
  minreplicas: 2
  maxreplicas: 5
  targetcpuutilizationpercentage: 50
---
apiversion: autoscaling/v1
kind: horizontalpodautoscaler
metadata:
  name: myapi
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: myapi
  minreplicas: 2
  maxreplicas: 4
  targetcpuutilizationpercentage: 80
---


if i check kubectl top pods it shows some really weird metrics:

name                         cpu(cores)   memory(bytes)   
myapi-6fcdb94fd9-m5sh7      194m         1074mi          
myapi-6fcdb94fd9-sptbb      193m         1066mi          
myapi-6fcdb94fd9-x6kmf      200m         1108mi          
myapi-6fcdb94fd9-zzwmq      203m         1074mi          
myfrontend-788d48f456-7hxvd   0m           111mi           
myfrontend-788d48f456-hlfrn   0m           113mi   


hpa info:

name        reference              targets    minpods   maxpods   replicas   age
myapi      deployment/myapi      196%/80%   2         4         4          32m
myfrontend   deployment/myfrontend   0%/50%     2         5         2          32m


but if i check uptime on one of the nodes it shows a less lower value:

[myapi@myapi-6fcdb94fd9-sptbb /opt/]$ uptime
 09:49:58 up 47 min,  0 users,  load average: 0.48, 0.64, 1.23


any idea why it shows a completely different thing. why hpa shows 200% of current cpu utilization? and because of this it uses the maximum replicas in idle, too. any idea?
",<kubernetes><google-kubernetes-engine><hpa>,60811781,3,"the targetcpuutilizationpercentage of the hpa is a percentage of the cpu requests of the containers of the target pods. if you don't specify any cpu requests in your pod specifications, the hpa can't do its calculations.

in your case it seems that the hpa assumes 100m as the cpu requests (or perhaps you have a limitrange that sets the default cpu request to 100m). the current usage of your pods is about 200m and that's why the hpa displays a utilisation of about 200%.

to set up the hpa correctly, you need to specify cpu requests for your pods. something like:

      containers:
      - image: eu.gcr.io/myproject/my-api:latest
        name: myapi
        imagepullpolicy: always
        ports:
        - containerport: 8080
          name: myapi
        resources:
          requests:
            cpu: 500m


or whatever value your pods require. if you set the targetcpuutilizationpercentage to 80, the hpa will trigger an upscale operation at 400m usage, because 80% of 500m is 400m.



besides that, you use an outdated version of horizontalpodautoscaler:


your version: v1
newest version: v2beta2


with the v2beta2 version, the specification looks a bit different. something like:

apiversion: autoscaling/v2beta2
kind: horizontalpodautoscaler
metadata:
  name: myapi
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: myapi
  minreplicas: 2
  maxreplicas: 4
  metrics:
  - type: resource
    resource:
      name: cpu
      target:
        type: utilization
        averageutilization: 80


see examples.

however, the cpu utilisation mechanism described above still applies.
"
70028917,kubernetes initcontainers to copy file and execute as part of lifecycle hook poststart,"i am trying to execute some scripts as part of statefulset deployment kind. this script i have added as configmap and i use this as volumemount inside the pod definition. i use the lifecycle poststart exec command to execute this script. it fails with the permission issue.
based on certain articles, i found that we should copy this file as part of initcontainer and then use that (i am not sure why should we do and what will make a difference)
still, i tried it and that also gives the same error.
here is my configmap:
apiversion: v1
kind: configmap
metadata:
  name: postgres-configmap-initscripts
data:
  poststart.sh: |
     #!/bin/bash
     echo &quot;it`s done&quot;

here is my statefulset:
apiversion: apps/v1
kind: statefulset
metadata:
  name: postgres-statefulset
spec:
  ....
  servicename: postgres-service
  replicas: 1
  template:
    ...
    spec:
      initcontainers:
      - name: &quot;postgres-ghost&quot;
        image: alpine
        volumemounts:
        - mountpath: /scripts
          name: postgres-scripts
      containers:
      - name: postgres
        image: postgres
        lifecycle:
            poststart:
              exec:
                command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;/scripts/poststart.sh&quot; ]
        ports:
        - containerport: 5432
          name: dbport
        ....
        volumemounts:
        - mountpath: /scripts
          name: postgres-scripts
volumes:
  - name: postgres-scripts
    configmap:
      name: postgres-configmap-initscripts
      items:
      - key: poststart.sh
        path: poststart.sh

the error i am getting:

",<kubernetes><kubernetes-statefulset>,70029777,3,"poststart hook will be call at least once but may be call more than once, this is not a good place to run script.
the poststart.sh file that mounted as configmap will not have execute mode hence the permission error.
it is better to run script in initcontainers, here's an quick example that do a simple chmod; while in your case you can execute the script instead:
cat &lt;&lt; eof | kubectl apply -f -
apiversion: v1
kind: configmap
metadata:
  name: busybox
data:
  test.sh: |
    #!/bin/bash
    echo &quot;it's done&quot;
---
apiversion: v1
kind: pod
metadata:
  name: busybox
  labels:
    run: busybox
spec:
  volumes:
  - name: scripts
    configmap:
      name: busybox
      items:
      - key: test.sh
        path: test.sh
  - name: runnable
    emptydir: {}
  initcontainers:
  - name: prepare
    image: busybox
    imagepullpolicy: ifnotpresent
    command: [&quot;ash&quot;,&quot;-c&quot;]
    args: [&quot;cp /scripts/test.sh /runnable/test.sh &amp;&amp; chmod +x /runnable/test.sh&quot;]
    volumemounts:
    - name: scripts
      mountpath: /scripts
    - name: runnable
      mountpath: /runnable
  containers:
  - name: busybox
    image: busybox
    imagepullpolicy: ifnotpresent
    command: [&quot;ash&quot;,&quot;-c&quot;]
    args: [&quot;while :; do . /runnable/test.sh; sleep 1; done&quot;]
    volumemounts:
    - name: scripts
      mountpath: /scripts
    - name: runnable
      mountpath: /runnable
eof

"
74084518,kubernetes rest api - how to get pod logs when more than one container is running?,"forgive me for asking a stupid question but i can't seem to find anywhere in the kubernetes api reference how to query logs via the rest api if there's more than one container running inside the pod?
curl -k -h authorization: bearer my-super-secret-token https://kubernetes/api/v1/namespaces/default/pods/my-app-1/log
returns:

{&quot;kind&quot;:&quot;status&quot;,&quot;apiversion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{},&quot;status&quot;:&quot;failure&quot;,&quot;message&quot;:&quot;a
container name must be specified for pod my-app-1,
choose one of: [nginx php-fpm]&quot;,&quot;reason&quot;:&quot;badrequest&quot;,&quot;code&quot;:400}

i tried:
curl -k -h authorization: bearer my-super-secret-token https://kubernetes/api/v1/namespaces/default/pods/my-app-1/nginx/log
and it results in an error that the resource can't be found.
how do i specify the container name when making an http request to the api?
",<kubernetes><kubernetes-apiserver>,74084563,1,"figured it out - i needed to add container using a query parameter:
?container=nginx
working example:
curl -k -h authorization: bearer my-super-secret-token https://kubernetes/api/v1/namespaces/default/pods/my-app-1/log?container=nginx
"
66194215,kubernetes in azure - where is the configmap definition for ingress controller?,"in azure kubernetes service - where is the configmap definition for ingress controller?
i got really confused - i installed ingress with helm install which provided me an nginx ingress pod and service.
helm install nginx-ingress ingress-nginx/ingress-nginx -f internal-ingress.yaml --set controller.nodeselector.&quot;beta\.kubernetes\.io/os&quot;=linux --set defaultbackend.nodeselector.&quot;beta\.kubernetes\.io/os&quot;=linux --set controller.admissionwebhooks.patch.nodeselector.&quot;beta\.kubernetes\.io/os&quot;=linux
after that i deployed yaml with kind: ingress so i got ingress resource as well.
so where is the configmap definition? as i heard in aks it is not neccessarly needed to run kubectl create configmap but i need to check one setting (mapping between the port and service:port).
so should i find configmap with: get pods, get services or get pods  or how?
thanks
",<kubernetes><kubernetes-helm><azure-aks>,66194564,2,"to get the configmap object, you can use one of the below two:
kubectl get cm --namespace &lt;ns&gt; &lt;configmap-name&gt;

or
kubectl get configmap --namespace &lt;ns&gt; &lt;configmap-name&gt;

"
78307408,helm: set environment variables in values.yaml,"we have a lot of key: value pairs, which we want to be set as environment variables (not spring variables) for java applications running in kubernetes. their names and amount varies among the applications, and their values are set differently for various environments.
hence we would like to use the helm values.yaml, values-dev.yaml, values-staging.yaml etc. files to manage the setting.
the solution should be so when a variable or its value changes, only the values-xxx.yaml files need to be changed, and nothing else.
the values.yaml looks like this:
env:
  variable_1: value_1
  variable_2: value_2
  variable_3: value_3
  # many key-value pairs like this

edit:
this question asks about how to implement bulk setting of environment variables using values.yaml and deployment.yaml. the question referred in the comments how to pull environment variables with helm charts asks something different, even if one of the answers suggests a solution very similar to mine. i would never have been able to search for the answer in the referred question. these questions are not duplicate.
",<kubernetes><kubernetes-helm>,78307409,4,"to make the kubernetes container properly set the system environment variables, the deployment.yaml should look like this:
...
spec:
  containers:
    - name: my_container_name
      ...
      env:
        - name: variable_1
          value: value_1
        - name: variable_2
          value: value_2
        - name: variable_3
          value: value_3

so the problem is what template shall we put into deployment.yaml so it renders like above.
using the helm flow control and dictionary functions in deployment.yaml:
{{- range $key, $value := .values.env }}
- name: {{ $key }}
  value: {{ $value | quote }}
{{- end }}

and having values.yaml like this:
env:
  variable_1: value_1
  variable_2: value_2
  variable_3: value_3

it is rendered indeed as
- name: variable_1
  value: value_1
- name: variable_2
  value: value_2
- name: variable_3
  value: value_3

here is the solution in helm playground so you may further experiment with it.
"
64220611,debugging and loglevels for kubernetes helm,"when calling helm template ... i get this error:
error: yaml parse error on `myfile.yaml`: error converting yaml to json: `yaml`: line 60: mapping values are not allowed in this context

i would like to know, if i can set debug options to analyze this problem.
because myfile.yaml is valid in another context with other values, it would be helpful, if i could print out the generated invalid yaml before helm tries to convert it to json.
there are options --debug and -v but these don't help.
remarks
there is another question with the same title. but that question is about a specific problem. my question is not about a specific problem. instead i would like to get general hints, how to analyze such problems.
",<kubernetes><kubernetes-helm>,64225576,2,"helm template --dry-run --debug does not validate the template/yaml.
this should print out the yaml as proposed to the kubernetes api.
"
70464136,kubectl apply ingress: unknown field error,"i have ingress as:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: mongoexpress-ingress
spec:
  rules:
  - host: mylocalmongoexpress.com
    http:
      paths:
      - backend:
          servicename: mongoexpress-service
          serviceport: 8081

when i run 'kubectl apply -f mongoexpress-ingress.yaml', i get error:

error: error validating &quot;mongoexpress-ingress.yaml&quot;: error validating
data: [validationerror(ingress.spec.rules[0].http.paths[0].backend):
unknown field &quot;servicename&quot; in
io.k8s.api.networking.v1.ingressbackend,
validationerror(ingress.spec.rules[0].http.paths[0].backend): unknown
field &quot;serviceport&quot; in io.k8s.api.networking.v1.ingressbackend,
validationerror(ingress.spec.rules[0].http.paths[0]): missing required
field &quot;pathtype&quot; in io.k8s.api.networking.v1.httpingresspath]; if you
choose to ignore these errors, turn validation off with
--validate=false

going through online resources, i couldn't find issue in yaml file.
so what am i missing here?
",<kubernetes><kubernetes-ingress><kubectl>,70464265,5,"ingress specification has changed from v1beta1 to v1. try:
...
spec:
  rules:
  - host: mylocalmongoexpress.com
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: mongoexpress-service
            port:
              number: 8081

"
63342051,"kubernetes ingress is not working , default backend 404","i'm new to kubernetes. i'm using gke managed service for k8s. there are 2 deployments nginx, httpd, and created nodeport services for those 2 deploys.
i'm trying to create ingress rule for the services. the nginx ingress controller is installed through helm. i have a domain from freenom and set the google cloud dns to use the static public ip. when i try to hit the ingress url (domain/nginx), it's giving:

&quot;default backend - 404&quot;


deployment:
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  selector:
    matchlabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx
  replicas: 1
---
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: httpd
  labels:
    name: httpd
spec:
  selector:
    matchlabels:
      app: httpd
  template:
    metadata:
      labels:
        app: httpd
    spec:
      containers:
        - name: httpd
          image: httpd
  replicas: 1

services:
apiversion: v1
kind: service
metadata:
  labels:
    name: nginx
  name: nginx-service
spec:
  ports:
  - port: 80
    protocol: tcp
    targetport: 80
  selector:
    app: nginx
  type: nodeport

same like for httpd service
ingress:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: test
  annotations:
    kubernetes.io/ingress.global-static-ip-name: testingk8s
spec:
  rules:
    - host: xyz.tk
      http: 
        paths:
          - path: /nginx
            backend:
              servicename: nginx-service
              serviceport: 80
          - path: /httpd
            backend:
              servicename: httpd-service
              serviceport: 80

ingress describe:
default backend:  default-http-backend:80 (10.48.0.7:8080)
rules:
  host           path  backends
  ----           ----  --------
  xyz.tk
                 /nginx   nginx-service:80 (10.48.0.25:80)
                 /httpd   httpd-service:80 (10.48.0.26:80)
annotations:     ingress.kubernetes.io/backends:
                   {&quot;k8s-be-30916--413d33a91e61ca5d&quot;:&quot;healthy&quot;,&quot;k8s-be-31376--413d33a91e61ca5d&quot;:&quot;healthy&quot;,&quot;k8s-be-32702--413d33a91e61ca5d&quot;:&quot;healthy&quot;}


ingress controller pod logs:
i0812 09:38:34.405188       6 event.go:278] event(v1.objectreference{kind:&quot;ingress&quot;, namespace:&quot;nginx&quot;, name:&quot;test&quot;, uid:&quot;61991dbd-a361-47d2-88cc-548a7c43e743&quot;, apiversion:&quot;networking.k8s.io/v1beta1&quot;, resourceversion:&quot;316030&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'create' ingress nginx/test
i0812 09:38:34.405815       6 controller.go:139] configuration changes detected, backend reload required.
i0812 09:38:34.532163       6 controller.go:155] backend successfully reloaded.
i0812 09:38:41.369315       6 status.go:275] updating ingress nginx/test status from [] to [{35.192.136.218 }]
i0812 09:38:41.374080       6 event.go:278] event(v1.objectreference{kind:&quot;ingress&quot;, namespace:&quot;nginx&quot;, name:&quot;test&quot;, uid:&quot;61991dbd-a361-47d2-88cc-548a7c43e743&quot;, apiversion:&quot;networking.k8s.io/v1beta1&quot;, resourceversion:&quot;316057&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'update' ingress nginx/test


",<kubernetes><google-kubernetes-engine><nginx-ingress>,63343670,5,"add annotations kubernetes.io/ingress.class: nginx and nginx.ingress.kubernetes.io/rewrite-target: /. so the ingress looks like below
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: test
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: xyz.tk
      http: 
        paths:
          - path: /nginx
            backend:
              servicename: nginx-service
              serviceport: 80
          - path: /httpd
            backend:
              servicename: httpd-service
              serviceport: 80

"
66302048,service is incorrectly selecting pod listening on some different port,"i tried the service definition example from here.
so, i created below service:
apiversion: v1
kind: service
metadata:
  name: service-simple-service
spec:
  selector:
    app: myapp
  ports:
    - protocol: tcp
      port: 80
      targetport: 9376

and then to test the concept, i created below pod:
apiversion: v1
kind: pod
metadata:
  name: service-simple-service-pod
  labels:
    app: myapp
spec:
  containers:
  - name: service-simple-service-pod-container-1
    image: nginx:alpine
    ports:
      - containerport: 9376

and i can see that a new endpoint for this pod is created, so all good till now, below is the output:
c:\users&gt;kubectl describe service/service-simple-service
name:              service-simple-service
namespace:         default
labels:            &lt;none&gt;
annotations:       &lt;none&gt;
selector:          app=myapp
type:              clusterip
ip:                10.98.246.70
port:              &lt;unset&gt;  80/tcp
targetport:        9376/tcp
endpoints:         10.244.0.8:9376
session affinity:  none
events:            &lt;none&gt;

then to test negative concept, i created below pod.
apiversion: v1
kind: pod
metadata:
  name: service-simple-service-pod-nouse
  labels:
    app: myapp
spec:
  containers:
  - name: service-simple-service-pod-nouse-container-1
    image: nginx:alpine
    ports:
      - containerport: 9378

but to my surprise this pod was also picked:
c:\users&gt;kubectl describe service/service-simple-service
name:              service-simple-service
namespace:         default
labels:            &lt;none&gt;
annotations:       &lt;none&gt;
selector:          app=myapp
type:              clusterip
ip:                10.98.246.70
port:              &lt;unset&gt;  80/tcp
targetport:        9376/tcp
endpoints:         10.244.0.10:9376,10.244.0.8:9376
session affinity:  none
events:            &lt;none&gt;

my understanding of service i created above was that scheduler will look for any pod having label as app: myapp and running on port 9376, so my expectation was that since this pod is running on port 9378 so it will not be picked up. so, my question is that why this &quot;service-simple-service-pod-nouse&quot; was picked up?
if someone says that my understanding was incorrect and service only selects pod based on label, then my question is that since &quot;service-simple-service-pod-nouse&quot; pod is listening on port 9378 then how &quot;service-simple-service&quot; service can send traffic to this pod?
",<kubernetes><google-kubernetes-engine><kubernetes-pod><kubernetes-service>,66302064,3,"sevice will picked all the pods that are labeled as the label selector of that service. service-simple-service service will select all the pods that are labeled as myapp because you tell in the service selector (app: myapp). this is the common and expected behavior of label-selector, you can see the k8s official doc
apiversion: v1
kind: service
metadata:
  name: service-simple-service
spec:
  selector:
    app: myapp
  ports:
    - protocol: tcp
      port: 80
      targetport: 9376

update
basically, a service get the requests and then it serves the traffic to the pods (those are labeled as the service selector), when a service take a pod then it opens a endpoint for that pod, when traffic comes to the service it sends those traffics in one of it endpoints(which is basically going to a pod). and the container port is basically the port inside the pod where the container is running.
"
65732355,how to map traffic from 127.0.0.1 to kubernetes ingress controller,"i am trying to install and setup kubernetes on my system without any public cloud provider.
what i tried
i am able to create services and access them through ingress controller ip
name                                 type           cluster-ip       external-ip    port(s)                      age
ingress-nginx-controller             loadbalancer   10.102.16.16     192.168.49.2   80:30548/tcp,443:31812/tcp   109m
ingress-nginx-controller-admission   clusterip      10.108.137.156   &lt;none&gt;         443/tcp                      109m

this is my ingress
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: odoo-ingress
spec:
  rules:
  - host: myservice.local.com
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: test-service
            port:
              number: 80

my hosts file contains
192.168.49.2    myservice.local.com

and i am able to access my service and deployment at myservice.local.com successfully.
what i want:
public internet --&gt; ingress controller --&gt; kubernetes services

i want that my ingress controller listen on 127.0.0.1 and in the hosts file it should be
127.0.0.1    myservice.local.com

i want this because i want to access this cluster from public internet. i am not using any public cloud provider for kubernetes.
",<nginx><kubernetes><kubernetes-ingress><nginx-ingress>,65734300,3,"minikube runs on virtual machine so in your machine there is another virtual machine with kuberentes. ingress works but only when you are on your machine. you can't access inside kubernetes because there is no proxy between your host and virtual machine.
public internet -&gt;&gt;&gt; your machine -&gt;&gt;&gt; virtual machine -&gt;&gt; ingress controller

switch to microk8s(no virtual box) or create nginx proxy on your machine and formward all requests to virtual machine with your kubernetes.
"
75800521,"failure when running cockroachdb helm chart on minikube: ""creating data directory: mkdir /cockroach/cockroach-data/auxiliary: permission denied""","when i try to run the cockroachdb on minikube v1.29.0 on fedora 37 (selinux disabled) with default parameters, 2 of 3 nodes fails with the following error:
creating data directory: mkdir /cockroach/cockroach-data/auxiliary: permission denied

i don't know if it's more related to cockroachdb, minikube or my linux system.
but if you have some information or hints, i'm all ears.
thank you !!
steps to reproduce
minikube start --cpus=2 --memory=2g --nodes=3

helm repo add cockroachdb https://charts.cockroachdb.com/
helm repo update

helm upgrade --install cockroachdb cockroachdb/cockroachdb

results
$ kubectl get all
name                         ready   status             restarts     age
pod/cockroachdb-0            0/1     crashloopbackoff   1 (8s ago)   26s
pod/cockroachdb-1            0/1     crashloopbackoff   1 (2s ago)   26s
pod/cockroachdb-2            0/1     running            0            26s
pod/cockroachdb-init-gkb2z   1/1     running            0            26s

name                         type        cluster-ip      external-ip   port(s)              age
service/cockroachdb          clusterip   none            &lt;none&gt;        26257/tcp,8080/tcp   26s
service/cockroachdb-public   clusterip   10.100.59.219   &lt;none&gt;        26257/tcp,8080/tcp   26s
service/kubernetes           clusterip   10.96.0.1       &lt;none&gt;        443/tcp              6m34s

name                           ready   age
statefulset.apps/cockroachdb   0/3     26s

name                                                  schedule       suspend   active   last schedule   age
cronjob.batch/cockroachdb-rotate-self-signer          0 0 1 */11 *   false     0        &lt;none&gt;          26s
cronjob.batch/cockroachdb-rotate-self-signer-client   0 0 */26 * *   false     0        &lt;none&gt;          26s

name                         completions   duration   age
job.batch/cockroachdb-init   0/1           26s        26s

$ kubectl get po -o wide
name                     ready   status             restarts      age   ip           node           nominated node   readiness gates
cockroachdb-0            0/1     crashloopbackoff   2 (15s ago)   52s   10.244.2.2   minikube-m03   &lt;none&gt;           &lt;none&gt;
cockroachdb-1            0/1     crashloopbackoff   2 (11s ago)   52s   10.244.1.4   minikube-m02   &lt;none&gt;           &lt;none&gt;
cockroachdb-2            0/1     running            0             52s   10.244.0.3   minikube       &lt;none&gt;           &lt;none&gt;
cockroachdb-init-gkb2z   1/1     running            0             52s   10.244.1.3   minikube-m02   &lt;none&gt;           &lt;none&gt;

$ kubectl logs cockroachdb-0
defaulted container &quot;db&quot; out of: db, copy-certs (init)
++ hostname
+ exec /cockroach/cockroach start --join=cockroachdb-0.cockroachdb.datastore.svc.cluster.local:26257,cockroachdb-1.cockroachdb.datastore.svc.cluster.local:26257,cockroachdb-2.cockroachdb.datastore.svc.cluster.local:26257 --advertise-host=cockroachdb-0.cockroachdb.datastore.svc.cluster.local --certs-dir=/cockroach/cockroach-certs/ --http-port=8080 --port=26257 --cache=25% --max-sql-memory=25% --logtostderr=info
flag --logtostderr has been deprecated, use --log instead to specify 'sinks: {stderr: {filter: ...}}'.
e230321 11:03:10.501705 1 1@cli/clierror/check.go:35  [-] 1  error: connection lost.
e230321 11:03:10.501705 1 1@cli/clierror/check.go:35  [-] 1 +creating data directory: mkdir /cockroach/cockroach-data/auxiliary: permission denied
error: connection lost.

creating data directory: mkdir /cockroach/cockroach-data/auxiliary: permission denied
failed running &quot;start&quot;

",<kubernetes><kubernetes-helm><minikube><cockroachdb>,75803953,1,"after asking chatgpt about this, he pointed that the securitycontext feature could be an issue: securitycontext should be disabled in values.yml in the helm chart as it prevents the writing of these files.
i still have a lot to learn about kube though.
"
58398526,nginx ingress controller in eks not able to route traffic to pods,"i have an eks cluster running kubernetes 1.14. i deployed the nginx controller on the cluster following these steps from the following link.

here are the steps that i followed - 


  kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml
  
  kubectl apply -f
  https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/aws/service-l4.yaml
  
  kubectl apply -f
  https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/aws/patch-configmap-l4.yaml


but i keep getting these errors intermittently in the ingress controller.

2019/10/15 15:21:25 [error] 40#40: *243746 upstream timed out (110: connection timed out) while connecting to upstream, client: 63.xxx.xx.xx, server: x.y.com, request: ""head / http/1.1"", upstream: ""http://172.20.166.58:80/"", host: ""x.y.com""


and sometimes these - 

{""log"":""2019/10/15 02:58:40 [error] 119#119: *2985 connect() failed (113: no route to host) while connecting to upstream, client: xx.1xx.81.1xx, server: a.b.com , request: \""options /api/v1/xxxx/xxxx/xxx http/2.0\"", upstream: \""http://172.20.195.137:9050/api/xxx/xxx/xxxx/xxx\ "", host: \""a.b.com \"", referrer: \""https://x.y.com/app/connections\""\n"",""stream"":""stderr"",""time"":""2019-10-15t02:58:40.565930449z ""}


i am using the native amazon vpc cni plugin for kubernetes for networking - 


  amazon-k8s-cni:v1.5.4


i noticed that a couple of replicas out of the 5 replicas of the nginx ingress controller pod were not able to talk to the backend application.
to check the connectivity between the nginx ingress controller pods and the backend applications i sshed into the nginx ingress controller pod and tried to curl the backend service and it timed out, but when i ssh into another backend service and then curl the same backend service it returns a 200 status code. the way i temporarily fixed it was by deleting the replicas that were not able to talk to the backend and recreated it. this temporarily fixed the issue but after a few hours the same errors start showing up again.
",<amazon-web-services><kubernetes><nginx-ingress><amazon-eks>,58560175,2,"amazon-k8s-cni:v1.5.4


has known issues with dns and pod to pod communication. it's recommended to revert back to

amazon-k8s-cni:v1.5.3


v1.5.4 release notes 

i had the same issues you're seeing and going back to v1.5.3 seemed to resolve it for me. i think they recently reverted the plugin back to v1.5.3 for when an eks cluster is launched anyways.
"
60890295,how to set java environment variables in a helm chart?,"what is the best practice to set environment variables for a java app's deployment in a helm chart so that i can use the same chart for dev and prod environments? i have separate kubernetes deployments for both the environments.

spec:
    containers:
        env:
           - name: system_opts
           - value: ""-dapp1.url=http://dev.app1.xyz -dapp2.url=http://dev.app2.abc ...""


similarly, my prod variables would something like 

""-dapp1.url=http://prod.app1.xyz -dapp2.url=http://prod.app2.abc ...""


now, how can i leverage helm to write a single chart but can create separated set of pods with different properties according to the environment as in

helm install my-app --set env=prod ./test-chart


or 

helm install my-app --set env=dev ./test-chart

",<kubernetes><kubernetes-helm>,60891464,3,"the best way is to use single deployment template and use separate value file for each environment.
it does not need to be only environment variable used in the application.
the same can be apply for any environment specific configuration. 

example:

deployment.yaml

spec:
    containers:
        env:
           - name: system_opts
           - value: ""{{ .values.opts }}""


values-dev.yaml

# system opts
opts: ""-dapp1.url=http://dev.app1.xyz -dapp2.url=http://dev.app2.abc ""


values-prod.yaml

# system opts
opts: ""-dapp1.url=http://prod.app1.xyz -dapp2.url=http://prod.app2.abc ""


then specify the related value file in the helm command.

for example, deploying on dev enviornemnt.

helm install -f values-dev.yaml my-app ./test-chart

"
53542898,how do i list images (tags) in a remote google cloud docker repo?,"i call this command to send my image to a repo.

docker push gcr.io/my-project/my-images:v1

it succeeds, as in fact i can apply a ""deployment"" yaml and my new service is available at gke.

my question: how do i list the images (tags) at that gcr.io repo address, to confirm that mine is there? 

docker image list gives me the local list, but not the remote list.

gcloud --project=my-project container images list gives an empty result. (yet, as stated, my  image is out there.)

how can i get this list?
",<docker><kubernetes><gcloud><google-kubernetes-engine>,53543071,4,"use --repository flag

 --repository=repository
    the name of the repository. format: *.gcr.io/repository. defaults to
    gcr.io/&lt;project&gt;, for the active project.


this example will return all the available images:

gcloud container images list --repository=gcr.io/your-project
name
gcr.io/your-project/your-image
gcr.io/your-project/another-image
gcr.io/your-project/one-more-image


if you want to list all the tags for the specified image, run

gcloud container images list-tags gcr.io/your-project/your-image
digest        tags     timestamp
0109315b26cf  5a9ad92  2018-11-15t13:24:56
98e2d1475275  343fca4  2018-11-15t11:35:52
df58b7269b89  d96aa6c  2018-11-14t17:11:18
47e93cb3a33f  7a9ff9d  2018-11-13t16:27:06

"
75325969,how can i `kubectl explain` the entire structure of a custom resource?,"i have a cr in the cluster. i know that there is a filed specialfield somewhere in this crd. i do not know where it is. right now i am randomly exploring the crd using kubectl explain path.to.some.filed to try to fiend the filed. is there some way to explain the entire nested structure using kubectl explain?
what i am looking for is something like this
kubectl explain-magic my-crd

my-crd
 a
  b
   c
 other
  field 
 more
  fields
 very 
  nested
   field

or as an alternative
my-crd
a
a.b
a.b.c
other
other.field
more
more.fields
very
very.nested
very.nested.field

",<kubernetes><kubectl>,75326074,2,"
add the --recursive flag to display all of the fields at once without descriptions. information about each field is
retrieved from the server in openapi format.

from kubectl help explain.
just do: kubectl explain --recursive my-crd
"
69277420,"eks ingress with single alb, multiple namespaces, and external dns","i'm trying to configure a single alb across multiple namespaces in aws eks, each namespace has its own  ingress resource.
i'm trying to configure the ingress controller aws-loadbalancer-controller on a k8s v1.20.
the problem i'm facing is that each time i try to deploy a new service it always spin-up a new classic loadbalancer in addition to the shared alb specified in the ingress config.
https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.2/

# service-realm1-dev.yaml:
apiversion: v1
kind: service
metadata:
  name: sentinel
  annotations:
    external-dns.alpha.kubernetes.io/hostname: realm1.dev.sentinel.mysite.io
  namespace: realm1-dev
  labels:
    run: sentinel
spec:
  ports:
    - port: 5001
      name: ps1
      protocol: tcp
  selector:
    app: sentinel
  type: loadbalancer

# ingress realm1-app
apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sentinel-ingress
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-protocol: http
    alb.ingress.kubernetes.io/healthcheck-port: traffic-port
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: &quot;15&quot;
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: &quot;5&quot;
    alb.ingress.kubernetes.io/success-codes: 200-300
    alb.ingress.kubernetes.io/healthy-threshold-count: &quot;2&quot;
    alb.ingress.kubernetes.io/unhealthy-threshold-count: &quot;2&quot;
    alb.ingress.kubernetes.io/listen-ports: '[{&quot;http&quot;:80}]'
  name: sentinel-ingress-controller
  namespace: realm1-dev
spec:
  rules:
    - host: realm1.dev.sentinel.mysite.io
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              serviceport: use-annotation
              servicename: sentinel


also i'm using external dns to create a route53 reecodset, and then i use the same configured dns to route requests to the specific eks service, is there any issue with this approach ?
",<kubernetes><kubernetes-ingress><amazon-eks>,69296982,6,"i was able to make it work using only one alb,
@yyashwanth, using nginx was my fallback plan, i'm trying to make the configuration as simple as possible, maybe in the future when we will try to deploy our solution in other cloud providers we will use nginx ingress controller.
1- to start the service type should be node port, use loadbalancer will create a classic lb.
apiversion: v1
kind: service
metadata:
  name: sentinel-srv
  annotations:
    external-dns.alpha.kubernetes.io/hostname: operatorv2.dev.sentinel.mysite.io
  namespace: operatorv2-dev
  labels:
    run: jsflow-sentinel
spec:
  ports:
    - port: 80
      targetport: 80
      name: ps1
      protocol: tcp
  selector:
    app: sentinel-app
  type: nodeport

2- second we need to configure group.name, for the ingress controller to merge all ingress configurations using the annotation alb.ingress.kubernetes.io/group.name
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  annotations:
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: &quot;15&quot;
    alb.ingress.kubernetes.io/healthcheck-path: /
    alb.ingress.kubernetes.io/healthcheck-port: traffic-port
    alb.ingress.kubernetes.io/healthcheck-protocol: http
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: &quot;5&quot;
    alb.ingress.kubernetes.io/healthy-threshold-count: &quot;2&quot;
    alb.ingress.kubernetes.io/listen-ports: '[{&quot;http&quot;: 80} ]'
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/success-codes: &quot;200&quot;
    alb.ingress.kubernetes.io/tags: createdby=aws-controller
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/unhealthy-threshold-count: &quot;2&quot;
    external-dns.alpha.kubernetes.io/hostname: operatorv2.sentinel.mysite.io
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/group.name: sentinel-group
  name: dev-operatorv2-sentinel-ingress-controller
  namespace: operatorv2-dev
spec:
  rules:
    - host: operatorv2.dev.sentinel.mysite.io
      http:
        paths:
          - path: /*
            backend:
              serviceport: 80
              servicename: sentinel-srv


"
72102294,how to run a kubernetes cronjob with modified values at runtime,"so i have a kubernetes cronjob object set to run periodically.
name                            schedule       suspend   active   last schedule   age
ticketing-job-lifetime-manager  45 */4 * * *   false     0        174m            25d

and i know how to call it manually:
# ticketing-job-manual-call will be the name of the job that runs
kubectl create job --from=cronjobs/ticketing-job-lifetime-manager ticketing-job-manual-call

but - what i want to do is call the job, but modify portions of it (shown below) before it is called.  specifically items.metadata.annotations and items.spec.jobtemplate.spec.containers.args.
if this is possible on-the-fly, i'd be over the moon.  if it requires creating a temporary object, then i'd appreciate an approach to doing this that is robust, performant - and safe.  thanks!
    apiversion: v1
    items:
      - apiversion: batch/v1
        kind: cronjob
        metadata:
          annotations:
            &lt;annotation-1&gt;              &lt;- want to modify these
            &lt;annotation-2&gt;
            ..
            &lt;annotation-n&gt;
          creationtimestamp: &quot;2022-05-03t13:24:49z&quot;
          labels:
            accountid: foo
            fooserviceaction: &quot;true&quot;
            fooservicemanaged: &quot;true&quot;
            cronname: foo
          name: foo
          namespace: my-namespace
          resourceversion: &quot;298013999&quot;
          uid: 57b2-4612-88ef-a0d5e26c8
        spec:
          concurrencypolicy: replace
          jobtemplate:
            metadata:
              annotations:
                &lt;annotation-1&gt;          &lt;- want to modify these
                &lt;annotation-2&gt;
                ..
                &lt;annotation-n&gt;
              creationtimestamp: null
              labels:
                accountid: 7761777c38d93b
                ticketserviceaction: &quot;true&quot;
                ticketservicemanaged: &quot;true&quot;
                cronname: ticketing-actions-7761777c38d93b-0
              name: ticketing-actions-7761777c38d93b-0
              namespace: rias
            spec:
              containers:
                - args:
                    - --accountid=something     &lt;- want to modify these
                    - --faultzone=something
                    - --type=something
                    - --cronjobname=something
                    - --plans=something
                  command:
                    - ./ticketing-job
                  env:
                    - name: foo_bar             &lt;- may want to modify these
                      value: &quot;false&quot;
                    - name: foo_baz
                      value: &quot;true&quot;

",<kubernetes><kubectl><kubernetes-cronjob>,72107579,2,"the way to think about this is that kubernetes resources are defined (definitively) by yaml|json config files. a useful advantage to having config files is that these can be checked into source control; you automatically audit your work if you create unique files for each resource (for every change).
kubernetes (kubectl) isn't optimized|designed to tweak resources although you can use kubectl patch to update deployed resources.
i encourage you to consider a better approach that is applicable to any kubernetes resource (not just job's) and this focuses on use yaml|json files as the way to represent state:

kubectl get the resource and output it as yaml|json (--output=json|yaml) persisting the result to a file (that could be source-controlled)
mutate the file using any of many tools but preferably yaml|json processing tools (e.g. yq or jq)
kubectl create or kubectl apply the file that results that reflects the intended configuration of the new resource.

by way of example, assuming you use jq:
# output 'ticketing-job-lifetime-manage' as a json file
kubectl get job/ticketing-job-lifetime-manage \
--namespace=${namespace} \
--output=json &gt; ${pwd}/ticketing-job-lifetime-manage.json

# e.g. replace '.metadata.annotations' entirely
jq '.metadata.annotations=[{&quot;foo&quot;:&quot;x&quot;},{&quot;bar&quot;:&quot;y&quot;}]' \
${pwd}/${pwd}/ticketing-job-lifetime-manage.json \
&gt; ${pwd}/${pwd}/new-job.json

# e.g. replace a specific container 'foo' specific 'args' key with value
jq '.spec.jobtemplate.spec.containers[]|select(.name==&quot;foo&quot;).args[&quot;--key&quot;]=&quot;value&quot; \
${pwd}/${pwd}/new-job.json \
&gt; ${pwd}/${pwd}/new-job.json

# etc.

# apply
kubectl create \
--filename=${pwd}/new-job.json \
--namespace=${namespace}


note you can pipe the output from the kubectl get through jq and into kubectl create if you wish but it's useful to keep a file-based record of the resource.

having to deal with yaml|json config file is a common issue with kubernetes (and every other technology that uses them). there are other tools e.g. jsonnet and cue that try to provide a more programmatic way to manage yaml|json.
"
70163713,k8s ingress resource does not add original url prefix to location response header,"i'm unable to specify an ingress resource correctly so that an app's location header is rewritten to include the original url path in front.
using config:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-fanout-namespace-xyz
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  namespace: namespace-xyz
spec:
  ingressclassname: nginx
  rules:
    - http:
        paths:
          - path: /analytics/spark/master(/|$)(.*)
            pathtype: prefix
            backend:
              service:
                name: spark-master-svc
                port:
                  number: 80
          - path: /analytics/jupyter/lab(/|$)(.*)
            pathtype: prefix
            backend:
              service:
                name: jupyter-proxy-public
                port:
                  number: 80

request url: https://xx-xx.yyy.elb.amazonaws.com/analytics/jupyter/lab/
response header: location: /hub/
redirects to https://xx-xx.yyy.elb.amazonaws.com/hub/, 404s.
this should instead send redirect for location: /analytics/jupyter/lab/
this seems to be what add-base-url was for, which is now deprecated. what is the proper replacement and how can i effectively make the location become /analytics/jupyter/lab/hub/ ?

if i remove rewrite-target altogether, then http://xx-xx.yyy.elb.amazonaws.com/analytics/jupyter/lab/ does not redirect at all, it just 404s.

info:
nginx ingress controller version:
-------------------------------------------------------------------------------
nginx ingress controller
  release:       v1.0.5
  build:         7ce96cbcf668f94a0d1ee0a674e96002948bff6f
  repository:    https://github.com/kubernetes/ingress-nginx
  nginx version: nginx/1.19.9

-------------------------------------------------------------------------------

kubernetes version (use kubectl version):
client version: version.info{major:&quot;1&quot;, minor:&quot;21+&quot;, gitversion:&quot;v1.21.2-13+d2965f0db10712&quot;, gitcommit:&quot;d2965f0db1071203c6f5bc662c2827c71fc8b20d&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-06-26t01:02:11z&quot;, goversion:&quot;go1.16.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;21+&quot;, gitversion:&quot;v1.21.2-eks-0389ca3&quot;, gitcommit:&quot;8a4e27b9d88142bbdd21b997b532eb6d493df6d2&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-07-31t01:34:46z&quot;, goversion:&quot;go1.16.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}

environment:

aws eks
amazon linux 2

ingress-nginx-controller was installed thorugh argocd / helm with version info shown above and no values overridden.
$ kubectl describe ingressclasses
name:         nginx
labels:       app.kubernetes.io/component=controller
              app.kubernetes.io/instance=ingress-controller
              app.kubernetes.io/managed-by=helm
              app.kubernetes.io/name=ingress-nginx
              app.kubernetes.io/version=1.0.5
              helm.sh/chart=ingress-nginx-4.0.9
annotations:  &lt;none&gt;
controller:   k8s.io/ingress-nginx
events:       &lt;none&gt;

",<nginx><kubernetes><reverse-proxy><kubernetes-ingress><nginx-ingress>,70170443,1,"jupyter-proxy needs its base_url to be set for the workload behind that service. now it's unaware of the fact it is being served from a sub path, so when it send the redirect it sends as if it was (and actually is) served from the root url.
a quick test showed that
helm install my-jupyterhub jupyterhub/jupyterhub -n jupyterhub \
--create-namespace \
--set hub.baseurl=&quot;/analytics/jupyter/lab&quot; \
--set ingress.enabled=true \
--set ingress.pathtype=&quot;implementationspecific&quot; \
--set proxy.service.type=nodeport \
--set ingress.annotations.'kubernetes\.io/ingress\.class'=nginx

deployed jupyter hub for me with ingress and i was able to access it via &lt;x.x.x.x&gt;/analytics/jupyter/lab/
"
74353385,"setting environment variables in kubernetes manifest using ""kubectl set env""","i am trying to update a helm-deployed deployment so that it uses a secret stored as a k8s secret resource.  this must be set as the storage_password environment variable in my pod.
in my case, the secret is in secrets/redis and the data item is redis-password:

$ kubectl get secret/redis -oyaml
apiversion: v1
data:
  redis-password: xxxxxxxxxxxxxxxx=
kind: secret
metadata:
  name: redis
type: opaque

i have tried:

$ kubectl set env --from secret/redis deployment/gateway --keys=redis-password
warning: key redis-password transferred to redis_password
deployment.apps/gateway env updated

when i look in my updated deployment manifest, i see the variable has been added but (as suggested) the variable has been set to redis_password:

        - name: redis_password
          valuefrom:
            secretkeyref:
              key: redis-password
              name: redis


i have also tried kubectl patch with a replace operation, but i can't get the syntax correct to have the secret inserted.
how do i change the name of the environment variable to storage_password?
",<kubernetes><kubectl><kubernetes-secrets><kubernetes-deployment>,74354981,3,"given a deployment that looks like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: example
spec:
  replicas: 1
  template:
    spec:
      containers:
        - image: alpinelinux/darkhttpd
          name: darkhttpd
          args:
            - --port
            - &quot;9991&quot;
          ports:
            - name: http
              protocol: tcp
              containerport: 9991
          env:
            - name: example_var
              value: example value

the syntax for patching in your secret would look like:
kubectl patch deploy/example --patch='
  {
    &quot;spec&quot;: {
      &quot;template&quot;: {
        &quot;spec&quot;: {
          &quot;containers&quot;: [
            {
              &quot;name&quot;: &quot;darkhttpd&quot;,
              &quot;env&quot;: [
                {
                  &quot;name&quot;: &quot;storage_password&quot;,
                  &quot;valuefrom&quot;: {
                    &quot;secretkeyref&quot;: {
                      &quot;name&quot;: &quot;redis&quot;,
                      &quot;key&quot;: &quot;redis-password&quot;
                    }
                  }
                }
              ]
            }
          ]
        }
      }
    }
  }
'

or using a jsonpatch style patch:
kubectl patch --type json deploy/example --patch='
[
  {
    &quot;op&quot;: &quot;add&quot;,
    &quot;path&quot;: &quot;/spec/template/spec/containers/0/env/-&quot;,
    &quot;value&quot;: {
      &quot;name&quot;: &quot;storage_password&quot;,
      &quot;valuefrom&quot;: {
        &quot;secretkeyref&quot;: {
          &quot;name&quot;: &quot;redis&quot;,
          &quot;key&quot;: &quot;redis-password&quot;
        }
      }
    }
  }
]
'

neither one is especially pretty because you're adding a complex nested structure to an existing complex nested structure.
"
51874503,kubernetes ingress network deny some paths,"i've a simple kubernetes ingress network.

i need deny the access some critical paths like /admin or etc.

my ingress network file shown as below.

 apiversion: extensions/v1beta1
 kind: ingress
 metadata:
 name: ingress-test
 spec:
   rules:
   - host: host.host.com
   http:
      paths:
        - path: /service-mapping
      backend:
         servicename: /service-mapping
         serviceport: 9042


how i can deny the custom path with kubernetes ingress network, with nginx annonations or another methods . 



i handle this issue with annotations shown as below . 

apiversion: extensions/v1beta1
kind: ingress
metadata:
   name: nginx-configuration-snippet
   annotations:
      nginx.ingress.kubernetes.io/configuration-snippet: |

     server_tokens off;
     location danger-path {
    deny all;
    return 403;
  }

spec:
  rules:
   - host: api.myhost.com
   http:
  paths:
  - backend:
      servicename: bookapi-2
      serviceport: 8080
    path: path 

",<nginx><kubernetes><kubernetes-ingress>,51894604,10,"i’ve faced the same issue and found the solution on github.
to achieve your goal, you need to create two ingresses first by default without any restriction:

apiversion: extensions/v1beta1
 kind: ingress
 metadata:
 name: ingress-test
 spec:
   rules:
   - host: host.host.com
   http:
      paths:
        - path: /service-mapping
      backend:
         servicename: /service-mapping
         serviceport: 9042


then, create a secret for auth as described in the doc:

creating the htpasswd

$ htpasswd -c auth foo
new password: &lt;bar&gt;
new password:
re-type new password:
adding password for user foo


creating the secret:

$ kubectl create secret generic basic-auth --from-file=auth
secret ""basic-auth"" created


second ingress with auth for paths which you need to restrict:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-with-auth
  annotations:
    # type of authentication
    nginx.ingress.kubernetes.io/auth-type: basic
    # name of the secret that contains the user/password definitions
    nginx.ingress.kubernetes.io/auth-secret: basic-auth
    # message to display with an appropiate context why the authentication is required
    nginx.ingress.kubernetes.io/auth-realm: ""authentication required - foo""
spec:
  rules:
  - host: host.host.com
    http:
      paths:
      - path: /admin
        backend:
          servicename: service_name
          serviceport: 80


according to sedooe answer, his solution may have some issues.
"
50762250,how to patch a deployed ingress resource on kubernetes?,"i have the following ingress resource:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: main-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/force-ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/proxy-read-timeout: ""86400""
    nginx.ingress.kubernetes.io/proxy-send-timeout: ""86400""

spec:
  tls:
  - secretname: the-secret
    hosts:
      - sample.domain.com
      - sample2.domain.com
      - rabbit.domain.com
      - hub.domain.com
      - grafana.domain.com

  rules:

  - host: sample.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: fe-srvc
          serviceport: 80
      - path: /api
        backend:
          servicename: be-srvc
          serviceport: 80

  - host: sample2.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: fe2-srvc
          serviceport: 80
      - path: /api
        backend:
          servicename: be-srvc
          serviceport: 80

## the extra services ###
  - host: rabbit.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: rabbitmq-srvc
          serviceport: 80


and i want to patch it after it is deployed.

so i use this, to try and replace the be-srvc value with some-srvc :

kubectl patch ing/main-ingress --patch '{ ""spec"" : { ""rules"": [{""http"":{""paths"":[ {""- path"":""/""},{""backend"":{""servicename"":""other-srvc""}},{""serviceport"":""80""} ] }}]}}'


and i get this error:

the ingress ""main-ingress"" is invalid:
* spec.rules[0].http.backend.servicename: required value
* spec.rules[0].http.backend.serviceport: invalid value: 0: must be between 1 and 65535, inclusive


any insight would be appreciated!
",<kubernetes><kubectl><kubernetes-ingress>,50766104,18,"your patch has a number of problems; for example ""- path"" instead of ""path"" but also incorrect referencing of object levels. however, even if you fixed the mistakes this would not work as intended. let's see why.

kubectl patch is a request for a strategic merge patch. when patching arrays, like the .spec.rules and .spec.rules.http.paths in this case, a strategic merge patch can use the defined patch type and merge patch merge key for the object to do the right thing. however, in case of the ingress object no one bothered to define these. this means that any patch will overwrite the entire object; it will not be a nice merge that one is hoping for.

to accomplish the particular change referred to in the question you can do:

kubectl get ing/main-ingress -o json \ 
  | jq '(.spec.rules[].http.paths[].backend.servicename | select(. == ""be-srvc"")) |= ""some-srvc""' \
  | kubectl apply -f -


the above will change all occurrences of the be-srvc service to some-srvc. keep in mind that there is a short race condition here: if the ingress is modified after kubectl get ran the change will fail with the error operation cannot be fulfilled on ingresses.extensions ""xx"": the object has been modified; to handle that case you need implement a retry logic.

if the indexes are known in the arrays mentioned above you can accomplish the patch directly:

kubectl patch ing/main-ingress --type=json \
  -p='[{""op"": ""replace"", ""path"": ""/spec/rules/0/http/paths/1/backend/servicename"", ""value"":""some-srvc""}]'
kubectl patch ing/main-ingress --type=json \
  -p='[{""op"": ""replace"", ""path"": ""/spec/rules/1/http/paths/1/backend/servicename"", ""value"":""some-srvc""}]'


the two commands above will change the backends for sample.domain.com/api and sample2.domain.com/api to some-srvc.

the two commands can also be combined like this:

kubectl patch ing/main-ingress --type=json \
  -p='[{""op"": ""replace"", ""path"": ""/spec/rules/0/http/paths/1/backend/servicename"", ""value"":""some-srvc""}, {""op"": ""replace"", ""path"": ""/spec/rules/1/http/paths/1/backend/servicename"", ""value"":""some-srvc""}]'


this has the same effect and as an added bonus there is no race condition here; the patch guaranteed to be atomic.
"
50020701,kubernetes secret tls certificate p12 and spring boot deployment doesn't work,"i'm currently stuck and don`t know how to proceed.

this is my spring boot application.properties

...
spring.datasource.driverclassname=org.postgresql.driver
spring.datasource.url=jdbc:postgresql://${postgres_host}:5432/postgres
spring.datasource.username=${postgres_user}
spring.datasource.password=${postgres_password}
spring.datasource.testwhileidle=true
spring.datasource.validationquery=select 1
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=update
spring.jpa.hibernate.naming-strategy=org.hibernate.cfg.improvednamingstrategy
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.postgresqldialect

#setup ssl
server.port: 8443
server.ssl.key-store: ${tls_certificate}
server.ssl.key-store-password: ${tls_password}
server.ssl.keystoretype: pkcs12
server.ssl.keyalias fundtr
...


my deployment yaml for spring boot application:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: f-app
  namespace: default
spec:
  replicas: 1
  template:
    metadata:
      name: f-app
      labels:
        app: f-app
    spec:
      containers:
      - name: f-app
        image: eu.gcr.io/..../...
        env:
          - name: postgres_user
            valuefrom:
              configmapkeyref:
                name: postgres-config
                key: postgres_user
          - name: postgres_password
            valuefrom:
              configmapkeyref:
                name: postgres-config
                key: postgres_password
          - name: postgres_host
            valuefrom:
              configmapkeyref:
                name: hostname-config
                key: postgres_host
          - name: tls-certificate
            valuefrom:
              secretkeyref:
                name: f-tls
                key: certificate.p12
          - name: tls-password
            valuefrom:
              secretkeyref:
                name: f-tls
                key: password


this is how i create secret in kubernetes:

kubectl create secret generic f-tls --from-file=certificate.p12 --from-literal=password=changeit


when it's deployed i'm getting 

state:         waiting
  reason:      crashloopbackoff
last state:    terminated
  reason:      containercannotrun
  message:     oci runtime error: container_linux.go:247: starting container process caused ""process_linux.go:295: setting oom score for ready process caused \""write /proc/13895/oom_score_adj: invalid argument\""""


when i remove the secrets from the deployment yaml it's working fine, but i could not understand what it the root cause of this issue. i'm using google cloud platform container engine.
",<spring-boot><kubernetes><google-kubernetes-engine><kubernetes-secrets><kubernetes-deployment>,67239263,5,"this answer is specific to springboot application and that is what asked in question.
step 1: create a generic secret from your keystore or p12 file
kubectl create secret generic f-tls-secret --from-file=certificate.p12 --from-literal=password=changeit

step 2: mount the secret to your pod using deployment object
spec:
  containers:
  - image: eu.gcr.io/..../...
    volumemounts:
      - name: tls
        mountpath: /workspace/resources/

  volumes:
    - name: tls
      secret: 
        secretname: f-tls-secret


configure ssl in application.properties file


#setup ssl
 server.port: 8443
 server.ssl.key-store: classpath:resources/certificate.p12
 server.ssl.key-store-password: ${tls_password}
 server.ssl.keystoretype: pkcs12
 server.ssl.keyalias fundtr


"
70955363,how to delete single pod in kubernetes permanently,"i want to delete single pod of kubernetes permanently but it will recreate that pod
i have tried many commands but it doesn't help me.
1. kubectl delete pod &lt;pod-name&gt;

2nd
kubectl get deployments

kubectl delete deployments &lt;deployments- name&gt;

kubectl get rs --all-namespaces
kubectl delete rs your_app_name


but none of that works
",<amazon-web-services><kubernetes><kubernetes-pod>,70957424,3,"my replica count is 0
...it will successfully delete the pod but then after it will restart
try:
apiversion: v1
kind: pod
metadata:
  name: ...
spec:
  restartpolicy: never  # &lt;-- add this
  containers:
  - name: ...

if the pod still restart, post output of kubectl describe pod &lt;pod name&gt; --namespace &lt;name&gt; to your question.
"
66740340,kubernetes deployment podname setting,"apiversion: apps/v1
kind: deployment
metadata:
  name: test-deployment
  labels:
    app: test
spec:
  replicas: 1
  selector:
    matchlabels:
      app: test
  template:
    metadata:
      name: test
      labels:
        app: test
    spec:
      containers:
        - name: server
          image: test_ml_server:2.3
          ports:
            - containerport: 8080
          volumemounts:
            - name: hostpath-vol-testserver
              mountpath: /app/test/api
#          env:
#            - name: pod_name
#              valuefrom:
#                fieldref:
#                  fieldpath: template.metadata.name
        - name: testdb
          image: test_db:1.4
          ports:
            - name: testdb
              containerport: 1433
          volumemounts:
            - name: hostpath-vol-testdb
              mountpath: /var/opt/mssql/data
#          env:
#            - name: pod_name
#              valuefrom:
#                fieldref:
#                  fieldpath: template.metadata.name
      volumes:
        - name: hostpath-vol-testserver
          hostpath:
            path: /usr/testhostpath/testserver
        - name: hostpath-vol-testdb
          hostpath:
            path: /usr/testhostpath/testdb

i want to set the name of the pod because it communicates internally based on the name of the pod
but when a pod is created, it cannot be used because the variable name is appended to the end.
how can i set the pod name?
",<kubernetes><rancher><kubernetes-deployment>,66740371,1,"it's better if you use, statefulset instead of deployment. statefulset's pod name will be like &lt;statefulsetname-0&gt;,&lt;statefulsetname-1&gt;... and you will need a clusterip service. with which you can bound your pods. see the doc for more details. ref
apiversion: v1
kind: service
metadata:
  name: test-svc
  labels:
    app: test
spec:
  ports:
  - port: 8080
    name: web
  clusterip: none
  selector:
    app: test

apiversion: apps/v1
kind: statefulset
metadata:
  name: test-statefulset
  labels:
    app: test
spec:
  replicas: 1
  servicename: test-svc
  selector:
    matchlabels:
      app: test
  template:
    metadata:
      name: test
      labels:
        app: test
    spec:
      containers:
        - name: server
          image: test_ml_server:2.3
          ports:
            - containerport: 8080
          volumemounts:
            - name: hostpath-vol-testserver
              mountpath: /app/test/api
        - name: testdb
          image: test_db:1.4
          ports:
            - name: testdb
              containerport: 1433
          volumemounts:
            - name: hostpath-vol-testdb
              mountpath: /var/opt/mssql/data
      volumes:
        - name: hostpath-vol-testserver
          hostpath:
            path: /usr/testhostpath/testserver
        - name: hostpath-vol-testdb
          hostpath:
            path: /usr/testhostpath/testdb

here, the pod name will be like this test-statefulset-0.
"
56862054,kubernetes ingress does not work with traefisk,"i created a kubernetes cluster in google cloud platform, after that, i installed helm/tiller on cluster, and after, i installed traefik with helm like oficial documentation says to do.

now i'm trying to create an ingress for a service, but if i put the annotation kubernetes.io/ingress.class: traefik, the load balancer for ingress is not created.
but without the annotation, it works with default ingress.
(the service type is nodeport)

edit: i also tried this example in a clean google cloud kubernetes cluster: https://supergiant.io/blog/using-traefik-as-ingress-controller-for-your-kubernetes-cluster/ but its the same, when i chose kubernetes.io/ingress.class: traefik, won't be created a load balancer for ingress.

my files are:
animals-svc.yaml:

---
apiversion: v1
kind: service
metadata:
  name: bear
spec:
  type: nodeport
  ports:
  - name: http
    targetport: 80
    port: 80
  selector:
    app: animals
    task: bear
---
apiversion: v1
kind: service
metadata:
  name: moose
spec:
  type: nodeport
  ports:
  - name: http
    targetport: 80
    port: 80
  selector:
    app: animals
    task: moose
---
apiversion: v1
kind: service
metadata:
  name: hare
  annotations:
    traefik.backend.circuitbreaker: ""networkerrorratio() &gt; 0.5""
spec:
  type: nodeport
  ports:
  - name: http
    targetport: 80
    port: 80
  selector:
    app: animals
    task: hare


animals-ingress.yaml:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: animals
  annotations:
    kubernetes.io/ingress.class: traefik
    # kubernetes.io/ingress.global-static-ip-name: ""my-reserved-global-ip""
    # traefik.ingress.kubernetes.io/frontend-entry-points: http
    # traefik.ingress.kubernetes.io/redirect-entry-point: http
    # traefik.ingress.kubernetes.io/redirect-permanent: ""true""
spec:
  rules:
  - host: hare.minikube
    http:
      paths:
      - path: /
        backend:
          servicename: hare
          serviceport: http
  - host: bear.minikube
    http:
      paths:
      - path: /
        backend:
          servicename: bear
          serviceport: http
  - host: moose.minikube
    http:
      paths:
      - path: /
        backend:
          servicename: moose
          serviceport: http


animals-deployment.yaml:

---
kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: bear
  labels:
    app: animals
    animal: bear
spec:
  replicas: 2
  selector:
    matchlabels:
      app: animals
      task: bear
  template:
    metadata:
      labels:
        app: animals
        task: bear
        version: v0.0.1
    spec:
      containers:
      - name: bear
        image: supergiantkir/animals:bear
        ports:
        - containerport: 80
---
kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: moose
  labels:
    app: animals
    animal: moose
spec:
  replicas: 2
  selector:
    matchlabels:
      app: animals
      task: moose
  template:
    metadata:
      labels:
        app: animals
        task: moose
        version: v0.0.1
    spec:
      containers:
      - name: moose
        image: supergiantkir/animals:moose
        ports:
        - containerport: 80
---
kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: hare
  labels:
    app: animals
    animal: hare
spec:
  replicas: 2
  selector:
    matchlabels:
      app: animals
      task: hare
  template:
    metadata:
      labels:
        app: animals
        task: hare
        version: v0.0.1
    spec:
      containers:
      - name: hare
        image: supergiantkir/animals:hare
        ports:
        - containerport: 80


the services are created, but the ingress loadbalancer is not created:



but, if i remove the line kubernetes.io/ingress.class: traefik it works with the default ingress of kubernetes
",<kubernetes><kubernetes-ingress>,56871788,1,"traefik does not create a load balancer for you by default.

as http(s) load balancing with ingress documentation mention:


  when you create an ingress object, the gke ingress controller creates
  a google cloud platform http(s) load balancer and configures it
  according to the information in the ingress and its associated
  services.


this is all applicable for  gke ingress controller(gce) - more info about gce you can find here: https://github.com/kubernetes/ingress-gce

if you would like to use traefik as ingress  - you have to  expose traefik service with type: loadbalancer

example:

apiversion: v1
kind: service
metadata:
  name: traefik
spec:
  type: loadbalancer
  selector:
    k8s-app: traefik-ingress-lb
  ports:
  - port: 80
    targetport: 80


more info with a lot of explanation diagrams and real working example you can find in the exposing kubernetes services to the internet using traefik ingress controller article.

hope this help.
"
60812042,rabbitmq fails to start after restart kubernetes cluster,"i'm running rabbitmq on kubernetes. this is my sts yaml file:

apiversion: v1
kind: service
metadata:
  name: rabbitmq-management
  labels:
    app: rabbitmq
spec:
  ports:
  - port: 15672
    name: http
  selector:
    app: rabbitmq
  type: nodeport
---
apiversion: v1
kind: service
metadata:
  name: rabbitmq
  labels:
    app: rabbitmq
spec:
  ports:
  - port: 5672
    name: amqp
  - port: 4369
    name: epmd
  - port: 25672
    name: rabbitmq-dist
  - port: 61613
    name: stomp
  clusterip: none
  selector:
    app: rabbitmq
---
apiversion: apps/v1
kind: statefulset
metadata:
  name: rabbitmq
spec:
  servicename: ""rabbitmq""
  replicas: 3
  selector:
    matchlabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
    spec:
      containers:
      - name: rabbitmq
        image: rabbitmq:management-alpine
        lifecycle:
          poststart:
            exec:
              command:
              - /bin/sh
              - -c
              - &gt;
                rabbitmq-plugins enable rabbitmq_stomp;
                if [ -z ""$(grep rabbitmq /etc/resolv.conf)"" ]; then
                  sed ""s/^search \([^ ]\+\)/search rabbitmq.\1 \1/"" /etc/resolv.conf &gt; /etc/resolv.conf.new;
                  cat /etc/resolv.conf.new &gt; /etc/resolv.conf;
                  rm /etc/resolv.conf.new;
                fi;
                until rabbitmqctl node_health_check; do sleep 1; done;
                if [[ ""$hostname"" != ""rabbitmq-0"" &amp;&amp; -z ""$(rabbitmqctl cluster_status | grep rabbitmq-0)"" ]]; then
                  rabbitmqctl stop_app;
                  rabbitmqctl join_cluster rabbit@rabbitmq-0;
                  rabbitmqctl start_app;
                fi;
                rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""exactly"",""ha-params"":3,""ha-sync-mode"":""automatic""}'
        env:
        - name: rabbitmq_erlang_cookie
          valuefrom:
            secretkeyref:
              name: rabbitmq-config
              key: erlang-cookie
        ports:
        - containerport: 5672
          name: amqp
        - containerport: 61613
          name: stomp
        volumemounts:
        - name: rabbitmq
          mountpath: /var/lib/rabbitmq
  volumeclaimtemplates:
  - metadata:
      name: rabbitmq
      annotations:
        volume.alpha.kubernetes.io/storage-class: do-block-storage
    spec:
      accessmodes: [ ""readwriteonce"" ]
      resources:
        requests:
          storage: 10gi


and i created the cookie with this command:

kubectl create secret generic rabbitmq-config --from-literal=erlang-cookie=c-is-for-cookie-thats-good-enough-for-me


all of my kubernetes cluster nodes are ready:

kubectl get nodes
name                 status   roles    age   version
kubernetes-master    ready    master   14d   v1.17.3
kubernetes-slave-1   ready    &lt;none&gt;   14d   v1.17.3
kubernetes-slave-2   ready    &lt;none&gt;   14d   v1.17.3


but after restarting the cluster, the rabbitmq didn't start. i tried to scale down and up the sts but the problem already exist. the output of kubectl describe pod rabbitmq-0:

kubectl describe pod rabbitmq-0
name:         rabbitmq-0
namespace:    default
priority:     0
node:         kubernetes-slave-1/192.168.0.179
start time:   tue, 24 mar 2020 22:31:04 +0000
labels:       app=rabbitmq
              controller-revision-hash=rabbitmq-6748869f4b
              statefulset.kubernetes.io/pod-name=rabbitmq-0
annotations:  &lt;none&gt;
status:       running
ip:           10.244.1.163
ips:
  ip:           10.244.1.163
controlled by:  statefulset/rabbitmq
containers:
  rabbitmq:
    container id:  docker://d5108f818525030b4fdb548eb40f0dc000dd2cec473ebf8cead315116e3efbd3
    image:         rabbitmq:management-alpine
    image id:      docker-pullable://rabbitmq@sha256:6f7c8d01d55147713379f5ca26e3f20eca63eb3618c263b12440b31c697ee5a5
    ports:         5672/tcp, 61613/tcp
    host ports:    0/tcp, 0/tcp
    state:         waiting
      reason:      poststarthookerror: command '/bin/sh -c rabbitmq-plugins enable rabbitmq_stomp; if [ -z ""$(grep rabbitmq /etc/resolv.conf)"" ]; then
  sed ""s/^search \([^ ]\+\)/search rabbitmq.\1 \1/"" /etc/resolv.conf &gt; /etc/resolv.conf.new;
  cat /etc/resolv.conf.new &gt; /etc/resolv.conf;
  rm /etc/resolv.conf.new;
fi; until rabbitmqctl node_health_check; do sleep 1; done; if [[ ""$hostname"" != ""rabbitmq-0"" &amp;&amp; -z ""$(rabbitmqctl cluster_status | grep rabbitmq-0)"" ]]; then
  rabbitmqctl stop_app;
  rabbitmqctl join_cluster rabbit@rabbitmq-0;
  rabbitmqctl start_app;
fi; rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""exactly"",""ha-params"":3,""ha-sync-mode"":""automatic""}'
' exited with 137: error: unable to perform an operation on node 'rabbit@rabbitmq-0'. please see diagnostics information and suggestions below.

most common reasons for this are:

 * target node is unreachable (e.g. due to hostname resolution, tcp connection or firewall issues)
 * cli tool fails to authenticate with the server (e.g. due to cli tool's erlang cookie not matching that of the server)
 * target node is not running

in addition to the diagnostics info below:

 * see the cli, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more
 * consult server logs on node rabbit@rabbitmq-0
 * if target node is configured to use long node names, don't forget to use --longnames with cli tools


diagnostics
===========

attempted to contact: ['rabbit@rabbitmq-0']

rabbit@rabbitmq-0:
  * connected to epmd (port 4369) on rabbitmq-0
  * epmd reports: node 'rabbit' not running at all
                  no other nodes on rabbitmq-0
  * suggestion: start the node

current node details:
 * node name: 'rabbitmqcli-575-rabbit@rabbitmq-0'
 * effective user's home directory: /var/lib/rabbitmq
 * erlang cookie hash: p1xnoe5pn3ug2fcrfzh7xg==

error: this command requires the 'rabbit' app to be running on the target node. start it with 'rabbitmqctl start_app'.
arguments given:
  node_health_check

usage

rabbitmqctl [--node &lt;node&gt;] [--longnames] [--quiet] node_health_check [--timeout &lt;timeout&gt;]
error:
{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :""$1"", :_, :_}, [], [:""$1""]}]]}}

diagnostics
===========

attempted to contact: ['rabbit@rabbitmq-0']

rabbit@rabbitmq-0:
  * connected to epmd (port 4369) on rabbitmq-0
  * epmd reports: node 'rabbit' not running at all
                  no other nodes on rabbitmq-0
  * suggestion: start the node

current node details:
 * node name: 'rabbitmqcli-10397-rabbit@rabbitmq-0'
 * effective user's home directory: /var/lib/rabbitmq
 * erlang cookie hash: p1xnoe5pn3ug2fcrfzh7xg==


    last state:     terminated
      reason:       completed
      exit code:    0
      started:      tue, 24 mar 2020 22:46:09 +0000
      finished:     tue, 24 mar 2020 22:58:28 +0000
    ready:          false
    restart count:  1
    environment:
      rabbitmq_erlang_cookie:  &lt;set to the key 'erlang-cookie' in secret 'rabbitmq-config'&gt;  optional: false
    mounts:
      /var/lib/rabbitmq from rabbitmq (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-bbl9c (ro)
conditions:
  type              status
  initialized       true
  ready             false
  containersready   false
  podscheduled      true
volumes:
  rabbitmq:
    type:       persistentvolumeclaim (a reference to a persistentvolumeclaim in the same namespace)
    claimname:  rabbitmq-rabbitmq-0
    readonly:   false
  default-token-bbl9c:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-bbl9c
    optional:    false
qos class:       besteffort
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason                  age                  from                         message
  ----     ------                  ----                 ----                         -------
  normal   scheduled               31m                  default-scheduler            successfully assigned default/rabbitmq-0 to kubernetes-slave-1
  normal   pulled                  31m                  kubelet, kubernetes-slave-1  container image ""rabbitmq:management-alpine"" already present on machine
  normal   created                 31m                  kubelet, kubernetes-slave-1  created container rabbitmq
  normal   started                 31m                  kubelet, kubernetes-slave-1  started container rabbitmq
   normal   sandboxchanged          16m (x9 over 17m)    kubelet, kubernetes-slave-1  pod sandbox changed, it will be killed and re-created.
  normal   pulled                  3m58s (x2 over 16m)  kubelet, kubernetes-slave-1  container image ""rabbitmq:management-alpine"" already present on machine
  warning  failedpoststarthook     3m58s                kubelet, kubernetes-slave-1  exec lifecycle hook ([/bin/sh -c rabbitmq-plugins enable rabbitmq_stomp; if [ -z ""$(grep rabbitmq /etc/resolv.conf)"" ]; then
  sed ""s/^search \([^ ]\+\)/search rabbitmq.\1 \1/"" /etc/resolv.conf &gt; /etc/resolv.conf.new;
  cat /etc/resolv.conf.new &gt; /etc/resolv.conf;
  rm /etc/resolv.conf.new;
fi; until rabbitmqctl node_health_check; do sleep 1; done; if [[ ""$hostname"" != ""rabbitmq-0"" &amp;&amp; -z ""$(rabbitmqctl cluster_status | grep rabbitmq-0)"" ]]; then
  rabbitmqctl stop_app;
  rabbitmqctl join_cluster rabbit@rabbitmq-0;
  rabbitmqctl start_app;
fi; rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""exactly"",""ha-params"":3,""ha-sync-mode"":""automatic""}'
]) for container ""rabbitmq"" in pod ""rabbitmq-0_default(2e561153-a830-4d30-ab1e-71c80d10c9e9)"" failed - error: command '/bin/sh -c rabbitmq-plugins enable rabbitmq_stomp; if [ -z ""$(grep rabbitmq /etc/resolv.conf)"" ]; then
  sed ""s/^search \([^ ]\+\)/search rabbitmq.\1 \1/"" /etc/resolv.conf &gt; /etc/resolv.conf.new;
  cat /etc/resolv.conf.new &gt; /etc/resolv.conf;
  rm /etc/resolv.conf.new;
fi; until rabbitmqctl node_health_check; do sleep 1; done; if [[ ""$hostname"" != ""rabbitmq-0"" &amp;&amp; -z ""$(rabbitmqctl cluster_status | grep rabbitmq-0)"" ]]; then
  rabbitmqctl stop_app;
  rabbitmqctl join_cluster rabbit@rabbitmq-0;
  rabbitmqctl start_app;
fi; rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""exactly"",""ha-params"":3,""ha-sync-mode"":""automatic""}'
' exited with 137: error: unable to perform an operation on node 'rabbit@rabbitmq-0'. please see diagnostics information and suggestions below.

most common reasons for this are:

 * target node is unreachable (e.g. due to hostname resolution, tcp connection or firewall issues)
 * cli tool fails to authenticate with the server (e.g. due to cli tool's erlang cookie not matching that of the server)
 * target node is not running

in addition to the diagnostics info below:

 * see the cli, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more
 * consult server logs on node rabbit@rabbitmq-0
 * if target node is configured to use long node names, don't forget to use --longnames with cli tools

diagnostics
===========

attempted to contact: ['rabbit@rabbitmq-0']

rabbit@rabbitmq-0:
  * connected to epmd (port 4369) on rabbitmq-0
  * epmd reports: node 'rabbit' not running at all
                  other nodes on rabbitmq-0: [rabbitmqprelaunch1]
  * suggestion: start the node

current node details:
 * node name: 'rabbitmqcli-433-rabbit@rabbitmq-0'
 * effective user's home directory: /var/lib/rabbitmq
 * erlang cookie hash: p1xnoe5pn3ug2fcrfzh7xg==

error: unable to perform an operation on node 'rabbit@rabbitmq-0'. please see diagnostics information and suggestions below.

most common reasons for this are:

 * target node is unreachable (e.g. due to hostname resolution, tcp connection or firewall issues)
 * cli tool fails to authenticate with the server (e.g. due to cli tool's erlang cookie not matching that of the server)
 * target node is not running

in addition to the diagnostics info below:

 * see the cli, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more
 * consult server logs on node rabbit@rabbitmq-0
 * if target node is configured to use long node names, don't forget to use --longnames with cli tools

diagnostics
===========

attempted to contact: ['rabbit@rabbitmq-0']

rabbit@rabbitmq-0:
  * connected to epmd (port 4369) on rabbitmq-0
  * epmd reports: node 'rabbit' not running at all
                  no other nodes on rabbitmq-0
  * suggestion: start the node

current node details:
 * node name: 'rabbitmqcli-575-rabbit@rabbitmq-0'
 * effective user's home directory: /var/lib/rabbitmq
 * erlang cookie hash: p1xnoe5pn3ug2fcrfzh7xg==

error: this command requires the 'rabbit' app to be running on the target node. start it with 'rabbitmqctl start_app'.
arguments given:
  node_health_check

, message: ""enabling plugins on node rabbit@rabbitmq-0:\nrabbitmq_stomp\nthe following plugins have been configured:\n  rabbitmq_management\n  rabbitmq_management_agent\n  rabbitmq_stomp\n  rabbitmq_web_dispatch\napplying plugin configuration to rabbit@rabbitmq-0...\nthe following plugins have been enabled:\n  rabbitmq_stomp\n\nset 4 plugins.\noffline change; changes will take effect at broker restart.\ntimeout: 70 seconds ...\nchecking health of node rabbit@rabbitmq-0 ...\ntimeout: 70 seconds ...\nchecking health of node rabbit@rabbitmq-0 ...\ntimeout: 70 seconds ...\nchecking health of node rabbit@rabbitmq-0 ...\ntimeout: 70 seconds ...\nchecking health of node rabbit@rabbitmq-0 ...\ntimeout: 70 seconds ...\
error:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror:\n{:aborted, {:no_exists, [:rabbit_vhost, [{{:vhost, :\""$1\"", :_, :_}, [], [:\""$1\""]}]]}}\nerror: unable to perform an operation on node 'rabbit@rabbitmq-0'. please see diagnostics information and suggestions below.\n\nmost common reasons for this are:\n\n * target node is unreachable (e.g. due to hostname resolution, tcp connection or firewall issues)\n * cli tool fails to authenticate with the server (e.g. due to cli tool's erlang cookie not matching that of the server)\n * target node is not running\n\nin addition to the diagnostics info below:\n\n * see the cli, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more\n * consult server logs on node rabbit@rabbitmq-0\n * if target node is configured to use long node names, don't forget to use --longnames with cli tools\n\ndiagnostics\n===========\n\nattempted to contact: ['rabbit@rabbitmq-0']\n\nrabbit@rabbitmq-0:\n  * connected to epmd (port 4369) on rabbitmq-0\n  * epmd reports: node 'rabbit' not running at all\n                  no other nodes on rabbitmq-0\n  * suggestion: start the node\n\ncurrent node details:\n * node name: 'rabbitmqcli-10397-rabbit@rabbitmq-0'\n * effective user's home directory: /var/lib/rabbitmq\n * erlang cookie hash: p1xnoe5pn3ug2fcrfzh7xg==\n\n""
  normal  killing  3m58s                kubelet, kubernetes-slave-1  failedpoststarthook
  normal  created  3m57s (x2 over 16m)  kubelet, kubernetes-slave-1  created container rabbitmq
  normal  started  3m57s (x2 over 16m)  kubelet, kubernetes-slave-1  started container rabbitmq


the output of kubectl get sts:

kubectl get sts
name        ready   age
consul      3/3     15d
hazelcast   2/3     15d
kafka       2/3     15d
rabbitmq    0/3     13d
zk          3/3     15d


and this is pod log that i copied from kubernetes dashboard:

2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags: list of feature flags found:
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags:   [x] drop_unroutable_metric
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags:   [x] empty_basic_get_metric
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags:   [x] implicit_default_bindings
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags:   [x] quorum_queue
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags:   [x] virtual_host_metadata
2020-03-24 22:58:41.402 [info] &lt;0.8.0&gt; feature flags: feature flag states written to disk: yes
2020-03-24 22:58:43.979 [info] &lt;0.319.0&gt; ra: meta data store initialised. 0 record(s) recovered
2020-03-24 22:58:43.980 [info] &lt;0.324.0&gt; wal: recovering [""/var/lib/rabbitmq/mnesia/rabbit@rabbitmq-0/quorum/rabbit@rabbitmq-0/00000262.wal""]
2020-03-24 22:58:43.982 [info] &lt;0.328.0&gt; 
 starting rabbitmq 3.8.2 on erlang 22.2.8
 copyright (c) 2007-2019 pivotal software, inc.
 licensed under the mpl 1.1. website: https://rabbitmq.com

  ##  ##      rabbitmq 3.8.2
  ##  ##
  ##########  copyright (c) 2007-2019 pivotal software, inc.
  ######  ##
  ##########  licensed under the mpl 1.1. website: https://rabbitmq.com

  doc guides: https://rabbitmq.com/documentation.html
  support:    https://rabbitmq.com/contact.html
  tutorials:  https://rabbitmq.com/getstarted.html
  monitoring: https://rabbitmq.com/monitoring.html

  logs: &lt;stdout&gt;

  config file(s): /etc/rabbitmq/rabbitmq.conf

  starting broker...2020-03-24 22:58:43.983 [info] &lt;0.328.0&gt; 
 node           : rabbit@rabbitmq-0
 home dir       : /var/lib/rabbitmq
 config file(s) : /etc/rabbitmq/rabbitmq.conf
 cookie hash    : p1xnoe5pn3ug2fcrfzh7xg==
 log(s)         : &lt;stdout&gt;
 database dir   : /var/lib/rabbitmq/mnesia/rabbit@rabbitmq-0
2020-03-24 22:58:43.997 [info] &lt;0.328.0&gt; running boot step pre_boot defined by app rabbit
2020-03-24 22:58:43.997 [info] &lt;0.328.0&gt; running boot step rabbit_core_metrics defined by app rabbit
2020-03-24 22:58:43.998 [info] &lt;0.328.0&gt; running boot step rabbit_alarm defined by app rabbit
2020-03-24 22:58:44.002 [info] &lt;0.334.0&gt; memory high watermark set to 1200 mib (1258889216 bytes) of 3001 mib (3147223040 bytes) total
2020-03-24 22:58:44.014 [info] &lt;0.336.0&gt; enabling free disk space monitoring
2020-03-24 22:58:44.014 [info] &lt;0.336.0&gt; disk free limit set to 50mb
2020-03-24 22:58:44.018 [info] &lt;0.328.0&gt; running boot step code_server_cache defined by app rabbit
2020-03-24 22:58:44.018 [info] &lt;0.328.0&gt; running boot step file_handle_cache defined by app rabbit
2020-03-24 22:58:44.019 [info] &lt;0.339.0&gt; limiting to approx 1048479 file handles (943629 sockets)
2020-03-24 22:58:44.019 [info] &lt;0.340.0&gt; fhc read buffering:  off
2020-03-24 22:58:44.019 [info] &lt;0.340.0&gt; fhc write buffering: on
2020-03-24 22:58:44.020 [info] &lt;0.328.0&gt; running boot step worker_pool defined by app rabbit
2020-03-24 22:58:44.021 [info] &lt;0.329.0&gt; will use 2 processes for default worker pool
2020-03-24 22:58:44.021 [info] &lt;0.329.0&gt; starting worker pool 'worker_pool' with 2 processes in it
2020-03-24 22:58:44.021 [info] &lt;0.328.0&gt; running boot step database defined by app rabbit
2020-03-24 22:58:44.041 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 9 retries left
2020-03-24 22:59:14.042 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 22:59:14.042 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 8 retries left
2020-03-24 22:59:44.043 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 22:59:44.043 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 7 retries left
2020-03-24 23:00:14.044 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:00:14.044 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 6 retries left
2020-03-24 23:00:44.045 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:00:44.045 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 5 retries left
2020-03-24 23:01:14.046 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:01:14.046 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 4 retries left
2020-03-24 23:01:44.047 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:01:44.047 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 3 retries left
2020-03-24 23:02:14.048 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:02:14.048 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 2 retries left
2020-03-24 23:02:44.049 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:02:44.049 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 1 retries left
2020-03-24 23:03:14.050 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_durable_queue]}
2020-03-24 23:03:14.050 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 0 retries left
2020-03-24 23:03:44.051 [error] &lt;0.328.0&gt; feature flag `quorum_queue`: migration function crashed: {error,{timeout_waiting_for_tables,[rabbit_durable_queue]}}
[{rabbit_table,wait,3,[{file,""src/rabbit_table.erl""},{line,117}]},{rabbit_core_ff,quorum_queue_migration,3,[{file,""src/rabbit_core_ff.erl""},{line,60}]},{rabbit_feature_flags,run_migration_fun,3,[{file,""src/rabbit_feature_flags.erl""},{line,1486}]},{rabbit_feature_flags,'-verify_which_feature_flags_are_actually_enabled/0-fun-2-',3,[{file,""src/rabbit_feature_flags.erl""},{line,2128}]},{maps,fold_1,3,[{file,""maps.erl""},{line,232}]},{rabbit_feature_flags,verify_which_feature_flags_are_actually_enabled,0,[{file,""src/rabbit_feature_flags.erl""},{line,2126}]},{rabbit_feature_flags,sync_feature_flags_with_cluster,3,[{file,""src/rabbit_feature_flags.erl""},{line,1947}]},{rabbit_mnesia,ensure_feature_flags_are_in_sync,2,[{file,""src/rabbit_mnesia.erl""},{line,631}]}]
2020-03-24 23:03:44.051 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 9 retries left
2020-03-24 23:04:14.052 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:04:14.052 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 8 retries left
2020-03-24 23:04:44.053 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:04:44.053 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 7 retries left
2020-03-24 23:05:14.055 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:05:14.055 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 6 retries left
2020-03-24 23:05:44.056 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:05:44.056 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 5 retries left
2020-03-24 23:06:14.057 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:06:14.057 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 4 retries left
2020-03-24 23:06:44.058 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:06:44.058 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 3 retries left
2020-03-24 23:07:14.059 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:07:14.059 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 2 retries left
2020-03-24 23:07:44.060 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:07:44.060 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 1 retries left
2020-03-24 23:08:14.061 [warning] &lt;0.328.0&gt; error while waiting for mnesia tables: {timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]}
2020-03-24 23:08:14.061 [info] &lt;0.328.0&gt; waiting for mnesia tables for 30000 ms, 0 retries left
2020-03-24 23:08:44.062 [error] &lt;0.327.0&gt; crash report process &lt;0.327.0&gt; with 0 neighbours exited with reason: {{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]},{rabbit,start,[normal,[]]}} in application_master:init/4 line 138
2020-03-24 23:08:44.063 [info] &lt;0.43.0&gt; application rabbit exited with reason: {{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]},{rabbit,start,[normal,[]]}}
{""kernel pid terminated"",application_controller,""{application_start_failure,rabbit,{{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]},{rabbit,start,[normal,[]]}}}""}
kernel pid terminated (application_controller) ({application_start_failure,rabbit,{{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_r

crash dump is being written to: /var/log/rabbitmq/erl_crash.dump...done

",<kubernetes><rabbitmq><kubernetes-statefulset>,64370825,6,"take a look at:
https://www.rabbitmq.com/clustering.html#restarting
you should be able to stop the app and then force boot:
rabbitmqctl stop_app
rabbitmqctl force_boot

"
72344186,how to append new ip in existing authorized network list on google cloud kubernetes cluster,"right now, i can add my ip using
gcloud container clusters update core-cluster --zone=asia-southeast1-a --enable-master-authorized-networks --master-authorized-networks w.x.y.z/32

but it overrides all the existing authorized networks that was already there.
is there any way to append the new ip to the existing list of authorized networks?
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,72353816,4,"you could automate what @gari singh said using gcloud, jq and tr. see below for doing it with cli:
new_cidr=8.8.4.4/32
export cluster=test-psp
old_cidr=$(gcloud container clusters describe $cluster --format json | jq -r '.masterauthorizednetworksconfig.cidrblocks[] | .cidrblock' | tr '\n' ',')
echo &quot;the existing master authorized networks were $old_cidr&quot;
gcloud container clusters update $cluster --master-authorized-networks &quot;$old_cidr$new_cidr&quot; --enable-master-authorized-networks

"
61742229,kubernetes: storageclass with local provisioner and statefulset kind,"one of my pods has 'statefulset' kind with volumeclaimtemplates section referring to a storageclass(sc) i created, see below.

sc:

apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumebindingmode: waitforfirstconsumer


statefulset yaml with reference to above created sc:

volumeclaimtemplates:
    - metadata:
        name: mydata
      spec:
        storageclassname: local-storage
        accessmodes:
          - readwriteonce
        resources:
          requests:
            storage: 2gi


as far as i am aware, a statefulset will create node specific pvcs without a need for explicit pv and pvc set up, i see that pv being created but the pod status is 'pending' with below warning.


  warning  failedscheduling  default-scheduler  0/4 nodes are available: 4 node(s) didn't find available persistent volumes to bind.


note that i don't have a default storageclass set up in the cluster, i believe that's not required for this scenario, is that correct?
do we need to enable or configure anything for 'local' provisioner to work in the cluster?

thanks
",<kubernetes><persistent-volume-claims><kubernetes-statefulset>,61764167,2,"found out hard way that missing piece for this to work was pv set up.

---
apiversion: v1
kind: persistentvolume
metadata:
  name: pv-loc-sc
spec:
  persistentvolumereclaimpolicy: delete
  storageclassname: local-storage 
  capacity:
    storage: 2gi
  accessmodes:
    - readwriteonce
  local:
    path: ""/var/lib/test""
  nodeaffinity:
    required:
      nodeselectorterms:
      - matchexpressions:
        - key: kubernetes.io/hostname
          operator: in
          values:
          - my-test-node-host-name


the failedscheduling warning went away with pv, sc, and reference to the sc in statefulset pod yaml.
"
70122497,crashloopbackoff on postgresql bitnami helm chart,"i know there have been already a lot of questions about this, and i read already most of them, but my problem does not seem to fit them.
i am running a postgresql from bitnami using a helm chart as described below. a clean setup is no problem and everything starts fine. but after some time, until now i could not find any pattern, the pod goes into crashloopbackoff and i cannot recover it whatever i try!
helm uninstall/install does not fix the problem. the pvs seem to be the problem, but i do not know why. and i do not get any error message, which is the weird and scary part of it.
i use a minikube to run the k8s and helm v3.

helm chart: https://artifacthub.io/packages/helm/bitnami/postgresql/10.9.5

here are the definitions and logs:
# source: aposphere/charts/sessiondb/templates/svc.yaml
apiversion: v1
kind: service
metadata:
  name: sessiondb
  labels:
    app.kubernetes.io/name: sessiondb
    helm.sh/chart: sessiondb-10.9.6
    app.kubernetes.io/instance: asdf
    app.kubernetes.io/managed-by: helm
  annotations:
  namespace: default
spec:
  type: clusterip
  ports:
    - name: tcp-postgresql
      port: 5432
      targetport: tcp-postgresql
  selector:
    app.kubernetes.io/name: sessiondb
    app.kubernetes.io/instance: asdf
    role: primary
---
# source: aposphere/charts/sessiondb/templates/statefulset.yaml
apiversion: apps/v1
kind: statefulset
metadata:
  name: sessiondb
  labels:
    app.kubernetes.io/name: sessiondb
    helm.sh/chart: sessiondb-10.9.6
    app.kubernetes.io/instance: asdf
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: default
spec:
  servicename: sessiondb-headless
  replicas: 1
  updatestrategy:
    type: rollingupdate
  selector:
    matchlabels:
      app.kubernetes.io/name: sessiondb
      app.kubernetes.io/instance: asdf
      role: primary
  template:
    metadata:
      name: sessiondb
      labels:
        app.kubernetes.io/name: sessiondb
        helm.sh/chart: sessiondb-10.9.6
        app.kubernetes.io/instance: asdf
        app.kubernetes.io/managed-by: helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podaffinity:
          
        podantiaffinity:
          preferredduringschedulingignoredduringexecution:
            - podaffinityterm:
                labelselector:
                  matchlabels:
                    app.kubernetes.io/name: sessiondb
                    app.kubernetes.io/instance: asdf
                    app.kubernetes.io/component: primary
                namespaces:
                  - &quot;default&quot;
                topologykey: kubernetes.io/hostname
              weight: 1
        nodeaffinity:
          
      securitycontext:
        fsgroup: 1001
      automountserviceaccounttoken: false
      containers:
        - name: sessiondb
          image: docker.io/bitnami/postgresql:11.13.0-debian-10-r33
          imagepullpolicy: &quot;ifnotpresent&quot;
          resources:
            requests:
              cpu: 250m
              memory: 256mi
          securitycontext:
            runasuser: 1001
          env:
            - name: bitnami_debug
              value: &quot;false&quot;
            - name: postgresql_port_number
              value: &quot;5432&quot;
            - name: postgresql_volume_dir
              value: &quot;/bitnami/postgresql&quot;
            - name: pgdata
              value: &quot;/bitnami/postgresql/data&quot;
            - name: postgres_user
              value: &quot;postgres&quot;
            - name: postgres_password
              valuefrom:
                secretkeyref:
                  name: postgresql-root-password
                  key: postgresql-password
            - name: postgres_db
              value: &quot;session&quot;
            - name: postgresql_enable_ldap
              value: &quot;no&quot;
            - name: postgresql_enable_tls
              value: &quot;no&quot;
            - name: postgresql_log_hostname
              value: &quot;false&quot;
            - name: postgresql_log_connections
              value: &quot;false&quot;
            - name: postgresql_log_disconnections
              value: &quot;false&quot;
            - name: postgresql_pgaudit_log_catalog
              value: &quot;off&quot;
            - name: postgresql_client_min_messages
              value: &quot;error&quot;
            - name: postgresql_shared_preload_libraries
              value: &quot;pgaudit&quot;
          ports:
            - name: tcp-postgresql
              containerport: 5432
          livenessprobe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -u &quot;postgres&quot; -d &quot;dbname=session&quot; -h 127.0.0.1 -p 5432
            initialdelayseconds: 30
            periodseconds: 10
            timeoutseconds: 5
            successthreshold: 1
            failurethreshold: 6
          readinessprobe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -u &quot;postgres&quot; -d &quot;dbname=session&quot; -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialdelayseconds: 5
            periodseconds: 10
            timeoutseconds: 5
            successthreshold: 1
            failurethreshold: 6
          volumemounts:
            - name: custom-init-scripts
              mountpath: /docker-entrypoint-initdb.d/
            - name: dshm
              mountpath: /dev/shm
            - name: data
              mountpath: /bitnami/postgresql
              subpath: 
      volumes:
        - name: custom-init-scripts
          configmap:
            name: sessiondb-scheme
        - name: dshm
          emptydir:
            medium: memory
  volumeclaimtemplates:
    - metadata:
        name: data
      spec:
        accessmodes:
          - &quot;readwriteonce&quot;
        resources:
          requests:
            storage: &quot;8gi&quot;

logs of the container:
% kubectl logs sessiondb-0
postgresql 10:09:01.48 
postgresql 10:09:01.48 welcome to the bitnami postgresql container
postgresql 10:09:01.49 subscribe to project updates by watching https://github.com/bitnami/bitnami-docker-postgresql
postgresql 10:09:01.49 submit issues and feature requests at https://github.com/bitnami/bitnami-docker-postgresql/issues
postgresql 10:09:01.49 
postgresql 10:09:01.50 debug ==&gt; configuring libnss_wrapper...
postgresql 10:09:01.51 info  ==&gt; ** starting postgresql setup **
postgresql 10:09:01.54 info  ==&gt; validating settings in postgresql_* env vars..
postgresql 10:09:01.55 info  ==&gt; loading custom pre-init scripts...
postgresql 10:09:01.55 info  ==&gt; initializing postgresql database...
postgresql 10:09:01.56 debug ==&gt; ensuring expected directories/files exist...
postgresql 10:09:01.57 info  ==&gt; pg_hba.conf file not detected. generating it...
postgresql 10:09:01.58 info  ==&gt; generating local authentication configuration
postgresql 10:09:01.58 info  ==&gt; deploying postgresql with persisted data...
postgresql 10:09:01.60 info  ==&gt; configuring replication parameters
postgresql 10:09:01.65 info  ==&gt; configuring fsync
postgresql 10:09:01.71 info  ==&gt; loading custom scripts...
postgresql 10:09:01.72 info  ==&gt; loading user's custom files from /docker-entrypoint-initdb.d ...
postgresql 10:09:01.72 info  ==&gt; starting postgresql in background...
pg_ctl: directory &quot;/bitnami/postgresql/data&quot; is not a database cluster directory

afterwards the container terminates, no more logs!
logs of the init container:
% kubectl logs sessiondb-0 init-chmod-data
+ chown 1001:1001 /bitnami/postgresql
+ mkdir -p /bitnami/postgresql/data
+ chmod 700 /bitnami/postgresql/data
+ find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name conf -not -name .snapshot -not -name lost+found
+ xargs chown -r 1001:1001
+ chmod -r 777 /dev/shm

permissions:
i have no name!@sessiondb-0:/$ stat /bitnami/postgresql/data
  file: /bitnami/postgresql/data
  size: 207         blocks: 0          io block: 4096   directory
device: 10301h/66305d   inode: 712929      links: 12
access: (0700/drwx------)  uid: ( 1001/ unknown)   gid: ( 1001/ unknown)
access: 2021-11-10 15:16:13.958633094 +0000
modify: 2021-11-26 08:40:42.621884636 +0000
change: 2021-11-26 10:37:47.844490933 +0000
 birth: -

describe the resources:
name:         sessiondb-0
namespace:    default
priority:     0
node:         ip-10-0-1-112.eu-central-1.compute.internal/10.0.1.112
start time:   fri, 26 nov 2021 10:40:02 +0100
labels:       app.kubernetes.io/component=primary
              app.kubernetes.io/instance=asdf
              app.kubernetes.io/managed-by=helm
              app.kubernetes.io/name=sessiondb
              controller-revision-hash=sessiondb-578ddf476b
              helm.sh/chart=sessiondb-10.9.6
              role=primary
              statefulset.kubernetes.io/pod-name=sessiondb-0
annotations:  &lt;none&gt;
status:       running
ip:           172.17.0.4
ips:
  ip:           172.17.0.4
controlled by:  statefulset/sessiondb
containers:
  sessiondb:
    container id:   docker://a94f894687f0813196a94afe88f64723f238eb7d2cb061e4c7ef17354f27dee8
    image:          docker.io/bitnami/postgresql:11.13.0-debian-10-r33
    image id:       docker-pullable://bitnami/postgresql@sha256:205e1c5a1d4b56d0d63f6579557652f958e321006c4cb5325d031d40313e4ea2
    port:           5432/tcp
    host port:      0/tcp
    state:          waiting
      reason:       crashloopbackoff
    last state:     terminated
      reason:       error
      exit code:    1
      started:      fri, 26 nov 2021 10:50:45 +0100
      finished:     fri, 26 nov 2021 10:50:46 +0100
    ready:          false
    restart count:  7
    requests:
      cpu:      250m
      memory:   256mi
    liveness:   exec [/bin/sh -c exec pg_isready -u &quot;postgres&quot; -d &quot;dbname=session&quot; -h 127.0.0.1 -p 5432] delay=30s timeout=5s period=10s #success=1 #failure=6
    readiness:  exec [/bin/sh -c -e exec pg_isready -u &quot;postgres&quot; -d &quot;dbname=session&quot; -h 127.0.0.1 -p 5432
[ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
] delay=5s timeout=5s period=10s #success=1 #failure=6
    environment:
      bitnami_debug:                        false
      postgresql_port_number:               5432
      postgresql_volume_dir:                /bitnami/postgresql
      pgdata:                               /bitnami/postgresql/data
      postgres_user:                        postgres
      postgres_password:                    &lt;set to the key 'postgresql-password' in secret 'postgresql-root-password'&gt;  optional: false
      postgres_db:                          session
      postgresql_enable_ldap:               no
      postgresql_enable_tls:                no
      postgresql_log_hostname:              false
      postgresql_log_connections:           false
      postgresql_log_disconnections:        false
      postgresql_pgaudit_log_catalog:       off
      postgresql_client_min_messages:       error
      postgresql_shared_preload_libraries:  pgaudit
    mounts:
      /bitnami/postgresql from data (rw)
      /dev/shm from dshm (rw)
      /docker-entrypoint-initdb.d/ from custom-init-scripts (rw)
conditions:
  type              status
  initialized       true 
  ready             false 
  containersready   false 
  podscheduled      true 
volumes:
  data:
    type:       persistentvolumeclaim (a reference to a persistentvolumeclaim in the same namespace)
    claimname:  data-sessiondb-0
    readonly:   false
  custom-init-scripts:
    type:      configmap (a volume populated by a configmap)
    name:      sessiondb-scheme
    optional:  false
  dshm:
    type:        emptydir (a temporary directory that shares a pod's lifetime)
    medium:      memory
    sizelimit:   &lt;unset&gt;
qos class:       burstable
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute op=exists for 300s
                 node.kubernetes.io/unreachable:noexecute op=exists for 300s
events:
  type     reason     age                  from               message
  ----     ------     ----                 ----               -------
  normal   scheduled  11m                  default-scheduler  successfully assigned default/sessiondb-0 to ip-10-0-1-112.eu-central-1.compute.internal
  normal   created    11m (x4 over 11m)    kubelet            created container sessiondb
  normal   started    11m (x4 over 11m)    kubelet            started container sessiondb
  normal   pulled     10m (x5 over 11m)    kubelet            container image &quot;docker.io/bitnami/postgresql:11.13.0-debian-10-r33&quot; already present on machine
  warning  backoff    110s (x57 over 11m)  kubelet            back-off restarting failed container

---

% kubectl describe pvc data-sessiondb-0
name:          data-sessiondb-0
namespace:     default
storageclass:  standard
status:        bound
volume:        pvc-6b56b20c-3e56-4a92-9278-794bf6cda4de
labels:        app.kubernetes.io/instance=asdf
               app.kubernetes.io/name=sessiondb
               role=primary
annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-provisioner: k8s.io/minikube-hostpath
finalizers:    [kubernetes.io/pvc-protection]
capacity:      8gi
access modes:  rwo
volumemode:    filesystem
used by:       sessiondb-0
events:        &lt;none&gt;

---

% kubectl describe pvc data-sessiondb-0
name:          data-sessiondb-0
namespace:     default
storageclass:  standard
status:        bound
volume:        pvc-6b56b20c-3e56-4a92-9278-794bf6cda4de
labels:        app.kubernetes.io/instance=asdf
               app.kubernetes.io/name=sessiondb
               role=primary
annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-provisioner: k8s.io/minikube-hostpath
finalizers:    [kubernetes.io/pvc-protection]
capacity:      8gi
access modes:  rwo
volumemode:    filesystem
used by:       sessiondb-0
events:        &lt;none&gt;
cyrill@cyrillsmbp4380 core % kubectl describe pv pvc-6b56b20c-3e56-4a92-9278-794bf6cda4de
name:            pvc-6b56b20c-3e56-4a92-9278-794bf6cda4de
labels:          &lt;none&gt;
annotations:     hostpathprovisioneridentity: 10bfa079-1086-4a77-849e-7d00de8e34dc
                 pv.kubernetes.io/provisioned-by: k8s.io/minikube-hostpath
finalizers:      [kubernetes.io/pv-protection]
storageclass:    standard
status:          bound
claim:           default/data-sessiondb-0
reclaim policy:  delete
access modes:    rwo
volumemode:      filesystem
capacity:        8gi
node affinity:   &lt;none&gt;
message:         
source:
    type:          hostpath (bare host directory volume)
    path:          /tmp/hostpath-provisioner/default/data-sessiondb-0
    hostpathtype:  
events:            &lt;none&gt;

edit: add logs with debug level
--&gt; looking to fix: directory &quot;/bitnami/postgresql/data&quot; is not a database cluster directory
edit2: add logs of the init container volumepermissions.enabled and permissions
edit3: ok, so i created a fresh version to compare the old and the new one. i am wondering, why there is such a difference in the files as both were working until one didn't anymore. (during regular business, no upgrades, nothing.)

",<postgresql><kubernetes><kubernetes-helm><bitnami>,70152451,3,"i really hope nobody else runs across this, but finally i found the problem and for once it was not only between the chair and the monitor, but also rtfm was involved.
as mentioned i am using minikube to run my k8s cluster which provides pvs stored on the host disk. where it is stored you may ask? exaclty, here: /tmp/hostpath-provisioner/default/data-sessiondb-0/data/. you find the problem? no, i also took some time to figure it out. why on earth does minikube use the tmp folder to store persistant volume claims?

this folder gets autom. cleared every now and so on.
solution: change the path and do not store pvs in
tmp folders.
they mention this here: https://minikube.sigs.k8s.io/docs/handbook/persistent_volumes/#a-note-on-mounts-persistence-and-minikube-hosts and give an example.
but why use the &quot;dangerous&quot; tmp path per default and not, let's say, data without putting a warning banner there?
sigh. closing this question ^^
--&gt; workaround: https://github.com/kubernetes/minikube/issues/7511#issuecomment-612099413

github issues to this topic:

https://github.com/kubernetes/minikube/issues/7511
https://github.com/kubernetes/minikube/issues/13038
https://github.com/kubernetes/minikube/issues/3318
https://github.com/kubernetes/minikube/issues/5144

my github issue for clarification in the docs: https://github.com/kubernetes/minikube/issues/13038#issuecomment-981821696
"
57842844,ingress sends traffic to the domain root,"i have a workload which is exposed through nodeport service with the name online-forms-lib-service. this workload has the /version route.

also i have the following ingress:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: test-ingress
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: online-forms-lib-service
          serviceport: 80
        path: /formslib/


the problem is, the /version route is not available at:

example.com/formslib/version


how to solve this?

update 

it goes to the application root when i call: 

example.com/formslib/


adding any path from there directs me to the default backend

update
added the annotation: 

  annotations:
    ingress.kubernetes.io/rewrite-target: /


still the same behaviour.
",<kubernetes><kubernetes-ingress>,57885089,1,"this behaviour is controlled by the rewrite annotations.

  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /


as of september, 2019, the gke ingress doesn't support the rewrite rules.

https://github.com/kubernetes/ingress-gce/issues/109

and no published plans for implementing it either.

the only solution is nginx or other 3rd party ingress controller which supports rewrite annotations.
"
71360867,how to create ingress-nginx for my kubernetes deployment and service?,"i am able to access my django app deployment using loadbalancer service type but i'm trying to switch to clusterip service type and ingress-nginx but i am getting 503 service temporarily unavailable when i try to access the site via the host url. describing the ingress also shows error: endpoints &quot;django-service&quot; not found and  error: endpoints &quot;default-http-backend&quot; not found. what am i doing wrong?
this is my service and ingress yaml:
---
apiversion: v1
kind: service
metadata:
  name: django-service
spec:
  type: clusterip
  ports:
  - name: http
    protocol: tcp
    port: 80
    targetport: 8000
---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: django-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/force-ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/ssl-redirect: 'true'
spec:
  tls:
  - hosts:
    - django.example.com
  rules:
  - host: django.example.com
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: django-service
            port:
              number: 80
  ingressclassname: nginx

kubectl get all
$ kubectl get all
name                                        ready   status    restarts   age
pod/django-app-5bdd8ffff9-79xzj             1/1     running   0          7m44s
pod/postgres-58fffbb5cc-247x9               1/1     running   0          7m44s

name                     type        cluster-ip      external-ip   port(s)    age
service/django-service   clusterip   10.233.29.58    &lt;none&gt;        80/tcp     7m44s
service/pg-service       clusterip   10.233.14.137   &lt;none&gt;        5432/tcp   7m44s

name                                   ready   up-to-date   available   age
deployment.apps/django-app             1/1     1            1           7m44s
deployment.apps/postgres               1/1     1            1           7m44s

name                                              desired   current   ready   age
replicaset.apps/django-app-5bdd8ffff9             1         1         1       7m44s
replicaset.apps/postgres-58fffbb5cc               1         1         1       7m44s

describe ingress
$ kubectl describe ing django-ingress
name:             django-ingress
labels:           &lt;none&gt;
namespace:        django
address:          10.10.30.50
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  sni routes django.example.com
rules:
  host                      path  backends
  ----                      ----  --------
  django.example.com
                            /   django-service:80 (&lt;error: endpoints &quot;django-service&quot; not found&gt;)
annotations:                nginx.ingress.kubernetes.io/force-ssl-redirect: true
                            nginx.ingress.kubernetes.io/rewrite-target: /
                            nginx.ingress.kubernetes.io/ssl-redirect: true
events:
  type    reason  age                   from                      message
  ----    ------  ----                  ----                      -------
  normal  sync    5m28s (x2 over 6m5s)  nginx-ingress-controller  scheduled for sync
  normal  sync    5m28s (x2 over 6m5s)  nginx-ingress-controller  scheduled for sync

",<kubernetes><kubernetes-ingress><nginx-ingress>,71361021,3,"i think you forgot to make the link with your deployment in your service.
apiversion: v1
kind: service
metadata:
  name: django-service
spec:
  type: clusterip
  ports:
  - name: http
    protocol: tcp
    port: 80
    targetport: 8000
  selector:
    app: your-deployment-name

your label must be set in your deployment as well:
spec:
  selector:
    matchlabels:
      app: your-deployment-name
  template:
    metadata:
      labels:
        app: your-deployment-name

"
65110087,"why does helm push with ""--dependency-update"" not find the repository by name but ""helm dependency update"" does?","i have a chart.yaml with the following:
chart.yaml
dependencies:
  - name: my-app
    version: &quot;0.1.0&quot;
    repository: &quot;@my-chartmuseum-repo&quot;

and i added the repo to helm:
# helm repo list
name                    url
my-chartmuseum-repo     http://127.0.0.1:8080/
stable                  https://charts.helm.sh/stable

when i run helm dependency update my-owning-app i get the successful message:
helm dependency update my-owning-app
hang tight while we grab the latest from your chart repositories...
...successfully got an update from the &quot;my-chartmuseum-repo&quot; chart repository
...successfully got an update from the &quot;stable&quot; chart repository
update complete. ⎈happy helming!⎈
saving 1 charts
downloading my-app from repo http://127.0.0.1:8080/
deleting outdated charts

however, when i try to do this via helm push my-owning-app/ my-chartmuseum-repo --dependency-update i get the error:
error: no repository definition for @my-chartmuseum-repo. please add them via 'helm repo add'
usage:
  helm push [flags]

flags:
# ...elided...

why would it work in the first command but not the second one to find the repository by name?
",<kubernetes><kubernetes-helm>,65234592,1,"this is a community wiki answer. feel free to expand on it.
the --dependency-update flag for the helm push plugin is currently not working properly due to the fact that it does not omit the @ symbol when checking the name of the repository.
as a workaround, you could use the helm dependency update with a --repository-config string flag:

path to the file containing repository names and urls (default
&quot;~/.config/helm/repositories.yaml&quot;)

"
60122498,how can i ping a password protected redis server using netcat in an initcontainer?,"note: solution can use netcat or any other built-in linux utility

i need to implement an initcontainer and liveness probe that confirms my redis pod is up for one of my redis dependent pods. i have attempted the netcat solution offered as the answer here ((printf ""ping\r\n""; sleep 1) | nc 10.233.38.133 6379) but i get -noauth authentication required. error in response. any way around this? i am aware i could install redis-cli or make a management command in my django code but would prefer not to. nor do i want to implement a web server for my redis instance and use curl command.
",<linux><kubernetes><redis><netcat><kubernetes-pod>,60122604,8,"you could always send in your auth command as part of your probe, like:

`""auth ....\r\nping\r\n""`


unless you're getting info from the server, you don't seem to care about the nature of the response, so no auth is required, just test for noauth.
"
56123758,any solution for multi-tenant setup with different dns?,"i have set up my frontend cluster in my kubernetes and exposed as frontend.loaner.com and i want to point the dns record of these both johndoe.loaner.com, janedoe.loaner.com to see the frontend.loaner.com.

is that possible to just point two dns to a 1 running server and works fine still having the hostname?

i read about the cname but it will redirect me to frontend.loaner.com
",<kubernetes><dns><multi-tenant><kubernetes-ingress>,56124404,2,"you can do it with a kubernetes ingress. basically, something like this:

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: test-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: frontend.loaner.com
    http:
      paths:
      - path: /
        backend:
          servicename: backend1
          serviceport: 80
  - host: johndoe.loaner.com
    http:
      paths:
      - path: /
        backend:
          servicename: backend2
          serviceport: 80
  - host: janedoe.loaner.com
    http:
      paths:
      - path: /
        backend:
          servicename: backend3
          serviceport: 80


the above ingress resource assumes you are using an nginx ingress controller in your cluster.
"
63673068,kubernetes deployment rollback api,"i'm looking for the api used by kubernetes clients to rollback deployments.
i can find that in the older versions of kubernetes api docs
post /apis/extensions/v1beta1/namespaces/{namespace}/deployments/{name}/rollback(reference) is the api being used. however this documentation seems to have been removed in versions later than 1.18 and i can't seem to find any replacement for this api either in the new documentation.
if the api no longer exists how do clients such as kubectl or any of the client libraries rollback deployments in the newer versions of kubernetes?
",<kubernetes><kubernetes-deployment>,63686737,3,"the missing api is an result of the changes made in the newest kubernetes version 1.19:

apiextensions.k8s.io/v1beta1  is deprecated in favor of
apiextensions.k8s.io/v1
(#90673,
@deads2k) [sig api machinery]

as suggested by community running kubectl with high verbosity level will allow to debug your commands at high level.  you can check here more about verbosity and debugging.
"
69074488,gke can't have multiple ingress nginx anymore?,"in the past i've installed them using:
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install ingress-nginx-01 ingress-nginx/ingress-nginx

and could have multiple.
now i'm getting this error when i try to install another:
error: rendered manifests contain a resource that already exists. unable to continue with
install: ingressclass &quot;nginx&quot; in namespace &quot;&quot; exists and cannot be imported into the
current release: invalid ownership metadata; annotation validation error: key
&quot;meta.helm.sh/release-name&quot; must equal &quot;ingress-nginx-02&quot;: current value is
&quot;ingress-nginx-01&quot;; annotation validation error: key
&quot;meta.helm.sh/release-namespace&quot; must equal &quot;ingress-02&quot;: current value is &quot;ingress-01&quot;

",<kubernetes><google-kubernetes-engine><kubernetes-ingress><nginx-ingress>,69074571,2,"you have to set the class name while installing the new nginx ingress controller again.
for example :
helm install stable/nginx-ingress --set controller.ingressclass=gce --namespace kube-system --set controller.replicacount=2 --set rbac.create=false
helm install stable/nginx-ingress --set controller.ingressclass=nginx --namespace kube-system --set controller.replicacount=2 --set rbac.create=false
helm install stable/nginx-ingress --set controller.ingressclass=third --namespace kube-system --set controller.replicacount=2 --set rbac.create=false

based on your helm version you can pass the name of helm as you did ingress-nginx-01, ingress-nginx-02 but main thing is class name: --set controller.ingressclass=gce
as error says
install: ingressclass &quot;nginx&quot; in namespace &quot;&quot; exists**strong text**

multiple ingress controllers
if you're running multiple ingress controllers or running on a cloud provider that natively handles ingress such as gke, you need to specify the annotation kubernetes.io/ingress.class: &quot;nginx&quot; in all ingresses that you would like the ingress-nginx controller to claim.
for instance,
metadata:
  name: foo
  annotations:
    kubernetes.io/ingress.class: &quot;gce&quot;

will target the gce controller, forcing the nginx controller to ignore it, while an annotation like
metadata:
  name: foo
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;

will target the nginx controller, forcing the gce controller to ignore it.
example : https://kubernetes.github.io/ingress-nginx/user-guide/multiple-ingress/
ref : https://vincentlauzon.com/2018/11/28/understanding-multiple-ingress-in-aks/
"
55308605,only the creator user can manage aws kubernetes cluster (eks) from kubectl?,"we have two clusters, named:


mycluster (created by me)
othercluster (not created by me)


where ""me"" is my own aws iam user.

i am able to manage the cluster i created, using kubectl:

&gt;&gt;&gt; aws eks update-kubeconfig --name mycluster –profile myuser
&gt;&gt;&gt; kubectl get svc
name         type        cluster-ip   external-ip   port(s)   age
kubernetes   clusterip   172.20.0.1   &lt;none&gt;        443/tcp   59d


but, i cannot manage the “othercluster” cluster (that was not created by me):

&gt;&gt;&gt; aws eks update-kubeconfig --name othercluster --profile myuser
&gt;&gt;&gt; kubectl get svc
name         type        cluster-ip   external-ip   port(s)   age
error: the server doesn't have a resource type ""svc""


after reading the feedback of some people experiencing the same issue in this github issue, i tried doing this under the context of the user who originally created the ""othercluster"".

i accomplished this by editing “~/.kube/config”, adding a “aws_profile” value at “users.user.env”. the profile represents the user who created the cluster.

~/.kube/config:

…
users
- name: othercluster
  user:
    exec:
      apiversion: client.authentication.k8s.io/v1alpha1
      args:
      - token
      - -i
      - othercluster
      command: aws-iam-authenticator
      env:
      - name: aws_profile
        value: other_user_profile
…


this worked:

# ~/.kube/config is currently pointing to othercluster

&gt;&gt;&gt; kubectl get svc 
name         type        cluster-ip   external-ip   port(s)   age
kubernetes   clusterip   172.20.0.1   &lt;none&gt;        443/tcp   1d


it is obviously not ideal for me to impersonate another person when i am managing the cluster. i would prefer to grant my own user access to manage the cluster via kubectl.
is there any way i can grant permission to manage the cluster to a user other than the original creator? this seems overly restrictive
",<amazon-web-services><kubernetes><amazon-eks>,55314570,3,"when an amazon eks cluster is created, the iam entity (user or role) that creates the cluster is added to the kubernetes rbac authorization table as the administrator. initially, only that iam user can make calls to the kubernetes api server using kubectl. 

to grant additional aws users the ability to interact with your cluster, you must edit the aws-auth configmap within kubernetes, adding a new mapusers entry for your configmap. this eks doc covers all the process.


  to add an iam user: add the user details to the mapusers section of
  the configmap, under data. add this section if it does not already
  exist in the file. each entry supports the following parameters:
  
  
  userarn: the arn of the iam user to add.
  username: the user name within kubernetes to map to the iam user. by    default, the user name is the arn of the iam user.
  groups: a list of groups within kubernetes to which the user is    mapped to. for more information, see default roles and role bindings
  in the kubernetes documentation.
  


example:

apiversion: v1
data:
  maproles: |
    - rolearn: arn:aws:iam::555555555555:role/devel-worker-nodes-nodeinstancerole-74rf4ubdukl6
      username: system:node:{{ec2privatednsname}}
      groups:
        - system:bootstrappers
        - system:nodes
  mapusers: |
    - userarn: arn:aws:iam::555555555555:user/my-new-admin-user
      username: my-new-admin-user
      groups:
        - system:masters

"
57216418,kubectl get resources by label with or operator,"i know we can do the following commands:


kubectl get pods -l app==&lt;kafka&gt; gets pods with kafka label 
kubectl get pods -l app!=&lt;kafka&gt; gets pods without kafka label 
kubectl get pods -l app=kafka,env=staging gets pods with both kafka and staging labels


but what about if i want to list all the pods which have either kafka or zookeeper label. something like -l app==kafka||zookeeper.

is this even possible with -l kubectl option...?
",<kubernetes><kubectl>,57280546,6,"have you tried this? 

kubectl get pods -l 'app in (kafka, zookeeper)'


see: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#api
"
40364980,making a service port externally visible,"i want to deploy a simple containerized app on gce. i've created a deployment file and a service file.  the latter includes type: nodeport and ""ports"": [{""port"": 443, ""targetport"": ""myapp-port"", ""protocol"": ""tcp""}] declarations.

after running kubectl create -f deployment.json and kubectl create -f service.json, the deployment (including pods and replica sets) and service are created.  however, the service is not visibly externally.  how do i make it so?  preferably i would want to make this change in the service.json file, so it's under revision control.
",<kubernetes><google-kubernetes-engine>,40396928,1,"probably because you missed

spec:
  type: loadbalancer


http://kubernetes.io/docs/user-guide/load-balancer/
"
39231880,kubernetes api - get pods on specific nodes,"reading the kubernets documentation it looks to be possible to select a certain range of pods based on labels. i want to select all the pods on one node but i don't want to label each pod on their corresponding node.
am i missing something from the documentation or is it just not possible to select by node?
if i do:
kubectl get pods \
--output=wide
--namespace=$ns \
--server=$server | head

#=&gt;

name   ready     status             restarts   age       node

can any of these headers be used as selector? if yes, how to do it with kubectl?  how to do it with the api?
",<kubernetes><kubectl>,50811992,495,"as mentioned in the accepted answer the pr is now merged and you can get pods by node as follows:

kubectl get pods --all-namespaces -o wide --field-selector spec.nodename=&lt;node&gt;

"
69426153,kubernetes - when to use horizontalpodautoscaler resource type?,"as mentioned in this answer: allow for easy updating of a replica set as well as the ability to roll back to a previous deployment.
so, kind: deployment scales replicasets, which scales pods, supports zero-downtime updates by creating and destroying replicasets

what is the purpose of horizontalpodautoscaler resource type?
apiversion: autoscaling/v1
kind: horizontalpodautoscaler
metadata:
  name: xyz
spec:
  maxreplicas: 4
  minreplicas: 2
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: xyz
  targetcpuutilizationpercentage: 70

",<kubernetes><kubernetes-pod><replicaset>,69426221,1,"as you write, with a deployment it is easy to manually scale an app horizontally, by changing the numer of replicas.
by using a horizontalpodautoscaler, you can automate the horizontal scaling by e.g. configuring some metric thresholds, therefore the name autoscaler.
"
49245313,unable to deploy ingress in local kubernetes cluster,"i'm trying to setup frontend for my two web applications by using ingress controller in local kubernetes cluster. i followed all steps outlined in [1] and detailed instructions in [2]. but so far out of luck. the error i got is the following:

warning creatingloadbalancerfailed error creating load balancer (will retry): failed to ensure load balancer for service default/frontend: error creating loadbalancer a58617b3f260011e8ad84fa163e0c90a: error creating loadbalancer {a58617b3f260011e8ad84fa163e0c90a
kubernetes external service a58617b3f260011e8ad84fa163e0c90a 7b4db6f7-3fc1-4c07-a84d-5c15b46e3ac2 &lt;nil&gt; }: expected http response code [201 202] when accessing [post https://host.xyz.com:9696/v2.0/lbaas/loadbalancers],
but got 409 instead
{""neutronerror"": {""message"": ""quota exceeded for resources: ['loadbalancer']."", ""type"": ""overquota"", ""detail"": """"}}


and my service stays in a pending state.

so far i have no idea where to look at to identify the problem and would appreciate any advice.

the manifest yaml file is almost identical to [2], it only lists https interface. but here it is for completeness

apiversion: extensions/v1beta1
kind: ingress
metadata:
   name: frontend
   annotations:
     ingress.kub.webernetes.io/rewrite-target: /
spec:
  tls:
  - secretname: ing-secret
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: nginx-ingress-lb
  containers:
  - args:
    - /nginx-ingress-controller
    - ""--default-backend-service=$(pod_namespace)/default-http-backend""
    - ""--default-ssl-certificate=$(pod_namespace)/ing-secret""
  env:
    - name: pod_name
      valuefrom:
        fieldref:
          fieldpath: metadata.name
    - name: pod_namespace
      valuefrom:
        fieldref:
          fieldpath: metadata.namespace
  image: ""gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.5""
  rules:
  - host: host.xxx.com
    https:
      paths:
      - path: /app1
        backend:
          servicename: app1
          serviceport: 8881
      - path: /app2
        backend:
          servicename: app2
          serviceport: 8882
---
apiversion: v1
kind: service
metadata:
  name: frontend
spec:
  type: loadbalancer
  ports:
  - name: https
    port: 443
    targetport: https
  selector:
    k8s-app: nginx-ingress-lb


[1] https://kubernetes.io/docs/concepts/services-networking/ingress/

[2] https://hackernoon.com/setting-up-nginx-ingress-on-kubernetes-2b733d8d2f45
",<nginx><kubernetes><kubernetes-ingress>,49245824,1,"it looks like openstack lbaas is being used by kubernetes to provision the load balancer service underlying the ingress resource (see https://host.xyz.com:9696/v2.0/lbaas/loadbalancers in the error log)

afaik this error indicates a resource limit has been reached on the number of load balancers provisioned. i would raise the issue with your cluster administrator.
"
77657716,cronjob is not executing at scheduled interval,"i have kubernetes cronjob at defined interval. this needs to be run for every 5hours 15mins. but might be issue with cron scheduled.
this is my kubernetes cronjob :

apiversion: batch/v1
kind: cronjob
metadata:
  name: cronjob-monitor
  namespace: cronjobs
  labels:
    app: cronjob-monitor
spec:
  schedule: &quot;15 5 * * *&quot;
  successfuljobshistorylimit: 2
  failedjobshistorylimit: 2
  concurrencypolicy: replace
  jobtemplate:
    spec:
      template:
        spec:
          nodeselector:
            agentpool: streaming
          restartpolicy: onfailure

this is not executing for every 5hrs 15th min. can any one guide me on this.
",<kubernetes><kubernetes-cronjob>,77657910,1,"i have observed that you have given cron job schedule syntax as  : &quot;15 5 * * *&quot; . this will run everyday 5th hr 15 min but not as per your requirement . so, seems to be a cron job schedule syntax issue. can you try by giving this syntax 15 */5 * * 1-7 . as per the below screenshot, this cron job syntax will run for every 5 hr's 15th min from monday to sunday.

you can use this crontab.guru play tool to check the syntax of the scheduled job according to our requirements. can you try the above suggested syntax and let me know.
"
46123457,restart container within pod,"i have a pod test-1495806908-xn5jn with 2 containers. i'd like to restart one of them called container-test. is it possible to restart a single container within a pod and how? if not, how do i restart the pod?

the pod was created using a deployment.yaml with:

kubectl create -f deployment.yaml

",<kubernetes><kubectl>,46127779,213,"
  is it possible to restart a single container


not through kubectl, although depending on the setup of your cluster you can ""cheat"" and docker kill the-sha-goes-here, which will cause kubelet to restart the ""failed"" container (assuming, of course, the restart policy for the pod says that is what it should do)


  how do i restart the pod


that depends on how the pod was created, but based on the pod name you provided, it appears to be under the oversight of a replicaset, so you can just kubectl delete pod test-1495806908-xn5jn and kubernetes will create a new one in its place (the new pod will have a different name, so do not expect kubectl get pods to return test-1495806908-xn5jn ever again)
"
55078150,should dependencies between helm charts reflect dependencies between microservices?,"given a following scheme of services and their dependencies i would like to engineer a set of helm charts.


api gateway calls service a and service c
service a calls service b
service b calls database
service c calls service b and service d


at the moment i see two alternatives:


each of the 6 components in a diagram below is a single chart and each arrow in a diagram is a single dependency.  
there's an umbrella chart that has a dependency on all other charts. the database chart is a dependency of service b chart. 


helm documentation suggest going with option 2. i am however more keen towards option 1 due to an ease of local development and ci/cd pipeline.

example scenario: developer is refactoring service c and he wants to run the code he changed and test it.


option 1. developer installs a service c chart only.
option 2: developer would have to either:


install an umbrella chart which leads to waste of a cpu and memory resources because of running unneeded services like service a or api gateway, which doesn't scale well with the complexity of the system;
install service c, then service b and then service d, which also doesn't scale well with the complexity of the system because it requires to perform many manual actions and also require from developer to be faimiliar with the architecture of the system in order to know what charts needs to be installed.



i would like to make an educated decision on which alternative to take. i am more keen towards option 1, but helm docs and also few examples i was able to find on the internet (link) are also going with option 2, so i think i might be missing something.
",<kubernetes><kubernetes-helm>,55091902,8,"i would recommend one chart per service, with the additional simplification of making the ""service b"" chart depend on its database.  i would make these charts independent: none of the services depend on any other.

the place where helm dependencies work well is where you have a service that embeds/hides specific single other parts.  the database behind b is an implementation detail, for example, and nothing outside b needs to know about it.  so b can depend on stable/postgres or some such, and this works well in helm.

there's one specific mechanical problem that causes problems for the umbrella-chart approach.  say service d also depended on a database, and it was the same ""kind"" of database (both use postgresql, say).  operationally you want these two databases to be separate.  helm will see the two paths umbrella &gt; b &gt; database and umbrella &gt; d &gt; database, and only install one copy of the database chart, so you'll wind up with the two services sharing a database.  you probably don't want that.

the other mechanical issue you'll encounter using helm dependencies here is that most resources are named some variant of {{ .release.name }}-{{ .chart.name }}.  in your option 1, say you do just install service c; you'd wind up with deployments like service-c-c, service-c-b, service-c-database.  if you then wanted to deploy service a alongside it, that would introduce its own service-a-b and service-a-database, which again isn't what you want.

i'm not aware of a great high-level open-source solution to this problem.  a make-based solution is hacky, but can work:

# -*- gnu-make -*-
all: api-proxy.deployed

%.deployed:
        helm upgrade --install --name $* -f values.yaml ./charts/$*
        touch $@

api-proxy.deployed: a.deployed c.deployed
a.deployed: b.deployed
c.deployed: b.deployed d.deployed

"
68540187,kubectl rollout status - when the command complete?,"currently i am using this in my pipeline
kubectl apply -f deployment.yaml &amp;&amp; kubectl rollout status -f deployment.yaml

with this in yaml
      readinessprobe:
        tcpsocket:
          port: 90
        initialdelayseconds: 120
        periodseconds: 10
        timeoutseconds: 10
        failurethreshold: 1
        successthreshold: 1
      livenessprobe:
        tcpsocket:
          port: 90
        initialdelayseconds: 120
        periodseconds: 20
        timeoutseconds: 2
        failurethreshold: 1
        successthreshold: 1

for me, kubectl rollout is running for a very long time, blocking the deployment pipeline. from the documentation

by default 'rollout status' will watch the status of the latest rollout until it's done

my question:
1/ which actions are the parts that contribute to the deployment &quot;until it's done&quot; (resource creation, resource teardown?... )
2/ does readinessprobe and livenessprobe contribute to the deployment time
",<kubernetes><kubectl>,68543710,7,"the criteria for this are in the kubectl source.  a deployment is &quot;complete&quot; if:

it hasn't timed out
its updated-replica count is at least its desired-replica count (every new pod has been created)
its current-replica count is at most its updated-replica count (every old pod has been destroyed)
its available-replica count is at least its updated-replica count (every new pod is running)

you can use kubectl get deployment -w or kubectl get pod -w to watch a deployment actually happen in real time; the kubectl get -w option watches the given resources and prints out a new line whenever they change.  you'll see the following sequence occur (with default deployment settings, one at a time for &quot;small&quot; deployments):

a new pod is created
the new pod passes its probes and become ready
an old pod is terminated
the old pod actually exits and is deleted

so for kubectl rollout status deployment/... to finish, all of these steps must happen – new pods are created, new pods all pass their health checks, old pods are destroyed – for every replica in the deployment.
"
55341714,how to specify values for parent helm chart,"i am trying to configure prometheus, which is included in the gitlab helm chart according to https://gitlab.com/charts/gitlab/blob/master/requirements.yaml

my main issue is how to configure prometheus, as the following values.yaml seems to be ignored:

global:
  registry:
    enabled: false
  # disabling minio still requires to disable gitlab.minio or it will complain about ""a valid backups.objectstorage.config.secret is needed""
  minio:
    enabled: false
  ingress:
    configurecertmanager: false
    class: ""nginx""
 ...

prometheus:
  install: true
  rbac:
    create: true
  #kubestatemetrics:
  #  enabled: true
  nodeexporter:
    enabled: true
  #pushgateway:
  #  enabled: true

  server:
    configmapoverridename: prometheus-config
    configpath: /etc/prometheus/conf/prometheus.yml
    persistentvolume:
      enabled: true
      accessmodes:
      - readwritemany
      mountpath: /etc/prometheus/conf
      # increase afterwards, this is for my tests
      size: 2gi

  alertmanager:
    enabled: true
    # overriding the default configuration with the existing one
    configmapoverridename: ""alertmanager""
    configfilename: config.yml
    persistentvolume:
      enabled: true
      accessmodes:
        - readwritemany
      mountpath: /prometheus
      # increase afterwards, this is for my tests
      size: 2gi

",<kubernetes><gitlab><openshift><kubernetes-helm>,55343512,6,"checked the link you provided and it seems you are trying to add values into values.yaml of your parent chart, where prometheus is a dependent sub-chart.

specifying values at parent values.yaml file is done exactly in the same way you provided above.

values for sub-chart should go into a property named exactly as the sub-chart.

parentprop1: value
parentprop2: value
global:
  globalprop1: value
  globalprop2: value
subchart1:
  subchartprop1: value
  subchartprop2: value


now in the above set of values, let's assume there is a parentchart and it has a sub-chart named subchart1. you need to understand the following points:


parentprop1 and parentprop2 can only be accessed in parentchart and not in subchart1 as values.parentprop1 and values.parentprop2
global properties can be accessed from both parent and subchart1 as values.global.globalprop1
subchartprop1 and subchartprop2 can be accessed as values.subchart1.subchartprop1 and values.subchart1.subchartprop2 in parentchart
subchartprop1 and subchartprop2 can be accessed as values.subchartprop1 and values.subchartprop2 in subchart1


also please don't forget to use proper syntax of double curly-braces {{ values.xyz }}

i hope it helps. :)
"
58223841,modify kubernetes deployment revision history limit,"how would we modify the default history limit in kubernetes. at this point, the default history limit is 3 revisions. i would like to increase this by 10. 

i use the below command to get the revision history

kubectl rollout history deployment &lt;deployment name&gt;
",<kubernetes><kubectl>,58224195,11,"ok, i found the answer to this.

every deployment has its own revision limit stored in its replica set in this field .spec.revisionhistorylimit. the respective replica set needs to be updated in order to change the revision limit.
"
67619312,retrieve pod description(kubectl describe) from the output of other expression,"in kubectl,  describe and get -o  can be used to get the details of a resource, can we get a describe of only a list of selected pods (different labels), my case is to details of selected pod names for analysis. i'm using describe but unable to get details of specific pods, there are quite a few to do it manually.
if it was events/ specific labels, i could do the below but need more specific details of certain pods out of 100 of them
kubectl get describe po -l app2=test &gt; desc.txt
kubectl get events -n test|grep -e 'app2|app3|hello1' &gt; events.txt


tried the below it returns the events of all pods in the namespace (doesnt help), any simpler way or may be this cannot be done or write a script to loop through the o/p?
kubectl get po -n test |grep -e 'app2|app3|hello1' |awk '{print $1}'|k describe po  -n test &gt; desc.txt

thanks for the help!
",<kubernetes><kubectl>,67619720,2,"are you saying you can't use labels?
not sure i understand correctly but if you need to choose pods by name - this will work:
kubectl get pod -oname | grep -e 'app2|app3|hello' | xargs kubectl describe

"
57122081,kubernetes sends traffic to the pod even after sending sigterm,"i have a springboot project with graceful shutdown configured. deployed on k8s 1.12.7 here are the logs,

2019-07-20 10:23:16.180 info [service,,,] 1 --- [ thread-7] com.jay.util.gracefulshutdown : received shutdown event
2019-07-20 10:23:16.180 info [service,,,] 1 --- [ thread-7] com.jay.util.gracefulshutdown : waiting for 30s to finish
2019-07-20 10:23:16.273 info [service,fd964ebaa631a860,75a07c123397e4ff,false] 1 --- [io-8080-exec-10] com.jay.resource.productresource : get /products?id=59
2019-07-20 10:23:16.374 info [service,9a569ecd8c448e98,00bc11ef2776d7fb,false] 1 --- [nio-8080-exec-1] com.jay.resource.productresource : get /products?id=68
...
2019-07-20 10:23:33.711 info [service,1532d6298acce718,08cfb8085553b02e,false] 1 --- [nio-8080-exec-9] com.jay.resource.productresource : get /products?id=209
2019-07-20 10:23:46.181 info [service,,,] 1 --- [ thread-7] com.jay.util.gracefulshutdown : resumed after hibernation
2019-07-20 10:23:46.216 info [service,,,] 1 --- [ thread-7] o.s.s.concurrent.threadpooltaskexecutor : shutting down executorservice 'applicationtaskexecutor'


application has received the sigterm at 10:23:16.180 from kubernetes. as per termination of pods point#5 says that the terminating pod is removed from the endpoints list of service, but it is contradicting that it forwarded the requests for 17 seconds (until 10:23:33.711) after sending sigterm signal. is there any configuration missing?

dockerfile

from openjdk:8-jre-slim
maintainer jay

run apt update &amp;&amp; apt install -y curl libtcnative-1 gcc &amp;&amp; apt clean

add build/libs/sample-service.jar /

cmd [""java"", ""-jar"" , ""sample-service.jar""]


gracefulshutdown

// https://github.com/spring-projects/spring-boot/issues/4657
class gracefulshutdown(val waittime: long, val timeout: long) : tomcatconnectorcustomizer, applicationlistener&lt;contextclosedevent&gt; {

    @volatile
    private var connector: connector? = null

    override fun customize(connector: connector) {
        this.connector = connector
    }

    override fun onapplicationevent(event: contextclosedevent) {

        log.info(""received shutdown event"")

        val executor = this.connector?.protocolhandler?.executor
        if (executor is threadpoolexecutor) {
            try {
                val threadpoolexecutor: threadpoolexecutor = executor

                log.info(""waiting for ${waittime}s to finish"")
                hibernate(waittime * 1000)

                log.info(""resumed after hibernation"")
                this.connector?.pause()

                threadpoolexecutor.shutdown()
                if (!threadpoolexecutor.awaittermination(timeout, timeunit.seconds)) {
                    log.warn(""tomcat thread pool did not shut down gracefully within $timeout seconds. proceeding with forceful shutdown"")

                    threadpoolexecutor.shutdownnow()

                    if (!threadpoolexecutor.awaittermination(timeout, timeunit.seconds)) {
                        log.error(""tomcat thread pool did not terminate"")
                    }
                }
            } catch (ex: interruptedexception) {
                log.info(""interrupted"")
                thread.currentthread().interrupt()
            }
        }else
            this.connector?.pause()
    }

    private fun hibernate(time: long){
        try {
            thread.sleep(time)
        }catch (ex: exception){}
    }

    companion object {
        private val log = loggerfactory.getlogger(gracefulshutdown::class.java)
    }
}
@configuration
class gracefulshutdownconfig(@value(""\${app.shutdown.graceful.wait-time:30}"") val waittime: long,
                             @value(""\${app.shutdown.graceful.timeout:30}"") val timeout: long) {

    companion object {
        private val log = loggerfactory.getlogger(gracefulshutdownconfig::class.java)
    }

    @bean
    fun gracefulshutdown(): gracefulshutdown {

        return gracefulshutdown(waittime, timeout)
    }

    @bean
    fun webserverfactory(gracefulshutdown: gracefulshutdown): configurableservletwebserverfactory {

        log.info(""gracefulshutdown configured with wait: ${waittime}s and timeout: ${timeout}s"")

        val factory = tomcatservletwebserverfactory()
        factory.addconnectorcustomizers(gracefulshutdown)
        return factory
    }
}


deployment file

apiversion: extensions/v1beta1
kind: deployment
metadata:
  labels:
    k8s-app: service
  name: service
spec:
  progressdeadlineseconds: 420
  replicas: 1
  revisionhistorylimit: 1
  selector:
    matchlabels:
      k8s-app: service
  strategy:
    rollingupdate:
      maxsurge: 2
      maxunavailable: 0
    type: rollingupdate
  template:
    metadata:
      labels:
        k8s-app: service
    spec:
      terminationgraceperiodseconds: 60
      containers:
      - env:
        - name: spring_profiles_active
          value: dev
        image: service:2
        imagepullpolicy: ifnotpresent
        livenessprobe:
          failurethreshold: 20
          httpget:
            path: /actuator/health
            port: 8080
          initialdelayseconds: 60
          periodseconds: 30
          timeoutseconds: 5
        name: service
        ports:
        - containerport: 8080
          protocol: tcp
        readinessprobe:
          failurethreshold: 60
          httpget:
            path: /actuator/health
            port: 8080
          initialdelayseconds: 100
          periodseconds: 10
          timeoutseconds: 5


update:

added custom health check endpoint

@restcontrollerendpoint(id = ""live"")
@component
class liveendpoint {

    companion object {
        private val log = loggerfactory.getlogger(liveendpoint::class.java)
    }

    @autowired
    private lateinit var gracefulshutdownstatus: gracefulshutdownstatus

    @getmapping
    fun live(): responseentity&lt;any&gt; {

        val status = if(gracefulshutdownstatus.isterminating())
            httpstatus.internal_server_error.value()
        else
            httpstatus.ok.value()

        log.info(""status: $status"")
        return responseentity.status(status).build()
    }
}


changed the livenessprobe,

  livenessprobe:
    httpget:
      path: /actuator/live
      port: 8080
    initialdelayseconds: 100
    periodseconds: 5
    timeoutseconds: 5
    failurethreshold: 3


here are the logs after the change,

2019-07-21 14:13:01.431  info [service,9b65b26907f2cf8f,9b65b26907f2cf8f,false] 1 --- [nio-8080-exec-2] com.jay.util.liveendpoint          : status: 200
2019-07-21 14:13:01.444  info [service,3da259976f9c286c,64b0d5973fddd577,false] 1 --- [nio-8080-exec-3] com.jay.resource.productresource   : get /products?id=52
2019-07-21 14:13:01.609  info [service,,,] 1 --- [       thread-7] com.jay.util.gracefulshutdown      : received shutdown event
2019-07-21 14:13:01.610  info [service,,,] 1 --- [       thread-7] com.jay.util.gracefulshutdown      : waiting for 30s to finish
...
2019-07-21 14:13:06.431  info [service,002c0da2133cf3b0,002c0da2133cf3b0,false] 1 --- [nio-8080-exec-3] com.jay.util.liveendpoint          : status: 500
2019-07-21 14:13:06.433  info [service,072abbd7275103ce,d1ead06b4abf2a34,false] 1 --- [nio-8080-exec-4] com.jay.resource.productresource   : get /products?id=96
...
2019-07-21 14:13:11.431  info [service,35aa09a8aea64ae6,35aa09a8aea64ae6,false] 1 --- [io-8080-exec-10] com.jay.util.liveendpoint          : status: 500
2019-07-21 14:13:11.508  info [service,a78c924f75538a50,0314f77f21076313,false] 1 --- [nio-8080-exec-2] com.jay.resource.productresource   : get /products?id=110
...
2019-07-21 14:13:16.431  info [service,38a940dfda03956b,38a940dfda03956b,false] 1 --- [nio-8080-exec-9] com.jay.util.liveendpoint          : status: 500
2019-07-21 14:13:16.593  info [service,d76e81012934805f,b61cb062154bb7f0,false] 1 --- [io-8080-exec-10] com.jay.resource.productresource   : get /products?id=152
...
2019-07-21 14:13:29.634  info [service,38a32a20358a7cc4,2029de1ed90e9539,false] 1 --- [nio-8080-exec-6] com.jay.resource.productresource   : get /products?id=191
2019-07-21 14:13:31.610  info [service,,,] 1 --- [       thread-7] com.jay.util.gracefulshutdown      : resumed after hibernation
2019-07-21 14:13:31.692  info [service,,,] 1 --- [       thread-7] o.s.s.concurrent.threadpooltaskexecutor  : shutting down executorservice 'applicationtaskexecutor'


with the livenessprobe of 3 failures, kubernetes served the traffic for 13 seconds after liveness failures i.e., from 14:13:16.431 to 14:13:29.634.

update 2:
the sequence of events (thanks to eamonn mcevoy)

seconds | healthy | events
   0    |    ✔    |   * liveness probe healthy
   1    |    ✔    |   - sigterm
   2    |    ✔    |   
   3    |    ✔    |   
   4    |    ✔    |   
   5    |    ✔    |   * liveness probe unhealthy (1/3)
   6    |    ✔    |   
   7    |    ✔    |   
   8    |    ✔    |   
   9    |    ✔    |   
   10   |    ✔    |   * liveness probe unhealthy (2/3)
   11   |    ✔    |   
   12   |    ✔    |   
   13   |    ✔    |   
   14   |    ✔    |   
   15   |    ✘    |   * liveness probe unhealthy (3/3)
   ..   |    ✔    |   * traffic is served       
   28   |    ✔    |   * traffic is served
   29   |    ✘    |   * pod restarts

",<spring-boot><deployment><kubernetes><kubernetes-pod>,57123663,5,"sigterm isn't putting the pod into a terminating state immediately. you can see in the logs your application begins graceful shutdown at 10:23:16.180 and takes >20 seconds to complete. at this point, the container stops and pod can enter the terminating state.

as far as kubernetes is concerned the pod looks ok during the graceful shutdown period. you need to add a liveness probe to your deployment; when it becomes unhealthy the traffic will stop.

livenessprobe:
  httpget:
    path: /actuator/health
    port: 8080
  initialdelayseconds: 100
  periodseconds: 10
  timeoutseconds: 5


update:

this is because you have a failure threshold of 3, so you are allowing traffic for up to 15 seconds after the sigterm;

e.g.

seconds | healthy | events
   0    |    ✔    |   * liveness probe healthy
   1    |    ✔    |   - sigterm
   2    |    ✔    |   
   3    |    ✔    |   
   4    |    ✔    |   
   5    |    ✔    |   * liveness probe issued
   6    |    ✔    |       .
   7    |    ✔    |       .
   8    |    ✔    |       .
   9    |    ✔    |       .
   10   |    ✔    |   * liveness probe timeout - unhealthy (1/3)
   11   |    ✔    |   
   12   |    ✔    |   
   13   |    ✔    |   
   14   |    ✔    |   
   15   |    ✔    |   * liveness probe issued
   16   |    ✔    |       .
   17   |    ✔    |       .
   18   |    ✔    |       .
   19   |    ✔    |       .
   20   |    ✔    |   * liveness probe timeout - unhealthy (2/3)
   21   |    ✔    |   
   22   |    ✔    |   
   23   |    ✔    |   
   24   |    ✔    |   
   25   |    ✔    |   * liveness probe issued
   26   |    ✔    |       .
   27   |    ✔    |       .
   28   |    ✔    |       .
   29   |    ✔    |       .
   30   |    ✘    |   * liveness probe timeout - unhealthy (3/3)
        |         |   * pod restarts



this is assuming that the endpoint returns an unhealthy response during the graceful shutdown. since you have timeoutseconds: 5, if the probe simply times out this will take much longer, with a 5 second delay between issuing a liveness probe request and receiving its response. it could be the case that the container actually dies before the liveness threshold is hit and you are still seeing the original behaviour
"
61462892,how to change users in kubectl?,"in my machine i have two kubectl users, my company's account and my personal account. i can confirm that by running kubectl config view.

i'm trying to access my company's cluster but kubectl is using to my personal credentials to authenticate. which is causing an error, as expected.

how do i change to my company's account?
",<kubernetes><kubectl>,61463000,8,"users and clusters are tied to a context and you can change users and clusters by changing the context.

kubectl config use-context my-context-name


above command sets the current context to my-context-name.now when kubectl is used the user and cluster tied to my-context-name context will be used.

check the docs for more details and various other available options.
"
75984109,how do i import dashboards by id from grafana.com? without json files and configmap,"i have a helm chart that deploys a kube-prometheus stack (prometheus, grafana, node-exporter), there are some json files (dashboards) in the grafana configuration, they are transferred to the grafana pod via configmap (common practice). i have a task to optimize this configuration to add grafana dashboards via their id from grafana.com and not to use json files (as they are very big). i know how to create a folder in grafana and specify the prometheus resource, but i don't understand how to export dashboards by id.
to create a folder i have a file (yaml) which is added via configmap to the directory /etc/grafana/provisioning/dashboards
- name: 'default'
  org_id: 1
  folder: 'my-dashboards'
  type: 'file'
  options:
    folder: '/var/lib/grafana/dashboards'

how to do it and in which file i need to insert this configuration to make it work. i will be grateful for help.
i tried to create configurations i found on github (dashboardproviders), but it only creates a folder (the code i specified), without dashboards
upd: what i have now
apiversion: 1
providers:
  # &lt;string&gt; an unique provider name. required
  - name: 'prometheus'
    # &lt;int&gt; org id. default to 1
    orgid: 1
    # &lt;string&gt; name of the dashboard folder.
    folder: 'my-dashboards'
    # &lt;string&gt; folder uid. will be automatically generated if not specified
    folderuid: ''
    # &lt;string&gt; provider type. default to 'file'
    type: file
    # &lt;bool&gt; disable dashboard deletion
    disabledeletion: false
    # &lt;int&gt; how often grafana will scan for changed dashboards
    updateintervalseconds: 10
    # &lt;bool&gt; allow updating provisioned dashboards from the ui
    allowuiupdates: false
    options:
      # &lt;string, required&gt; path to dashboard files on disk. required when using the 'file' type
      path: /var/lib/grafana/dashboards
      # &lt;bool&gt; use folder names from filesystem to create folders in grafana
      foldersfromfilesstructure: true

dashboards:
  default:
    minio:
      gnetid: 13502
      revision: 2
      datasource: prometheus


but it still doesn't work...why?
",<kubernetes><kubernetes-helm><grafana><dashboard>,75985106,5,"it is (or can be) a part of the grafana helm chart, from what i remember when used it in the past. that configuration needs to go into the values.yaml when using that helm chart.
specifically here to enable/configure dashboardproviders and here to provision the dashboard using dashboard id from the grafana website.
can also refer to some documentation here.
hope it helps.
update:
using the below config i was able to import the minio dashboard (the one op tried to import):
dashboardproviders:
  dashboardproviders.yaml:
   apiversion: 1
   providers:
   - name: 'default'
     orgid: 1
     folder: 'default'
     type: file
     disabledeletion: true
     editable: true
     options:
       path: /var/lib/grafana/dashboards/standard

dashboards:
  default:
    minio:
      gnetid: 13502
      revision: 2
      datasource: prometheus


ofcourse i don't have the prometheus data source, hence the warning sign(s).
"
76764211,kubernetes deny commnunications between pods,"i have two deployments in kubernetes on azure both with three replicas. both deployments use oauth2 reverse proxy for external users/requests authentication. the manifest file for both deployments looks like the following:

apiversion: apps/v1
kind: deployment
metadata:
  name: myservice1
  labels:
    aadpodidbinding: my-pod-identity-binding
spec:
  replicas: 3
  progressdeadlineseconds: 1800
  selector:
    matchlabels:
      app: myservice1
  template:
    metadata:
      labels:
        app: myservice1
        aadpodidbinding: my-pod-identity-binding
      annotations:
        aadpodidbinding.k8s.io/userassignedmsiclientid: pod-id-client-id
        aadpodidbinding.k8s.io/subscriptionid: my-subscription-id
        aadpodidbinding.k8s.io/resourcegroup: my-resource-group
        aadpodidbinding.k8s.io/usemsi: 'true'
        aadpodidbinding.k8s.io/clientid: pod-id-client-id
    spec:
      securitycontext:
        fsgroup: 2000
      containers:
        - name: myservice1
          image: mycontainerregistry.azurecr.io/myservice1:latest
          imagepullpolicy: always
          ports:
          - containerport: 5000
          securitycontext:
            runasuser: 1000
            allowprivilegeescalation: false
          readinessprobe:
            initialdelayseconds: 1
            periodseconds: 2
            timeoutseconds: 60
            successthreshold: 1
            failurethreshold: 1
            httpget:
              host:
              scheme: http
              path: /healthcheck
              port: 5000
              httpheaders:
              - name: host
                value: http://127.0.0.1
          resources:
            requests:
              memory: &quot;4g&quot;
              cpu: &quot;2&quot;
            limits:
              memory: &quot;8g&quot;
              cpu: &quot;4&quot;
          env:
          - name: message
            value: hello from the external app!!
---
apiversion: v1
kind: service
metadata:
  name: myservice1
spec:
  type: clusterip
  ports:
  - port: 80
    targetport: 5000
  selector:
    app: myservice1
---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/auth-url: &quot;https://myservice1.com/oauth2/auth&quot;
    nginx.ingress.kubernetes.io/auth-signin: &quot;https://myservice1.com/oauth2/start?rd=https://myservice1.com/oauth2/callback&quot;
    kubernetes.io/ingress.class: nginx-external
    nginx.org/proxy-connect-timeout: 3600s
    nginx.org/proxy-read-timeout: 3600s
    nginx.org/proxy-send-timeout: 3600s  
  name: myservice1-external
spec:
  rules:
  - host: myservice1.com
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: myservice1
            port:
              number: 80


now, i want to restrict the communication between the pods in two ways:

intra-deployments: i want to deny any communication between the 3 pods of each deployments internally; meaning that all 3 pods can and must only communicate with their corresponding proxy (ingress part of the manifest)

inter-deployments: i want to deny any communications between any two pods belonging to two deployments; meaning that if for example pod1 from deployment1 tries lets say to ping or send http request to pod2 from deployment2; this will be denied.

allow requests throw proxies: the only requests that are allowed to enter must go through the correspoding deployment's proxy.


how to implement the manifest for the netwrok policy that achieves these requirements?
",<kubernetes><kubernetes-ingress><azure-aks>,76814072,1,"you can make use of networkpolicies and reference the policy in your ingress configuration like below:-
my networkpolicy.yml:-
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: default-deny-all
spec:
  podselector: {}
  policytypes:
  - ingress
  - egress


i applied it in my azure kubernetes like below:-
kubectl apply -f networkpolicy.yml
kubectl get networkpolicies




then use the below yml file to reference the networkpolicy in the ingress settings:-
ingress.yml:-
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: ingress-access
spec:
  podselector:
    matchlabels:
      app.kubernetes.io/name: ingress-nginx
  ingress:
  - from:
    - ipblock:
        cidr: 192.168.1.0/24
---
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: ingress-to-backends
spec:
  podselector:
    matchlabels:
      app: myapp
  ingress:
  - from:
    - namespaceselector:
        matchlabels:
          ingress: &quot;true&quot;
      podselector:
        matchlabels:
          app.kubernetes.io/name: ingress-nginx



"
71351229,helm hook for both pod and job for kubernetes not running all yamls,"i am using kubernetes with helm 3.
it is ran on centos linux 7 (core).
k8s (check by running: kubectl version):
git version (kubernetes): v1.21.6, go version: go1.16.9.
helm version: v3.3.4
helm version (git) go1.14.9.
i need to create a job that is running after a pod is created.
the pod yaml:
apiversion: v1
kind: pod
metadata:
  name: {{ include &quot;test.fullname&quot; . }}-mysql
  labels:
    app: {{ include &quot;test.fullname&quot; . }}-mysql
  annotations:
    &quot;helm.sh/hook&quot;: post-install
    &quot;helm.sh/hook-weight&quot;: &quot;-20&quot;
    &quot;helm.sh/delete-policy&quot;: before-hook-creation
spec:
  containers:
    - name: {{ include &quot;test.fullname&quot; . }}-mysql
      image: {{ .values.mysql.image }}
      imagepullpolicy: ifnotpresent
      env:
        - name: mysql_root_password
          value: &quot;12345&quot;
        - name: mysql_database
          value: test

the job:
apiversion: batch/v1
kind: job
metadata:
  name: {{ include &quot;test.fullname&quot; . }}-migration-job
  labels:
    app: {{ include &quot;test.fullname&quot; . }}-migration-job
  annotations:
    &quot;helm.sh/hook&quot;: post-install
    &quot;helm.sh/hook-weight&quot;: &quot;-10&quot;
    &quot;helm.sh/hook-delete-policy&quot;: hook-succeeded, hook-failed
spec:
  parallelism: 1
  completions: 1
  backofflimit: 1
  template: #podtemplatespec (core/v1)
    spec: #podspec (core/v1)
    initcontainers: # regular
    - name: wait-mysql
      image: bitnami/kubectl
      imagepullpolicy: ifnotpresent
      args:
        - wait
        - pod/{{ include &quot;test.fullname&quot; . }}-mysql
        - --namespace={{ .release.namespace }}
        - --for=condition=ready
        - --timeout=120s
    containers:
      - name: {{ include &quot;test.fullname&quot; . }}
        image: {{ .values.mymigration.image }}
        imagepullpolicy: ifnotpresent
        command: {{- toyaml .values.image.entrypoint | nindent 12 }}
        args: {{- toyaml .values.image.cmd | nindent 12}}

mysql is mysql 5.6 image.
when i write the above, also run helm install test ./test --namespace test --create-namespace
even though i changed the hook for pre-install (for pod and job), the job is never running.
in both situations, i get messages (and need to press - to exit - i don't want this behavior either:

pod test-mysql pending pod test-mysql pending pod


test-mysql pending pod test-mysql running pod


test-mysql running pod test-mysql running pod


test-mysql running ...

in this example, when i put a 'bug' in the job, for example: containersx instead of container, i don't get any notification that i have a wrong syntax.
maybe because mysql is running (and not completed), can i force to go to the next yaml declared by hook? (even i declare the proper order for pod and job. pod should run before job).
what is wrong, and how can i ensure the pod is created before the job? and when the pod starts running, my job will run after that?
thanks.
",<mysql><kubernetes><hook><kubernetes-helm><kubernetes-jobs>,71624559,1,"as per your configuration, it looks like you need to set post-install  hook precisely for job as it should execute after all resources are loaded into kubernetes. on executing  pre-install hook both on pod and job, it is run before the rest of the chart is loaded, which seems to prevent job from starting.
"
63636936,multiple replicas of nginx-ingress-controller on aws eks,"
are there any issues to scale replicas:1 to replicas:3 for nginx-ingress-controller deployment?
so the controller has created aws classic elb, with many replicas - are we going to have the same (single elb) or one per pod (as number of pods will increase)?

the reason i'm asking is that i'm running the controller inside ec2spot-based aws eks cluster and when the ec2spotinstance is interrupted by aws - i get downtime.
",<kubernetes><nginx-ingress><amazon-eks>,63637088,2,"
are there any issues to scale replicas:1 to replicas:3 for
nginx-ingress-controller deployment?

nginx ingress controller watches on few resources exposed by kubernetes api server such as service, endpoints etc. when you scale number of replicas it might put more pressure on the kubernetes api server because now 3 replicas will watch instead of 1.but with increase of 2 replicas it may not be observable but i suggest to put some monitoring in place to observe any impact.

so the controller has created aws classic elb, with many replicas -
are we going to have the same (single elb) or one per pod (as number
of pods will increase)?

yes you will have same and single elb because elb is created per service object. so increase in replica count of pod should not create new elb. same elb will send traffic to the kubernetes service which will perform load balancing to 3 replica pods of nginx ingress controller.
"
76359283,troubleshooting kubectl get pods command: why is .spec.containers.ports.containerport returning <none>?,"i am getting the ip address assigned to the pod using kubectl get pods -o custom-columns=&quot;pod_ip&quot;:.status.podips command.
and based on same approach, i am using kubectl get pods -o custom-columns=&quot;pod_port&quot;:.spec.containers.ports.containerport command to get the port number but it is coming as blank.
cloudshell:~$ kubectl get pods -o custom-columns=&quot;pod_ip&quot;:.status.podips
pod_ip
[map[ip:10.32.0.194]]

cloudshell:~$ kubectl get pods -o custom-columns=&quot;pod_port&quot;:.spec.containers.ports.containerport
pod_port
&lt;none&gt;

cloudshell:~$ kubectl get pods -o custom-columns=&quot;pod_port&quot;:.spec.containers
pod_port
[map[image:nginx:1.10.1 imagepullpolicy:ifnotpresent name:servic1 ports:[map[containerport:8080 protocol:tcp]] resources:map[limits:map[cpu:500m ephemeral-storage:1gi memory:2gi] requests:map[cpu:500m ephemeral-storage:1gi memory:2gi]] securitycontext:map[capabilities:map[drop:[net_raw]]] terminationmessagepath:/dev/termination-log terminationmessagepolicy:file volumemounts:[map[mountpath:/var/run/secrets/kubernetes.io/serviceaccount name:kube-api-access-mgk8k readonly:true]]]]

cloudshell:~$ 

i have tried to use kubectl get pods -o custom-columns=&quot;port number of pod&quot;:.spec.containers command and i can see that my mapping (.spec.containers.ports.containerport) is correct but somehow it is still not working.
i am totally sure that .spec.containers.ports.containerport mapping correct, and same command format is giving ip address, so not able to catch what is wrong.
is anyone able to catch what is wrong here?
",<kubernetes><google-kubernetes-engine><kubectl>,76360463,5,"try:
kubectl get pods \
--output=custom-columns=\
&quot;pod_port&quot;:.spec.containers[*].ports[*].containerport

you can include .metadata.name too to aid clarity:
kubectl get pods \
--output=custom-columns=\
&quot;name&quot;:.metadata.name,\
&quot;pod_port&quot;:.spec.containers[*].ports[*].containerport

it's not clearly (!?) documented but i suspect the format is kubectl's jsonpath and there (appears to be) a subtle distinction between e.g. .spec.containers[] and .spec.containers[*] where the former stops when the property is not found and the latter includes everything.
because .spec will always include one or more .containers, but each container may not have .ports, you can also:
kubectl get pods \
--output=custom-columns=\
&quot;pod_port&quot;:.spec.containers[].ports[*].containerport

which containers[] but ports[*] to the same effect.
note as explained in container v1 core see &quot;ports&quot;, ports that are exposed by the container need not be specified through ports i.e. this command will return documented ports but this list may exclude ports that are exposed by the containers (and not documented).
"
59483171,imagepullsecrets on default service account don't seem to work,"i am basically trying to pull gcr images from azure kubernetes cluster.
i have the folowing for my default service account:

kubectl get serviceaccounts default -o yaml                            
apiversion: v1
imagepullsecrets:
- name: gcr-json-key-stg
kind: serviceaccount
metadata:
  creationtimestamp: ""2019-12-24t03:42:15z""
  name: default
  namespace: default
  resourceversion: ""151571""
  selflink: /api/v1/namespaces/default/serviceaccounts/default
  uid: 7f88785d-05de-4568-b050-f3a5dddd8ad1
secrets:
- name: default-token-gn9vb


if i add the same imagepullsecret to individual deployments, it works. so, the secret is correct. however, when i use it for a default service account, i get a imagepullbackoff error which on describing confirms that it's a permission issue.

am i missing something?
i have made sure that my deployment is not configured with any other specific serviceaccount and should be using the default serviceaccount.
",<kubernetes><google-kubernetes-engine><azure-aks>,59556866,1,"ok, the problem was that the default service account that i added the imagepullsecret wasn't in the same namespace.
once, i patched the default service account in that namespace, it works perfectly well.
"
66613889,java jib-maven-plugin with kubernetes memory controll,"actually i'm using the jib-maven-plugin to create docker container for my application. then i'm going to deploy it to google servers where we have a kubernetes environment.
actually we are playing with the java env. variables from the jib-maven-plugin's config (pom.xml):
&lt;jvmflags&gt;
  &lt;jvmflag&gt;-xx:minrampercentage=60.0&lt;/jvmflag&gt;
  &lt;jvmflag&gt;-xx:maxrampercentage=80.0&lt;/jvmflag&gt;
  &lt;jvmflag&gt;-xx:+heapdumponoutofmemoryerror&lt;/jvmflag&gt;
  &lt;jvmflag&gt;-djdk.tls.client.protocols=&quot;tlsv1,tlsv1.1,tlsv1.2&quot;&lt;/jvmflag&gt;
&lt;/jvmflags&gt;

now we would like to move these configurations to our deployment yml file, we found something like:
env:
- name: java_opts
  value: &quot;-xx:minrampercentage=60.0 -xx:maxrampercentage=90.0 -xx:+heapdumponoutofmemoryerror&quot;
...
resources: 
    limits:
        memory: 512mi
    requests:
        memory: 256mi

but it seems that if we remove these configs from the jib-maven-plugin's config file and move them to the yml file they are simply not working. the container starts without having any effects of the mentioned settings.
we are using open jdk 11, that may be also important.
how it's possible to control the java env. options from the deployment file?
thank you so much for your help, have a nice day!
",<kubernetes><google-kubernetes-engine><java-11><jib>,66623367,4,"the problem is that you're setting java_opts and not jdk_java_options.
java_opts is used by some application servers like tomcat, but the jdk itself uses jdk_java_options.
therefore, a working kubernetes yaml would be something like:
apiversion: apps/v1
kind: deployment
metadata:
    ...
spec:
  template:
    metadata:
        ...
    spec:
      containers:
        - name: ...
          image: ...
          env:
            - name: jdk_java_options
              value: -xx:minrampercentage=60 -xx:maxrampercentage=80 -xx:+heapdumponoutofmemoryerror -djdk.tls.client.protocols=&quot;tlsv1,tlsv1.1,tlsv1.2&quot;

"
73908532,how to use the same iam role for two node groups in an eks cluster in terraform?,"context: i am trying to setup fluent bit for logging activities in pods in a number of node groups included in a cluster. and so it requires that each node group have an iam role assigned to it with all the required policies so, fluent bit's daemonset could record and save logs into log groups in cloud watch. here's the repo of the solution i am following.
what have i tried:

create individual node group roles and attach policies by passing inputs into relevant variables of the modules. like so:

module &quot;eks&quot; {
...
        eks_managed_node_groups = {
            one = {

              create_iam_role          = true
              iam_role_name            = &quot;fluent-bit-logger&quot;
              iam_role_use_name_prefix = true
              iam_role_description     = &quot;fluent-bit-logging for node group 1&quot;
              iam_role_tags = {
                name = &quot;fb-ng-2&quot;
              }
            two = {
               (same config, with obvious naming changes)
              }
           }
...
}


the above step worked but i am trying to setup fluent bit through terraform's helm resource and based on the solution i am following i am required to input only one iam node role or that's what i make of it.

use the eks_managed_node_group_defaults attribute to create and
assign hopefully the same iam role to both the node groups and this is how i did it.


module &quot;eks&quot; {
  source  = &quot;terraform-aws-modules/eks/aws&quot;
  version = &quot;18.26.6&quot;

  cluster_name    = local.cluster_name
  cluster_version = &quot;1.21&quot;

  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets

  eks_managed_node_group_defaults = {
    ami_type = &quot;al2_x86_64&quot;

    attach_cluster_primary_security_group = true

    # disabling and using externally provided security groups
    create_security_group = false

    # fluent-bit (iam-policy-role)
    create_iam_role          = true
    iam_role_name            = &quot;fluent-bit-logger&quot;
    iam_role_use_name_prefix = false
    iam_role_description     = &quot;fluent-bit-logging - default for node groups&quot;
    iam_role_tags = {
      name = &quot;fb-ng-default&quot;
      }


what i expect to get
a message of successful eks cluster module execution (including the expected common node group role for the both node groups within.
the error i get
error: failed creating iam role (fluent-bit-logger): entityalreadyexists: role with name fluent-bit-logger already exists.
│   status code: 409, request id: fx11xxax-axex-4xxx-b749-09xx8x8xx17x
│ 
│   with module.eks-cluster.module.eks.module.eks_managed_node_group[&quot;two&quot;].aws_iam_role.this[0],
│   on .terraform/modules/eks-cluster.eks/modules/eks-managed-node-group/main.tf line 431, in resource &quot;aws_iam_role&quot; &quot;this&quot;:
│  431: resource &quot;aws_iam_role&quot; &quot;this&quot; {


",<amazon-web-services><kubernetes><terraform><devops><amazon-eks>,73909396,2,"the error message states that you are attempting to create the same role twice, which would cause the aws api to error. this is consistent with your config given the argument value:
create_iam_role = true

for two different eks node groups. you would need to change the value to false, manage the role with e.g. aws_iam_role.fluent_bit_logger, and then (best practices) update accordingly:
iam_role_name = aws_iam_role.fluent_bit_logger.name

otherwise, you could manage the role within the eks module declaration by using the config you shared in the first part of the question.
"
33942709,run a single kubectl command for a specific project and cluster?,"background

we're using jenkins to deploy a new version of a kubernetes (k8s) replication controller to our test or prod cluster. the test and prod (k8s) clusters are located under different (google cloud platform) projects. we have configured two profiles for our gcloud sdk on jenkins, one for test (test-profile) and one for prod (prod-profile). we have defined a managed script in jenkins that performs the rolling update for our replication controller. the problems is that i cannot find a way to control to which project i want to target the kubectl rolling-update command (you can specify which cluster but not which project afict). so right now our script that does the rolling update to our test server looks something like this:

gcloud config configurations activate test-profile &amp;&amp; kubectl rolling-update ...


while this works it could be extremely dangerous if two jobs run concurrently for different environments. say that job 1 targets the test environment and job 2 targets prod. if job2 switches the active profile to ""prod-profile"" before job 1 has executed its rolling-update command job 1 will target to wrong project and in worse case update the wrong replication controller (if the clusters have the same name).

question

is there a way to specify which project that a kubectl command is targeting (for example during a rolling update) that is safe to run concurrently?
",<google-cloud-platform><kubernetes><google-kubernetes-engine>,34009951,11,"you can pass the --cluster= or --context= flags to kubectl to set a single run.  for example, if i have two clusters in my ~/.kube/config ""foo"" and ""bar"":

$ kubectl --cluster=foo get pods
name              ready     status    restarts   age
foo-ht1qh   1/1       running   0          3h
foo-wf8f4   1/1       running   0          3h
foo-yvgpd   1/1       running   0          3h


vs

$ kubectl --cluster=bar get pods
name              ready     status    restarts   age
bar-de4h7   1/1       running   0          9h
bar-c4g03   1/1       running   0          9h
bar-2sprd   1/1       running   0          9h

"
68046669,get all the pods dynamically created belonging to an autoscaled deployment,"i am running an application/deployment called cons1persec on google kubernetes engine gke. my application/deployment is being monitored through a controller application and autoscaled approparitely based on a metric. i can view the logs of my deployment in google cloud logs explorer through the following query :
resource.type=&quot;k8s_container&quot;
resource.labels.project_id=&quot;autoscaling-kafka&quot;
resource.labels.location=&quot;europe-west1-d&quot;
resource.labels.cluster_name=&quot;autoscalekafka&quot;
resource.labels.namespace_name=&quot;default&quot;
labels.k8s-pod/app=&quot;cons1persec&quot; severity&gt;=default

my question is about the appropriate query to get the number of pods created belonging to my application/deployment  cons1persec, the name of pods and their creation/deletion time etc..
thank you.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,68113849,1,"when using deployment, it makes use of deployment’s name as a prefix for a pod’s name it creates and we cannot have two deployments with the same name, so we can make use of these to query for pods belonging to a specific deployment.
refer to the below sample query which uses regular expressions/substring comparison operator to match the deployment name which is prefix of a pod’s name and reason for log creation to query for the pod’s name, creation/deletion and corresponding timestamps.
sample log query:
severity = info
resource.type = &quot;k8s_cluster&quot;
log_name = &quot;projects/&lt;project-id&gt;/logs/events&quot;
jsonpayload.reason = (&quot;successfulcreate&quot; or &quot;successfuldelete&quot;)
# using regular expressions[1]
jsonpayload.metadata.name =~ &quot;&lt;workload-name&gt;\s*&quot;  
# using substring comparison operator[2]
jsonpayload.metadata.name : &quot;workload-name&quot;

[1]- https://cloud.google.com/logging/docs/view/logging-query-language#regular-expressions
[2]- https://cloud.google.com/logging/docs/view/logging-query-language#comparisons
"
69423932,container initialization order in pod on k8s,"i want to run two containers on a single pod.
container1 is a test that tries to connect to a sql server database that runs on container2.
how can i make sure that the sql container (container2) will run and be ready before container1 starts?
initcontainer won't work here, as it will run before both containers.
this is my compose.yaml:
apiversion: v1
kind: pod
metadata:
  name: sql-test-pod
  labels:
    name: sql-test
spec:
  restartpolicy: never
  containers:
    - name: my-sqldb
      image: docker-registry.com/database
      imagepullpolicy: always
      resources:
        limits:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
        requests:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
    - name: tests
      tty: true
      stdin: true
      image: docker-registry.com/test
      imagepullpolicy: always
      resources:
        limits:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
        requests:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
      env:
      - name: sqlhostname
        value: &quot;sqlhostnameplaceholder&quot;
  nodeselector:
    kubernetes.io/os: windows
  tolerations:
  - key: &quot;windows&quot;
    operator: &quot;equal&quot;
    value: &quot;2019&quot;
    effect: &quot;noschedule&quot;

",<kubernetes><kubernetes-pod>,69484044,4,"in order to make sure that container1 will start only after container2's sql server is up the only way i found is to use poststart container's lifecycle event.
poststart triggered after after the container is create, it is true that  there is no guarantee, that the poststart handler is called before the container's entrypoint is called, but it turns out that the kubelet code that starts the container blocks the start of the next container until the post-start handler terminates.
and this is how my new compose file will look like:
apiversion: v1
kind: pod
metadata:
  name: sql-test-pod
  labels:
    name: sql-test
spec:
  restartpolicy: never
  containers:
    - name: my-sqldb
      image: docker-registry.com/database
      imagepullpolicy: always
      lifecycle:
        poststart:
          exec:
            command: ['powershell.exe', '-command', &quot;$connectionstring = 'server=sql-test-pod;user id=user;password=password'; $sqlconnection = new-object system.data.sqlclient.sqlconnection $connectionstring; $i=0; while($i -lt 6) {try { $i++;$sqlconnection.open();$sqlconnection.close(); return}catch {write-error $_; start-sleep 30}}&quot;]
      resources:
        limits:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
        requests:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
    - name: tests
      tty: true
      stdin: true
      image: docker-registry.com/test
      imagepullpolicy: always
      resources:
        limits:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
        requests:
          memory: &quot;4096mi&quot;
          cpu: &quot;750m&quot;
      env:
      - name: sqlhostname
        value: &quot;sql-test-pod&quot;
  nodeselector:
    kubernetes.io/os: windows
  tolerations:
  - key: &quot;windows&quot;
    operator: &quot;equal&quot;
    value: &quot;2019&quot;
    effect: &quot;noschedule&quot;

similar case you can find here
"
75856082,kubernetes - name based tcp routing,"i would like to create several databases inside kubernetes, and expose them trough ingresses, similar like name based virtual hosting solutions at standard http applications (https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting).
the problem is, databases works with tcp protocol.
if i try to set up tcp loadbalancing in my ingress controller (https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/exposing-tcp-udp-services.md), it works but one port can be used for one database only.
kubectl get cm -n ingress-nginx ingress-nginx-tcp -oyaml
apiversion: v1
data:
  &quot;1521&quot;: oracle/oracle-19c-ee-svc:1521
kind: configmap
metadata:
  annotations:
    meta.helm.sh/release-name: ingress-nginx
    meta.helm.sh/release-namespace: ingress-nginx
  creationtimestamp: &quot;2023-03-27t11:52:08z&quot;
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: ingress-nginx-4.6.0
  name: ingress-nginx-tcp
  namespace: ingress-nginx
  resourceversion: &quot;3997675&quot;
  uid: 7c477751-1ee1-462a-a4d6-ad78b003abf7

i would like to achieve name based tcp routing, similar like in the first link i posted.
as example:
db1.example.com:1521 -&gt; goes to service db1
db2.example.com:1521 -&gt; goes to service db2

(where example.com resolved as the loadbalancer ip, service db1 and db2 are services in kubernetes connected to two different databases)
have you any suggestion? even if it only resolvable with different type of ingress controller? or gateway api?
",<kubernetes><kubernetes-ingress>,75856121,3,"this is simply not possible, the way http(s) does this utilizes l7 support based on host header and/or sni. tcp is not capable of understanding what name you are using, cause the resolution happens on the client end, and tcp connection is established using resulting ip with no trace of what domain name was used to resolve to that ip.
if you absolutely have to, one way to get around this could be to use a db proxy service to create something a bit like a db &quot;ingress controller&quot; which could route based on the username. ie. user1@server1 proxies to server1 while user1@server2 proxies to server2. you can see this utilizes a l7 characteristic of usernames being provided with a routing indicator. if that is even available for your specific db is a diffeent question.
"
41509439,"difference between clusterip, nodeport and loadbalancer service types in kubernetes?","question 1 - i'm reading the documentation and i'm slightly confused with the wording. it says:

clusterip: exposes the service on a cluster-internal ip. choosing this value makes the service only reachable from within the cluster. this is the default servicetype
nodeport: exposes the service on each node’s ip at a static port (the nodeport). a clusterip service, to which the nodeport service will route, is automatically created. you’ll be able to contact the nodeport service, from outside the cluster, by requesting &lt;nodeip&gt;:&lt;nodeport&gt;.
loadbalancer: exposes the service externally using a cloud provider’s load balancer. nodeport and clusterip services, to which the external load balancer will route, are automatically created.

does the nodeport service type still use the clusterip but just at a different port, which is open to external clients? so in this case is &lt;nodeip&gt;:&lt;nodeport&gt; the same as &lt;clusterip&gt;:&lt;nodeport&gt;?
or is the nodeip actually the ip found when you run kubectl get nodes and not the virtual ip used for the clusterip service type?
question 2 - also in the diagram from the link below:

is there any particular reason why the client is inside the node? i assumed it would need to be inside a clusterin the case of a clusterip service type?
if the same diagram was drawn for nodeport, would it be valid to draw the client completely outside both the node andcluster or am i completely missing the point?
",<kubernetes><containers><kubernetes-service>,41510604,479,"a clusterip exposes the following:

spec.clusterip:spec.ports[*].port

you can only access this service while inside the cluster. it is accessible from its spec.clusterip port. if a spec.ports[*].targetport is set it will route from the port to the targetport. the cluster-ip you get when calling kubectl get services is the ip assigned to this service within the cluster internally.
a nodeport exposes the following:

&lt;nodeip&gt;:spec.ports[*].nodeport
spec.clusterip:spec.ports[*].port

if you access this service on a nodeport from the node's external ip, it will route the request to spec.clusterip:spec.ports[*].port, which will in turn route it to your spec.ports[*].targetport, if set. this service can also be accessed in the same way as clusterip.
your nodeips are the external ip addresses of the nodes. you cannot access your service from spec.clusterip:spec.ports[*].nodeport.
a loadbalancer exposes the following:

spec.loadbalancerip:spec.ports[*].port
&lt;nodeip&gt;:spec.ports[*].nodeport
spec.clusterip:spec.ports[*].port

you can access this service from your load balancer's ip address, which routes your request to a nodeport, which in turn routes the request to the clusterip port. you can access this service as you would a nodeport or a clusterip service as well.
"
69290796,persistent storage in eks failing to provision volume,"i followed the steps from aws knowledge base to create persistent storage: use persistent storage in amazon eks
unfortunately, persistentvolume(pv) wasn't created:
kubectl get pv
no resources found

when i checked the pvc logs, i'm getting the following  provisioning failed message:
storageclass.storage.k8s.io &quot;ebs-sc&quot; not found

failed to provision volume with storageclass &quot;ebs-sc&quot;: rpc error: code = deadlineexceeded desc = context deadline exceeded

i'm using kubernetes v1.21.2-eks-0389ca3

update:
the storageclass.yaml used in the example has provisioner set to ebs.csi.aws.com
kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: ebs-sc
provisioner: ebs.csi.aws.com
volumebindingmode: waitforfirstconsumer

when i updated it using @gohm'c answer, it created a pv.
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: ebs-sc
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
reclaimpolicy: retain
volumebindingmode: waitforfirstconsumer

",<amazon-web-services><kubernetes><amazon-eks><persistent-volumes><kubernetes-pvc>,69293093,10,"storageclass.storage.k8s.io &quot;ebs-sc&quot; not found

failed to provision volume with storageclass &quot;ebs-sc&quot;

you need to create the storage class &quot;ebs-sc&quot; after ebs csi driver is installed, example:
cat &lt;&lt; eof | kubectl apply -f -
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: ebs-sc
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
reclaimpolicy: retain
volumebindingmode: waitforfirstconsumer
eof

see here for more options.
"
71589025,how to add token_id to .kube/config file directly,"the official documentation of kubernetes (https://kubernetes.io/docs/reference/access-authn-authz/authentication/) states at some point: &quot;3. call kubectl with --token being the id_token or add tokens to .kube/config&quot; (just search for mentioned phrase in the provided doc url to get the context).

can anyone give me example where can i &quot;add tokens to .kube/config&quot; directly?
i am in a scenario, when it is needed for me, i can access my cluster with --token inline option but i need to go with adding it to .kube/config.
i am trying to do sth like this but doesn't work (still need to add --token inline option, doesn't work without it):
users:
  - user:
      token: &gt;-
        ey...........

",<kubernetes><kubectl><kubeconfig>,71589295,3,"yeah... yellow duck works... 5 sec after posting question i noticed that the &quot;context&quot; stuff is the key factor here, so the user of clyster need to match the name of user in users (i was missing the &quot;name&quot; filed for my user, matching the correct cluster context...), e.g.:
users:
  - name: shoot-x
    user:
      token: &gt;-
        ey

"
40426071,kubectl access to google cloud container engine fails,"in google cloud platform i have a container-cluster with three running instances. i now want to connect from my terminal to be able to run kubectl commands. for this i ran the command 

gcloud container clusters get-credentials cluster-1 --zone europe-west1-b --project project-id


i am using the real project name of course. this is the command shown by the dashboard when clicking on 'connect with the cluster'. the output of this command is:

fetching cluster endpoint and auth data.
kubeconfig entry generated for cluster-1.


but when i run kubectlcommands afterwards like kubectl cluster-info i always get:

unable to connect to the server: oauth2: cannot fetch token: 400 bad request
response: {
  ""error"" : ""invalid_grant"",
  ""error_description"" : ""token has been revoked.""
}


what am i missing here? gcloud commands like gcloud container clusters list work
",<kubernetes><gcloud><google-kubernetes-engine><kubectl>,40430091,25,"i tried from a different machine at home, and there it was working after installing and setting up gcloud. i think that on my work machine there is still an oauth token stored with which i authenticated to a different google account i used for a test.

edit: i got it running now. the problem was that i missed the second of the necessary calls:

gcloud auth login
gcloud auth application-default login

"
59239422,service deployed on eks does not answer on its external-ip,"
i created a small application, made a docker image of it, which runs
fine locally using docker run.
i created an eks cluster on amazon.
i put the image up on ecr, wrote a yaml file for a deployment and loadbalancer service, and used kubectl apply -f to deploy to my cluster


i can see my service:

$ kubectl get svc
name         type           cluster-ip     external-ip                                                               port(s)        age
frd-front    loadbalancer   10.100.199.8   a2c269b1619ee11ea90f20636eb75c46-1160809648.us-east-2.elb.amazonaws.com   80:32594/tcp   40m
kubernetes   clusterip      10.100.0.1     &lt;none&gt;                                                                    443/tcp        22h


but if i go to http://a2c269b1619ee11ea90f20636eb75c46-1160809648.us-east-2.elb.amazonaws.com there is no repsponse


how can i start troubleshooting this?
do you have any ideas right off the bat?


thanks  =)
",<kubernetes><kubectl><amazon-elb><amazon-eks>,59243197,5,"the issue can be one of the two  reasons:


docker image: the image may not be exposing the output as expected on the mentioned port.
k8s service: the service yaml may be configured with wrong target port or service port 


if you find that there is no issue in both the reasons. 

try to use port-forward on your pod  and check weather is  available.

usage: 
check for pod

kubectl port-forward pod-name-765d459796-258hz 8080:8080 // host-port:container-port


check for service 

kubectl port-forward svc/myservice 80:8080



if both are working fine, then its issue with loadbalancer side or service outbound or network policies.
if not working even after port-forward then issue with docker image or deployment yaml.

"
68845920,kubernetes: get port from aconfig?,"is there any way to inject a port value for a service (and other places) from a configmap? tried this:
apiversion: v1
kind: service
metadata:
  name: service
  namespace: namespace
spec:
  ports:
    - port: 80
      targetport:
        valuefrom:
          configmapkeyref:
            name: config
            key: port
      protocol: tcp
  selector:
    app: service


but got an error
validationerror(service.spec.ports[0].targetport): invalid type for io.k8s.apimachinery.pkg.util.intstr.intorstring: got &quot;map&quot;, expected &quot;string&quot;

",<kubernetes><configmap><kubernetes-service>,68864704,1,"ok, so i've checked it more in-depth and it looks like you can't make a reference like this to the configmap in your service.spec definition. this kind of usage of the valuefrom can be used only for container environment variables as described in here.
on the other hand you can specify in your deployment.spec (in that case service.spec.ports.targetport) the targetport by name, for example mycustomport and reference to this mycustomport between deployment.spec and service.spec.
a note as per the kubernetes api reference docs:

targetport - number or name of the port to access on the pods targeted by the service. number must be in the range 1 to 65535. name must be an iana_svc_name. if this is a string, it will be looked up as a named port in the target pod's container ports. if this is not specified, the value of the 'port' field is used (an identity map). this field is ignored for services with clusterip=none, and should be omitted or set equal to the 'port' field. more info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service

"
79013363,how to check ephemeral storage that is allocated to eks node,"how to check ephemeral storage that is allocated to eks node using kubectl command?
i have tried the following: i tried describing the node using kubectl describe node &lt;node-name&gt; which gave lot of info, out of which following is the section related to ephemeral storage.
capacity:
  attachable-volumes-aws-ebs:  25
  cpu:                         8
  ephemeral-storage:           157274092ki
  hugepages-1gi:               0
  hugepages-2mi:               0
  memory:                      32042484ki
  pods:                        58

allocatable:
  attachable-volumes-aws-ebs:  25
  cpu:                         7
  ephemeral-storage:           142796319300
  hugepages-1gi:               0
  hugepages-2mi:               0
  memory:                      30916084ki
  pods:                        58

allocated resources:
  (total limits may be over 100 percent, i.e., overcommitted.)
  resource                    requests      limits
  --------                    --------      ------
  cpu                         1105m (15%)   750m (10%)
  memory                      3052mi (10%)  3486mi (11%)
  ephemeral-storage           0 (0%)        0 (0%)
  hugepages-1gi               0 (0%)        0 (0%)
  hugepages-2mi               0 (0%)        0 (0%)
  attachable-volumes-aws-ebs  0             0

with those 3 sections, can anyone help me to find the exact ephemeral-storage that is allocated to node?
[in allocatable section, i do not see units for ephemeral-stoage (142796319300), what is default unit here]
",<amazon-web-services><kubernetes><amazon-eks><ephemeral-storage>,79013424,3,"in the output of your kubectl describe node command, the ephemeral-storage value in the allocatable section is in bytes.
capacity (total storage): 157274092ki, is around 150 gib.
allocatable (available storage for workloads): 142796319300 bytes, is about 133 gib.
so basically, your node has 150 gib of total ephemeral storage, with ~ 133 gib available for applications.
"
66931177,how to set http2-max-streams-per-connection with kops,"is it possible to set the --http2-max-streams-per-connection value for a cluster created by kops.
i have an interesting situation where one of my nodes falls into a notready status whenever i deploy a helm chart to it and i feel like it might be connected to this setting.
the nodes are generally fine and run without any issues, but once i deploy my helm chart, the status of whatever node it gets deployed to changes after a few minutes to notready which i find weird.
i've done a bit of reading and seen a number of similar issues pointing to the setting --http2-max-streams-per-connection but i'm not how to go about setting this.
any ideas anyone?
",<kubernetes><kubernetes-helm><kops>,66934018,1,"you should be able to set this by adding the following to the cluster spec:
spec:
  kubeapiserver:
    http2maxstreamsperconnection: &lt;value&gt;

see https://pkg.go.dev/k8s.io/kops/pkg/apis/kops#kubeapiserverconfig and https://kops.sigs.k8s.io/cluster_spec/
that being said, i do not believe the reason for your notready nodes is due to that setting. you may want to join #kops-users on the kubernetes slack space and ask for help triaging that problem.
"
74003216,helm does not resolve local dependencies repository file path,"i'm triyng to do one helm chart for different environments. in many tutorials such scheme should works, but my structure does not read value from dependency repository. helm just ignores it.
i have following folder structure
helm
   - charts
       - core-web
           - chart.yaml
           - values.yaml
           - templates
       - frontend
           - chart.yaml
           - values.yaml
           - templates
   - prod
       - chart.yaml
       - values.yaml
   - dev
       - chart.yaml
       - values.yaml

prod/chart.yaml
apiversion: v1
name: test
version: 1.0.0

dependencies:
  - name: core-web
    version: &quot;1.37.0&quot;
    repository: file://../charts/core-web/
  - name: frontend
    version: &quot;1.6.0&quot;
    repository: &quot;file://../charts/frontend&quot;

from helm folder i execute following command
helm install ./prod --dry-run --generate-name -n sandbox -f prod/values.yaml
error: installation failed: found in chart.yaml, but missing in charts/ directory: core-web, frontend

if i move charts forlder to prod folder, then everithing works.
why helm does not accept file path from dependency repository?
it should: https://helm.sh/docs/helm/helm_dependency/
thanks for the help.
",<kubernetes><kubernetes-helm>,74003677,7,"try to replicate the issue, seems like a cache issue
you can verify that helm dependency on which path it's looking for charts.
helm template test ./prod
#output error: found in chart.yaml, but missing in charts/ directory: backend, web-app

then i tried to verify the path on which the helm looking
helm dep ls ./prod

from the output its clear it's still looking into the wrong path with the status missing as its still looking for chart inside prod folder.
name    version repository              status
backend 1.2.3   file://charts/backend/  missing
web-app 1.2.3   file://charts/web-app/  missing

so to fix this
helm dependency update  ./prod

then i can see
helm dep ls ./prod


"
59161185,how to configure custom ldap in grafana helm chart?,"i'm a newbie at kubernetes and helm, trying to customise stable/grafana helm chart (https://github.com/helm/charts/tree/master/stable/grafana) with my own ldap. what's the difference between auth.ldap part of grafana.ini and ldap section of chart's values.yaml file? how can i configure ldap host address and credentials?
",<kubernetes><ldap><grafana><kubernetes-helm>,59162522,7,"to enable ldap configuration on grafana. you need to update both parts.

in values.yaml, there are two sections of grafana.ini and ldap.  to enable ldap you need to update both sections. check below:

first grafana.ini

grafana.ini:
  paths:
    data: /var/lib/grafana/data
    logs: /var/log/grafana
    plugins: /var/lib/grafana/plugins
    provisioning: /etc/grafana/provisioning
  analytics:
    check_for_updates: true
  log:
    mode: console
  grafana_net:
    url: https://grafana.net
## ldap authentication can be enabled with the following values on grafana.ini
## note: grafana will fail to start if the value for ldap.toml is invalid
   auth.ldap:
     enabled: true
     allow_sign_up: true
     config_file: /etc/grafana/ldap.toml


here in grafana.ini part, first enable the auth.ldap to true and specify the configuration file as ldap.toml

second, ldap

## grafana's ldap configuration
## templated by the template in _helpers.tpl
## note: to enable the grafana.ini must be configured with auth.ldap.enabled
ldap:
  enabled: true
  # `existingsecret` is a reference to an existing secret containing the ldap configuration
  # for grafana in a key `ldap-toml`.
  existingsecret: """"
  # `config` is the content of `ldap.toml` that will be stored in the created secret
   config: |-
     verbose_logging = true

     [[servers]]
     host = ""my-ldap-server""
     port = 636
     use_ssl = true
     start_tls = false
     ssl_skip_verify = false
     bind_dn = ""uid=%s,ou=users,dc=myorg,dc=com""


in this part, the helm prepares the ldap.toml file using the ldap configuration, that is specified in the first step.

thus update the ldap host, port, bind_dn as per configurations.
"
67156127,kubernetes secret is not stored in encoded format in environment variables,"i am a beginner to kubernetes. i have created a secret file and referred it in deployment yaml file.
app-secret.yaml
apiversion: v1
kind: secret
metadata:
  name: app-secret
data:
  username: ywrtaw4=
  password: ywrtaw4=

deploy.yaml
env:
          - name: deploy_env
            value: ${env}
          - name: namespace_name
            valuefrom:
                fieldref:
                  fieldpath : metadata.namespace
          - name: app_username
            valuefrom:
                secretkeyref:
                  name: app-secret
                  key: username
          - name: app_password
            valuefrom:
                secretkeyref:
                  name: app-secret
                  key: password

while using the command kubectl get secret pod-54rfxd -n dev-ns -o json, it is printing the username and password in encoded format only. when i query for the environment variables list using the command kubectl exec pod-54rfxd -n dev-ns -- printenv, it was giving below result.
app_username=admin
app_password=admin

why it was not in encoded format in environment variables. could you please let me know the reason and is it possible to have it in encoded format?
",<kubernetes><kubernetes-secrets><kubernetes-security>,72971082,2,"you could use the stringdata format:
apiversion: v1
kind: secret
metadata:
  name: app-secret
stringdata:
  username: &quot;ywrtaw4=&quot;
  password: &quot;ywrtaw4=&quot;

from k8s doc:

k8s doc
"
60826194,"kubectl exec fails with the error ""unable to use a tty - input is not a terminal or the right kind of file""","i am running a jenkins pipeline with the following command:

kubectl exec -it kafkacat-5f8fcfcc57-2txhc -- kafkacat -b cord-kafka -c -t bbsim-olt-0-events -o s@1585031458


which is running fine on the terminal of the machine the pipeline is running on, but on the actual pipeline i get the following error: ""unable to use a tty - input is not a terminal or the right kind of file""

any tips on how to go about resolving this?
",<kubernetes><jenkins-pipeline><kubectl>,60826364,43,"when the flags -it are used with kubectl exec, it enables the tty interactive mode. given the error that you mentioned, it seems that jenkins doesn't allocate a tty.

since you are running the command in a jenkins job, i would assume that your command is not necessarily interactive. a possible solution for the problem would be to simply remove the -t flag and try to execute the following instead:

kubectl exec -i kafkacat-5f8fcfcc57-2txhc -- kafkacat -b cord-kafka -c -t bbsim-olt-0-events -o s@1585031458

"
35213589,docker container with non-root user deployed in google container engine can not write to mounted gce persistent disk,"i'm playing with kubernetes and google container engine (gke).
i deployed a container from this image jupyter/all-spark-notebook
this is my replication controller :
{
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;kind&quot;: &quot;replicationcontroller&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;datalab-notebook&quot;
  },
  &quot;spec&quot;: {
    &quot;replicas&quot;: 1,
    &quot;selector&quot;: {
      &quot;app&quot;: &quot;datalab-notebook&quot;
    },
    &quot;template&quot;: {
      &quot;metadata&quot;: {
        &quot;name&quot;: &quot;datalab-notebook&quot;,
        &quot;labels&quot;: {
          &quot;environment&quot;: &quot;test&quot;,
          &quot;app&quot;: &quot;datalab-notebook&quot;
        }
      },
      &quot;spec&quot;: {
        &quot;containers&quot;: [{
          &quot;name&quot;: &quot;datalab-notebook-container&quot;,
          &quot;image&quot;: &quot;jupyter/all-spark-notebook&quot;,
          &quot;env&quot;: [],
          &quot;ports&quot;: [{
            &quot;containerport&quot;: 8888,
            &quot;name&quot;: &quot;datalab-port&quot;
          }],
          &quot;volumemounts&quot;: [{
            &quot;name&quot;: &quot;datalab-notebook-persistent-storage&quot;,
            &quot;mountpath&quot;: &quot;/home/jovyan/work&quot;
          }]
        }],
        &quot;volumes&quot;: [{
          &quot;name&quot;: &quot;datalab-notebook-persistent-storage&quot;,
          &quot;gcepersistentdisk&quot;: {
            &quot;pdname&quot;: &quot;datalab-notebook-disk&quot;,
            &quot;fstype&quot;: &quot;ext4&quot;
          }
        }]
      }
    }

  }
}

as you can see i mounted a google compute engine persistent disk. my issue is that the container uses a non-root user and the mounted disk is owned by root. so my container can not write to the disk.

is there a way to mount gce persistent disks and make them read/write for containers without non-root users?
another general question : is it safe to run container with root user in google container engine?

thank you in advance for your inputs
",<kubernetes><google-kubernetes-engine>,35373538,2,"i ran into the same problem. the workaround i used was to run df -h on the host machine that the container was running on. from there i was able to find the bind point of the persistant storage. it should look something like /var/lib/kubelet/plugins/kubernetes.io/gce-pd/mounts/&lt;pd-name&gt;. it will also be one of the ones that has a file system that starts with /dev that isn't mounted to root.

once you've found that you can run sudo chmod -r 0777 /var/lib/kubelet/plugins/kubernetes.io/gce-pd/mounts/&lt;pd-name&gt; from the host box, and now at least your container can use the directory, though the files will still be owned by root.
"
74441381,datadog: api key invalid dropping transaction when installing datadog agent,"i'm trying to install datadog agent for a kubernetes cluster using helm.
this is the helm command i'm using for it:
helm repo add datadog https://helm.datadoghq.com

helm repo update

helm upgrade --install datadog datadog/datadog \
  --namespace monitoring \
  --create-namespace \
  --atomic \
  --set datadog.apikey=&lt;my-datadog-api-key&gt; \
  --set targetsystem=linux \
  --values values.yaml

values file:
datadog:
  kubelet:
    host:
      valuefrom:
        fieldref:
          fieldpath: spec.nodename
    hostcapath: /etc/kubernetes/certs/kubeletserver.crt
    tlsverify: false # required as of agent 7.35. see notes.

however, when i run the liveness probe error with error 500 which shows the error below:

cluster | error | (pkg/forwarder/transaction/transaction.go:344 in internalprocess) | api key invalid, dropping transaction for https://orchestrator.datadoghq.com/api/v1/orchestrator.

",<kubernetes><kubernetes-helm><datadog>,74441382,18,"here's how i solved it:
the issue had to do with the datadog destination site. the destination site for my metrics, traces, and logs is supposed to be datadoghq.eu. this is set using the variable dd_site, and it defaults to datadoghq.com if it is not set.
to check what your datadog destination site just look at the url of your datadog dashboard:

for us it will be - https://app.datadoghq.com/
for eu it will be - https://app.datadoghq.eu/

to set this in your helm chart simply do either of the following:
helm repo add datadog https://helm.datadoghq.com

helm repo update

helm upgrade --install datadog datadog/datadog \
  --namespace monitoring \
  --create-namespace \
  --atomic \
  --set datadog.apikey=&lt;my-datadog-api-key&gt; \
  --set targetsystem=linux \
  --set datadog.site=datadoghq.eu \
  --values values.yaml

or set it in your values file:
datadog:
  site: datadoghq.eu
  kubelet:
    host:
      valuefrom:
        fieldref:
          fieldpath: spec.nodename
    hostcapath: /etc/kubernetes/certs/kubeletserver.crt
    tlsverify: false # required as of agent 7.35. see notes.

references:

datadog agent forwarder fails liveness probe when new spot instance joins cluster, causing multiple restarts #1697

dd_site set to us3.datadoghq.com, but process-agent and security-agent still try to connect to non us3 endpoints #9180


"
65402310,"in helm 3, what exactly are ""install --dry-run"", ""template --validate"" and ""lint"" doing?","i've seen conflicting information on what all of these things do. for example:

helm install --dry-run --debug or helm template --debug: we've seen this trick already. it's a great way to have the server render your templates, then return the resulting manifest file.

from: https://helm.sh/docs/chart_template_guide/debugging/#helm
that implies that both template --debug and the dry run send it to the server. is that true?
i've also seen some places that if you have a schema, that template --validate will also do linting. is that true? and does the dry run also lint?
here's my &quot;guess&quot;:

helm template calls lint even if you don't add --validate

and helm template --debug does not send it to the server, but just prints out more debug info


--validate does nothing that isn't done with the regular template call
helm install --dry-run will send each yaml generated to k8s with the following command(s): kubectl apply --validate=true --dry-run=true --f myyaml.yaml

is this correct? is that how helm does a dry run? (and in helm 3 there's no tiller)



",<kubernetes><yaml><kubernetes-helm>,65402624,10,"short answers:

helm template without --validate doesn't contact the kubernetes server at all.  helm template --validate and helm install --dry-run do some additional checks that do involve contacting the api server.
helm lint is different and neither command runs linking.

under the hood, helm install and helm template are very similar: both create an action.install object and configure it.
helm template is always --dry-run.  if you don't specify helm template --validate, then helm uses a default set of api versions, and in fact renders the chart without contacting a kubernetes server at all.  if the chart includes custom resource definitions (crds), helm template without --validate won't complain that they're not being processed.  the key important effect of helm template --debug is that, if the template produces invalid yaml, it will get printed out anyways.
helm install --dry-run --debug and helm install --validate seem extremely similar, in terms of the options they push into the core installer logic.  in both cases they actually render the chart without talking to the kubernetes server.  after doing the render, they do check with the kubernetes client that the produced yaml is valid for what objects the cluster supports, and they both check whether any of the created objects currently exist in the cluster.
helm doesn't actually run kubectl.  it instead directly uses the kubernetes go client library.
helm lint is a totally separate action.  it runs additional checks on the unrendered chart; for example, if there is a file in the templates directory that's not a *.tpl, *.yml, *.yaml, or *.txt file, you'll get a complaint.  none of the install or template paths run it.
"
76084895,kubectl get pods: field selectors,"i'm running this command:
# kubectl get pods --all-namespaces --field-selector=metadata.namespace!=kube-system,metadata.namespace!=monitoring,metadata.namespace!=rtf

which gives me output like this:
namespace                        name              ready   status    restarts   age
123456-1234-1234-1234-123456789  some-app-123456   2/2     running   0          10m
123456-1234-1234-1234-123456789  some-app-789112   1/2     running   0          10m

i would like to be able to filter on the ready column, but i can't seem to find the right field-selector value.
is this possible?
i've tried searching around for a list of available field-selectors, and haven't had any luck. it's possible that one doesn't exist.
",<kubernetes><kubectl>,76085021,2,"i don't think kubectl get pods supports field selectors based on the ready column directly.
but kubectl provides a method exporting the resource configuration (yaml) directly into json, -o json. then, we can use jq to read, parse, and mutate k8s object results from kubectl.
in your case, you could use a command like this to filter all pods (excluding the pods from namespaces kube-system, monitoring &amp; rtf) not in ready state:
kubectl get pods --all-namespaces --field-selector=metadata.namespace!=kube-system,metadata.namespace!=monitoring,metadata.namespace!=rtf -ojson | jq '.items[] | select(.status.containerstatuses[].ready==false) | .metadata.namespace + &quot;/&quot; + .metadata.name'

and/or change ready=true to get the pods in ready state.
have a look at this article for many more such uses of jq with kubectl
hope it helps.
"
58939075,auto-provisioning not creating new node pool,"i am trying to set up auto-provisioning on google's kubernetes service gke. i created a cluster with both auto-scaling and auto-provisioning like so:

gcloud beta container clusters create ""some-name"" --zone ""us-central1-a"" \
  --no-enable-basic-auth --cluster-version ""1.13.11-gke.14"" \
  --machine-type ""n1-standard-1"" --image-type ""cos"" \
  --disk-type ""pd-standard"" --disk-size ""100"" \
  --metadata disable-legacy-endpoints=true \
  --scopes ""https://www.googleapis.com/auth/devstorage.read_only"",""https://www.googleapis.com/auth/logging.write"",""https://www.googleapis.com/auth/monitoring"",""https://www.googleapis.com/auth/servicecontrol"",""https://www.googleapis.com/auth/service.management.readonly"",""https://www.googleapis.com/auth/trace.append"" \
  --num-nodes ""1"" --enable-stackdriver-kubernetes --enable-ip-alias \
  --network ""projects/default-project/global/networks/default"" \
  --subnetwork ""projects/default-project/regions/us-central1/subnetworks/default"" \
  --default-max-pods-per-node ""110"" \
  --enable-autoscaling --min-nodes ""0"" --max-nodes ""8"" \
  --addons horizontalpodautoscaling,kubernetesdashboard \
  --enable-autoupgrade --enable-autorepair \
  --enable-autoprovisioning --min-cpu 1 --max-cpu 8 --min-memory 1 --max-memory 16


the cluster has 1 node pool with 1 node having 1 vcpu. i tried running a deployment which requests 4 vcpu, so it would clearly not be satisfied by the current node pool. 

kubectl run say-lol --image ubuntu:18.04 --requests cpu=4 -- bash -c 'echo lolol'


here is what i want to happen: the auto-scaler should fail to accommodate the new deployment, as the existing node pool doesn't have enough cpu. the auto-provisioner should try to create a new node pool with a new node of 4 vcpu to run the new deployment. 

here is what is happening: the auto-scaler fails as expected. but the auto-provisioner is doing nothing. the pod remains pending indefinitely. no new node pools get created.

$ kubectl get events
last seen   type      reason              kind         message
50s         warning   failedscheduling    pod          0/1 nodes are available: 1 insufficient cpu.
4m7s        normal    nottriggerscaleup   pod          pod didn't trigger scale-up (it wouldn't fit if a new node is added): 1 insufficient cpu
9m17s       normal    successfulcreate    replicaset   created pod: say-lol-5598b4f6dc-vz58k
9m17s       normal    scalingreplicaset   deployment   scaled up replica set say-lol-5598b4f6dc to 1

$ kubectl get pod
name                       ready   status    restarts   age
say-lol-5598b4f6dc-vz58k   0/1     pending   0          9m14s

$ kubectl get nodes
name                                       status   roles    age   version
gke-some-name-default-pool-4ec86782-bv5t   ready    &lt;none&gt;   31m   v1.13.11-gke.14


why isn't a new node pool getting created to run the new deployment?

edit: it seems the cpu=4 is the problematic part. if i change to cpu=1.5, it works. a new node pool is created and the pods start running. however, i indicated --max-cpu 8 so it should clearly be able to handle 4 vcpus.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,58940329,2,"issue could be related to allocatable cpu. please check the machine type that was created. 

specifying this --max-cpu 8 does not mean that new node will have 8 cores. instead it specifies the maximum number of cores in the cluster.

changing to --max-cpu 40 should give better results as it will allow for a bigger machine type to be created.
"
68642661,generating a redirect with traefik ingress on k3s?,"i'm running prometheus and grafana under k3s, accessible (respectively) at http://monitoring.internal/prometheus and http://monitoring.internal/grafana. the grafana ingress object, for example, looks like:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: grafana
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
    - host: monitoring.internal
      http:
        paths:
          - path: /grafana
            pathtype: prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000

this works fine, except  that if you land at
http://monitoring.internal/, you get a 404 error.  i would like
requests for http://monitoring.internal/ to redirect to
http://monitoring.internal/grafana. i could perhaps create another
service that runs  something like darkhttpd ... --forward-all http://monitoring.internal/grafana, and create  an  ingress object
that would  map / to that service, but it seems like there  ought to
be a way to do this with traefik  itself.
it looks like i'm running traefik 2.4.8 locally:
$ kubectl -n kube-system exec -it deployment/traefik -- traefik version
version:      2.4.8
codename:     livarot
go version:   go1.16.2
built:        2021-03-23t15:48:39z
os/arch:      linux/amd64

i've found this documentation for 1.7 that suggests there is an annotation for exactly this purpose:

traefik.ingress.kubernetes.io/app-root: &quot;/index.html&quot;: redirects
all requests for / to the defined path.

but setting that on the grafana ingress object doesn't appear to have
any impact, and i haven't been able to find similar docs for 2.x
(i've looked around
here, for
example).
what's the right way to set up this sort of redirect?
",<kubernetes><kubernetes-ingress><traefik><k3s>,68643697,1,"since i haven't been able to figure out traefik yet, i thought i'd post my solution here in case anyone else runs into the same situation. i am hoping someone comes along who knows the right way to to do this, and if i figure out i'll update this answer.
i added a new deployment that runs darkhttpd as a simple director:
apiversion: apps/v1
kind: deployment
metadata:
  name: redirector
spec:
  replicas: 1
  template:
    spec:
      containers:
        - name: redirector
          image: docker.io/alpinelinux/darkhttpd
          ports:
            - containerport: 8080
          args:
            - --forward-all
            - http://monitoring.internal/grafana

a corresponding service:
apiversion: v1
kind: service
metadata:
  name: redirector
spec:
  ports:
    - port: 8080
      protocol: tcp
      targetport: 8080

and the  following ingress object:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: redirector
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
    - host: monitoring.internal
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: redirector
                port:
                  number: 8080

these are  all deployed with kustomize, which  takes care of
adding labels and selectors in the appropriate places. the
kustomization.yaml look like:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

resources:
- deployment.yaml
- ingress.yaml
- service.yaml

commonlabels:
  component: redirector

with all this in place, requests to http://monitoring.internal/ hit the redirector pod.
"
68939439,docker volume mount to kubernetes volume,"i am trying out to have a volume mount on kubernetes.
currently i have a docker image which i run like:
docker run --mount type=bind,source=&quot;$(pwd)&quot;&lt;host_dir&gt;,target=&lt;docker_dir&gt; container

to have this run on google kubernetes cluster, i have:

create a google compute disk
created a persistent volume which refers to the disk:


kind: persistentvolume
...
    namespace: default
    name: pvc
spec:
  claimref:
    namespace: default
    name: pvc
  gcepersistentdisk:
    pdname: disk-name
    fstype: ext4
---
...
kind: persistentvolumeclaim
metadata:
  name: pvc
spec:
  storageclassname: &quot;storage&quot;
...
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 2000gi


created pod with mount

kind: pod
apiversion: v1
metadata:
  name: k8s-pod
spec:
  volumes:
    - name: pvc
      persistentvolumeclaim:
       claimname: pvc
  containers:
    - name: image_name
      image: eu.gcr.io/container:latest
      volumemounts:
        - mountpath: &lt;docker_dir&gt;
          name: dir

i am missing out where the binding between the host and container/pod directories will take place. also where do i mention that binding in my yaml files.
i will appreciate any help :)
",<docker><kubernetes><google-kubernetes-engine>,68951469,2,"you are on the right path here.  in your pod spec, the name of the volumemount should match the name of the volumes.  so in your case,
volumes:
    - name: pvc
      persistentvolumeclaim:
       claimname: pvc

volume name is pvc. so your volumemount should be
volumemounts:
        - mountpath: &quot;/path/in/container&quot;
          name: pvc

so, for example, to mount this volume at /mydata in your container, your pod spec would look like
kind: pod
apiversion: v1
metadata:
  name: k8s-pod
spec:
  volumes:
    - name: pvc
      persistentvolumeclaim:
       claimname: pvc
  containers:
    - name: image_name
      image: eu.gcr.io/container:latest
      volumemounts:
        - mountpath: &quot;/mydata&quot;
          name: pvc

"
51473304,how do i change the version of my kubernetes,"currently using version 1.11.0 of kuberenetes.

client version: version.info{major:""1"", minor:""11"", gitversion:""v1.11.0"", gitcommit:""91e7b4fd31fcd3d5f436da26c980becec37ceefe"", gittreestate:""clean"", builddate:""2018-06-27t20:17:28z"", goversion:""go1.10.2"", compiler:""gc"", platform:""linux/amd64""}


but having trouble changing the version of my kuberentes to 1.10.5 in ubuntu.
any ideas how to change the my current version of kubernetes?
",<linux><ubuntu><kubernetes><kubectl><minikube>,51473979,1,"this solves my problem apt-get install -y kubectl=1.10.5-00
"
73330816,how to create the gcp workload identity iam bindings in terraform?,"gcp allows the kubernetes service account to impersonate the iam service account by adding an iam policy binding between the two service accounts. this binding allows the kubernetes service account to act as the iam service account.
gcloud iam service-accounts add-iam-policy-binding gsa_name@gsa_project.iam.gserviceaccount.com \
    --role roles/iam.workloadidentityuser \
    --member &quot;serviceaccount:project_id.svc.id.goog[namespace/ksa_name]&quot;

we would like to create the same via terraform resource and we tried this way, refer: article
resource &quot;google_service_account_iam_binding&quot; &quot;service-account-iam&quot; {
  service_account_id = &quot;gsa_name@gsa_project.iam.gserviceaccount.com&quot;
  role               = &quot;roles/iam.workloadidentityuser&quot;
  members = [
    &quot;serviceaccount:project_id.svc.id.goog[namespace/ksa_name]&quot;,
  ]
}

but we received the below error:

error: &quot;service_account_id&quot; (&quot;xxx@xxx.iam.gserviceaccount.com&quot;) doesn't match regexp &quot;projects/(?:(?:[-a-z0-9]{1,63}\.)(?:a-z?):)?(?:[0-9]{1,19}|(?:a-z0-9?)|-)/serviceaccounts/((?:(?:[-a-z0-9]{1,63}\.)(?:a-z?):)?(?:[0-9]{1,19}|(?:a-z0-9?))@[a-z]+.gserviceaccount.com$|[0-9]{1,20}-compute@developer.gserviceaccount.com|a-z@[-a-z0-9\.]{1,63}\.iam\.gserviceaccount\.com$)&quot;

what's wrong here?
",<kubernetes><google-cloud-platform><google-kubernetes-engine><gcp-iam>,73330913,3,"service_account_id is the fully-qualified name of the service account to apply the policy to.
projects/project_id/serviceaccounts/service_account_email
"
70054382,aws eks service external-ip of load balancer is pending,"i was working on a staging cluster for my application, it required around 12 load balancers for my services definition. all of 12 looked pretty much the same:
apiversion: v1
kind: service
metadata:
  labels:
    app: my-app-api
  name: my-app-api
  namespace: default
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: &lt;some aws cert name&gt;
    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: &quot;https&quot;
spec:
  externaltrafficpolicy: cluster
  ipfamilies:
    - ipv4
  ipfamilypolicy: singlestack
  ports:
    - name: http
      port: 80
      protocol: tcp
      targetport: 5001
    - name: https
      port: 443
      protocol: tcp
      targetport: 5001
  selector:
    app: my-app-api
  sessionaffinity: none
  type: loadbalancer

after that i went on creating production cluster with the same setup. after i have created it and deployed k8s manifests: deployments, services, i was not able to get loadbalancer ingress with kubectl describe service command. i noticed the following picture:
name          type           cluster-ip  external-ip                         port(s)                      age
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:30339/tcp,443:32754/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:31538/tcp,443:32061/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:30976/tcp,443:31323/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:30288/tcp,443:32073/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:32270/tcp,443:31159/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   ****.us-west-1.elb.amazonaws.com    80:31966/tcp,443:30944/tcp   1m
kubernetes    clusterip      &lt;some_ip&gt;   &lt;none&gt;                              443/tcp                      1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:31901/tcp,443:30444/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:31510/tcp,443:30393/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:32613/tcp,443:32616/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:32069/tcp,443:30320/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:31667/tcp,443:32194/tcp   1m
&lt;some-name&gt;   loadbalancer   &lt;some_ip&gt;   pending                             80:31943/tcp,443:32081/tcp   1m

",<amazon-web-services><kubernetes><amazon-eks><aws-application-load-balancer>,70054383,1,"after troubleshooting the reason of above behaviour, i have made the following conclusions about loadbalancers(lb):

service.beta.kubernetes.io/aws-load-balancer-ssl-cert directly depends on aws load balancer, and if certificate is not signed in a region where lb is created, lb will not be added to the k8s cluster.
my problem was because k8s cluster could not automatically provision aws lb for newly created service, as default lb limit for single region in aws account is 20

i requested quota increase lb limit from aws, but since it took more time, i moved my production cluster to a different aws region.
after that lbs created as expected and i could get my ingresses.
"
54644564,"cannot shell into the container, rpc error: code = 5 desc ... shim-log.json: no such file or directory","trying to shell into the container by kubectl exec -it xxxxxx

but it returns 

rpc error: code = 5 desc = open /var/run/docker/libcontainerd/containerd/faf3fd49262cc738e16368001eba5e1113abcb8a87e7b818cb84af3799906149/30fe901c16e0465aa15b596bf3e4f244fb12a7e4133b6e4da5aa35167a8dfb30/shim-log.json: no such file or directory


trying to reboot the node but not help
",<kubernetes><kubectl>,54662420,1,"thanks @prafull ladha

eventually i restarted the docker (systemctl restart docker) of that node which my pods could not be shelled, and it resumes to normal
"
51786114,changing configuration in running kubernetes pod,"i have written the nifi.properties into a kubernetes configmap. when i deploy nifi (as a statefulset) i want to have this nifi.properties file to be used by the nifi i just deployed. to do so i added a volume for the configmap and mounted it in the container. the associated statefulset.yaml looks like this:

...
containers:
- name: 'myname'
  image: 'apache/nifi:latest'
  ports:
    - name: http
      containerport: 8080
      protocol: tcp
    - name: http-2
      containerport: 1337
      protocol: tcp
  volumemounts:
    - name: 'nifi-config'
      mountpath: /opt/nifi/nifi-1.6.0/conf/nifi.properties
volumes:
- name: 'nifi-config'
  configmap:
    name: 'nifi-config'
...


this doesn't work, i think it is, because nifi is already running and the nifi.properties file is locked by the service. the pod cannot be created, i get an error: ...device or resource is busy. i also tried that with the bootstrap.conf file, which works, but i don't think that changes in there are recognized by the nifi service because it would have to be restarted.  

i already had the same issue with nifi deployed on pure docker, where i worked around by stopping the container, copying the files and starting the container; not very pretty, but working. 

using environment variables to change values in nifi as stated here is also not an option, because the possibility of changing parameters there are very limited.

this problem doesn't occurs for nifi only. i think that there are many situations where someone want's to change the configuration for a system running within kubernetes, so i hope there is any solution to handle this issue.
",<configuration><kubernetes><apache-nifi><kubernetes-helm><configmap>,51840608,1,"i solved this with the help of this helm file, but changed it a bit. actually it is nearly the same as the answer that pepov has given, but as stated in my comment, i got a crashloopbackoff. this also had nothing to do with the image version, because i used my own image that is based on nifi 1.6.0 also containing some custom processors.  

so my solution is to use the poststart handler of kubernetes. problem is that it is not guaranteed that this handler is called before the entrypoint (see). but in this case the pod would crash and restart, eventually getting it right; right now i haven't had this problem, so it seems to be good for now.
i copy the content of the configmap into a dedicated folder and copy them in the associated nifi folder in the poststart handler.

so here is the statefulset.yaml:

...
containers:
- name: 'myname'
  image: 'apache/nifi:latest'
  ports:
    - name: http
      containerport: 8080
      protocol: tcp
    - name: http-2
      containerport: 1337
      protocol: tcp
  volumemounts:
    - name: 'nifi-config'
      mountpath: /opt/nifi/nifi-1.6.0/kubeconfig
  lifecycle:
    poststart:
      exec:
        command:
          - bash
          - -c
          - |
            cp -a /opt/nifi/nifi-1.6.0/kubeconfig/. /opt/nifi/nifi-1.6.0/conf
volumes:
- name: 'nifi-config'
  configmap:
    name: 'nifi-config'
...

"
64950361,what is the best way to verify a deployment.yaml kubernetes file?,"i have the following deployment.yaml file in kuberentes:
apiversion: apps/v1
kind: deployment
metadata:
  name: basic-deployment
spec:
  replicas: 2
  selector:
    matchlabels:
      app: nginx
  template:
    metadata:
      labels:
        app: basic
    spec:
      containers:
      - name: basic
        image: nginx
        volumemounts:
        - name: config-volume
          mountpath: /etc/nginx/conf.d
      volumes:
      - name: config-volume
        configmap:
          name: basic-config


i am not sure how i can fix the following error when i run kubectl create -f basic-deployment.yaml:
the deployment &quot;basic-deployment&quot; is invalid: spec.template.metadata.labels: invalid value: map[string]string{&quot;app&quot;:&quot;basic&quot;}: selector does not match template labels
",<kubernetes><kubectl><kubernetes-deployment>,64950503,1,"apiversion: apps/v1
kind: deployment
metadata:
  name: basic-deployment
spec:
  replicas: 2
  selector:
    matchlabels:
      app: basic
  template:
    metadata:
      labels:
        app: basic
    spec:
      containers:
      - name: basic
        image: nginx
        volumemounts:
        - name: config-volume
          mountpath: /etc/nginx/conf.d
      volumes:
      - name: config-volume
        configmap:
          name: basic-config

basically, the selector match label in your deployment spec needs to match a label in your template. in your case, you have app: nginx as a matching label for the selector and you have app: basic in your template, so no match.
you would have to have something either one app: nginx or app: basic on both so that there is a match.
"
60030016,keeping my servers o/s' static ip-addresses during kubernetes setup,"i have a newbie kubernetes setup question that i can't find the answer to. maybe community friends can help me.

my setup:

i have a personal r&amp;d lab created using a robust pc running:


fedora-30 (the outer host o/s)
multiple lxc o/s containers (as guests running centos-8)
and docker ce nested and running within those lxc guest containers


using this setup, i'm able to mutate the ""personality"" of this environment to assume various technology and application development stacks.

now the outer host and lxc guest o/s' all have static ip-address on the same subnet as any other device on my personal (home) network (basically bridged because it's just easier). the relevant hosts and ip-addresses for this question, are:


fedora-30 outer host (the pc): 192.168.0.16/24
vps10 (centos-8) lxc guest: 192.168.0.180/24 -- k8s00
vps11 (centos-8) lxc guest: 192.168.0.181/24 -- k8s01
vps12 (centos-8) lxc guest: 192.168.0.182/24 -- k8s02
vps13 (centos-8) lxc guest: 192.168.0.183/24 -- k8s03


i would like to setup a small kubernetes cluster, with k8s00 (above) being it's master node, and with k8s01, k8s02 and k8s03 (above) being the worker nodes. again, these are lxc o/s containers with docker ce nested within them (all working well).

my question:

as i set up kubernetes, i would like to keep these ip-addresses  (since other r&amp;d lab projects depend on them). yet i can't tell from the documentation if i can or cannot keep them. in other words, does the below initialization command (example below) imply that i need to wipe out all ip-addresses and let it take over ip-address assignment; or i don't need to do that because the command simply creates an ""overlay network"" using the specified cidr (atop my aforementioned static ip-addresses).

many documents and books focus on super simple setups or all-in-a-box setups, which don't apply to my scenario here.

anyway, i hope it's the latter (i.e. being able to keep my ip-addresses) because they effectively represent the bare-metal addresses of those lxc ""servers"", which i would like to keep.

vps10$ sudo kubeadm init --pod-network-cidr=some-network/some-mask [other_options]


p.s. assuming the answer is that i can keep my said static ip-addresses, what cidr might be recommend for the above command? same subnet; different subnet, etc.

sorry for the verbose question. this will literally be my first kubernetes setup, and things are already complicated, so i appreciate any walk-through answers.

thanks. i hope this helps others, too.
\(◠﹏◠)/
",<docker><kubernetes><kubernetes-pod>,60030684,5,"you can keep your k8s cluster nodes static ip addresses.  
while kubeadm init, your specified pod network subnet should not overlap with your cluster nodes subnet. in below command, specified pod subnet is not overlapping with your cluster subnet.

sudo kubeadm init --pod-network-cidr=10.16.96.0/24 --apiserver-advertise-address=&lt;master-node-ip_addr&gt; 


you can initialize pod subnet of your choice but if it will overlap with you cluster nodes subnet, then it will create a complicated situation. (as these are 2 different subnetworks but if you specify same subnet range then your newly created pod could have a ip address same as one of your cluster node ip address)
"
65017380,kubernetes network policy deny-all policy not blocking basic communication,"i am running a gke cluster version 1.17.13-gke.1400.
i have applied the following network policy in my cluster -
apiversion: networking.k8s.io/v1
kind: networkpolicy
metadata:
  name: default-deny
  namespace: default
spec:
  podselector: {}
  policytypes:
  - ingress
  - egress

which should block all communication to or from pods on the default namespace.
however, it does not. as is evident from this test -
$ kubectl run p1 -it  --image google/cloud-sdk
root@p1:/# ping 8.8.8.8
ping 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=114 time=1.14 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=114 time=1.21 ms
^c
root@p1:/# curl www.google.com 
&lt;!doctype html&gt;&lt;html itemscope=&quot; ...

from the docs, seems like this application should be pretty straight forward.
any help in understanding what i'm doing wrong, or tips for further troubleshooting, will be appreciated.
thanks,
nimrod,
",<kubernetes><google-kubernetes-engine><kubernetes-networkpolicy>,65022827,12,"for network policies to take effect, your cluster needs to run a network plugin which also enforces them. project calico or cilium are plugins that do so. this is not the default when creating a cluster!
so first, you should check if your cluster is set up accordingly as described in the google cloud network policies docs. this is somehow abstracted away behind the --enable-network-policy flag.
if it is enabled, you should see some calico pods in the kube-system namespace.
kubectl get pods --namespace=kube-system
if there is a plugin in place which enforces network policies, you need to make sure to have deployed the network policy in the desired namespace - and check if your test using kubectl run is executed in that namespace, too. you might have some other namespace configured in your kube context and not hit the default namespace with your command.
"
70742380,how to `kubectl get all` in k9s?,"instead of navigating a namespace via e.g. :service, then :pod etc, i would like to see everything that's in the namespace in a single view. as if you would type kubectl -n argocd get all.
can't find the info in the docs. is this even possible?
",<kubernetes><kubectl>,78350592,6,"as per mikolaj s. answer, there is now a feature called workloads that displays something similar to kubectl get all (thread on github)
to use it, just type :workloads to view all namespace's resources or :workloads your-namespace to filter all resources from a specific namespace.

the only drawback is that this view cannot display crds, so to view those you'll still need to switch between them.
"
30184856,how to update a set of pods running in kubernetes?,"what is the preferred way of updating a set of pods (e.g. after making code changes &amp; pushing underlying docker image to docker hub) controlled by a replication controller in kubernetes cluster?

i can see 2 ways:


deleting &amp; re-creating replication controller manually
using kubectl rolling-update


with the rolling-update i have to change the replication controller name. since i'm storing replication controller definition in yaml file and not generating it manually, having to change the file to push out a code update seems to bring about bad habits like alternating between 2 names for the replication controller (e.g. controllera and controllerb) to avoid name conflict.

what is the better way?
",<kubernetes><kubectl>,30194982,27,"update: kubectl rolling-update has been deprecated and the replacement command is kubectl rollout. also note that since i wrote the original answer the deployment resource has been added and is a better choice than replicasets as the rolling update is performed server side instead of by the client. 



you should use kubectl rolling-update. we recently added a feature to do a ""simple rolling update"" which will update the image in a replication controller without renaming it. it's the last example shown in the kubectl help rolling-update output:

// update the pods of frontend by just changing the image, and keeping the old name
$ kubectl rolling-update frontend --image=image:v2


this command also supports recovery -- if you cancel your update and restart it later, it will resume from where it left off. even though it creates a new replication controller behind the scenes, at the end of the update the new replication controller takes the name of the old replication controller so it appears as pure update rather than switching to an entirely new replication controller. 
"
52957287,"kubernetes edit secret error: ""cannot restore slice from...""","i'm trying to edit a kubernetes secret using:

kubectl edit secret mysecret -o yaml


and adding a new variable on data:

data:
  new_var: true


but i receive the error:


  cannot restore slice from bool


if i try to use some number, like:

data:
  new_var: 1


i receive another error after close the editor:


  cannot restore slice from int64


what this error means?
",<kubernetes><kubectl>,52957288,4,"this error happens when the variable is not a valid base64 value.

so, to use the value true, you need to use his base64 representation:

new_var: dhj1zq==

"
62014761,kubernetes liveness probe,"how can i write kubernetes readiness probe for my spring boot application, which takes around 20 second to startup ? i tried to follow example from configure liveness, readiness and startup probes, but i'm not sure how does kubernetes figure out status code 200 as success 

apiversion: v1
kind: pod
metadata:
  labels:
    app: backend
    name: liveness-http
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessprobe:
      httpget:
        path: /healthz
        port: 8080
        httpheaders:
        - name: custom-header
          value: awesome
      initialdelayseconds: 3
      periodseconds: 3

",<kubernetes><google-kubernetes-engine>,62014837,4,"kubernetes kubelet will make a http request at /healthz path in your application and expects http status code 200 returned from that endpoint for the probe to be successful. so you need to have a rest endpoint in a rest controller which will return 200 from /healthz. an easy way to achieve it would be to include spring boot actuator dependency and change the liveness probe path to /actuator/health/liveness. spring boot actuator by default comes with a rest controller endpoint which returns 200 from /actuator/health/liveness.

https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html#production-ready-kubernetes-probes
"
69978994,list secrets used by certain pod in k8s,"i'd like to know if kubectl offers an easy way to list all the secrets that a certain pod/deployment/statefulset is using, or if there is some way to cleanly retrieve this info. when doing a kubectl describe for a pod, i see i can get a list of mounted volumes which include the ones that come from secrets that i could extract using jq and the like, but this way feels a bit clumsy. i have been searching a bit to no avail. do you know if there is anything like that around? perhaps using the api directly?
",<kubernetes><kubectl><kubernetes-secrets>,69982162,4,"to list all secrets currently in use by a pod use:
kubectl get pods -o json | jq '.items[].spec.containers[].env[]?.valuefrom.secretkeyref.name' | grep -v null | sort | uniq

in the other hand if you want to access to stored secrets in the api:

kubernetes secrets are, by default, stored unencrypted in the api
server's underlying data store (etcd). anyone with api access can
retrieve or modify a secret, and so can anyone with access to etcd.
additionally, anyone who is authorized to create a pod in a namespace
can use that in order to safely use secrets, take at least the
following steps:

enable encryption at rest for secrets.
enable or configure rbac rules that restrict reading data in secrets    (including via indirect means).
where appropriate, also use mechanisms such as rbac to limit which    principals are allowed to create new secrets or replace existing
ones.access to read any secret in that namespace; this includes
indirect access such as the ability to create a deployment.


if you want more information about secrets in kubernetes, follow this link.
"
57843340,how to pass gke credential to kubernetes provider with terraform?,"i've created a gke cluster with terraform and i also want to manage kubernetes with terraform as well. however, i don't know how to pass gke's credentials to the kubernetes provider.

i followed the example in the google_client_config data source documentation and i got 


  data.google_container_cluster.cluster.endpoint is null


here is my failed attempt https://github.com/varshard/gke-cluster-terraform/tree/title-terraform

cluster.tf is responsible for creating a gke cluster, which work fine.

kubernetes.tf is responsible for managing kubernetes, which failed to get gke credential.
",<kubernetes><terraform><google-kubernetes-engine><terraform-provider-gcp>,57850274,11,"you don't need the google_container_cluster data source here at all because the relevant information is also in the google_container_cluster resource that you are creating in the same context.
data sources are for accessing data about a resource that is created either entirely outside of terraform or in a different terraform context (eg different state file and different directory that is terraform apply'd).
i'm not sure how you're in your current state where the data source is selecting an existing container cluster and then you define a resource to create that container cluster using the outputs of the data source but this is way overcomplicated and slightly broken - if you destroyed everything and reapplied it wouldn't work as is.
instead you should remove the google_container_cluster data source and amend your google_container_cluster resource to instead be:
resource &quot;google_container_cluster&quot; &quot;cluster&quot; {
  name     = &quot;${var.project}-cluster&quot;
  location = var.region

  # ...
}

and then refer to this resource in your kubernetes provider:
provider &quot;kubernetes&quot; {
  load_config_file = false
  host                   = &quot;https://${google_container_cluster.cluster.endpoint}&quot;
  cluster_ca_certificate = base64decode(google_container_cluster.cluster.master_auth.0.cluster_ca_certificate)
  token                  = data.google_client_config.current.access_token
}

"
42973882,configure nfs server for persistentvolume either via dns or static clusterip,"i have a kubernetes cluster running on google container engine that defines a pod running a nfs-server, which i want to access in other pods via various persistentvolumes.

what is the best way to configure the nfs service, if it is in the same cluster?

according to various documentation ive found its not possible to rely on kube-dns for this, because the node starting the kubernetes pod is not configured to use it as its dns.

so this is out of question (and really does not work - ive tested it, with various different hostname/fqdn...)

apiversion: v1
kind: persistentvolume
metadata:
  name: xxx-persistent-storage
  labels:
    app: xxx
spec:
  capacity:
    storage: 10gi
  nfs:
    path: ""/exports/xxx""
    server: nfs-service.default.svc.cluster.local  # &lt;-- does not work


i can start the nfs server and check its clusterip via kubectl describe svc nfs-service and then hardcode its endpoint-ip for the pv (this works):

apiversion: v1
kind: persistentvolume
metadata:
  name: xxx-persistent-storage
  labels:
    app: xxx
spec:
  capacity:
    storage: 10gi
  nfs:
    path: ""/exports/xxx""
    server: 10.2.1.7  # &lt;-- does work


but this feels wrong - as soon as i need to recreate the nfs-service ill get a new ip and i have to reconfigure all the pvs based on it.


what is the best-practice here? im surprised i did not find any example for it, because i supposed thats quite a normal thing to do - isnt it?
is it possible to set a kind of static ip for a service, so that i can rely on having always the same ip for the nfs service?

",<kubernetes><nfs><google-kubernetes-engine><kube-dns>,42981791,3,"you are on the right track. to make sure that your service is using a static ip just add clusterip: 1.2.3.3 under the spec: section of the service.

from the canonical example:


  in the future, we'll be able to tie these together using the service names, but for now, you have to hardcode the ip.

"
58524762,helm install gives error while installing jenkins,"while i am trying to install jenkins using helm chart, it gives error.

$ helm install --name jenkins --namespace jenkins --values values.yml stable/jenkins



  error: render error in ""jenkins/templates/deprecation.yaml"": template: jenkins/templates/deprecation.yaml:105:14: executing ""jenkins/templates/deprecation.yaml"" at : error calling fail: master.servicetype does no longer exist. it has been renamed to master.servicetype


values.yml

master:
  serviceport: 8080
  servicetype: nodeport
  nodeport: 32123
  scriptapproval:
    - ""method groovy.json.jsonslurperclassic parsetext java.lang.string""
    - ""new groovy.json.jsonslurperclassic""
    - ""staticmethod org.codehaus.groovy.runtime.defaultgroovymethods leftshift java.util.map java.util.map""
    - ""staticmethod org.codehaus.groovy.runtime.defaultgroovymethods split java.lang.string""
  installplugins:
    - kubernetes:1.7.1   
    - workflow-aggregator:2.5   
    - workflow-job:2.21   
    - credentials-binding:1.16   
    - git:3.9.1   
agent:
  volumes:
    - type: hostpath
      hostpath: /var/run/docker.sock
      mountpath: /var/run/docker.sock

persistence:
  enabled: true
  storageclass: jenkins-volume   
  size: 3gi

networkpolicy:
  enabled: false
  apiversion: extensions/v1beta1

rbac:
  install: true
  serviceaccountname: default
  apiversion: v1beta1
  roleref: cluster-admin

",<jenkins><kubernetes><yaml><kubernetes-helm><minikube>,58525109,1,"your values.yaml file isn't compatible with jenkins's values.yaml. you should follow the format they suggest. 

master:
  serviceport: 8080
  servicetype: nodeport
  nodeport: 32123
  scriptapproval:
    - ""method groovy.json.jsonslurperclassic parsetext java.lang.string""
    - ""new groovy.json.jsonslurperclassic""
    - ""staticmethod org.codehaus.groovy.runtime.defaultgroovymethods leftshift java.util.map java.util.map""
    - ""staticmethod org.codehaus.groovy.runtime.defaultgroovymethods split java.lang.string""
  installplugins:
    - kubernetes:1.7.1   
    - workflow-aggregator:2.5   
    - workflow-job:2.21   
    - credentials-binding:1.16   
    - git:3.9.1 

  ......


you can find the actual format at jenkins/values.yaml. 
"
64247397,how to get the manifest file with all values populated from helm chart?,"is there a way to obtain the manifest file from a helm chart? the manifest file needs to be able to run just like a helm install. this will need to have all values populated and aggregated into one manifest file for kubectl apply -f
",<kubernetes><kubernetes-helm>,64247606,12,"if i heard you properly, then my answer is: you can. and it is helm template cmd. see
$ helm template --help

render chart templates locally and display the output.

any values that would normally be looked up or retrieved in-cluster will be
faked locally. additionally, ...

"
70204722,split string and extract variables with shell script,"question
given this single-line string:
pg_user=postgres pg_port=1234 pg_pass=icontain=and*symbols

what would be the right way to assign each value to its designated variable so that i can use it afterward?

context
i'm parsing the context of a k8s secret within a cronjob so that i can periodically call a stored procedure in our postgres database.
to do so, i plan on using:
pg_output_value=$(pgpassword=$pg_passwd psql -qtax -h $pg_host -p $pg_port -u $pg_user -d $pg_database -c $pg_tr_cleanup_query)

echo $pg_output_value

the actual entire helm chart i'm currently trying to fix looks like this:
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: {{ template &quot;fullname&quot; $ }}-tr-cleanup-cronjob
spec:
  concurrencypolicy: forbid
  schedule: &quot;* * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          restartpolicy: onfailure
          volumes:
          - name: postgres
            secret:
              secretname: {{ template &quot;fullname&quot; $ }}-postgres
          containers:
          - name: {{ template &quot;fullname&quot; $ }}-tr-cleanup-pod
            image: postgres:12-alpine
            imagepullpolicy: always
            env:
              - name: pg_props
                valuefrom:
                  secretkeyref:
                    name: {{ template &quot;fullname&quot; $ }}-postgres
                    key: postgres.properties
            command:
              - /bin/sh
              - -c
              - echo &quot;props:&quot; &amp;&amp; echo $pg_props &amp;&amp; pg_user=$(grep &quot;^pg_user=&quot; | cut -d&quot;=&quot; -f2-) &amp;&amp; echo $pg_user &amp;&amp; pg_tr_cleanup_query=&quot;select something from public.somewhere;&quot; &amp;&amp; echo $pg_tr_cleanup_query &amp;&amp; pg_output_value=$(pgpassword=$pg_passwd psql -qtax -h $pg_host -p $pg_port -u $pg_user -d $pg_database -c $pg_tr_cleanup_query) &amp;&amp; echo pg_output_value
            volumemounts:
              - name: postgres
                mountpath: /etc/secrets/postgres

current approach
as you can see, i'm currently using:
pg_user=$(grep &quot;^pg_user=&quot; | cut -d&quot;=&quot; -f2-)

that is because i initially thought the secret would be output on multiple lines, but it turns out that i was wrong. the echo $pg_user displays an empty string.
",<shell><kubernetes><kubernetes-cronjob>,70205752,1,"option 1
this function can be reused to assign each variable individually:
extract() {
  echo &quot;$input&quot; | grep -o &quot;$1=.*&quot; | cut -d&quot; &quot; -f1 | cut -d&quot;=&quot; -f2- ;
}

and to use it:
pg_user=$(extract pg_user)
pg_port=$(extract pg_port)
pg_pass=$(extract pg_pass)


option 2
another potential solution, with a security concern, is to simply use:
eval &quot;$input&quot;

it should only be used if you have validated the input.

contextual complete answer
and because i've presented the k8s context in the question, here is the answer as plugged into that solution.
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: {{ template &quot;fullname&quot; $ }}-cronjob
spec:
  concurrencypolicy: forbid
  schedule: &quot;* * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          restartpolicy: onfailure
          volumes:
          - name: postgres
            secret:
              secretname: {{ template &quot;fullname&quot; $ }}-postgres
          containers:
          - name: {{ template &quot;fullname&quot; $ }}-cronjob-pod
            image: postgres:12-alpine
            imagepullpolicy: always
            env:
              - name: pg_props
                valuefrom:
                  secretkeyref:
                    name: {{ template &quot;fullname&quot; $ }}-postgres
                    key: postgres.properties
            command:
              - /bin/sh
              - -c
              - &gt;-
                extract() { echo &quot;$pg_props&quot; | grep -o &quot;$1=.*&quot; | cut -d&quot; &quot; -f1 | cut -d&quot;=&quot; -f2- ; } &amp;&amp;

                export pghost=$(extract pg_host) &amp;&amp;
                export pgport=$(extract pg_port) &amp;&amp;
                export pgdatabase=$(extract pg_database) &amp;&amp;
                export pguser=$(extract pg_user) &amp;&amp;

                pg_schema=$(extract pg_schema) &amp;&amp;
                pg_query=&quot;select tenant_schema from $pg_schema.tenant_schema_mappings;&quot; &amp;&amp;

                pgpassword=$(extract pg_passwd) psql --echo-all -c &quot;$pg_query&quot;
            volumemounts:
              - name: postgres
                mountpath: /etc/secrets/postgres

"
66818476,is it possible to use same hostname with multiple ingress resources running in different namespaces?,"i want to use the same hostname let's say example.com with multiple ingress resources running in different namespaces i.e monitoring and myapp. i'm using kubernetes nginx-ingress controller.
haproxy-ingress.yaml
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: haproxy-ingress
  namespace: myapp
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;  
spec:
  tls:
  - hosts:
    # fill in host here
    - example.com
    
  rules:
    - host: example.com
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: haproxy
                port:
                  number: 80


grafana-ingress.yaml
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: grafana-ingress
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
spec:
  tls:
  - hosts:
    - example.com
    
  rules:
    - host: example.com
      http:
        paths:
          # only match /grafana and paths under /grafana/
          - path: /grafana(/|$)(.*)
            pathtype: prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000


when i'm doing curl example.com then it is redirecting me to the deployment running in namespace one(as expected) but when i'm doing curl example.com/grafana then still it is redirecting me to namespace one deployment.
please help.
",<kubernetes><kubernetes-ingress>,66819715,4,"yes it is possible.
there can be two issues in your case.
one is you don't need the regex path for grafana ingress. simple /grafana path will be fine with path type prefix as with path type prefix any /grafana/... will be redirected associated service. so the manifest file will be:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: grafana-ingress
  namespace: monitoring
spec:
  tls:
  - hosts:
    - example.com
    
  rules:
    - host: example.com
      http:
        paths:
          - path: /grafana
            pathtype: prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000


and the second issue can be the related service or deployment might not be the under same namespace monitoring. please make sure the deployment/service/secret or other resources needed for grafana remains under the same namespace monitoring.
"
54827386,how to check if network policy have been applied to pod?,"i'm trying to restrict to my openvpn to allow accessing internal infrastructure and limit it only by 'develop' namespace, so i started with simple policy that denies all egress traffic and see no effect or any feedback from cluster that it was applied, i've read all docs both official and not and didn't find a solution, here is my policy:

kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: policy-openvpn
  namespace: default
spec:
  podselector:
    matchlabels:
      app: openvpn
  policytypes:
  - egress
  egress: []


i've applied network policy above with kubectl apply -f policy.yaml command, but i don't see any effect of this policy, i'm still able to connect to anything from my openvpn pod, how to debug this and see what's wrong with my policy? 

it seems like a black-box for me and what can do only is try-error method, which seems not how it should work. 

how can i validate that it finds pods and applies policy to them?

i'm using latest kubernetes cluster provided by gke

i noticed that i didn't check 'use networkpolicy' in google cloud settings and after i checked my vpn just stopped worked, but i don't know how to check it, or why vpn just allows me to connect and blocks all network requests, very strange, is there a way to debug is instead of randomly changing stuff?
",<kubernetes><google-kubernetes-engine><kubernetes-networkpolicy><gke-networking>,57229083,21,"gke uses calico for implementing network policy. you need to enable network network policy for master and nodes before applying network policy. you can verify whether calico is enabled by looking for calico pods in kube-system namespace.

kubectl get pods --namespace=kube-system


for verifying the network policies you can see the following commands. 

kubectl get networkpolicy
kubectl describe networkpolicy &lt;networkpolicy-name&gt;

"
77452894,skaffold - how to stop it from pulling the images locally?,"we work with a remote eks where all of our images reside in.
when we're running skaffold it checks the gitlab registry cache and if there's a cached image it will always pull it locally and then deploy it remotely to the eks.
is there a way to let skaffold deploy it directly to the eks without pulling it locally first?
for the deployment, we're using helm and the build bellow is an example of what we have inside our skaffold.yamls -
build:
  tagpolicy:
    inputdigest: {}
  artifacts:
    - image: web_microservice
      context: ../../
      sync: {}
      custom:
        buildcommand: build/buildx.sh &quot;web/dockerfile&quot; production
        dependencies:
          dockerfile:
            path: web/dockerfile
  local:
    usebuildkit: true 

",<kubernetes><gitlab><amazon-eks><skaffold>,77600273,1,"apparently, there was a bug in skaffold so i fixed it and it will be released in the next version (2.10.0).
https://github.com/googlecontainertools/skaffold/pull/9181
besides that, there should be a cluster: {} inside the build section instead of the local: usebuildkit: true.
"
59009016,"kubernetes ingress perform authorization before route, like api gateway","it's possible to perform an authorization(rule-based like) into kubernetes ingress(like kong, nginx).
for example, i have this:

apiversion: extensions/v1beta1

kind: ingress
metadata:
  name: foo-bar
spec:
  rules:
  - host: api.foo.bar
    http:
      paths:
      - path: /service
        backend:
          servicename: service.foo.bar
          serviceport: 80


but before redirect to /service, i need to perform a call in my authorization api to valid if the request token has the rule to pass for /service.

or i really need to use an api gateway behind ingress like a spring zuul to do this?
",<kubernetes><kubernetes-ingress><nginx-ingress><api-gateway><kong-ingress>,59009416,3,"ingress manifest is just input for a controller. you also need an ingress controller, an proxy that understand the ingress object. kong and nginx is two examples of implementation.

nginx  ingress controller is provided from the kubernetes community and it has an example of configuring an external oauth2 proxy using annotations

annotations:
  nginx.ingress.kubernetes.io/auth-url: ""https://$host/oauth2/auth""
  nginx.ingress.kubernetes.io/auth-signin: ""https://$host/oauth2/start?rd=$escaped_request_uri""

"
57506474,upgrading from helm stable/cert-manager to jetstack/cert-manager,"we have a production aks cluster that has a stable/cert-manager helm chart installed to allow using let's encrypt certificates. the current version installed is cert-manager-v0.6.0 in the kube-system namespace.

let's encrypt is to stop support for traffic from cert-manager pre 8.0 version from 1st of november 2019.

i would like to upgrade but the latest available stable chart version is v0.6.7. seems like the way to go is to switch to jetstack/cert-manager.

how do i best approach this? shall i uninstall the current stable/cert-manager chart and install from scratch with the jetstack/cert-manager? any resource on how to tackle this without downtime in production would be much appreciated. please let me know if i can provide any more details.
",<kubernetes><kubernetes-helm><lets-encrypt><azure-aks><cert-manager>,57521186,2,"for anyone asking the same question, i have tried to perform clean install on my test cluster and this seemed to work fairly smoothly. i have found what the name of my the helm release was by running helm list 

then i have performed the following steps:

1.backup:

kubectl get -o yaml \
   --all-namespaces \
   issuer,clusterissuer,certificates,orders,challenges &gt; cert-manager-backup.yaml


source

2.delete:

# uninstall the helm chart
helm delete --purge &lt;your release name here&gt;

# ensure the cert-manager customresourcedefinition resources do not exist:
kubectl delete crd \
    certificates.certmanager.k8s.io \
    issuers.certmanager.k8s.io \
    clusterissuers.certmanager.k8s.io


described in step 2 here

3.install a fresh jetstack version:

# install the customresourcedefinition resources separately
kubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.9/deploy/manifests/00-crds.yaml

# create the namespace for cert-manager
kubectl create namespace cert-manager

# label the cert-manager namespace to disable resource validation
kubectl label namespace cert-manager certmanager.k8s.io/disable-validation=true

# add the jetstack helm repository
helm repo add jetstack https://charts.jetstack.io

# update your local helm chart repository cache
helm repo update

# install the cert-manager helm chart
helm install --name &lt;your release name here&gt; --namespace cert-manager --version v0.9.1 jetstack/cert-manager


described here

4.restore:

i have tried running

kubectl apply -f cert-manager-backup.yaml


as described here but this step actually didn't fully work for me. the issuers were created (self signed and ca) but i could not re-create the certificates and clusterissuer. these were the errors i have received:

error from server (internalerror): internal error occurred: failed calling webhook ""clusterissuers.admission.certmanager.k8s.io"": the server is currently unable to handle the request
error from server (internalerror): internal error occurred: failed calling webhook ""certificates.admission.certmanager.k8s.io"": the server is currently unable to handle the request


i had my original yaml files and was able to create the clusterissuer and certificate by applying them
"
68738047,helm rollback commands rollback the entire release in sub-chart scenario,"given a situation where we have helm chart a which contains a sub-chart b. let's perform below sequence of operations.

helm install test /path/to/a . it installs the sub-chart b as well under the same helm release name i.e. test
do some configuration changes that impacts both the charts. e.g. change some env variables.
do helm upgrade test /path/to/a . upgrades all the affected pods under chart a and b
due to some reasons, i want to just rollback the new changes done on sub-chart b but keep the new changes on a.
do helm rollback test.

now, the step 5th rollbacks the chart a changes as well. now, the question is, can i restrict the rollback just to chart b ? is it possible.
",<kubernetes><kubernetes-helm>,68740479,1,"this is not possible.  the parent chart a and the subchart b are parts of the same helm release once they're installed, and you can only upgrade or roll back the entire release, not fragments of it.
if you keep your deployment configuration in source control, you could do a partial revert of your per-environment configuration file the same way you'd do a partial revert of any other file, and then helm upgrade again to the &quot;new&quot; (partially-reverted) configuration.
"
75936245,how to use the latest kubectl-convert to update a file on disk,"i want to update bunch of ingress.yaml files in my microservices project to use the new kubernetes api version. currently the ingresses are using apiversion: extensions/v1beta1 still.
i'm confused with the plugin (kubectl convert) and the whole new binary (kubectl-convert)... which tool should i be using in 2023?
i would like to have a one liner command to update all ingress.yaml files recursively inside current directory.
maybe the new tool has some bugs in it? i'm getting this error with the bash script i assumed would work:
find . -name &quot;ingress.yaml&quot; | while read file; do kubectl-convert -f &quot;$file&quot; &gt; &quot;$file&quot;; done
error: no objects passed to convert

",<bash><kubernetes><kubectl>,75943036,1,"i prefer to use kubectl convert plugin and the following cmd should do the trick for you:
find . -name &quot;ingress.yaml&quot; | while read file; do kubectl convert -f &quot;$file&quot; --output-version networking.k8s.io/v1 &gt; &quot;$file&quot;.bak &amp;&amp; mv &quot;$file&quot;.bak &quot;$file&quot;; done

tested locally on a set of 3 ingress.yaml file nested within different sub-folders.
i've assumed you're moving from extensions/v1beta1 to networking.k8s.io/v1.
as is the general practice, make sure to back up your files before running this (or any such) command, in case of any unexpected issues.
hope this helps.
"
73303670,how to edit a helm chart (loki) config files for grafana cloud,"i have installed loki and grafana via helm charts to my cloud hosted k8s cluster. how do i send the loki metrics to grafana cloud? i know i should edit the promtail config file but how do i locate and view/edit helm chart files?
my installation procedure for loki+grafana are:
helm upgrade --install loki --namespace=monitoring grafana/loki-stack
helm upgrade --install grafana --namespace=monitoring grafana/grafana
kubectl port-forward service/grafana 3000:80 -n monitoring

this installation of loki only exposes loki to grafana locally. i wish to enter the configuration of loki (or more specifically promtail) so that i can send the loki logs to my grafana cloud account and monitor the logs from grafana cloud as well.
i have done this in a non-k8s setting by modifying the promtail-config.yaml which is referenced to send the logs to grafana cloud. adding the grafana cloud url to the promtail config such as:
clients:
  - url: http://loki:3100/loki/api/v1/push
  - url: https://123456:ekw0...=@logs-prod3.grafana.net/api/prom/push

when i explore grafana cloud &gt; intergrations and connections &gt; loki hosted logs &gt; k8s cluster. i receive the following instructions

your configuration, complete with your
api key, has been generated below. copy and paste this code to
promtail/config.yaml to send data using promtail.

the code snippet:
curl -fss https://raw.githubusercontent.com/grafana/loki/master/tools/promtail.sh | sh -s 123456 eb9... logs-prod3.grafana.net default | kubectl apply --namespace=default -f  -

i am new to helm charts, so i do not know how to view the helm config files and where they are stored. or how to obtain the promtail/config.yaml file from helm or the k8s cluster.
",<kubernetes><kubernetes-helm><grafana><grafana-loki><promtail>,73316610,1,"i'm not an expert in loki but i downloaded the default values.yaml that chart uses and there seems an option to mention the promtail configuration which should help you (shown below) and looking at the commands above, it seems helm would have used default values to install the chart, you can still modify them in 2 ways.
1st: run the below to get the values.yaml that was used to install the chart by default, modify the promtail configuration and then upgrade the installation using the modified values.yaml
helm get values -n monitoring grafana/loki-stack loki &gt; values.installed.loki.yaml

*modify the values.installed.loki.yaml, on line number 5 there are a few *promtail configuration you may need to set
 promtail:
   enabled: true
   config:
     lokiaddress: http://{{ .release.name }}:3100/loki/api/v1/push


once done, upgrade the chart with the modified values with -f flag
helm upgrade --install loki --namespace=monitoring grafana/loki-stack -f values.installed.loki.yaml

2nd: get the default values.yaml as shown below which is used for loki installation, modify the promtail configuration and upgrade the installation as shown below
helm show values grafana/loki-stack &gt; values.loki.yaml

modify values.loki.yaml for the promtail configuration and upgrade the chart
 promtail:
   enabled: true
   config:
     lokiaddress: http://{{ .release.name }}:3100/loki/api/v1/push

run an upgrade on the existing installation with the new values.yaml

helm upgrade --install loki --namespace=monitoring grafana/loki-stack -f values.loki.yaml

"
65008764,pulling docker image in gke,"apologies if this is a duplicate, i haven't found a solution in similar questions.
i'm trying to upload a docker image to google kubernetes engine.
i've did it successfully before, but i can't seem to find my luck this time around.
i have google sdk set up locally with kubectl and my google account, which is project owner and has all required permissions.
when i use
kubectl create deployment hello-app --image=gcr.io/{project-id}/hello-app:v1

i see the deployment on my gke console, consistently crashing as it &quot;cannot pull the image from the repository.errimagepull cannot pull image '' from the registry&quot;.
it provides 4 recommendations, which i have by now triple checked:

check for spelling mistakes in the image names.
check for errors when pulling the images manually (all fine in cloud shell)
check the image pull secret settings
so, based on this https://blog.container-solutions.com/using-google-container-registry-with-kubernetes, i manually added 'gcr-json-key' from a new service account with project view permissions as well as 'gcr-access-token' to kubectl default service account.
check the firewall for the cluster to make sure the cluster can connect to the ''. afaik, this should not be an issue with a newly set up cluster.

the pods themselve provide the following error code:
failed to pull image &quot;gcr.io/{project id}/hello-app:v1&quot;: 
[rpc error: code = unknown desc = error response from daemon: 
get https://gcr.io/v2/{project id}/hello-app/manifests/v1: unknown: unable to parse json key., 
rpc error: code = unknown desc = error response from daemon: 
get https://gcr.io/v2/{project id}/hello-app/manifests/v1: 
unauthorized: not authorized., rpc error: code = unknown desc = error response from daemon: 
pull access denied for gcr.io/{project id}/hello-app, 
repository does not exist or may require 'docker login': denied: 
permission denied for &quot;v1&quot; from request &quot;/v2/{project id}/hello-app/manifests/v1&quot;.]

my question now, what am i doing wrong or how can i find out why my pods can't pull my image?

kubernetes default serviceaccount spec:
kubectl get serviceaccount -o json
{
    &quot;apiversion&quot;: &quot;v1&quot;,
    &quot;imagepullsecrets&quot;: [
        {
            &quot;name&quot;: &quot;gcr-json-key&quot;
        },
        {
            &quot;name&quot;: &quot;gcr-access-token&quot;
        }
    ],
    &quot;kind&quot;: &quot;serviceaccount&quot;,
    &quot;metadata&quot;: {
        &quot;creationtimestamp&quot;: &quot;2020-11-25t15:49:16z&quot;,
        &quot;name&quot;: &quot;default&quot;,
        &quot;namespace&quot;: &quot;default&quot;,
        &quot;resourceversion&quot;: &quot;6835&quot;,
        &quot;selflink&quot;: &quot;/api/v1/namespaces/default/serviceaccounts/default&quot;,
        &quot;uid&quot;: &quot;436bf59a-dc6e-49ec-aab6-0dac253e2ced&quot;
    },
    &quot;secrets&quot;: [
        {
            &quot;name&quot;: &quot;default-token-5v5fb&quot;
        }
    ]
}

",<docker><kubernetes><google-kubernetes-engine>,65009544,3,"it does take several steps and the blog post you referenced appears to have them correctly. so, i suspect your error is in one of the steps.
couple of things:

the error message says failed to pull image &quot;gcr.io/{project id}/hello-app:v1&quot;. did you edit the error message to remove your {project id}? if not, that's one problem.

my next concern is the second line: unable to parse json key. this suggests that you created the secret incorrectly:



create the service account and generate a key
create the secret exactly as shown: kubectl create secret docker-registry gcr-json-key... (in the default namespace unless --namespace=... differs)
update the kubernetes spec with imagepullsecrets

because of the imagepullsecrets requirement, i'm not aware of an alternative kubectl run equivalent but, you can try accessing your image using docker from your host:
see: https://cloud.google.com/container-registry/docs/advanced-authentication#json-key
and then try docker pull gcr.io/{project id}/hello-app:v1 ensuring that {project id} is replaced with the correct gcp project id.
this proves:

the service account &amp; key are correct
the container image is correct

that leaves, your creation of the secret and your kubernetes spec to test.

note the service account iam permission of project viewer is overly broad for gcr access, see the permissions
use storageobject viewer (roles/storage.objectviewer) if the service account needs only to pull images.

"
52179574,shortcut for typing kubectl --all-namespaces everytime,"is there any alias we can make for all-namespace as kubectl don't recognise the command kubectl --all-namespaces or any kind of shortcut to minimize the typing of the whole command.
",<bash><shell><kubernetes><kubectl>,52179973,20,"
  is there any alias we can make for all-namespace


based on this excellent so answer you can create alias that inserts arguments between prefix and suffix like so:

alias kca='f(){ kubectl ""$@"" --all-namespaces -o wide;  unset -f f; }; f'


and then use it regularly like so:

kca get nodes
kca get pods
kca get svc,sts,deploy,pvc,pv


etc..

note: there is -o wide added for fun as well to get more detailed info about resources not normally namespaced like nodes and pv... 
"
66314139,scrape jenkins metrics with prometheus,"i'm new to prometheus, so i'm not sure what i'm doing wrong but these are my service and service monitor definitions.
apiversion: v1
kind: service
metadata:
  name: jenkins
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: '8080'
    prometheus.io/path: '/prometheus'
  labels:
    app.kubernetes.io/instance: jenkins
    app.kubernetes.io/component: jenkins
spec:
  type: clusterip
  ports:
    - port: 8080
      targetport: 8080
  selector:
    app: jenkins

apiversion: monitoring.coreos.com/v1
kind: servicemonitor
metadata:
  name: jenkins
  labels:
    app.kubernetes.io/instance: jenkins
    app.kubernetes.io/component: jenkins
    release: prometheus
spec:
  endpoints:
  - interval: 10s
    path: /prometheus/
    port: &quot;8080&quot;
  joblabel: app.kubernetes.io/instance
  selector:
    matchlabels:
      app.kubernetes.io/component: jenkins
      app.kubernetes.io/instance: jenkins

but my jenkins doesn't appear under the targets list on the prometheus ui.
it appears under service discovery which makes me believe that the operator is correctly picking it up through the release: prometheus label.
i have installed the prometheus plugin on jenkins and i'm able to view metrics when i curl https://&lt;jenkins_url&gt;/prometheus/
what i'm trying to figure out is why jenkins doesn't appear under the targets list.
is there any proper documentation on how to go about this or can anyone who has successfully implemented this share any pointers?
",<jenkins><kubernetes><prometheus><kubernetes-helm><prometheus-operator>,66329368,1,"there is no better docs than reading the code itself.
you need pay attention to this line in the custom resource definition of servicemonitor.
port:
  description: name of the service port this endpoint refers to.
               mutually exclusive with targetport.
  type: string

basically, you created a servicemonitor to a service port named &quot;8080&quot;.
endpoints:
  - interval: 10s
    path: /prometheus/
    port: &quot;8080&quot;

but you defined an unnamed service whose port number is 8080.
spec:
  type: clusterip
  ports:
    - port: 8080
      targetport: 8080

do you see the mismatch now?
you need
either use targetport: 8080 and targetport only in servicemonitor,
or, even better, use port: &quot;web&quot; in servicemonitor, and at the same time, name your service &quot;web&quot;.
servicemonitor:
endpoints:
  - interval: 10s
    path: /prometheus/
    port: &quot;web&quot;

service:
spec:
  type: clusterip
  ports:
    - name: &quot;web&quot;
      port: 8080
      targetport: 8080

"
69694985,gke ingress resource returns 404 although it is connected to a service,"i added a default nginx-ingress deployment with a regional ip that i got from gcp.
helm install nginx-ingress \
             nginx-stable/nginx-ingress \
             --set rbac.create=true \
             --set controller.service.loadbalancerip=&quot;&lt;gcp regional ip&gt;&quot;

i have a dockerized node app with a single .js file. which i deployed with a basic helm chart. the service is called node-app-blue-helm-chart
const http = require('http');

const hostname = '0.0.0.0';
const port = 80;

const server = http.createserver((req, res) =&gt; {
    if (req.url == '/another-page'){
        res.statuscode = 200;
            res.setheader('content-type', 'text/html');
                res.end('&lt;h1&gt;another page&lt;/h1&gt;');

    } else {
        res.statuscode = 200;
            res.setheader('content-type', 'text/html');
                res.end('&lt;h1&gt;hello world&lt;/h1&gt;');
    }
});

server.listen(port, hostname, () =&gt; {
    console.log('server running at http://%s:%s/', hostname, port);
});

process.on('sigint', function() {
    console.log('caught interrupt signal and will exit');
    process.exit();
});

i deployed following ingress resource:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-resource
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
spec:
  rules:
  - host: &quot;*.example.com&quot;
    http:
      paths:
      - path: /*
        pathtype: prefix
        backend:
          service:
            name: node-app-blue-helm-chart
            port:
              number: 80

although ingress resource acquires ip and endpoint. it still returns 404 error. what can be wrong? can host: &quot;*.example.com&quot; section be a problem?
more info:
kubectl describe ing ingress-resource
name:             ingress-resource
namespace:        default
address:          &lt;gcp regional ip&gt;
default backend:  default-http-backend:80 (10.0.0.2:8080)
rules:
  host           path  backends
  ----           ----  --------
  *.example.com  
                 /*   node-app-blue-helm-chart:80 (10.0.0.15:80)
annotations:     kubernetes.io/ingress.class: nginx
                 nginx.ingress.kubernetes.io/ssl-redirect: false
events:          &lt;none&gt;


kubectl describe svc node-app-blue-helm-chart
name:              node-app-blue-helm-chart
namespace:         default
labels:            app.kubernetes.io/instance=node-app-blue
                   app.kubernetes.io/managed-by=helm
                   app.kubernetes.io/name=helm-chart
                   app.kubernetes.io/version=1.16.0
                   helm.sh/chart=helm-chart-0.1.0
annotations:       meta.helm.sh/release-name: node-app-blue
                   meta.helm.sh/release-namespace: default
selector:          app.kubernetes.io/instance=node-app-blue,app.kubernetes.io/name=helm-chart
type:              clusterip
ip families:       &lt;none&gt;
ip:                10.3.248.13
ips:               10.3.248.13
port:              http  80/tcp
targetport:        80/tcp
endpoints:         10.0.0.15:80
session affinity:  none
events:            &lt;none&gt;

what i tried:
removing * from /* in ingress resource. didn't fix the issue.
kubectl describe ing ingress-resource
name:             ingress-resource
namespace:        default
address:          w.x.y.z
default backend:  default-http-backend:80 (10.0.0.2:8080)
rules:
  host           path  backends
  ----           ----  --------
  *.example.com  
                 /   node-app-blue-helm-chart:80 (10.0.0.15:80)
annotations:     kubernetes.io/ingress.class: nginx
                 nginx.ingress.kubernetes.io/ssl-redirect: false
events:
  type    reason          age        from                      message
  ----    ------          ----       ----                      -------
  normal  addedorupdated  &lt;invalid&gt;  nginx-ingress-controller  configuration for default/ingress-resource was added or updated

",<kubernetes><google-kubernetes-engine><kubernetes-helm><kubernetes-ingress><nginx-ingress>,69695029,2,"try to edit your ingress. you have set a path=/*, which may not be what you meant to do. a / should do:
[...]
spec:
  rules:
  - host: &quot;*.example.com&quot;
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: node-app-blue-helm-chart
            port:
              number: 80

"
63952902,kubernetes (openshift) 👉 kubectl (oc - openshift cli) `patch` return the error: cannot unmarshal array into go value of type map[string]interface {},"i try to patch a service (add port declaration):
kind: service
apiversion: v1
metadata:
  name: istio-ingressgateway
  namespace: istio-system
  labels:
    app: istio-ingressgateway
    istio: ingressgateway
    release: istio
spec:
  ports:
    - name: status-port
      protocol: tcp
      port: 15021
      targetport: 15021
      nodeport: 30805
    - name: http2
      protocol: tcp
      port: 80
      targetport: 8080
      nodeport: 32130
    - name: https
      protocol: tcp
      port: 443
      targetport: 8443
      nodeport: 30720
    - name: tls
      protocol: tcp
      port: 15443
      targetport: 15443
      nodeport: 31202
  selector:
    app: istio-ingressgateway
    istio: ingressgateway
  clusterip: 172.30.62.239
  type: loadbalancer
  sessionaffinity: none
  externaltrafficpolicy: cluster
status:
  loadbalancer: {}

using kubectl or oc patch-command
kubectl patch service istio-ingressgateway -n istio-system --patch - &lt;&lt;eof
spec:
  ports:
    - name: gw
      protocol: tcp
      port: 3080
      targetport: 3080
      nodeport: 31230
eof

, but get an error
error from server (badrequest): json: cannot unmarshal array into go value of type map[string]interface {}

👉🏻 under the hood, k8s/openshift use golang to parse yaml 👉 i tried to find same solutions in go - failed...
what's wrong?
",<go><kubernetes><yaml><openshift><kubectl>,63954566,3,"try to use json to patch
oc patch service/simple-server -p \
'{ &quot;spec&quot;: { &quot;ports&quot;: [ { &quot;name&quot;: &quot;gw&quot;, &quot;protocol&quot;: &quot;tcp&quot;, &quot;port&quot;: 1234,&quot;targetport&quot;: 1234 } ] } }'

"
54535869,use prometheus with external ip address,"we have k8s cluster and i’ve application which is running there.
now i try to add https://prometheus.io/
and i use the command 

helm install stable/prometheus --version 6.7.4 --name my-prometheus

this command works and i got this

name:   my-prometheus
last deployed: tue feb  5 15:21:46 2019
namespace: default
status: deployed
...

when i run command 

kubectl get services

i got this 

kubernetes                         clusterip   100.64.0.1       &lt;none&gt;        443/tcp    2d4h
my-prometheus-alertmanager         clusterip   100.75.244.55   &lt;none&gt;        80/tcp     8m44s
my-prometheus-kube-state-metrics   clusterip   none             &lt;none&gt;        80/tcp     8m43s
my-prometheus-node-exporter        clusterip   none             &lt;none&gt;        9100/tcp   8m43s
my-prometheus-pushgateway          clusterip   100.75.24.67     &lt;none&gt;        9091/tcp   8m43s
my-prometheus-server               clusterip   100.33.26.206   &lt;none&gt;        80/tcp     8m43s


i didnt get any externalip

does someone knows how to add it ?  via service? any example for this

update

i’ve added the following yml

apiversion: v1
kind: service
metadata:
  name: prometheus-service
spec:
  selector:
    app: prometheus-server
  type: loadbalancer
  ports:
    - port: 8080
      targetport: 9090
      nodeport: 30001


which created successfully 

now i see the external ip like when running kubectl get services

my-prometheus-server               loadbalancer   100.33.26.206   8080:30001/tcp     80/tcp     8m43s


and i use in the browser 100.33.26.206:30001 and nothing happen, any idea? 
",<kubernetes><google-cloud-platform><prometheus><kubernetes-helm>,54535995,2,"i think what you are trying to do is to create a service with a type loadbalancer, those have an internal and external ip.
you can create one like any other service but you should precise those two fields:
externaltrafficpolicy: local
type: loadbalancer

updated:
there seems to be some confusion, you don't need an external ip to monitor your apps, it will only be used to access prometheus ui.
the ui is accessible on port 9090 but prometheus is never accessed by the exporter as it will be prometheus wich will be scraping the exporters.
now to access a service from the internet you should have a google ip, but it seems that what you have is still an internal ip, it's in the same subnet as the other clusterip, and it should not. for now in place of an external ip it's showing a port redirect wich is also wrong as the prometheus ui is on port 9090 (if you didn't modify your configuration it should still be). you should try to remove the &quot;nodeport&quot; and leave the port redirect to kubernetes.
"
61172390,treafik let's encrypt simplest example on gke,"i am trying to work on simplest possible example of implementing let's encrypt with traefik on gke using this article. i have made some changes to suit my requirement but i am unable to get the acme certificate.

what i have done so far


run the following command and create all the resource objects except ingress-route


$ kubectl apply -f 00-resource-crd-definition.yml,05-traefik-rbac.yml,10-service-account.yaml,15-traefik-deployment.yaml,20-traefik-service.yaml,25-whoami-deployment.yaml,30-whoami-service.yaml
customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us created
customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us created
customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us created
customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us created
customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us created
clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created
clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created
serviceaccount/traefik-ingress-controller created
deployment.apps/traefik created
service/traefik created
deployment.apps/whoami created
service/whoami created



get the ip of the traefik service exposed as load balancer


$ kubectl get service
name         type           cluster-ip      external-ip    port(s)                                     age
kubernetes   clusterip      10.109.0.1      &lt;none&gt;         443/tcp                                     6h16m
traefik      loadbalancer   10.109.15.230   34.69.16.102   80:32318/tcp,443:32634/tcp,8080:32741/tcp   70s
whoami       clusterip      10.109.14.91    &lt;none&gt;         80/tcp                                      70s



create a dns record for this ip


$ nslookup k8sacmetest.gotdns.ch
server:         192.168.1.1
address:        192.168.1.1#53

non-authoritative answer:
name:   k8sacmetest.gotdns.ch
address: 34.69.16.102



create the resource ingress-route


$ kubectl apply -f 35-ingress-route.yaml
ingressroute.traefik.containo.us/simpleingressroute created
ingressroute.traefik.containo.us/ingressroutetls created



logs of traefik


time=""2020-04-25t20:10:31z"" level=info msg=""configuration loaded from flags.""
time=""2020-04-25t20:10:32z"" level=error msg=""subset not found for default/whoami"" providername=kubernetescrd ingress=simpleingressroute namespace=default
time=""2020-04-25t20:10:32z"" level=error msg=""subset not found for default/whoami"" providername=kubernetescrd ingress=ingressroutetls namespace=default
time=""2020-04-25t20:10:52z"" level=error msg=""unable to obtain acme certificate for domains \""k8sacmetest.gotdns.ch\"": unable to generate a certificate for the domains [k8sacmetest.gotdns.ch]: acme: error -&gt; one or more domains had a problem:\n[k8sacmetest.gotdns.ch] acme: error: 400 :: urn:ietf:params:acme:error:connection :: timeout during connect (likely firewall problem), url: \n"" routername=default-ingressroutetls-08dd2bb9eecaa72a6606@kubernetescrd rule=""host(`k8sacmetest.gotdns.ch`) &amp;&amp; pathprefix(`/tls`)"" providername=default.acme


what i have acheived


traefik dashboard


link


whoami with notls


link

not able to get the acme certificate using for tls whoami

my-pain

infra details


i am using google kubernetes cluster (the one being talked about here -cloud.google.com/kubernetes-engine, click on go to console). 
traefik version is 2.2. 
and i am using ""cloudshell"" to access the cluster"". 


ask:

1) where am i going wrong to get the tls certificate? 

2) if its firewall issue how to resolve?

3) if you have any other better example for treafik let's encrypt simplest example on gke please let me know
",<kubernetes><google-kubernetes-engine><lets-encrypt><traefik>,61178740,2,"just run sudo before kubectl port-forward command. you are trying to bind to privileged ports, so you need more permissions.

it is not the simplest example for gke, because you could use gke loadbalnacer instead of kubectl port-forward.

try with this:

apiversion: v1
kind: service
metadata:
  name: traefik
spec:
  ports:
    - protocol: tcp
      name: web
      port: 80
      targetport: web
    - protocol: tcp
      name: websecure
      port: 443
      targetport: websecure
  selector:
    app: traefik
  type: loadbalancer


then you can find your new ip with kubectl get svc in external-ip column, add proper dns record for your domain and you should be fine.
"
50613717,deploy gitlab with helm. nginx-ingress pods can't start,"call install: 

helm install --name gitlab1 -f values.yaml gitlab/gitlab-omnibus


i see pods can't start.

and i see error:no service with name nginx-ingress/default-http-backend found: services ""default-http-backend"" is forbidden: user ""system:serviceaccount:nginx-ingress:default"" cannot get services in the namespace ""nginx-ingress""

i think about abac/rbac... but what doing with this...

logs from nginx pod:

# kubectl logs nginx-ndxhn --namespace nginx-ingress
[dumb-init] unable to detach from controlling tty (errno=25 inappropriate ioctl for device).
[dumb-init] child spawned with pid 7.
[dumb-init] unable to attach to controlling tty (errno=25 inappropriate ioctl for device).
[dumb-init] setsid complete.
i0530 21:30:23.232676       7 launch.go:105] &amp;{nginx 0.9.0-beta.11 git-a3131c5 https://github.com/kubernetes/ingress}
i0530 21:30:23.232749       7 launch.go:108] watching for ingress class: nginx
i0530 21:30:23.233708       7 launch.go:262] creating api server client for https://10.233.0.1:443
i0530 21:30:23.234080       7 nginx.go:182] starting nginx process...
f0530 21:30:23.251587       7 launch.go:122] no service with name nginx-ingress/default-http-backend found: services ""default-http-backend"" is forbidden: user ""system:serviceaccount:nginx-ingress:default"" cannot get services in the namespace ""nginx-ingress""
[dumb-init] received signal 17.
[dumb-init] a child with pid 7 exited with exit status 255.
[dumb-init] forwarded signal 15 to children.
[dumb-init] child exited with status 255. goodbye.


# kubectl get svc -w --namespace nginx-ingress nginx
name      type           cluster-ip    external-ip   port(s)                                   age
nginx     loadbalancer   10.233.25.0   &lt;pending&gt;     80:32048/tcp,443:31430/tcp,22:31636/tcp   9m


# kubectl describe svc --namespace nginx-ingress nginx
name:                     nginx
namespace:                nginx-ingress
labels:                   &lt;none&gt;
annotations:              service.beta.kubernetes.io/external-traffic=onlylocal
selector:                 app=nginx
type:                     loadbalancer
ip:                       10.233.25.0
ip:                       1.1.1.1
port:                     http  80/tcp
targetport:               80/tcp
nodeport:                 http  32048/tcp
endpoints:                
port:                     https  443/tcp
targetport:               443/tcp
nodeport:                 https  31430/tcp
endpoints:                
port:                     git  22/tcp
targetport:               22/tcp
nodeport:                 git  31636/tcp
endpoints:                
session affinity:         none
external traffic policy:  cluster
events:                   &lt;none&gt;


# kubectl get pods --all-namespaces
namespace       name                                                   ready     status             restarts   age
default         gitlab1-gitlab-75576c4589-lnf56                        0/1       running            2          11m
default         gitlab1-gitlab-postgresql-f66555d65-nqvqx              1/1       running            0          11m
default         gitlab1-gitlab-redis-58cf598657-ksptm                  1/1       running            0          11m
default         gitlab1-gitlab-runner-55d458ccb7-g442z                 0/1       crashloopbackoff   6          11m
default         glusterfs-9cfcr                                        1/1       running            0          1d
default         glusterfs-k422g                                        1/1       running            0          1d
default         glusterfs-tjtvq                                        1/1       running            0          1d
default         heketi-75dcfb7d44-thxpm                                1/1       running            0          1d
default         nginx-nginx-ingress-controller-775b5b9c6d-hhvlr        1/1       running            0          2h
default         nginx-nginx-ingress-default-backend-7bb66746b9-mzgcb   1/1       running            0          2h
default         nginx-pod1                                             1/1       running            0          1d
kube-lego       kube-lego-58c9f5788d-pdfb5                             1/1       running            0          11m
kube-system     calico-node-hq2v7                                      1/1       running            3          2d
kube-system     calico-node-z4nts                                      1/1       running            3          2d
kube-system     calico-node-z9r9v                                      1/1       running            4          2d
kube-system     kube-apiserver-k8s-m1.me                               1/1       running            4          2d
kube-system     kube-apiserver-k8s-m2.me                               1/1       running            5          1d
kube-system     kube-apiserver-k8s-m3.me                               1/1       running            3          2d
kube-system     kube-controller-manager-k8s-m1.me                      1/1       running            4          2d
kube-system     kube-controller-manager-k8s-m2.me                      1/1       running            4          1d
kube-system     kube-controller-manager-k8s-m3.me                      1/1       running            3          2d
kube-system     kube-dns-7bd4d5fbb6-r2rnf                              3/3       running            9          2d
kube-system     kube-dns-7bd4d5fbb6-zffvn                              3/3       running            9          2d
kube-system     kube-proxy-k8s-m1.me                                   1/1       running            3          2d
kube-system     kube-proxy-k8s-m2.me                                   1/1       running            3          1d
kube-system     kube-proxy-k8s-m3.me                                   1/1       running            3          2d
kube-system     kube-scheduler-k8s-m1.me                               1/1       running            4          2d
kube-system     kube-scheduler-k8s-m2.me                               1/1       running            4          1d
kube-system     kube-scheduler-k8s-m3.me                               1/1       running            4          2d
kube-system     kubedns-autoscaler-679b8b455-pp7jd                     1/1       running            3          2d
kube-system     kubernetes-dashboard-55fdfd74b4-6z8qp                  1/1       running            0          1d
kube-system     tiller-deploy-75b7d95f5c-8cmxh                         1/1       running            0          1d
nginx-ingress   default-http-backend-6679b97b47-w6cx7                  1/1       running            0          11m
nginx-ingress   nginx-ndxhn                                            0/1       crashloopbackoff   6          11m
nginx-ingress   nginx-nk2jg                                            0/1       crashloopbackoff   6          11m
nginx-ingress   nginx-rz7xj                                            0/1       crashloopbackoff   6          11m


logs on runner:

# kubectl logs gitlab1-gitlab-runner-55d458ccb7-g442z
+ cp /scripts/config.toml /etc/gitlab-runner/
+ /entrypoint register --non-interactive --executor kubernetes
running in system-mode.                            

error: registering runner... failed                 runner=tqtcbx5u status=couldn't execute post against http://gitlab1-gitlab.default:8005/api/v4/runners: post http://gitlab1-gitlab.default:8005/api/v4/runners: dial tcp 10.233.7.205:8005: i/o timeout
panic: failed to register this runner. perhaps you are having network problems


pvc is fine

# kubectl get pvc
name                                status    volume                                     capacity   access modes   storageclass     age
gitlab1-gitlab-config-storage       bound     pvc-c957bd23-644f-11e8-8f10-4ccc6a60fcbe   1gi        rwo            gluster-heketi   13m
gitlab1-gitlab-postgresql-storage   bound     pvc-c964e7d0-644f-11e8-8f10-4ccc6a60fcbe   30gi       rwo            gluster-heketi   13m
gitlab1-gitlab-redis-storage        bound     pvc-c96f9146-644f-11e8-8f10-4ccc6a60fcbe   5gi        rwo            gluster-heketi   13m
gitlab1-gitlab-registry-storage     bound     pvc-c959d377-644f-11e8-8f10-4ccc6a60fcbe   30gi       rwo            gluster-heketi   13m
gitlab1-gitlab-storage              bound     pvc-c9611ab1-644f-11e8-8f10-4ccc6a60fcbe   30gi       rwo            gluster-heketi   13m
gluster1                            bound     pvc-922b5dc0-6372-11e8-8f10-4ccc6a60fcbe   5gi        rwo            gluster-heketi   1d

# kubectl version
client version: version.info{major:""1"", minor:""10"", gitversion:""v1.10.2"", gitcommit:""81753b10df112992bf51bbc2c2f85208aad78335"", gittreestate:""clean"", builddate:""2018-04-27t09:10:24z"", goversion:""go1.9.3"", compiler:""gc"", platform:""linux/amd64""}
server version: version.info{major:""1"", minor:""10"", gitversion:""v1.10.2"", gitcommit:""81753b10df112992bf51bbc2c2f85208aad78335"", gittreestate:""clean"", builddate:""2018-04-27t09:10:24z"", goversion:""go1.9.3"", compiler:""gc"", platform:""linux/amd64""}

",<kubernetes><gitlab><kubernetes-helm><gitlab-omnibus>,50616563,2,"
  i think about abac/rbac... but what doing with this...


you are correct, and the error message explains exactly what is wrong. there are two paths forward: you can fix the role and rolebinding for the default serviceaccount in the nginx-ingress namespace, or you can switch the deployment to use a serviceaccount other than default in order to assign that deployment the specific permissions required. i recommend the latter, but the former may be less typing.

the rough version of the role and rolebinding lives in the nginx-ingress repo but may need to be adapted for your needs, including updating the apiversion away from v1beta1

after that change has taken place, you'll need to delete the nginx-ingress pods in order for them to pick up their new role and conduct whatever initialization tasks nginx does during startup.



separately, you will for sure want to fix this business:


  post http://gitlab1-gitlab.default:8005/api/v4/runners: dial tcp 10.233.7.205:8005: i/o timeout


i can't offer more concrete actions without knowing more about your cni setup and the state of affairs of the actual gitlab pod, but an i/o timeout is certainly a very weird error to get for in cluster communication.
"
57923651,kubectl get deployments output differ from this in documentation,"when i run this command

kubectl get deployments


at my linux ubuntu 18 machine, i got different output than expected (according to documentation).

expected:


actual:



of course, i am not talking about values, i am talking about names of labels. 

[edit]

my k8s version:

",<kubernetes><kubectl>,57924113,3,"this is just an old output format. the newer output you're getting below contains all the same information; the ""ready"" field is a combination of the old ""desired"" and ""current"".

it's showing as 4/5 in your output to indicate 4 pods ready/current, and 5 pods desired.

hope this helps.
"
68827197,get permanent certificate to access to kubectl,"i have setup a cluster on aws using kops. i want to connect to the cluster from my local machine.
i have to do cat ~/.kube/config, copy the content and replace it with my local kube config to access to the cluster.
the problem is that it expires after certain amount of time. is there a way to get permanent access to the cluster?
",<kubernetes><kubectl><kops>,68831981,2,"not sure if you can get permanent access to the cluster, but based on official kops documentation you can just run kops update cluster command with --admin={duration} flag and set expire time to a very big value.
for example - let set it for almost 10 years:
kops update cluster {your-cluster-name} --admin=87599h --yes

then just copy as usual your config file to the client.
based on official release notes, to back to the previous behaviour just use value 87600h.
"
51730497,helm chart versions for ci/cd,"i have a helm repository set up for my ci/cd pipeline, but the one thing i am having trouble with is helm's versioning system which is focused on a semantic versioning system as in x.x.x. 

i want to be able to specify tags like ""staging"", ""latest"", and ""production"", and although i am able to successfully upload charts with string versions

name               chart version   app version
chartmuseum/myrchart latest          1.0


any attempt to actually access the chart fails, such as

helm inspect chartmuseum/mychart --version=latest

generates the error:

error: failed to download ""chartmuseum/mychart"" (hint: running 'helm repo update' may help)

i don't really want to get into controlled semantic versioning at this point in development, or the mess that is appending hashes to a version. is there any way to get helm to pull non-semantically tagged chart versions?
",<kubernetes><kubernetes-helm>,51752953,1,"i found something that worked for me. since the semvar allows you to append values after the last number like 0.1.0-aebcaber, i've taken to simply using 0.1.0-latest and overwriting that in chartmuseum on uploads.
"
68944355,generating a kubeconfig file and authenticating for google cloud,"i have a kubernetes cluster. inside my cluster is a django application which needs to connect to my kubernetes cluster on gke. upon my django start up (inside my dockerfile), i authenticate with google cloud by using:
gcloud auth activate-service-account $gke_service_account_name --key-file=$google_application_credentials
gcloud config set project $gke_project_name
gcloud container clusters get-credentials $gke_cluster_name --zone $gke_zone

i am not really sure if i need to do this everytime my django container starts, and i am not sure i understand how authentication to google cloud works. could i perhaps just generate my kubeconfig file, store it somewhere safe and use it all the time instead of authenticating?
in other words, is a kubeconfig file enough to connect to my gke cluster?
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,68946857,1,"if your service is running in a pod inside the gke cluster you want to connect to, use a kubernetes service account to authenticate.

create a kubernetes service account and attach it to your pod. if your pod already has a kubernetes service account, you may skip this step.

use kubernetes rbac to grant the kubernetes service account the correct permissions.


the following example grants edit permissions in the prod namespace:
kubectl create rolebinding yourserviceaccount \
    --clusterrole=edit \
    --serviceaccount=yournamespace:yourserviceaccount\
    --namespace=prod


at runtime, when your service invokes kubectl, it automatically receives the credentials you configured.

you can also store the credentials as a secret and mount it on your pod so that it can read them from there
to use a secret with your workloads, you can specify environment variables that reference the secret's values, or mount a volume containing the secret.
you can create a secret using the command-line or a yaml file.
here is an example using command-line
kubectl create secret secret_type secret_name data

secret_type: the secret type, which can be one of the following:

generic:create a secret from a local file, directory, or literal value.
docker-registry:create a dockercfg secret for use with a docker registry. used to authenticate against docker registries.
tls:create a tls secret from the given public/private key pair. the public/private key pair must already exist. the public key certificate must be .pem encoded and match the given private key.

for most secrets, you use the generic type.
secret_name: the name of the secret you are creating.
data: the data to add to the secret, which can be one of the following:

a path to a directory containing one or more configuration files, indicated using the --from-file or --from-env-file flags.
key-value pairs, each specified using --from-literal flags.

if you need more information about kubectl create you can check the reference documentation
"
75428735,internal error when trying to access pgadmin via kubectl proxy,"i've installed pgadmin (https://artifacthub.io/packages/helm/runix/pgadmin4) in my k8s cluster. using port-forwarding i can access the web interface of pgadmin, but i want to use kubectl proxy instead of kubectl port-forward because when using port forwarding the connection is not stable enough (see the problems with lost connection to pod). so i hope kubectl proxy is more stable, but my problem is when i run kubectl proxy and try to access pgadmin, i'm getting the following error in my browser:
stream error: stream id 5; internal_error
i'm using the following url to access pgadmin: http://localhost:8001/api/v1/namespaces/default/services/pgadmin-pgadmin4:80/proxy. since the browser is already being redirected to http://localhost:8001/api/v1/namespaces/default/services/pgadmin-pgadmin4:80/proxy/login?next=%2f (not the last part), i know that pgadmin is working, but i've no idea how to solve the internal error issue. when i check the console that runs the kubectl proxy command, the output is the following:
starting to serve on 127.0.0.1:8001
e0212 17:56:51.338567   41088 proxy_server.go:147] error while proxying request: stream error: stream id 5; internal_error

any idea how to fix this issue? an alternative would be to have a stable port-forwarding, but it seems that there's only the &quot;while-true&quot;-solution to restart the port-forwarding whenever the connection to the pod has been lost.
",<kubernetes><proxy><kubectl><portforwarding>,75460539,1,"it seems that few filters / rules are obstructing your access to pgadmin from kubernettes cluster. this can be resolved by removing the filters. use the below command for connecting pgadmin without any filters.
kubectl proxy --address='0.0.0.0' --disable-filter=true

"
51114050,unable to run kubernetes (kubectl) and minikube on windows 10. unable to connect to the server: dial tcp [::1]:8080: connectex:,"here's the full error unable to connect to the server: dial tcp [::1]:8080: connectex: no connection could be made because the target machine actively refused it.

here's my kubectl config view

apiversion: v1
clusters: []
contexts:
- context:
    cluster: """"
    user: """"
  name: dev
current-context: dev
kind: config
preferences: {}
users: []


i'm running minikube start. it's stuck on starting vm...

in hyper-v manager, i have minikube vm running. 
",<kubernetes><kubectl><minikube>,51115564,2,"check out ""minikube on windows 10 with hyper-v"" by jock reed

the command to run, from a windows cmd console as administrator, is:

minikube start --vm-driver hyperv --hyperv-virtual-switch ""primary virtual switch""


with ""primary virtual switch"" being the name of the new ""external"" ""virtual network switch"" you have created first.

don't forget to turn off dynamic memory for the minikube vm (minikube issue 2326)

and possibly, disable ipv6  on network adapter windows 10 (issue 754

make sure to use the v0.28.0/minikube-windows-amd64 executable, as mentioned in issue 1943.
"
61383190,how to add rules to allow traffic on some port range for nodeport on aws eks?,"my exposed service on nodeport seems to not allow traffic through it.

so how to add rules to allow traffic for that port range on cli not on the console?

",<amazon-web-services><amazon-ec2><kubernetes><amazon-eks><aws-security-group>,61475242,3,"ec2 security groups

there is a security group on your screen.

see more about security groups:


ec2 security groups
creating a security group


cli for aws security groups

as for cli for working with aws security groups, see this article: creating, configuring, and deleting security groups for amazon ec2 - aws command line interface

$ aws ec2 create-security-group --group-name my-sg --description ""my security group"" --vpc-id vpc-1a2b3c4d
{
    ""groupid"": ""sg-903004f8""
}

$ aws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 3389 --cidr 203.0.113.0/24



  the following command adds another rule to enable ssh to instances in the same security group.


$ aws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 22 --cidr 203.0.113.0/24



  to view the changes to the security group, run the describe-security-groups command.


$ aws ec2 describe-security-groups --group-ids `sg-903004f8`


o/p is:

{
    ""securitygroups"": [
        {
            ""ippermissionsegress"": [
                {
                    ""ipprotocol"": ""-1"",
                    ""ipranges"": [
                        {
                            ""cidrip"": ""0.0.0.0/0""
                        }
                    ],
                    ""useridgrouppairs"": []
                }
            ],
            ""description"": ""my security group""
            ""ippermissions"": [
                {
                    ""toport"": 22,
                    ""ipprotocol"": ""tcp"",
                    ""ipranges"": [
                        {
                            ""cidrip"": ""203.0.113.0/24""
                        }
                    ]
                    ""useridgrouppairs"": [],
                    ""fromport"": 22
                }
            ],
            ""groupname"": ""my-sg"",
            ""ownerid"": ""123456789012"",
            ""groupid"": ""sg-903004f8""
        }
    ]
}


p.s. awless.io - a mighty cli for aws

there is also a bit outdated but still convenient cli tool: 
wallix/awless: a mighty cli for aws


  a mighty cli for aws http://awless.io/


here the medium post about it
"
69436490,update kubernetes service endpoint ip,"i uses a kubernetes application with a service that has a single endpoint. if using curl i retrieve it, i got something like this:
{
  &quot;kind&quot;: &quot;endpoints&quot;,
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
  ...
  &quot;subsets&quot;: [
    {
      &quot;addresses&quot;: [
        {
          &quot;ip&quot;: &quot;172.16.235.204&quot;
        }
      ],
      ...
    }
  ]

now under given circumstances, my application needs to change its ip with a curl patch. i am using the following code:
kube_service_dir=&quot;/var/run/secrets/kubernetes.io/serviceaccount&quot;
kube_token_filename=&quot;${kube_service_dir}/token&quot;
kube_ca_cert=&quot;${kube_service_dir}/ca.crt&quot;
kube_token=$(cat ${kube_token_filename})
body='[{&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;subsets/0/addresses/0/ip&quot;, &quot;value&quot;: &quot;172.16.140.18&quot;}]'
curl -xpatch --cacert ${kube_ca_cert} -h &quot;content-type: application/json-patch+json&quot; -h &quot;authorization: bearer ${kube_token}&quot; --data &quot;${body}&quot; &quot;https://${kubernetes_api_host}:${kubernetes_api_port}/api/v1/namespaces/cf-db/endpoints/cfdb-ccdb&quot;

as you can see my patch json is trying to apply a replace operation on this path subsets/0/addresses/0/ipsetting the new ip.
but when i run it i got:
{
  &quot;kind&quot;: &quot;status&quot;,
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    
  },
  &quot;status&quot;: &quot;failure&quot;,
  &quot;message&quot;: &quot;the server rejected our request due to an error in our request&quot;,
  &quot;reason&quot;: &quot;invalid&quot;,
  &quot;details&quot;: {
    
  },
  &quot;code&quot;: 422

can someone help me to figure out what's wrong with my code? i tried a lot of variations using also examples on stackoverflow but no luck.
",<kubernetes><kubernetes-apiserver>,69439297,1,"after a lot of tries and errors, i found the solution below.
a solution like this is used in patroni (but there is written in python) where the service has one endpoint that always references the master node. when a failover o switchover occurs the patroni code update the service endpoint. a code like this can be used whenever you have a statefulset and you always want to have the service reference the master node even in a failover scenario.
kube_service_dir=&quot;/var/run/secrets/kubernetes.io/serviceaccount&quot;
kube_token_filename=&quot;${kube_service_dir}/token&quot;
kube_ca_cert=&quot;${kube_service_dir}/ca.crt&quot;
kube_token=$(cat ${kube_token_filename})
kubernetes_api_host=${kubernetes_service_host}
kubernetes_api_port=${kubernetes_service_port}

generatepatchdata()
{
  local master_ip=$1
  local master_port=$2

  cat &lt;&lt;eof
{&quot;subsets&quot;: [{&quot;addresses&quot;: [{&quot;ip&quot;: &quot;$master_ip&quot;}], &quot;ports&quot;: [{&quot;name&quot;: &quot;postgresql&quot;, &quot;port&quot;: $master_port, &quot;protocol&quot;: &quot;tcp&quot;}]}]}
eof
}

patchendpointip() {
    local master_ip=$1
    local master_port=$2
    curl -xpatch --cacert ${kube_ca_cert} -h &quot;content-type: application/merge-patch+json&quot; -h &quot;authorization: bearer ${kube_token}&quot; &quot;https://${kubernetes_api_host}:${k
ubernetes_api_port}/api/v1/namespaces/cf-db/endpoints/cfdb-ccdb&quot; --data &quot;$(generatepatchdata $master_ip $master_port)&quot;
}

getendpointip() {
    curl -ssk -h &quot;authorization: bearer ${kube_token}&quot; &quot;https://${kubernetes_api_host}:${kubernetes_api_port}/api/v1/namespaces/cf-db/endpoints/cfdb-ccdb&quot;
}

patchendpointip &quot;172.16.140.13&quot; &quot;5431&quot;
getendpointip

"
58622284,can i combine storageclass with persistentvolume in gke?,"i'm fairly new to kubernetes and find it difficult to get it working from documentation, kubenetes docs says that storageclass contains the fields provisioner, parameters, and reclaimpolicy, which are used when a persistentvolume belonging to the class needs to be dynamically provisioned however can i use storageclass with pv(not dynamic allocation) to specify high performance disk allocation such as ssd?

without storageclass it worked fine for me.

following is my manifest

kind: persistentvolume
metadata:
  name: gke-pv
  labels:
    app: test
spec:
  capacity:
    storage: 10gi
  accessmodes:
    - readwriteonce
  gcepersistentdisk:
    pdname: gce-disk
    fstype: ext4
---
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: gke-pvc
  labels:
    app: test
spec:
  accessmodes:
    - readwriteonce
  storageclassname: ssd-sc 
  resources:
    requests:
      storage: 2gi
  selector:
    matchlabels:
      app: test

",<kubernetes><google-cloud-platform><storage><google-kubernetes-engine>,58627188,1,"the problem that is going on here is that if you want to statically provision persistentvolumes, they don't have a storageclass.  however, gke clusters are created with a standard storageclass which is the default, and so the pvc gets confused and tries to dynamically allocate.

the solution is to have the pvc request an empty storage class, which forces it to look at the statically provisioned pvs.

so you'd use a sequence like this to create a pv and then get it bound to a pvc:


manually provision the ssd:


gcloud compute disks create --size=10gi --zone=[your zone] --type=pd-ssd already-created-ssd-disk


then apply a pv object that uses the statically provisioned disk, like so:


apiversion: v1
kind: persistentvolume
metadata:
  name: ssd-for-k8s-volume
spec:
  capacity:
    storage: 10gi
  volumemode: filesystem
  accessmodes:
    - readwriteonce
  gcepersistentdisk:
    pdname: already-created-ssd-disk
    fstype: ext4



then, you can claim it with a pvc like this:


apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: pvc-ssd-demo
spec:
  storageclassname: """"
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 10gi


you could also use labels to refine which pvs are selected, of course, for example if you have some that are ssd and others that are regular spinning metal.

note that the idea of using a storageclass for static provisioning isn't really the right thing, since storageclass is tied to how you describe storage for dynamic provisioning.
"
63556649,deploy elk stack in kubernetes with helm volumebinding error,"i'm trying to deploy elk stack in kubernetes cluster with helm, using this chart. when i launch
helm install elk-stack stable/elastic-stack
i receive the following message:

name: elk-stack
last deployed: mon aug 24 07:30:31 2020
namespace: default
status: deployed
revision: 1
notes:
the elasticsearch cluster and associated extras have been installed.
kibana can be accessed:

  * within your cluster, at the following dns name at port 9200:

    elk-stack-elastic-stack.default.svc.cluster.local

  * from outside the cluster, run these commands in the same shell:

    export pod_name=$(kubectl get pods --namespace default -l ""app=elastic-stack,release=elk-stack"" -o jsonpath=""{.items[0].metadata.name}"")
    echo ""visit http://127.0.0.1:5601 to use kibana""
    kubectl port-forward --namespace default $pod_name 5601:5601

but when i run

kubectl get pods

the result is:

name                                              ready   status              restarts   age
elk-stack-elasticsearch-client-7fcfc7b858-5f7fw   0/1     running   0          12m
elk-stack-elasticsearch-client-7fcfc7b858-zdkwd   0/1     running   1          12m
elk-stack-elasticsearch-data-0                    0/1     pending   0          12m
elk-stack-elasticsearch-master-0                  0/1     pending   0          12m
elk-stack-kibana-cb7d9ccbf-msw95                  1/1     running   0          12m
elk-stack-logstash-0                              0/1     pending   0          12m

using kubectl describe pods command, i see that for elasticsearch pods the problem is:

 warning  failedscheduling  6m29s      default-scheduler  running ""volumebinding"" filter plugin for pod ""elk-stack-elasticsearch-data-0"": pod has unbound immediate persistentvolumeclaims

and for logstash pods:

warning  failedscheduling  7m53s      default-scheduler  running ""volumebinding"" filter plugin for pod ""elk-stack-logstash-0"": pod has unbound immediate persistentvolumeclaims

output of kubectl get pv,pvc,sc -a:

name                                      capacity   access modes   reclaim policy   status        claim                           storageclass   reason   age
persistentvolume/elasticsearch-data       10gi       rwo            retain           bound         default/elasticsearch-data      manual                  16d

namespace      name                                                                status    volume                   capacity   access modes   storageclass   age
default        persistentvolumeclaim/claim1                                        pending                                                      slow           64m
default        persistentvolumeclaim/data-elk-stack-elasticsearch-data-0           pending                                                                     120m
default        persistentvolumeclaim/data-elk-stack-elasticsearch-master-0         pending                                                                     120m
default        persistentvolumeclaim/data-elk-stack-logstash-0                     pending                                                                     120m
default        persistentvolumeclaim/elasticsearch-data                            bound     elasticsearch-data       10gi       rwo            manual         16d
default        persistentvolumeclaim/elasticsearch-data-elasticsearch-data-0       pending                                                                     17d
default        persistentvolumeclaim/elasticsearch-data-elasticsearch-data-1       pending                                                                     17d
default        persistentvolumeclaim/elasticsearch-data-quickstart-es-default-0    pending                                                                     16d
default        persistentvolumeclaim/elasticsearch-master-elasticsearch-master-0   pending                                                                     17d
default        persistentvolumeclaim/elasticsearch-master-elasticsearch-master-1   pending                                                                     17d
default        persistentvolumeclaim/elasticsearch-master-elasticsearch-master-2   pending                                                                     16d

namespace   name                                         provisioner            reclaimpolicy   volumebindingmode   allowvolumeexpansion   age
            storageclass.storage.k8s.io/slow (default)   kubernetes.io/gce-pd   delete          immediate           false                  66m


storage class slow and persistent volume claim claim1 are my experiments. i create they using kubectl create and a yaml file, the others is automatically created by helm (i think).
output of kubectl get pvc data-elk-stack-elasticsearch-master-0 -o yaml:

apiversion: v1
kind: persistentvolumeclaim
metadata:
  creationtimestamp: ""2020-08-24t07:30:38z""
  finalizers:
  - kubernetes.io/pvc-protection
  labels:
    app: elasticsearch
    release: elk-stack
  managedfields:
  - apiversion: v1
    fieldstype: fieldsv1
    fieldsv1:
      f:metadata:
        f:labels:
          .: {}
          f:app: {}
          f:release: {}
      f:spec:
        f:accessmodes: {}
        f:resources:
          f:requests:
            .: {}
            f:storage: {}
        f:volumemode: {}
      f:status:
        f:phase: {}
    manager: kube-controller-manager
    operation: update
    time: ""2020-08-24t07:30:38z""
  name: data-elk-stack-elasticsearch-master-0
  namespace: default
  resourceversion: ""201123""
  selflink: /api/v1/namespaces/default/persistentvolumeclaims/data-elk-stack-elasticsearch-master-0
  uid: de58f769-f9a7-41ad-a449-ef16d4b72bc6
spec:
  accessmodes:
  - readwriteonce
  resources:
    requests:
      storage: 4gi
  volumemode: filesystem
status:
  phase: pending

can somebody please help me to fix this problem? thanks in advance.
",<elasticsearch><kubernetes><kubernetes-helm>,63562137,2,"the reason why pod is pending is below pvcs are pending because corresponding pvs are not created.
data-elk-stack-elasticsearch-master-0
data-elk-stack-logstash-0
data-elk-stack-elasticsearch-data-0

since you have mentioned this is for local development you can use hostpath volume for the pv. so create pv for each of the pending pvcs using the sample pv below. so you will create 3 pvs in total.
apiversion: v1
kind: persistentvolume
metadata:
  name: elk-master
  labels:
    type: local
spec:
  capacity:
    storage: 4gi
  accessmodes:
    - readwriteonce
  hostpath:
    path: &quot;/mnt/data&quot;
---
apiversion: v1
kind: persistentvolume
metadata:
  name: elk-logstash
  labels:
    type: local
spec:
  capacity:
    storage: 2gi
  accessmodes:
    - readwriteonce
  hostpath:
    path: &quot;/mnt/data&quot;
---
apiversion: v1
kind: persistentvolume
metadata:
  name: elk-data
  labels:
    type: local
spec:
  capacity:
    storage: 30gi
  accessmodes:
    - readwriteonce
  hostpath:
    path: &quot;/mnt/data&quot;

"
66527084,why ingress rules are not followed? default backend is reached instead,"i have ha proxy ingress installed on kubernetes aks. i installed it using:
helm install ingress haproxy-ingress/haproxy-ingress

my ingress is this:
apiversion: networking.k8s.io/v1beta1
kind: ingress  
metadata:
  name: ravendb
  namespace: default
  labels:
    app: ravendb
  annotations:
    ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;
spec:
  rules:
  - host: a.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-0
          serviceport: 443
        path: /
  - host: tcp-a.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-0
          serviceport: 38888
        path: /
  - host: b.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-1
          serviceport: 443
        path: /
  - host: tcp-b.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-1
          serviceport: 38888
        path: /
  - host: c.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-2
          serviceport: 443
        path: /
  - host: tcp-c.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-2
          serviceport: 38888
        path: /

however when i point my browser to https://a.raven.aedas-prev.inercya.com i get the default backend. ha proxy doesn't reverse proxy the request to ravendb-0 service.
what i'm doing wrong? what can i do to make the ingress work?
pods are running:
haproxy-ingress-8548ff5ff4-9wmxv            1/1     running            0          137m
ingress-default-backend-b6f678779-9d88r     1/1     running            0          137m
ravendb-0                                   1/1     running            0          137m
ravendb-1                                   1/1     running            0          139m
ravendb-2                                   1/1     running            0          141m

and services are configured:
name                       type           cluster-ip     external-ip      port(s)                        age
haproxy-ingress            loadbalancer   10.0.166.252   xx.xx.xx.xx    443:30526/tcp,1936:32388/tcp   139m
ingress-default-backend    clusterip      10.0.102.165   &lt;none&gt;           8080/tcp                       139m
kubernetes                 clusterip      10.0.0.1       &lt;none&gt;           443/tcp                        412d
ravendb                    clusterip      none           &lt;none&gt;           443/tcp,38888/tcp,161/tcp      411d
ravendb-0                  clusterip      10.0.193.14    &lt;none&gt;           443/tcp,38888/tcp,161/tcp      411d
ravendb-1                  clusterip      10.0.156.73    &lt;none&gt;           443/tcp,38888/tcp,161/tcp      411d
ravendb-2                  clusterip      10.0.53.227    &lt;none&gt;           443/tcp,38888/tcp,161/tcp      411d

",<kubernetes><ravendb><kubernetes-ingress><azure-aks><haproxy-ingress>,66529942,2,"i finally figured out what i was missing. i added kubernetes.io/ingress.class: haproxy annotation and problem solved:
apiversion: networking.k8s.io/v1beta1
kind: ingress  
metadata:
  name: ravendb
  namespace: default
  labels:
    app: ravendb
  annotations:
    ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;
    kubernetes.io/ingress.class: haproxy
spec:
  rules:
  - host: a.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-0
          serviceport: 443
        path: /
  - host: tcp-a.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-0
          serviceport: 38888
        path: /
  - host: b.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-1
          serviceport: 443
        path: /
  - host: tcp-b.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-1
          serviceport: 38888
        path: /
  - host: c.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-2
          serviceport: 443
        path: /
  - host: tcp-c.raven.aedas-prev.inercya.com
    http:
      paths:
      - backend:
          servicename: ravendb-2
          serviceport: 38888
        path: /

now haproxy ingress works as expected, reverse proxying external traffic to internal services.
"
55866411,nginx.ingress.kubernetes.io/use-regex not working as expected,"i have the following ingress section:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: tb-ingress
  namespace: thingsboard
  annotations:
    nginx.ingress.kubernetes.io/use-regex: ""true""
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/proxy-read-timeout: ""3600""
spec:
  rules:
  - http:
      paths:
      - path: /api/v1/.*
        backend:
          servicename: tb-http-transport
          serviceport: http
      - path: /static/rulenode/.*
        backend:
          servicename: tb-node
          serviceport: http
      - path: /static/.*
        backend:
          servicename: tb-web-ui
          serviceport: http
      - path: /index.html.*
        backend:
          servicename: tb-web-ui
          serviceport: http
      - path: /
        backend:
          servicename: tb-web-ui
          serviceport: http


however, this does not seem to be working. gke gives me an 


  invalid path pattern, invalid


error.
",<kubernetes><google-kubernetes-engine>,55867869,4,"it seems to me, you forgot to specify kubernetes.io/ingress.class: ""nginx"" annotation. if you don't specify any kubernetes.io/ingress.class - gke will consider using its own ingress which does not support regexps.
"
55503893,helm patch default service account,"i have a helm chart that i use to add a list of users to my cluster, but i would like to modify my default service account to include an image pull secret. there doesn't seem to be any patch functionality in helm.

is a post-install hook the best i can do?
",<kubernetes><kubernetes-helm>,55789723,4,"i had the same issue. what i did is:

apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  name: default
  namespace: your_namespace
rules:
- apigroups:
  - """"
  resources:
  - serviceaccounts
  verbs:
  - get
---
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: default
  namespace: your_namespace
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: default
subjects:
- kind: serviceaccount
  name: default
  namespace: your_namespace


and then:

apiversion: batch/v1
kind: job
metadata:
  name: create-image-pull-secret
  annotations:
    ""helm.sh/hook"": pre-install
    ""helm.sh/hook-delete-policy"": hook-succeeded
spec:
  template:
    spec:
      restartpolicy: never
      containers:
      - name: k8s
        image: google/cloud-sdk
        imagepullpolicy: ifnotpresent
        command: [""/bin/sh"",""-c"", ""kubectl patch serviceaccount default -p '{\""imagepullsecrets\"": [{\""name\"": \""your_secret_name\""}]}'""]


note that i use a pre-install hook. i did that because i needed the imagepullsecret working for my child dependencies. also, the patch command allowed to use a secret name that doesn't exist yet.
"
52730163,helm chart passing multiple environment values for single key,"i am new to helm charts and i am trying to pass some environment variables to schema-registry 

values.yaml 

replicacount: 1

image:
  repository: confluentinc/cp-schema-registry
  tag: 5.0.0
  pullpolicy: ifnotpresent
  env:
    - name: ""schema_registry_kafkastore_bootstrap_servers""
      value: ""plaintext://xx.xxx.xx.x:9092,plaintext://xx.xxx.xx.x:9092,plaintext://xx.xxx.xx.x:9092""
    - name: ""schema_registry_listeners""
      value: ""http://0.0.0.0:8083""


but these environment variables are not passed to the pod. 

i tried passing as part of install command, but it failed because i cannot pass multiple values, can anyone please let me know how you have passed your multiple environment variables

ubuntu@ip-10-xx-x-xx:~/helm-test$ helm install helm-test-0.1.0.tgz --set schema_registry_kafkastore_bootstrap_servers=plaintext://xx.xxx.xx.xx:9092,plaintext://xx.xxx.xx.xx:9092,plaintext://xx.xxx.xx.xx:9092,schema_registry_listeners=http://0.0.0.0:8083
error: failed parsing --set data: key ""97:9092"" has no value (cannot end with ,)




after trying to pass the environment values both inside the values.yaml file and also as install command

replicacount: 1

image:
  repository: confluentinc/cp-schema-registry
  tag: 5.0.0
  pullpolicy: ifnotpresent
  env:
    - name:
       schema_registry_kafkastore_bootstrap_servers: ""plaintext://10.xxx.x.xx:9092,plaintext://10.xxx.x.xx:9092,plaintext://10.xxx.x.xx.xxx:9092""
       schema_registry_listeners: ""http://0.0.0.0:8083""


helm install helm-test-0.1.0.tgz --set env.name.schema_registry_kafkastore_bootstrap_servers=""plaintext://10.xx.x.xx:9092\,plaintext://10.xx.x.xx:9092\,plaintext://10.xx.x.xx:9092"", --set env.nameschema_registry_listeners=""http://0.0.0.0:8083""


i escaped the commas since it was throwing an error 
error: failed parsing --set data: key ""xxx:9092"" has no value (cannot end with ,)

i see that my environment values does not show when i try to describe a deployment.

kubectl describe deployment/crusty-aardwolf-helm-test
name:                   crusty-aardwolf-helm-test
namespace:              default
creationtimestamp:      wed, 10 oct 2018 14:23:37 +0000
labels:                 app.kubernetes.io/instance=crusty-aardwolf
                        app.kubernetes.io/managed-by=tiller
                        app.kubernetes.io/name=helm-test
                        helm.sh/chart=helm-test-0.1.0
annotations:            deployment.kubernetes.io/revision=1
selector:               app.kubernetes.io/instance=crusty-aardwolf,app.kubernetes.io/name=helm-test
replicas:               1 desired | 1 updated | 1 total | 0 available | 1 unavailable
strategytype:           rollingupdate
minreadyseconds:        0
rollingupdatestrategy:  25% max unavailable, 25% max surge
pod template:
  labels:  app.kubernetes.io/instance=crusty-aardwolf
           app.kubernetes.io/name=helm-test
  containers:
   helm-test:
    image:        confluentinc/cp-schema-registry:5.0.0
    port:         80/tcp
    host port:    0/tcp
    liveness:     http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    readiness:    http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    environment:  &lt;none&gt;


why are my environment values not passed to my container? can someone please point me in right direction.
",<kubernetes><kubectl><kubernetes-helm>,52730743,7,"the values.yaml is more for actual values. you can use go template substitutions if you'd like to but it's less common. (these substitutions get used later in a template)

when you specify --set in for example helm install --set foo=bar foo will be overridden by bar in the values.yaml file. what you may really want is something like this:

...
env:
  name:
    schema_registry_kafkastore_bootstrap_servers: ""plaintext://xx.xxx.xx.x:9092,plaintext://xx.xxx.xx.x:9092,plaintext://xx.xxx.xx.x:9092""
    schema_registry_listeners: ""http://0.0.0.0:8083""


and then on the helm install command line:

helm install helm-test-0.1.0.tgz --set env.name.schema_registry_kafkastore_bootstrap_servers=""plaintext://xx.xxx.xx.xx:9092,plaintext://xx.xxx.xx.xx:9092,plaintext://xx.xxx.xx.xx:9092"" --set env.nameschema_registry_listeners=""http://0.0.0.0:8083""


more information on how to set the values here.
"
57969331,hpa implementation on single node kubernetes cluster,"i am running kubernetes cluster on gke. running the monolithic application and now migrating to microservices so both are running parallel on cluster.

a monolithic application is simple python app taking the memory of 200mb around.

k8s cluster is simple single node cluster gke having 15gb memory and 4vcpu.

now i am thinking to apply the hpa for my microservices and monolithic application.

on single node i have also installed graylog stack which include (elasticsearch, mongodb, graylog pod). sperated by namespace devops.

in another namespace monitoring there is grafana, prometheus, alert manager running. 

there is also ingress controller and cert-manager running.

now in default namespace there is another elasticsearch for application use, redis, rabbitmq running. these all are single pod, type statefulsets or deployment with volume.

now i am thinking to apply the hpa for microservices and application. 

can someone suggest how to add node-pool on gke and auto scale. when i added node in pool and deleted old node from gcp console whole cluster restarted and service goes down for while.

plus i am thinking to use the affinity/anti-affinity so can someone suggest devide infrastructure and implement hpa.
",<docker><elasticsearch><kubernetes><google-cloud-platform><google-kubernetes-engine>,57973262,1,"from the wording in your question, i suspect that you want to move your current workloads to the new pool without disruption.

since this action represents a voluntary disruption, you can start by defining a poddisruptionbudget to control the number of pods that can be evicted in this voluntary disruption operation:


  a pdb limits the number of pods of a replicated application that are down simultaneously from voluntary disruptions.


the settings in the pdb depend on your application and your business needs, for a reference on the values to apply, you can check this.

following this, you can drain the nodes where your application is scheduled since it will be ""protected"" by the budget and, drain uses the eviction api instead of directly deleting the pods, which should make evictions graceful.

regarding affinity, i'm not sure how it fits in the beforementioned goal that you're trying to achieve. however, there is an answer of this particular regard in the comments.
"
51739659,how do i push a docker image in virtual box to google repository?,"i have a virtualbox development:

$docker-machine ls

name          active   driver     state        url             swarm  docker errors
development    -     virtualbox  running  tcp://*.*.*.*:****  v18.05.0-ce   


inside development i have this:

$docker images
repository            tag      image id         created         size
busybox              latest   e1ddd7948a1c      1 day ago      1.16mb
pritam/play-docker   latest   34eb2664f14e      1 day ago      1.4gb


now i want to push this image inside virtual box to google repository. how do i that? 
",<docker><kubernetes><dockerfile><google-kubernetes-engine><kubernetes-ingress>,51936329,1,"you can use docker push command 

docker push imagetagname



  http://docs.docker.com/engine/reference/commandline/push


for your own registry you can use

 docker push registry.example.com/image 



  http://blog.docker.com/2013/07/how-to-use-your-own-registry.


and for google container registry reference:


  http://cloud.google.com/container-registry/docs/pushing-and-pulling


docker [push/pull] gcr.io/{project_id}/{image}:tag 


for authentication you can check google container registry reference


  https://medium.com/google-cloud/using-googles-private-container-registry-with-docker-1b470cf3f50a


after you get google auth keys as json format (key.json)

docker login -u _json_key -p “$(cat key.json)”


after login success you can push your image 

 docker push gcr.io/project_id/imagename:tag

"
61500755,call to kubernetes service failed,"kubernetes version: 1.5.2
os: centos 7
etcd version: 3.4.0  

first, i create an etcd pod, the etcd dockerfile and etcd pod yaml file like this:
etcd dockerfile:

from alpine

copy . /usr/bin
workdir /usr/bin

cmd etcd --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://0.0.0.0:2379

expose 2379


pod yaml file

apiversion: v1
kind: pod
metadata:
  name: etcd
  namespace: storageplatform
  labels:
    app: etcd
spec:
  containers:
    - name: etcd
      image: ""karldoenitz/etcd:3.4.0""
      ports:
        - containerport: 2379
          hostport: 12379


after created the docker image and push to dockerhub, i run the command kubectl apply -f etcd.yaml to create the etcd pod.
the ip of etcd pod is 10.254.140.117, i ran the command use etcdctl_api=3 etcdctl --endpoints=175.24.47.64:12379 put 1 1 and got ok.
my service yaml:  

apiversion: v1
kind: service
metadata:
  name: storageservice
  namespace: storageplatform
spec:
  type: nodeport
  ports:
    - port: 12379
      targetport: 12379
      nodeport: 32379
  selector:
    app: etcd


apply the yaml file to create the service.run the command kubectl get services -n storageplatform, i got these infomation.  

namespace         name                   cluster-ip       external-ip   port(s)           age
storageplatform   storageservice         10.254.140.117   &lt;nodes&gt;       12379:32379/tcp   51s


after all, i run the command 

etcdctl_api=3 etcdctl --endpoints=10.254.140.117:32379 get 1


or

etcdctl_api=3 etcdctl --endpoints={host-ip}:32379 get 1


i got error: context deadline exceeded.

what's the matter? how to make the service useful?
",<kubernetes><kubernetes-pod><kubernetes-service>,61503473,1,"change the service to refer to containerport instead of hostport

apiversion: v1
kind: service
metadata:
  name: storageservice
  namespace: storageplatform
spec:
  type: nodeport
  ports:
    - port: 2379
      targetport: 2379
      nodeport: 32379
  selector:
    app: etcd

"
69991507,how to trigger tekton pipeline from gitlab ci directly with predefined gitlab ci variables & tekton logs streamed into gitlab pipeline logs,"we have a aws eks running (setup using pulumi), where we installed tekton as described in the cloud native buildpacks tekton docs. the example project is available.
our tekton pipeline is configured like this (which is derived from the cloud native buildpacks tekton docs also):
apiversion: tekton.dev/v1beta1
kind: pipeline
metadata:
  name: buildpacks-test-pipeline
spec:
  params:
    - name: image
      type: string
      description: image url to push
    - name: source_url
      type: string
      description: a git repo url where the source code resides.
    - name: source_revision
      description: the branch, tag or sha to checkout.
      default: &quot;&quot;
  workspaces:
    - name: source-workspace # directory where application source is located. (required)
    - name: cache-workspace # directory where cache is stored (optional)
  tasks:
    - name: fetch-repository # this task fetches a repository from github, using the `git-clone` task you installed
      taskref:
        name: git-clone
      workspaces:
        - name: output
          workspace: source-workspace
      params:
        - name: url
          value: &quot;$(params.source_url)&quot;
        - name: revision
          value: &quot;$(params.source_revision)&quot;
        - name: subdirectory
          value: &quot;&quot;
        - name: deleteexisting
          value: &quot;true&quot;
    - name: buildpacks # this task uses the `buildpacks` task to build the application
      taskref:
        name: buildpacks
      runafter:
        - fetch-repository
      workspaces:
        - name: source
          workspace: source-workspace
        - name: cache
          workspace: cache-workspace
      params:
        - name: app_image
          value: &quot;$(params.image)&quot;
        - name: builder_image
          value: paketobuildpacks/builder:base # this is the builder we want the task to use (required)

we added source_url and source_revision as parameters already.
the question is: how can we trigger a tekton pipelinerun from gitlab ci (inside our .gitlab-ci.yml) adhering to the following requirements:

simplest possible approach
do not use the extra complexity introduced by tekton triggers (incl. commit-status-tracker) but still keep gitlab as the source of truth (e.g. see green/red pipeline runs on commits etc.)
report successfully run tekton pipelines as green gitlab ci pipelines &amp; failed tekton pipelines as red gitlab ci pipelines
preserve/stream the tekton pipeline logs into gitlab ci pipeline logs - both in case of errors or success inside the tekton pipelines
use gitlab ci predefined variables for a generic approach

",<kubernetes><gitlab><gitlab-ci><amazon-eks><tekton>,69991508,7,"tldr;
i created a fully comprehensible example project showing all necessary steps and running pipelines here: https://gitlab.com/jonashackt/microservice-api-spring-boot/ with the full .gitlab-ci.yml to directly trigger a tekton pipeline:
image: registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0

variables:
  aws_default_region: 'eu-central-1'

before_script:
  - mkdir ~/.kube
  - echo &quot;$ekskubeconfig&quot; &gt; ~/.kube/config
  - echo &quot;--- testdrive connection to cluster&quot;
  - kubectl get nodes

stages:
  - build

build-image:
  stage: build
  script:
    - echo &quot;--- create parameterized tekton pipelinerun yaml&quot;
    - tkn pipeline start buildpacks-test-pipeline
      --serviceaccount buildpacks-service-account-gitlab
      --workspace name=source-workspace,subpath=source,claimname=buildpacks-source-pvc
      --workspace name=cache-workspace,subpath=cache,claimname=buildpacks-source-pvc
      --param image=$ci_registry_image
      --param source_url=$ci_project_url
      --param source_revision=$ci_commit_ref_slug
      --dry-run
      --output yaml &gt; pipelinerun.yml

    - echo &quot;--- trigger pipelinerun in tekton / k8s&quot;
    - pipeline_run_name=$(kubectl create -f pipelinerun.yml --output=jsonpath='{.metadata.name}')

    - echo &quot;--- show tekton pipelinerun logs&quot;
    - tkn pipelinerun logs $pipeline_run_name --follow

    - echo &quot;--- check if tekton pipelinerun failed &amp; exit gitlab pipeline accordingly&quot;
    - kubectl get pipelineruns $pipeline_run_name --output=jsonpath='{.status.conditions[*].reason}' | grep failed &amp;&amp; exit 1 || exit 0

here are the brief steps you need to do:
1. choose a base image for your .gitlab-ci.yml providing aws cli, kubectl and tekton cli (tkn)
this is entirely up to you. i created an example project https://gitlab.com/jonashackt/aws-kubectl-tkn which provides an image, which is based on the official https://hub.docker.com/r/amazon/aws-cli image and is accessible via registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0.
2. ci/cd variables for aws cli &amp; kubernetes cluster access
inside your gitlab ci project (or better: inside the group, where your gitlab ci project resides in) you need to create aws_access_key_id, aws_secret_access_key as ci/cd variables holding the the aws cli credentials (beware to mask them while creating them in order to prevent them beeing printed into the gitlab ci logs). depending on your eks clusters (or other k8s clusters) config, you need to provide a kubeconfig to access your cluster. one way is to create a gitlab ci/cd variable like ekskubeconfig providing the necessary file (e.g. in the example project this is provided by pulumi with pulumi stack output kubeconfig &gt; kubeconfig). in this setup using pulumi there are no secret credentials inside the kubeconfig so the variable doesn't need to be masked. but be aware of possible credentials here and protect them accordingly if needed.

also define aws_default_region containing your eks cluster's region:
# as we need kubectl, aws &amp; tkn cli we use https://gitlab.com/jonashackt/aws-kubectl-tkn
image: registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0

variables:
  aws_default_region: 'eu-central-1'

3. use kubeconfig and testdrive cluster connection in before_script section
preparing things we need later inside other steps could be done inside the before_script section. so let's create the directory ~/.kube there and create the file ~/.kube/config from the contents of the variable ekskubeconfig. finally fire a kubectl get nodes to check if the cluster connection is working. our before_script section now looks like this:
before_script:
  - mkdir ~/.kube
  - echo &quot;$ekskubeconfig&quot; &gt; ~/.kube/config
  - echo &quot;--- testdrive connection to cluster&quot;
  - kubectl get nodes

4. pass parameters to tekton pipelinerun
passing parameters via kubectl isn't trivial - or even needs to be done using a templating engine like helm. but luckily the tekton cli has something for us: tkn pipeline start accepts parameters. so we can transform the cloud native buildpacks tekton pipelinerun yaml file into a tkn cli command like this:
tkn pipeline start buildpacks-test-pipeline \
    --serviceaccount buildpacks-service-account-gitlab \
    --workspace name=source-workspace,subpath=source,claimname=buildpacks-source-pvc \
    --workspace name=cache-workspace,subpath=cache,claimname=buildpacks-source-pvc \
    --param image=registry.gitlab.com/jonashackt/microservice-api-spring-boot \
    --param source_url=https://gitlab.com/jonashackt/microservice-api-spring-boot \
    --param source_revision=main \
    --timeout 240s \
    --showlog

now here are some points to consider. first the name buildpacks-test-pipeline right after the tkn pipeline start works as an equivalent to the yaml files spec: pipelineref: name: buildpacks-test-pipeline definition.
it will also work as a reference to the pipeline object defined inside the file pipeline.yml which starts with metadata: name: buildpacks-test-pipeline like:
apiversion: tekton.dev/v1beta1
kind: pipeline
metadata:
name: buildpacks-test-pipeline
...
second to define workspaces isn't trivial. luckily there's help. we can define a workspace in tkn cli like this: --workspace name=source-workspace,subpath=source,claimname=buildpacks-source-pvc.
third using the parameters as intended now becomes easy. simply use --param accordingly. we also use --showlog to directly stream the tekton logs into the commandline (or gitlab ci!) together with --timeout.
finally using gitlab ci predefined variables our .gitlab-ci.yml's build stage looks like this:
build-image:
  stage: build
  script:
    - echo &quot;--- run tekton pipeline&quot;
    - tkn pipeline start buildpacks-test-pipeline
      --serviceaccount buildpacks-service-account-gitlab
      --workspace name=source-workspace,subpath=source,claimname=buildpacks-source-pvc
      --workspace name=cache-workspace,subpath=cache,claimname=buildpacks-source-pvc
      --param image=$ci_registry_image
      --param source_url=$ci_project_url
      --param source_revision=$ci_commit_ref_slug
      --timeout 240s
      --showlog

5. solve the every gitlab ci pipeline is green problem
this could have been everything we need to do. but: right now every gitlab ci pipeline is green, regardless of the tekton pipeline's status.
therefore we remove --showlog and --timeout again, but add a --dry-run together with the --output yaml flags. without the --dry-run the tkn pipeline start command would create a pipelinerun object definition already, which we can't create then using kubectl anymore:
build-image:
  stage: build
  script:
    - echo &quot;--- create parameterized tekton pipelinerun yaml&quot;
    - tkn pipeline start buildpacks-test-pipeline
      --serviceaccount buildpacks-service-account-gitlab
      --workspace name=source-workspace,subpath=source,claimname=buildpacks-source-pvc
      --workspace name=cache-workspace,subpath=cache,claimname=buildpacks-source-pvc
      --param image=$ci_registry_image
      --param source_url=$ci_project_url
      --param source_revision=$ci_commit_ref_slug
      --dry-run
      --output yaml &gt; pipelinerun.yml

now that we removed --showlog and don't start an actual tekton pipeline using tkn cli, we need to create the pipeline run using:
- pipeline_run_name=$(kubectl create -f pipelinerun.yml --output=jsonpath='{.metadata.name}')

having the temporary variable pipeline_run_name available containing the exact pipeline run id, we can stream the tekton pipeline logs into our gitlab ci log again:
- tkn pipelinerun logs $pipeline_run_name --follow

finally we need to check for tekton pipeline run's status and exit our gitlab ci pipeline accordingly in order to prevent red tekton pipelines resulting in green gitlab ci pipelines. therefore let's check the status of the tekton pipeline run first. this can be achieved using --output=jsonpath='{.status.conditions[*].reason}' together with a kubectl get pipelineruns:
kubectl get pipelineruns $pipeline_run_name --output=jsonpath='{.status.conditions[*].reason}'

then we pipe the result into a grep which checks, if failed is inside the status.condiditons.reason field.
finally we use a bash onliner (which is &lt;expression to check true or false&gt; &amp;&amp; command when true || command when false) to issue the suitable exit command (see https://askubuntu.com/a/892605):
- kubectl get pipelineruns $pipeline_run_name --output=jsonpath='{.status.conditions[*].reason}' | grep failed &amp;&amp; exit 1 || exit 0

now every gitlab ci pipeline becomes green, when the tekton pipeline succeeded - and gets red when the tekton pipeline failed. the example project has some logs if you're interested. it's pretty cool to see the tekton logs inside the gitlab ci logs:

"
70145472,getting connection refused while trying to access service from kubernetes pod,"i am new to kubernetes and i am trying to learn it by deploying a simple node server using aws eks. (kubernetes is alreay setup to talk to the created aws eks cluster)
here is code for my simple node file (server.js)
const express = require('express')
const app = express()
const port = 8080

app.get('/', (req, res) =&gt; {
 res.send('hello world!')
})

app.listen(port, () =&gt; {
console.log(`example app listening at http://localhost:${port}`)
})

here is how the dockerfile looks like:
from node:12
# create app directory
workdir /usr/src/app
# install app dependencies
copy package*.json ./
run npm ci
# bundle app source
copy . .
expose 8080
cmd [ &quot;node&quot;, &quot;server.js&quot; ]

i am able to run the above server in my local by creating a docker image.
now, in order to deploy this server here are the steps that i followed: 
first, i pushed the above image to doceker hub (aroraankit7/simple-server)
second, i created a deployment.yaml file which looks like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: simple-server-app
  labels:
    app: simple-server-app
spec:
  replicas: 2
  selector:
    matchlabels:
      app: simple-server-app
   template:
     metadata:
       labels:
         app: simple-server-app
     spec:
       containers:
       - name: simple-server
         image: aroraankit7/simple-server:v1
         ports:
         - containerport: 8080

third, i deployed this using kubectl apply command. here is the output for kubectl get pods

then, i created the service.yaml file. here is how it looks:
apiversion: v1
kind: service
metadata:
name: simple-server-svc
labels:
  run: simple-server
spec:
  ports:
  - port: 8080
    targetport: 8080
    protocol: tcp
  selector:
    run: simple-server

i then deployed this using the kubectl apply command. output for kubectl describe services:

next, i logged into on of my pods by using the command: kubectl -it exec simple-server-app-758dfb88f4-4cfmp bash
while inside this pod, i ran the following the command: curl http://simple-server-svc:8080 and this was the output that i got: curl: (7) failed to connect to simple-server-svc port 8080: connection refused
why is the connection getting refused?
when i am running curl http:localhost://8080, i am getting the right output (hello world! in this case)
",<node.js><docker><kubernetes><amazon-eks><kubernetes-pod>,70145832,1,"your service is not bound to the deployment. you need to modify the selector in your service.yaml to the following:
apiversion: v1
kind: service
metadata:
 name: simple-server-svc
 labels:
  run: simple-server
spec:
  ports:
  - port: 8080
    targetport: 8080
    protocol: tcp
  selector:
    app: simple-server-app

you can use kubectl expose command to avoid mistakes like this.
"
56035913,how can i safely change resturl for glusterfs storage class on my kubernetes cluster?,"heketi pod was restarted on our kubernetes cluster and now i'm struggling with how to change glusterfs storage class resturl with new heketi endpoint.
what are the safest options without any data loss on our pvcs?
i was able to recreate kubernetes cluster v1.11.10 on our test environment and start investigating on it. when i tried to edit storage class i got:

""storageclass.storage.k8s.io ""glusterfs"" is invalid: parameters forbidden: updates to parameters are forbidden.""


we are using kubernetes v.1.11.10.
i tried to create new storage class with correct heketi endpoint, but i couldn't edit pvcs:

persistentvolumeclaim ""test-pvc"" is invalid: spec: forbidden: is immutable after creation except resources.requests for bound claims 


i was able only to delete old storage class and create new with correct heketi resturl.
",<kubernetes><glusterfs><kubernetes-pvc>,56036232,6,"you may try to use ""kubectl replace"" like that:

kubectl replace -f storage-class.yaml --force 


just make sure that you use heketi service name as a rest url to avoid further such issues.
"
76814834,logback file with kubernetes,"i have a microservice application based on springboot and deployed on kubernetes with helm chart.
i'd like to continue to use the logback file we used previously to write the application logs in a formatted way.
this is my logback.xml file we used in:
&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;configuration scan=&quot;true&quot; scanperiod=&quot;10 seconds&quot; debug=&quot;true&quot;&gt;
    &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt;
    &lt;logger name=&quot;org.springframework.web&quot; level=&quot;info&quot;/&gt;
    &lt;logger name=&quot;com.netflix&quot; level=&quot;warn&quot;/&gt;
&lt;/configuration&gt;

this is my configmap.xml:
apiversion: v1
kind: configmap
metadata:
  name: {{ .values.app.name }}-configmap
  namespace: {{ .values.namespace }}
data:
  application.yml : |+
    server:
      ssl:
        enabled: false

i don't know how to add it.
",<spring-boot><kubernetes><logging><kubernetes-helm><logback>,76814951,1,"you need to add the logback.xml file to the root folder of the helm chart template.
this is the structure of the folder:
├── app-root
│   ├── logback.xml
│   ├── values
│   ├── template
│       ├── configmap.xml
│       ├── deployment.xml
│       ├── ...

then, add in the configmap.yml file the import of that file:
apiversion: v1
kind: configmap
metadata:
  name: {{ .values.app.name }}-configmap
  namespace: {{ .values.namespace }}
data:
  application.yml : |+
    server:
      ssl:
        enabled: false
  logback.xml : |+
{{ .files.get &quot;base-logback.xml&quot; | indent 4 }}

"
72087720,kubernetes service account token ignored in jupyter,"i am spinning up a new jupyter notebook instance from jupiter hub and wish to have kubernetes api access from inside the spun up container. according to the docs, i added the parameter for service account in my helm values and as expected, i can see the service account token mounted as expected.
subu@jupyter-subu:~$ sudo ls /run/secrets/kubernetes.io/serviceaccount/
ca.crt  namespace  token

when i try to run kubectl however, i get an access denied
subu@jupyter-subu:~$ kubectl get pods
error: open /var/run/secrets/kubernetes.io/serviceaccount/token: permission denied

fair enough, but run it as sudo and it simply ignores the service account token.
subu@jupyter-subu:~$ sudo kubectl get pods
the connection to the server localhost:8080 was refused - did you specify the right host or port?

if i setup the kubectl config manually with the details of the token, it works totally though, its just the default settings that don't work. any ideas on why this could be happening would be much appreciated!
",<kubernetes><jupyter><kubectl><jupyterhub>,72090381,2,"in order to make kubectl use the projected token, the environment variables kubernetes_service_port and kubernetes_service_host must be set in your environment. these are automatically injected upon pod start, but likely only for your user, not for the sudo root user.
make sure to pass these variables for the root environment (sudo -e kubectl get pods) or make sure the projected token is readable by your user (this should be achievable by setting the kubespawner's singleuser_uid to your uid https://github.com/jupyterhub/kubespawner/issues/140).
"
58412426,increase startup threshold for k8s container in v1.12,"following the documentation here, i could set the threshold for container startup like so:

startupprobe:
  httpget:
    path: /healthz
    port: liveness-port
  failurethreshold: 30
  periodseconds: 10


unfortunately, it seems like startupprobe.failurethreshold is not compatible with our current k8s version (1.12.1):

unknown field ""startupprobe"" in io.k8s.api.core.v1.container; if you choose to ignore these errors, turn validation off with --validate=false


is there a workaround for this? i'd like to give a container a chance of ~40+ minutes to start.
",<kubernetes><kubernetes-pod><kubernetes-container>,58413171,6,"yes, startupprobe was introduced with 1.16 - so you cannot use it with kubernetes 1.12.

i am guessing you are defining a livenessprobe - so the easiest way to get around your problem is to remove the livenessprobe. most applications won't need one (some won't even need a readinessprobe). see also this excellent article: liveness probes are dangerous.
"
79160967,502 bad gateway: unable to access kubernetes pods via ingress nginx,"i'm trying to set up ingress nginx on a local kubernetes cluster (using docker desktop for windows with kubernetes enabled) to expose multiple microservices, but i'm encountering &quot;502 bad gateway&quot; errors with &quot;connect() failed (111: connection refused)&quot; and &quot;service 'default/auth-cluster-ip' does not have any active endpoint&quot; in the ingress nginx logs.
the kubernetes object configurations are done using yaml files.
here's my ingress nginx configuration yaml:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-service
  annotations:
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
spec:
  ingressclassname: nginx
  rules:
    - host: instagram-clone.dev
      http:
        paths:
          - path: /v1/auth/?(.*)
            pathtype: implementationspecific
            backend:
              service:
                name: auth-cluster-ip
                port:
                  number: 3000
          - path: /v1/profile/?(.*)
            pathtype: implementationspecific
            backend:
              service:
                name: profile-cluster-ip
                port:
                  number: 3000

and here's the deployment and service config for the auth section, for reference:
apiversion: apps/v1
kind: deployment
metadata:
  name: auth-depl
spec:
  replicas: 1
  selector:
    matchlabels:
      app: auth
  template:
    metadata:
      labels:
        app: auth
    spec:
      containers:
        - name: auth
          image: instagram-clone/auth
          env:
            - name: jwt_secret
              valuefrom:
                secretkeyref:
                  name: jwt-secret
                  key: jwt_secret
---
apiversion: v1
kind: service
metadata:
  name: auth-cluster-ip
spec:
  selector:
    app: auth
  ports:
    - name: auth
      protocol: tcp
      port: 3000
      targetport: 3000

i also updated the hosts file with this line: 127.0.0.1 instagram-clone.dev
here's my node.js auth microservice index.js:
export const app = express();

app.use(json());

app.use(&quot;/&quot;, authrouter);

debugging steps taken:

i verified that the auth-cluster-ip service is active and responds correctly when i perform a direct port-forward to the pod.
despite this, ingress seems unable to connect to the backend service, even though auth-cluster-ip appears to be configured properly.

",<kubernetes><kubernetes-ingress><ingress-nginx>,79169975,1,"the error was related to how i defined the path in the microservice. i initially thought that every request matching the base url defined in the ingress file would be forwarded to the correct pod, with the rest of the url being handled by the microservice itself. i simply misunderstood how route definitions in the ingress configuration actually work.
the correct path definition for mounting the route is:
app.use(&quot;/v1/auth&quot;, authrouter);

just like defined in the ingress config file.
hope this can be helpful for someone.
"
67615265,fluentbit in gke autopilot or alternatives?,"i'm migrating my cluster to gke using autpilot mode, and i'm trying to apply fluentbit for logging (to be sent to elasticsearch and then kibana to be alerted on a slack channel).
but it seems that gke autopilot doesn't want me to do anything on the hostpath other than reading into files inside /var/log according to this documentation. however fluentbit needs to access /var/lib/docker/containers which is different from /var/log and also access to write inside /var/log
is there a way to get around this or how do you usually log in gke autopilot with alerts?
experience sharing is also welcome
",<kubernetes><google-kubernetes-engine><fluent-bit>,67619326,2,"citing the official documentation:

external monitoring tools
most external monitoring tools require access that is restricted. solutions from several google cloud partners are available for use on autopilot, however not all are supported, and custom monitoring tools cannot be installed on autopilot clusters.
-- cloud.google.com: kubernetes engine: docs: concepts: autopilot overview: external monitoring tools 

host options restrictions
hostport and hostnetwork are not permitted because node management is handled by gke. using hostpath volumes in write mode is prohibited, while using hostpath volumes in read mode is allowed only for /var/log/ path prefixes. using host namespaces in workloads is prohibited.
-- cloud.google.com: kubernetes engine: docs: concepts: autopilot overview: host options restrictions

as you've already found the access to the /var/lib/docker/containers directory is not possible with the gke in autopilot mode.
as a workaround you could try to either:

use gke cluster in standard mode.
use cloud operations with its slack notification channel. you can read more about this topic by following:

cloud.google.com: monitoring: alerts
cloud.google.com: monitoring: support: notification options: slack



i'd reckon you could also consider checking the guide for exporting logs to elasticsearch from cloud logging:

cloud.google.com: architecture: scenarios for exporting cloud logging: elasticsearch


additional resources:

stackoverflow.com: answer: prometheus on gke autopilot?


"
60980184,unable to list pods in any state except completed,"problem:
i want to list all pods except those not in completed state.

field selector still outputs pods in completed phase when selected not completed in kubectl command

proposed solution: observe that am also getting pods in completed phase.

kubectl get pods --all-namespaces --field-selector=spec.nodename=node1,status.phase!=completed --no-headers


test-2d7dbabf-f8cc-4c0b-af3b-80db52d2257e nightly-2020-04-01-13-00-tokyo-demo-route-gt-4245049053 2/2 running 0 13m
test-2d7dbabf-f8cc-4c0b-af3b-80db52d2257e nightly-2020-04-01-13-00-willows-405-a2a-1380625152 0/2 completed 0 3h31m
test-2d7dbabf-f8cc-4c0b-af3b-80db52d2257e nightly-2020-04-01-13-00-willows-405-a2a-1464250510 0/2 completed 0 7h33m


client version: version.info{major:""1"", minor:""16"", gitversion:""v1.16.2"", gitcommit:""c97fe5036ef3df2967d086711e6c0c405941e14b"", gittreestate:""clean"", builddate:""2019-10-15t19:18:23z"", goversion:""go1.12.10"", compiler:""gc"", platform:""linux/amd64""}
server version: version.info{major:""1"", minor:""13"", gitversion:""v1.13.5"", gitcommit:""2166946f41b36dea2c4626f90a77706f426cdea2"", gittreestate:""clean"", builddate:""2019-03-25t15:19:22z"", goversion:""go1.11.5"", compiler:""gc"", platform:""linux/amd64""}


but when i do for running it works and lists only completed phase pods

kubectl get pods --all-namespaces --field-selector=spec.nodename=node1,status.phase!=running --no-headers

",<kubernetes><kubectl>,60980699,5,"completed is not a valid pod phase, use succeeded instead.

pending, running, succeeded, failed and unknown are the valid values for pod phase. 

to get the non-completed pods, 

kubectl get pods --all-namespaces --field-selector=spec.nodename=node1,status.phase!=succeeded --no-headers

"
51487188,can i run a helm command on all releases of a given chart?,"i'm frequently installing multiple instances of an umbrella helm chart across multiple namespaces for testing.  i'd like to continue using the randomly generated names, but also be able to tear down multiple releases of the same chart in one command that doesn't need to change for each new release name.

so for charts like this:

$ helm ls
name                revision    updated                     status      chart                 namespace
braided-chimp       1           mon jul 23 15:52:43 2018    deployed    foo-platform-0.2.1    foo-2
juiced-meerkat      1           mon jul  9 15:19:43 2018    deployed    postgresql-0.9.4      default
sweet-sabertooth    1           mon jul 23 15:52:34 2018    deployed    foo-platform-0.2.1    foo-1


i can delete all releases of the foo-platform-0.2.1 chart by typing the release names like:

$ helm delete braided-chimp sweet-sabertooth


but every time i run the command, i have to update it with the new release names.

is it possible to run list / delete on all instances of a given chart across all namespaces based on the chart name?  (i'm thinking something like what kubectl supports with the -l flag.)

for instance, how can i achieve something equivalent to this?

$ helm delete -l 'chart=foo-platform-0.2.1'


is there a better way to do this?
",<kubernetes><kubernetes-helm>,51489150,1,"you could try:

helm delete $(helm ls | awk '$9 ~ /search/ { print $1 }')

replacing search with whatever chart name pattern you want to use

it gets thrown off a little because awk is going to delimit on the spaces, which the timestamp has several of.

so what would traditionally be tab delimited:

1=name 2=revision 3=updated 4=status 5=chart 6=namespace

becomes:

1=mottled-whippet 2=1 3=fri 4=jul 5=20 6=13:15:45 7=2018   8=deployed 9=postgresql-0.15.0 10=namespace
"
65636666,how to get a list of docker images given some kubernetes template?,"to simplify, i want to list all the docker images defined in a helm chart.
for eg, let's say i have the following set of templates:
$ helm template jenkins/jenkins

https://charts.jenkins.io/
then, i want to somehow use kubectl to parse this result so i can apply a filter such as:
kubectl get pods -l k8s-app=kube-dns -o jsonpath={.items[*].spec.containers[*].name}

to return me the list. however, that command is to get pods. any clue?
edit: i found a way:
❯ helm template jenkins/jenkins | kubectl apply -f - --dry-run=client -o jsonpath=&quot;{..image}&quot; | tr -s '[[:space:]]' '\n' | sort | uniq
bats/bats:1.2.1
jenkins/jenkins:2.263.1
kiwigrid/k8s-sidecar:0.1.275

with one drawback: kubectl needs to be connected to a cluster. i would like to prevent that.
",<kubernetes><kubernetes-helm>,65637423,2,"you can use a different jsonpath to get all images:
kubectl get pods -a -o jsonpath=&quot;{..image}&quot;
if you just want unique images: kubectl get pods -a -o jsonpath=&quot;{..image}&quot; | tr -s '[[:space:]]' '\n' | sort -u.
substituting -a for the namespace of your chart or manifests.
if you have the manifests on your machine and not deployed, of course, you can just grep: grep 'image: ' *.yml
you can also use go template syntax:
kubectl get pods -a -o go-template --template=&quot;{{range .items}}{{range .spec.containers}}{{.image}} {{end}}{{end}}&quot;
if you have more than one chart in a given namespace, i think grepping would be the best way: helm template some-chart | grep 'image:'
edit:
since this will be running in ci, it would be better to use a little bit of code to avoid potential false positives. this python script does the trick:
#!/usr/bin/env python3
import sys
import yaml  # pip install pyyaml
from nested_lookup import nested_lookup  # pip install nested-lookup

template = &quot;&quot;

for line in sys.stdin:
    template += line

parts = template.split('---')
for p in parts:
    y = yaml.safe_load(p)
    matches = nested_lookup(&quot;image&quot;, y)
    if (len(matches)):
        print(&quot;\n&quot;.join(matches))

usage: helm template jenkins/jenkins | ./this-script.py. it prints out each occurrence of images, so if you only want unique images you'd need to throw all the matches in a list, then unique that before printing (or pipe it to sort -u).
"
76260278,kubernetes cronjob - escaping a curl command with nested json and command substitution,"i have the following kubernets cronjob definition:
apiversion: batch/v1
kind: cronjob
metadata:
  name: mycronjob
spec:
  schedule: &quot;*/1 * * * *&quot;
  failedjobshistorylimit: 1
  successfuljobshistorylimit: 1
  jobtemplate:
    spec:
      backofflimit: 2
      parallelism: 1
      template:
        metadata:
          annotations:
            linkerd.io/inject: disabled
        spec:
          containers:
            - name: mycronjob
              image: curlimages/curl:7.72.0
              env:
                - name: current_time
                  value: $(date +&quot;%y-%m-%dt%h:%m:%s.%sz&quot;)
              args:
                - /bin/sh
                - -ec
                - &quot;curl --request post --header 'content-type: application/json' -d '{\&quot;label\&quot;:\&quot;myservicebuslabel\&quot;,\&quot;data\&quot;:\&quot;{\'timestamp\':\'$(echo $current_time)\'}\&quot;,\&quot;queuename\&quot;:\&quot;myservicebusqueue\&quot;}' https://mycronjobproxy.net/api/httptrigger?code=mysecretcode&quot;
          restartpolicy: onfailure

notice i pass a dynamic date to curl via an environment variable, as described here.
however, this produces an error at runtime (copied from k9s):
curl: (3) unmatched close brace/bracket in url position 26:                                                                                                                    
+&quot;%y-%m-%dt%h:%m:%s.%sz&quot;)}&quot;,&quot;queuename&quot;:&quot;myservicebusqueue&quot;}
                         ^

i suspect this is likely an issue with combining double- and single quotes and escape characters. the curl command runs fine locally on macos, but not when deployed using the curlimages/curl:7.72.0. there seems to be some difference in behavior.
on macos, on my local dev machine, i can run the command like so:
curl --request post --header &quot;content-type: application/json&quot; -d &quot;{'label':'myservicebuslabel','data':{'timestamp':'$(echo $current_time)'},'queuename':'myservicebusqueue'}&quot; https://mycronjobproxy.net/api/httptrigger?code=mysecretcode

output:
message was successfully sent using the following params: label = myservicebuslabel | data = {&quot;timestamp&quot;: &quot;2023-05-15t15:44:45.1684158285z&quot;} | queuename = myservicebusqueue%

but when i use that version in my k8s cronjob yaml file, my ide (jetbrains rider) says: &quot;scalar value expected.&quot; it seems like the whole command must be enclosed in double quotes.
what is the correct way to quote/escape this curl command?
",<kubernetes><curl><escaping><kubernetes-cronjob><command-substitution>,76262407,1,"the requirement for sh -c is that whatever command you want it to run must be passed in a single argument.  with the list-form args:, you're explicitly specifying the argument list, and you can use any yaml string syntax so long as it is in a single list item.
the first thing this means is that you don't need the outermost set of double quotes.  that can be useful to disambiguate some kinds of structures and values – &quot;true&quot;, &quot;17&quot; – but in this case the item is pretty clearly a string and not something else.  this removes a layer of quoting.
this also means alternate yaml syntaxes are available here.  given the sheer length of this line, i might look at using a folded block scalar here: if the list item value is just &gt;- at the end of the line, then the following (indented) lines will be combined together with a single space (&gt;) and there will not be a final newline (-).
kubernetes doesn't do command substitution in env:.  if you want an environment variable to hold a dynamic value like this, it needs to be embedded or computed in the command in some form.  since you're already using sh -c syntax you need to add that into the command string.
there is one shell-syntax concern here as well.  in your example, the curl -d argument is a single-quoted string curl -d '{...}'.  within that single-quoted string, command substitution and other shell processing doesn't happen.  you need to change these single quotes to double quotes, which means you need to escape the double quotes in the json body; but if we remove the yaml double quotes as well, it is only single escaping.  you also then don't need to quote the single quotes inside this string.
(while we're here, don't $(echo $variable), just use $variable directly.)
this should all combine to form:
args:
  - /bin/sh
  - -ec
  - &gt;-
      current_time=$(date +&quot;%y-%m-%dt%h:%m:%s.%sz&quot;);
      curl
        --request post
        --header 'content-type: application/json'
        -d &quot;{\&quot;label\&quot;:\&quot;myservicebuslabel\&quot;,\&quot;data\&quot;:\&quot;{'timestamp':'$current_time'}\&quot;,\&quot;queuename\&quot;:\&quot;myservicebusqueue\&quot;}&quot;
        https://mycronjobproxy.net/api/httptrigger\?code=mysecretcode

so note that we have two commands, explicitly separated with a semicolon (at the end of the first line).  the curl arguments are split out one to a line for readability but with no additional punctuation (no backslashes at the ends of lines).  the -d option is double-quoted so the variable expansion happens; the single quotes inside the double-quoted string are not escaped.

is the data field itself intended to be a json object serialized as a string?  in that case you will need to use double quotes inside of a double-quoted json string inside a double-quotes shell argument.  the layers of escaping would look like:

create the innermost json-string argument
{&quot;timestamp&quot;:&quot;$current_time&quot;}


embed that in a json string and serialize it, which means escaping the double quotes
{&quot;data&quot;:&quot;{\&quot;timestamp\&quot;:\&quot;$current_time\&quot;}&quot;}


embed that in a shell string, escaping both the double quotes and backslashes
-d &quot;{\&quot;data\&quot;:\&quot;{\\\&quot;timestamp\\\&quot;:\\\&quot;$current_time\\\&quot;}\&quot;}&quot;



it might be more straightforward to use a tool like jq to construct or manipulate the json, or to put a template string in a configmap and then use sed or envsubst to replace the dynamic value.
"
55367948,"kubernetes go-client persistentvolumeclaim not provisioned on request, stuck in pending state","while using the go-client api after i use the api.persistentvolumeclaims(namespace).create(createopts) call the persistentvolumeclaim appears as a resource but stays in the pending state.  i do not see any events when using kubectl describe pvc, i also don't see any volumes being created etc.

$ kubectl describe pvc --namespace=test -r
name:          93007732-9d8c-406e-be99-f48faed3a061
namespace:     test
storageclass:  microk8s-hostpath
status:        pending
volume:        93007732-9d8c-406e-be99-f48faed3a061
labels:        &lt;none&gt;
annotations:   &lt;none&gt;
finalizers:    [kubernetes.io/pvc-protection]
capacity:      0
access modes:  
volumemode:    filesystem
events:        &lt;none&gt;
mounted by:    &lt;none&gt;


the code i am using is as follows:


        volume, errgo := uuid.newrandom()                                                                                                                                                 
        if errgo != nil {                                                                                                                                                                 
                job.failed = kv.wrap(errgo).with(""stack"", stack.trace().trimruntime())                                                                                                    
                return job.failed                                                                                                                                                         
        }                                                                                                                                                                                 
        job.volume = volume.string()

        fs := v1.persistentvolumefilesystem
        createopts := &amp;v1.persistentvolumeclaim{
                objectmeta: metav1.objectmeta{
                        name:      job.volume,
                        namespace: job.namespace,
                        uid:       types.uid(job.volume),
                },
                spec: v1.persistentvolumeclaimspec{
                        accessmodes: []v1.persistentvolumeaccessmode{v1.readwriteonce},
                        resources: v1.resourcerequirements{
                                requests: v1.resourcelist{
                                        v1.resourcename(v1.resourcestorage): resource.mustparse(""10gi""),
                                },
                        },
                        volumename: job.volume,
                        volumemode: &amp;fs,
                },
                status: v1.persistentvolumeclaimstatus{
                        phase:       v1.claimbound,
                        accessmodes: []v1.persistentvolumeaccessmode{v1.readwriteonce},
                        capacity: v1.resourcelist{
                                v1.resourcename(v1.resourcestorage): resource.mustparse(""10gi""),
                        },
                },
        }

        api := client().corev1()
        if _, errgo = api.persistentvolumeclaims(namespace).create(createopts); errgo != nil {
                job.failed = kv.wrap(errgo).with(""stack"", stack.trace().trimruntime())
                return job.failed
        }



i have tried to find good examples for using the create api with persistent volumes but most examples appear to be for watchers etc and so i spent quite sometime trying to reverse engineer code leading me explicitly setting the status but this appears to have had zero impact.  i also tried defaulting the volumemode within the spec which did not help.

the examples i have read come from:

https://github.com/kubernetes/kubernetes/blob/master/pkg/controller/volume/persistentvolume/framework_test.go

https://godoc.org/k8s.io/api/core/v1#persistentvolumespec

https://github.com/vladimirvivien/k8s-client-examples/tree/master/go/pvcwatch

https://medium.com/programming-kubernetes/building-stuff-with-the-kubernetes-api-part-4-using-go-b1d0e3c1c899


does anyone know of actually example code for these apis that goes beyond unit testing within the _test.go files, or can anyone provide any hints as to how to get the creation process actually rolling within the cluster ?  i have assumed that the downstream resources needed for example the volume etc are automatically provisioned when i attempt to create the claim resource.

many thanks for taking a look if you got this far...
",<kubernetes><persistent-volume-claims><kubernetes-go-client>,55369331,3,"what you are doing in the code looks correct. however, it looks like that your pvc can't find a matching pv to bind together. 

it looks like you are using a hostpath pv (with a storage class) that doesn't  support dynamic provisioning. also, documented here.

so most likely you will have to create a hostpath pv so that your pvc can bind to it. the volume has to be equal or greater in size as what you are requesting in your pvc.

another option is to use a local volume that supports dynamic provisioning which is different from hostpath.

you can debug the dynamic provisioning and binding of the pvc/pv by looking at the kube-controller-manager logs on your k8s control plane leader.
"
51718202,helm how to define .release.name value,"i have created basic helm template using helm create command. while checking the  template for ingress its adding the string release-name and appname like this release-name-microapp

how can i change .release.name value?

helm template --kube-version 1.11.1  microapp/

# source: microapp/templates/ingress.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: release-name-microapp
  labels:
    app: microapp
    chart: microapp-0.1.0
    release: release-name
    heritage: tiller
  annotations:
    kubernetes.io/ingress.class: nginx

",<kubernetes><kubernetes-helm>,51718333,120,"this depends on what version of helm you have; helm version can tell you this.
in helm version 2, it's the value of the helm install --name parameter, or absent this, a name helm chooses itself.  if you're checking what might be generated via helm template that also takes a --name parameter.
in helm version 3, it's the first parameter to the helm install command.  helm won't generate a name automatically unless you explicitly ask it to helm install --generate-name.  helm template also takes the same options.
also, in helm 3, if you want to specify a name explicitly, you should use the --name-template flag. e.g. helm template --name-template=dummy in order to use the name dummy instead of release-name
"
55088104,gitlab autodevops how to always keep one pod alive,"i'm using gitlab autodevops to deploy app on my kubernetes cluster. that app should always have only one instance running. 
problem is, during the update process, helm kills currently running pod before the new pod is ready. this causes downtime period, when old version is already killed and new one isn't ready yet. to make it worse, app need significant time to start (2+ minutes).

i have tried to  set minavailable: 1 in poddisruptionbudget, but no help. 
any idea how can i tell helm to wait for readiness of updated pod before killing old one? (having 2 instances running simultaneously for several second is not such a problem for me)
",<kubernetes><gitlab><devops><gitlab-ci><kubernetes-helm>,55101566,1,"you can release a new application version in few ways, it's necessary to choose the one that fit your needs.
i would recommend one of the following:
ramped - slow rollout

a ramped deployment updates pods in a rolling update fashion, a secondary replicaset is created with the new version of the application, then the number of replicas of the old version is decreased and the new version is increased until the correct number of replicas is reached.

spec:
  replicas: 3
  strategy:
    type: rollingupdate
    rollingupdate:
      maxsurge: 2        # how many pods we can add at a time
      maxunavailable: 0  # maxunavailable define how many pods can be unavailable
                         # during the rolling update

full example and steps can be found here.
blue/green - best to avoid api versioning issues

a blue/green deployment differs from a ramped deployment because the “green” version of the application is deployed alongside the “blue” version. after testing that the new version meets the requirements, we update the kubernetes service object that plays the role of load balancer to send traffic to the new version by replacing the version label in the selector field.

apiversion: v1
kind: service
metadata:
 name: my-app
 labels:
   app: my-app
spec:
 type: nodeport
 ports:
 - name: http
   port: 8080
   targetport: 8080

 # note here that we match both the app and the version.
 # when switching traffic, we update the label “version” with
 # the appropriate value, ie: v2.0.0
 selector:
   app: my-app
   version: v1.0.0

full example and steps can be found here.
canary - for testing

a canary deployment consists of routing a subset of users to a new functionality. in kubernetes, a canary deployment can be done using two deployments with common pod labels. one replica of the new version is released alongside the old version. then after some time and if no error is detected, scale up the number of replicas of the new version and delete the old deployment.
using this replicaset technique requires spinning-up as many pods as necessary to get the right percentage of traffic. that said, if you want to send 1% of traffic to version b, you need to have one pod running with version b and 99 pods running with version a. this can be pretty inconvenient to manage so if you are looking for a better managed traffic distribution, look at load balancers such as  haproxy  or service meshes like  linkerd, which provide greater controls over traffic.

manifest for version a:
spec:
  replicas: 3

manifest for version b:
spec:
  replicas: 1

full example and steps can be found here.
you can also play with interactive tutorial - updating your app on kubernetes.
i recommend reading deploy, scale and upgrade an application on kubernetes with helm.
"
58687909,kubernetes ingress domain redirect,"i want to redirect domain in nginx ingress kubernete.

https://test.example.io/preview/qlxivcdgxcaq134650121853ftg4


if in url preview comes change domain redirect 

https://test.app.example.io/preview/qlxivcdgxcaq134650121853ftg4


what i was trying

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    certmanager.k8s.io/cluster-issuer: staging
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: nginx
  name: staging-ingress
spec:
  rules:
  - host: test.example.io
    http:
      paths:
      - path: /
        backend:
          servicename: service-1
          serviceport: 80
      - path: /preview/*
        backend:
          url: 
          servicename: service-2
          serviceport: 80
  tls:
  - hosts:
    - test.example.io
    secretname: staging


for simple nginx block is like 

location ~ /preview
    {
      rewrite /preview https://test.app.example.com$uri permanent;
    }

",<docker><kubernetes><kubernetes-ingress><nginx-ingress>,58689690,22,"my logic thinking, try it : 

metadata:
      annotations:
        nginx.ingress.kubernetes.io/configuration-snippet: |
         rewrite /preview https://test.app.example.com$uri permanent;

spec:
      rules:
      - host: test.example.io
        http:
          paths:
          - path: /
            backend:
              servicename: service-1
              serviceport: 80
      - host: test.app.example.io
        http:
          paths:
          - path: /preview/*
            backend:
              servicename: service-2
              serviceport: 80


hope it works ! 

on code above: you should not access using: https://test.app.example.io/preview/ (it just be redirected link ) at all.
"
52628474,how to make an environment variable different across two pods of the same deployment in kubernetes?,"based on this it is possible to create environment variables that are the same across all the pods of the deployment that you define.

is there a way to instruct kubernetes deployment to create pods that have different environment variables?

use case:

let's say that i have a monitoring container and i want to create 4 replicas of it. this container has a service that is mailing if an environment variables defines so. eg, if the env var is_master is true, then the service proceeds to send those e-mails.

apiversion: v1
kind: deployment
metadata:
  ...
spec:
  ...
  replicas: 4
  ...
  template:
    ...
    spec:
      containers:
      -env: 
        -name: is_master
         value: &lt;------------- true only in one of the replicas


(in my case i'm using helm, but the same thing can be without helm as well)
",<deployment><kubernetes><environment-variables><containers><kubernetes-helm>,52637367,4,"what you are looking for is, as far as i know, more like an anti-pattern than impossible.

from what i understand, you seem to be looking to deploy a scalable/ha monitoring platform that wouldn't mail x times on alerts, so you can either make a sidecar container that will talk to its siblings and ""elect"" the master-mailer (a statefulset will make it easier in this case), or just separate the mailer from the monitoring and make them talk to each other through a service. that would allow you to load-balance both monitoring and mailing separately.

monitoring-1 \                 / mailer-1
monitoring-2 --- &gt; mailer.svc -- mailer-2
monitoring-3 /                 \ mailer-3


any mailing request will be handled by one and only one mailer from the pool, but that's assuming your monitoring pods aren't all triggered together on alerts... if that's not the case, then regardless of your ""master"" election for the mailer, you will have to tackle that first.

and by tackling that first i mean adding a master-election logic to your monitoring platform, to orchestrate master fail-overs on events, there are a few ways to do so, but it really depends on what your monitoring platform is and can do...

although, if your replicas are just there to extend compute power somehow and your master is expected to be static, then simply use a statefulset, and add a one liner at runtime doing if hostname == $statefulset-name-0 then master, but i feel like it's not the best idea.
"
60083889,kubectl --token=$token doesn't run with the permissions of the token,"when i am using the command kubectl with the --token flag and specify a token, it still uses the administrator credentials from the kubeconfig file.
this is what i did:
namespace=&quot;default&quot;
service_account_name=&quot;sa1&quot;
kubectl create sa $service_account_name
kubectl create clusterrolebinding list-pod-clusterrolebinding \
     --clusterrole=list-pod-clusterrole \
     --serviceaccount=&quot;$namespace&quot;:&quot;$service_account_name&quot;
kubectl create clusterrole list-pod-clusterrole \
     --verb=list \
     --resource=pods

token=`kubectl get secrets $(kubectl get sa $service_account_name -o json | jq -r '.secrets[].name') -o json | jq -r '.data.token' | base64 -d`

# expected it will fail but it doesn't because it uses the admin credentials
kubectl get secrets --token $token


the token have permissions to list pods, so i expect the kubectl get secrets --token $token to fail but it doesn't because it still uses the context of the administrator.
i don't create new context, i know kubectl have this ability to use bearer token and want to understand how to do it.
i also tried this kubectl get secrets --insecure-skip-tls-verify --server https://&lt;master_ip&gt;:6443 --token $tokenand it also didn't return a forbidden result.
if you test it you can use katacoda:
https://www.katacoda.com/courses/kubernetes/playground
edit:
i tried to create context with this:
namespace=&quot;default&quot;
service_account_name=&quot;sa1&quot;
context_name=&quot;sa1-context&quot;
user_name=&quot;sa1-username&quot;
cluster_name=&quot;kubernetes&quot;

kubectl create sa &quot;$service_account_name&quot; -n &quot;$namespace&quot;
secret_name=`kubectl get serviceaccounts $service_account_name -n $namespace -o json | jq -r '.secrets[].name'`
token=`kubectl get secrets $secret_name -n $namespace -o json | jq -r '.data | .token' | base64 -d`

# create user with the jwt token of the service account
echo &quot;[*] setting credentials for user: $user_name&quot;
kubectl config set-credentials $user_name --token=$token

# makue sure the cluster name is correct !!!
echo &quot;[*] setting context: $context_name&quot;
kubectl config set-context $context_name \
--cluster=$cluster_name \
--namespace=$namespace \
--user=$user_name

but when i tried kubectl get secrets --context $context_name it still succeeded and was supposed fail because it doesn't have permissions for that.
edit 2:
option to run it correctly based on the kubectl api:
kubectl get pods --token `cat /home/natan/token` -s https://&lt;ip&gt;:8443 --certificate-authority /root/.minikube/ca.crt --all-namespaces

or without tls:
kubectl get pods --token `cat /home/natan/token` -s https://&lt;ip&gt;:8443 --insecure-skip-tls-verify --all-namespaces

",<kubernetes><kubectl><bearer-token>,60093966,6,"this is tricky because if you are using client certificate for authenticating to kubernetes api server overriding token with kubectl is not going to work because the authentication with certificate happens early in the process during the tls handshake.even if you provide a token in kubectl it will be ignored.this is the reason why you are able to get secrets because the client certificate have permission to get secrets and the token is ignored.

so if you want to use kubectl token the kubeconfig file should not have client certificate and then you can override that token with --token flag in kubectl. see the discussion in the question on how to create a kubeconfig file for a service account token.

also you can view the bearer token being sent in kubectl command using command

kubectl get pods --v=10 2&gt;&amp;1 | grep -i bearer

"
67107771,access k8s services via ingress,"we have configured metallb since our k8s cluster is hosted on bare metal infrastructure. it seems to be running fine with all pods up and running.
[~]# kubectl get all -n metallb-system
name                             ready   status    restarts   age
pod/controller-b78574c59-47qfv   1/1     running   0          24h
pod/speaker-4q2vm                1/1     running   0          24h
pod/speaker-m8kwk                1/1     running   0          24h
pod/speaker-t4rvs                1/1     running   0          24h

name                     desired   current   ready   up-to-date   available   node selector            age
daemonset.apps/speaker   3         3         3       3            3           kubernetes.io/os=linux   24h

name                         ready   up-to-date   available   age
deployment.apps/controller   1/1     1            1           24h

name                                   desired   current   ready   age
replicaset.apps/controller-b78574c59   1         1         1       24h

we have configured ingress controller via helm from  https://github.com/kubernetes/ingress-nginx/releases/tag/helm-chart-3.29.0 and updating hostnetwork,ingressclass,kind to true,ingress-nginx,daemonset respectively in file values.yaml. the helm installation seems to have worked fine with all daemonset pods running and an lb ip provided to created ingress controller service.
[~]# kubectl get all -n ingress-nginx
name                                            ready   status    restarts   age
pod/devingress-ingress-nginx-controller-c2x42   1/1     running   0          18h
pod/devingress-ingress-nginx-controller-wtmgw   1/1     running   0          18h

name                                                    type           cluster-ip       external-ip      port(s)                      age
service/devingress-ingress-nginx-controller             loadbalancer     x.x.x.x         1.2.3.40     80:32386/tcp,443:30020/tcp   18h
service/devingress-ingress-nginx-controller-admission   clusterip        x.x.x.x           &lt;none&gt;        443/tcp                      18h

name                                                 desired   current   ready   up-to-date   available   node selector            age
daemonset.apps/devingress-ingress-nginx-controller   2         2         2       2            2           kubernetes.io/os=linux   18h

now we have deployed two pods namely nginx with loadbalancer service type &amp; nginx-deploy-main with clusterip service type.
[~]# kubectl get all -n default
name                                     ready   status    restarts   age
pod/nginx-854cf6b4d7-lv5ss               1/1     running   0          18h
pod/nginx-deploy-main-6b5457fbb5-7tg9z   1/1     running   0          18h

name                           type           cluster-ip      external-ip      port(s)          age
service/nginx                  loadbalancer   x.x.x.x        1.2.3.41       8080:31101/tcp    18h
service/nginx-deploy-main      clusterip      x.x.x.x          &lt;none&gt;           80/tcp          18h

name                                ready   up-to-date   available   age
deployment.apps/nginx               1/1     1            1           18h
deployment.apps/nginx-deploy-main   1/1     1            1           18h

name                                           desired   current   ready   age
replicaset.apps/nginx-854cf6b4d7               1         1         1       18h
replicaset.apps/nginx-deploy-main-6b5457fbb5   1         1         1       18h

below is the ingress resource setup to access nginx-deploy-main.
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: ingress-resource
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  ingressclassname: nginx
  rules:
  - host: nginx-main.int.org.com
    http:
      paths:
      - path: /
        backend:
          servicename: nginx-deploy-main
          serviceport: 80

and the ingress resource seems to be created correctly pointing to nginx-deploy-main service.
[~]# kubectl get ing -n default
name                 class   hosts                           address   ports   age
ingress-resource     nginx   nginx-main.int.org.com                    80      19h

[~]# kubectl describe ing/ingress-resource -n default
name:             ingress-resource
namespace:        default
address:
default backend:  default-http-backend:80 (&lt;none&gt;)
rules:
  host                           path  backends
  ----                           ----  --------
  nginx-main.int.org.com
                                 /   nginx-deploy-main:80 (x.x.x.x:80)
annotations:                     kubernetes.io/ingress.class: nginx
events:                          &lt;none&gt;

outside of k8s cluster, we have nginx set up serving as reverse proxy with domain int.org.com resolution.
below is the nginx configuration which should help me hit url http://nginx-main.int.org.com and get response but the response returned is 404.
upstream nginx-main.int.org.com {
  server 1.2.3.40:80;     ## ingress controller service ip
}

server {
  listen 80;
  server_name nginx-main.int.org.com;
  location / {
    proxy_pass http://nginx-main.int.org.com;
  }
}

now when i try to access nginx pod (not nginx-main) using its loadbalancer service ip with below configuration , its able to provide response and works just fine
upstream nginx.int.org.com {
  server 1.2.3.41:8080;
}

server {
  listen 80;
  server_name nginx.int.org.com;
  location / {
    proxy_pass http://nginx.int.org.com;
  }
}

am i missing something here with regards to ingress controller or resource. port forwarding works fine and am able to access services using the same.
this really is a blocker and any help or documentation reference would be really useful .
",<nginx><jenkins><kubernetes><kubernetes-ingress><ingress-controller>,67294428,1,"we tried with another ingress controller i.e. https://github.com/nginxinc/kubernetes-ingress and were able to make it work .
below were the steps done .
[~] git clone https://github.com/nginxinc/kubernetes-ingress/
[~] cd kubernetes-ingress/deployments
[~] git checkout v1.11.1
[~] kubectl apply -f common/ns-and-sa.yaml
[~] kubectl apply -f rbac/rbac.yaml
[~] kubectl apply -f common/default-server-secret.yaml
[~] kubectl apply -f common/nginx-config.yaml
[~] kubectl apply -f common/ingress-class.yaml

created daemon-set pods with  extra environment argument i.e. --enable-custom-resources=false added in yaml due to below issue in controller logs
refer : kubernetes cluster working but getting this error from the nginx controller
[~] kubectl apply -f daemon-set/nginx-ingress.yaml
[~] kubectl get all -n nginx-ingress -o wide
name                      ready   status    restarts   age     ip            node         nominated node   readiness gates
pod/nginx-ingress-gd8gw   1/1     running   0          3h55m   x.x.x.x      worker1          &lt;none&gt;           &lt;none&gt;
pod/nginx-ingress-kr9lx   1/1     running   0          3h55m   x.x.x.x      worker2          &lt;none&gt;           &lt;none&gt;
 
name                           desired   current   ready   up-to-date   available   node selector   age     containers     images                                                  selector
daemonset.apps/nginx-ingress   2         2         2       2            2           &lt;none&gt;          5h14m   nginx-ingress   nginx/nginx-ingress:1.11.1   app=nginx-ingress

hit respective worker nodes at port 80 and a 404 response means its working fine.
deployed a sample application using github link https://github.com/vipin-k/ingress-controller-v1.9.0/blob/main/hotel.yml and updated host entry within ingress object to hotel.int.org.com
[~] kubectl create -f hotel.yaml
[~] kubectl get all -n hotel -o wide
name                         ready   status    restarts   age     ip            node         nominated node   readiness gates
pod/hotel-65d644c8f7-bj597   1/1     running   0          3h51m   x.x.x.x     worker1          &lt;none&gt;           &lt;none&gt;
pod/hotel-65d644c8f7-csvgp   1/1     running   0          3h51m   x.x.x.x     worker2          &lt;none&gt;           &lt;none&gt;
 
name                type        cluster-ip       external-ip   port(s)   age     selector
service/hotel-svc   clusterip   x.x.x.x   &lt;none&gt;        80/tcp    3h51m   app=hotel
 
name                    ready   up-to-date   available   age     containers   images                                                    selector
deployment.apps/hotel   2/2     2            2           3h51m   hotel        nginxdemos/hello:plain-text   app=hotel
 
name                               desired   current   ready   age     containers   images                                                    selector
replicaset.apps/hotel-65d644c8f7   2         2         2       3h51m   hotel        nginxdemos/hello:plain-text   app=hotel,pod-template-hash=65d644c8f7

[~] kubectl get ing -n hotel
name            class   hosts                       address   ports   age
hotel-ingress   nginx   hotel.int.org.com            80      3h52m
[~] kubectl describe ing hotel-ingress -n hotel
name:             hotel-ingress
namespace:        hotel
address:
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;) 
rules:
  host                       path  backends
  ----                       ----  --------
  hotel.int.org.com
                             /        hotel-svc:80 (x.x.x.x:80,x.x.x.x:80)
annotations:                 events:  &lt;none&gt;

updated external nginx configuration with enabled domain resolution .
upstream hotel.int.org.com {
  server 1.2.3.41:80;  #worker1
  server 1.2.3.42:80;  #worker2
}

server {
  listen 80;
  server_name hotel.int.org.com;
  location / {
    proxy_pass http://hotel.int.org.com;
  }
}

restart nginx and verify able to access via browser its serving response from respective running hotel namespace daemonset pods.
[~]# curl hotel.int.org.com
server address: x.x.x.x:80
server name: hotel-65d644c8f7-bj597
date: 28/apr/2021:05:47:15 +0000
uri: /
request id: 28d5cfab4ea28beea49879422b7e8f4c

[~]# curl hotel.int.org.com
server address: x.x.x.x:80
server name: hotel-65d644c8f7-csvgp
date: 28/apr/2021:05:52:06 +0000
uri: /
request id: 4135cacf83f8bf41c9677104500e610b

exploring with metallb too and will post solution once its works
"
59413073,kubernetes haproxy ingress doesn't work without explicitly setting host header,"i followed the tutorial from https://www.haproxy.com/documentation/hapee/1-9r1/traffic-management/kubernetes-ingress-controller/ to setup the haproxy controller (community edition) and the ""echo server"" app that should be accessed.

when i run curl -l -h 'host: echo.example.com' localhost:30884 i get the desired response

request served by app-58f7d69f54-p2kq8

http/1.1 get /

host: echo.example.com
user-agent: curl/7.61.1
accept: */*
x-forwarded-for: 10.42.0.0



however if i just use curl -l  echo.example.com:30884 i get the response default backend - 404
so apperently the request reaches the ingress controller, but the ingress controller doesn't know which host should be used.

running kubectl get ing gives me

eignungstest              eignungstest.example.com          10.43.173.120   80      17h
kube-web-view             dashboard.example.com                             80      16h
web-ingress               echo.example.com                                  80      16h


it seems there is no address assigned, but running the same commands above with the host eignungstest.example.com i get the same results, so that should be of no relevance.

is there a setting i'm missing that prevents the host header from being passed when i dont explicitly specify it?
",<kubernetes><haproxy><kubectl>,59413425,1,"ingress controller and ingress looks fine. 

as you can see in your kubectl response the ingress is pointing to port 80 of that service which would pick up echo.example.com. 

so it only knows about port 80 of echo.example.com, but when you try curl -l echo.example.com:30884, it is checking for that particular port and routing all the traffic to default backend. 

make sure you could directly curl -l echo.example.com, if it doesn't work check the service if the service has something similar.

spec:
  ports:
    - port: 80
      targetport: 3001


you might have done the service part right as well. hope this helps.
"
74054955,powershell pod failing in kubernetes cluster,"i need to run powershell as an container in kubernetes
i am using following deployment file sample.yaml
apiversion: v1
kind: pod
metadata:
  name: powershell
spec:
  containers:
  - name: powershell
    image: mcr.microsoft.com/powershell:latest

when i run kubectl apply -f sample.yaml
i get the following error on kubectl get pods
powershell        0/1     crashloopbackoff   3 (50s ago)   92s

i did check the log kubectl logs powershell
powershell 7.2.6
copyright (c) microsoft corporation.

https://aka.ms/powershell
type 'help' to get help.

ps /&gt; ←[?1h

but when i run same image as a docker container with following command its working
docker run --rm -it mcr.microsoft.com/powershell:latest

",<powershell><kubernetes><kubernetes-pod>,74056099,4,"if you want to keep a container for running, you should write like this yaml..
apiversion: v1
kind: pod
metadata:
  name: powershell
spec:
  containers:
  - name: powershell
    image: mcr.microsoft.com/powershell:latest
    command: [&quot;pwsh&quot;]
    args: [&quot;-command&quot;, &quot;start-sleep&quot;, &quot;3600&quot;]


[root@master1 ~]# kubectl get pod powershell
name         ready   status    restarts   age
powershell   1/1     running   0          3m32s
[root@master1 ~]# kubectl exec -it powershell -- pwsh
powershell 7.2.6
copyright (c) microsoft corporation.

https://aka.ms/powershell
type 'help' to get help.

ps /&gt; date
thu oct 13 12:50:24 pm utc 2022
ps /&gt;


"
52799007,"in my dockerfile, how do i use the `copy --from` syntax to use images from google container registry?","i'm using google kubernetes engine, cloud build, and image registry. according to the kubectl docs, i can use external images in dockerfiles with copy --from. this would be very useful because when i run gcloud builds submit on my dockerfile, i'd like to add in images already built on gcr instead of rebuilding everything in one dockerfile.

i've tried adding lines like copy --from=quickstart-image:latest /some/path/thing.conf /thing.conf but i always get

pull access denied for quickstart-image, repository does not exist or may require 'docker login'

is there some authentication step i'm missing? how can i get this to work?
",<docker><kubernetes><google-cloud-platform><google-kubernetes-engine><google-container-registry>,52799526,3,"by default, quickstart-image refers to docker hub which, as error message suggests, it is not existing in docker hub.

if you want to use an image from gcr, you have to use full address like asia.gcr.io/project-name/repo-name.
"
69625797,kafka issue while connecting to zookeeper (kubernetes-kafka:1.0-10.2.1),"i have used this document for creating kafka https://kow3ns.github.io/kubernetes-kafka/manifests/
able to create zookeeper, facing issue with the creation of kafka.getting error to connect with the zookeeper.
this is the manifest i have used for creating
for kafka:
https://kow3ns.github.io/kubernetes-kafka/manifests/kafka.yaml
for zookeeper
https://github.com/kow3ns/kubernetes-zookeeper/blob/master/manifests/zookeeper.yaml
the logs of the kafka
 kubectl logs -f pod/kafka-0 -n kaf
[2021-10-19 05:37:14,535] info kafkaconfig values:
        advertised.host.name = null
        advertised.listeners = null
        advertised.port = null
        authorizer.class.name =
        auto.create.topics.enable = true
        auto.leader.rebalance.enable = true
        background.threads = 10
        broker.id = 0
        broker.id.generation.enable = true
        broker.rack = null
        compression.type = producer
        connections.max.idle.ms = 600000
        controlled.shutdown.enable = true
        controlled.shutdown.max.retries = 3
        controlled.shutdown.retry.backoff.ms = 5000
        controller.socket.timeout.ms = 30000
        create.topic.policy.class.name = null
        default.replication.factor = 1
        delete.topic.enable = false
        fetch.purgatory.purge.interval.requests = 1000
        group.max.session.timeout.ms = 300000
        group.min.session.timeout.ms = 6000
        host.name =
        inter.broker.listener.name = null
        inter.broker.protocol.version = 0.10.2-iv0
        leader.imbalance.check.interval.seconds = 300
        leader.imbalance.per.broker.percentage = 10
        listener.security.protocol.map = ssl:ssl,sasl_plaintext:sasl_plaintext,trace:trace,sasl_ssl:sasl_ssl,plaintext:plaintext
        listeners = plaintext://:9093
        log.cleaner.backoff.ms = 15000
        log.cleaner.dedupe.buffer.size = 134217728
        log.cleaner.delete.retention.ms = 86400000
        log.cleaner.enable = true
        log.cleaner.io.buffer.load.factor = 0.9
        log.cleaner.io.buffer.size = 524288
        log.cleaner.io.max.bytes.per.second = 1.7976931348623157e308
        log.cleaner.min.cleanable.ratio = 0.5
        log.cleaner.min.compaction.lag.ms = 0
        log.cleaner.threads = 1
        log.cleanup.policy = [delete]
        log.dir = /var/lib/kafka
        log.dirs = /tmp/kafka-logs
        log.flush.interval.messages = 9223372036854775807
        log.flush.interval.ms = null
        log.flush.offset.checkpoint.interval.ms = 60000
        log.flush.scheduler.interval.ms = 9223372036854775807
        log.index.interval.bytes = 4096
        log.index.size.max.bytes = 10485760
        log.message.format.version = 0.10.2-iv0
        log.message.timestamp.difference.max.ms = 9223372036854775807
        log.message.timestamp.type = createtime
        log.preallocate = false
        log.retention.bytes = -1
        log.retention.check.interval.ms = 300000
        log.retention.hours = 168
        log.retention.minutes = null
        log.retention.ms = null
        log.roll.hours = 168
        log.roll.jitter.hours = 0
        log.roll.jitter.ms = null
        log.roll.ms = null
        log.segment.bytes = 1073741824
        log.segment.delete.delay.ms = 60000
        max.connections.per.ip = 2147483647
        max.connections.per.ip.overrides =
        message.max.bytes = 1000012
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = info
        metrics.sample.window.ms = 30000
        min.insync.replicas = 1
        num.io.threads = 8
        num.network.threads = 3
        num.partitions = 1
        num.recovery.threads.per.data.dir = 1
        num.replica.fetchers = 1
        offset.metadata.max.bytes = 4096
        offsets.commit.required.acks = -1
        offsets.commit.timeout.ms = 5000
        offsets.load.buffer.size = 5242880
        offsets.retention.check.interval.ms = 600000
        offsets.retention.minutes = 1440
        offsets.topic.compression.codec = 0
        offsets.topic.num.partitions = 50
        offsets.topic.replication.factor = 3
        offsets.topic.segment.bytes = 104857600
        port = 9092
        principal.builder.class = class org.apache.kafka.common.security.auth.defaultprincipalbuilder
        producer.purgatory.purge.interval.requests = 1000
        queued.max.requests = 500
        quota.consumer.default = 9223372036854775807
        quota.producer.default = 9223372036854775807
        quota.window.num = 11
        quota.window.size.seconds = 1
        replica.fetch.backoff.ms = 1000
        replica.fetch.max.bytes = 1048576
        replica.fetch.min.bytes = 1
        replica.fetch.response.max.bytes = 10485760
        replica.fetch.wait.max.ms = 500
        replica.high.watermark.checkpoint.interval.ms = 5000
        replica.lag.time.max.ms = 10000
        replica.socket.receive.buffer.bytes = 65536
        replica.socket.timeout.ms = 30000
        replication.quota.window.num = 11
        replication.quota.window.size.seconds = 1
        request.timeout.ms = 30000
        reserved.broker.max.id = 1000
        sasl.enabled.mechanisms = [gssapi]
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.principal.to.local.rules = [default]
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.mechanism.inter.broker.protocol = gssapi
        security.inter.broker.protocol = plaintext
        socket.receive.buffer.bytes = 102400
        socket.request.max.bytes = 104857600
        socket.send.buffer.bytes = 102400
        ssl.cipher.suites = null
        ssl.client.auth = none
        ssl.enabled.protocols = [tlsv1.2, tlsv1.1, tlsv1]
        ssl.endpoint.identification.algorithm = null
        ssl.key.password = null
        ssl.keymanager.algorithm = sunx509
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = jks
        ssl.protocol = tls
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = pkix
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = jks
        unclean.leader.election.enable = true
        zookeeper.connect = zk-cs.default.svc.cluster.local:2181
        zookeeper.connection.timeout.ms = 6000
        zookeeper.session.timeout.ms = 6000
        zookeeper.set.acl = false
        zookeeper.sync.time.ms = 2000
 (kafka.server.kafkaconfig)
[2021-10-19 05:37:14,569] info starting (kafka.server.kafkaserver)
[2021-10-19 05:37:14,570] info connecting to zookeeper on zk-cs.default.svc.cluster.local:2181 (kafka.server.kafkaserver)
[2021-10-19 05:37:14,579] info starting zkclient event thread. (org.i0itec.zkclient.zkeventthread)
[2021-10-19 05:37:14,583] info client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 gmt (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:host.name=kafka-0.kafka-hs.kaf.svc.cluster.local (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.version=1.8.0_131 (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.vendor=oracle corporation (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.class.path=:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b05.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/connect-api-0.10.2.1.jar:/opt/kafka/bin/../libs/connect-file-0.10.2.1.jar:/opt/kafka/bin/../libs/connect-json-0.10.2.1.jar:/opt/kafka/bin/../libs/connect-runtime-0.10.2.1.jar:/opt/kafka/bin/../libs/connect-transforms-0.10.2.1.jar:/opt/kafka/bin/../libs/guava-18.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0-b05.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0-b05.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0-b05.jar:/opt/kafka/bin/../libs/jackson-annotations-2.8.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.8.5.jar:/opt/kafka/bin/../libs/jackson-core-2.8.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.8.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.8.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.8.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.8.5.jar:/opt/kafka/bin/../libs/javassist-3.20.0-ga.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka/bin/../libs/javax.inject-1.jar:/opt/kafka/bin/../libs/javax.inject-2.5.0-b05.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.0.1.jar:/opt/kafka/bin/../libs/jersey-client-2.24.jar:/opt/kafka/bin/../libs/jersey-common-2.24.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.24.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.24.jar:/opt/kafka/bin/../libs/jersey-guava-2.24.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.24.jar:/opt/kafka/bin/../libs/jersey-server-2.24.jar:/opt/kafka/bin/../libs/jetty-continuation-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-http-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-io-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-security-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-server-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-servlet-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-servlets-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jetty-util-9.2.15.v20160210.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.3.jar:/opt/kafka/bin/../libs/kafka-clients-0.10.2.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-0.10.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-0.10.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-0.10.2.1.jar:/opt/kafka/bin/../libs/kafka-tools-0.10.2.1.jar:/opt/kafka/bin/../libs/kafka_2.11-0.10.2.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.11-0.10.2.1-test-sources.jar:/opt/kafka/bin/../libs/kafka_2.11-0.10.2.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-1.3.0.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/reflections-0.9.10.jar:/opt/kafka/bin/../libs/rocksdbjni-5.0.1.jar:/opt/kafka/bin/../libs/scala-library-2.11.8.jar:/opt/kafka/bin/../libs/scala-parser-combinators_2.11-1.0.4.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.21.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.21.jar:/opt/kafka/bin/../libs/snappy-java-1.1.2.6.jar:/opt/kafka/bin/../libs/validation-api-1.1.0.final.jar:/opt/kafka/bin/../libs/zkclient-0.10.jar:/opt/kafka/bin/../libs/zookeeper-3.4.9.jar (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:java.compiler=&lt;na&gt; (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:os.name=linux (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:os.arch=amd64 (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:os.version=5.4.141-67.229.amzn2.x86_64 (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:user.name=kafka (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:user.home=/home/kafka (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,583] info client environment:user.dir=/ (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,584] info initiating client connection, connectstring=zk-cs.default.svc.cluster.local:2181 sessiontimeout=6000 watcher=org.i0itec.zkclient.zkclient@5e0826e7 (org.apache.zookeeper.zookeeper)
[2021-10-19 05:37:14,591] info terminate zkclient event thread. (org.i0itec.zkclient.zkeventthread)
[2021-10-19 05:37:14,592] fatal fatal error during kafkaserver startup. prepare to shutdown (kafka.server.kafkaserver)
org.i0itec.zkclient.exception.zkexception: unable to connect to zk-cs.default.svc.cluster.local:2181
        at org.i0itec.zkclient.zkconnection.connect(zkconnection.java:72)
        at org.i0itec.zkclient.zkclient.connect(zkclient.java:1228)
        at org.i0itec.zkclient.zkclient.&lt;init&gt;(zkclient.java:157)
        at org.i0itec.zkclient.zkclient.&lt;init&gt;(zkclient.java:131)
        at kafka.utils.zkutils$.createzkclientandconnection(zkutils.scala:106)
        at kafka.utils.zkutils$.apply(zkutils.scala:88)
        at kafka.server.kafkaserver.initzk(kafkaserver.scala:326)
        at kafka.server.kafkaserver.startup(kafkaserver.scala:187)
        at kafka.server.kafkaserverstartable.startup(kafkaserverstartable.scala:39)
        at kafka.kafka$.main(kafka.scala:67)
        at kafka.kafka.main(kafka.scala)
caused by: java.net.unknownhostexception: zk-cs.default.svc.cluster.local: name or service not known
        at java.net.inet4addressimpl.lookupallhostaddr(native method)
        at java.net.inetaddress$2.lookupallhostaddr(inetaddress.java:928)
        at java.net.inetaddress.getaddressesfromnameservice(inetaddress.java:1323)
        at java.net.inetaddress.getallbyname0(inetaddress.java:1276)
        at java.net.inetaddress.getallbyname(inetaddress.java:1192)
        at java.net.inetaddress.getallbyname(inetaddress.java:1126)
        at org.apache.zookeeper.client.statichostprovider.&lt;init&gt;(statichostprovider.java:61)
        at org.apache.zookeeper.zookeeper.&lt;init&gt;(zookeeper.java:445)
        at org.apache.zookeeper.zookeeper.&lt;init&gt;(zookeeper.java:380)
        at org.i0itec.zkclient.zkconnection.connect(zkconnection.java:70)
        ... 10 more
[2021-10-19 05:37:14,594] info shutting down (kafka.server.kafkaserver)
[2021-10-19 05:37:14,597] info shut down completed (kafka.server.kafkaserver)
[2021-10-19 05:37:14,597] fatal fatal error during kafkaserverstartable startup. prepare to shutdown (kafka.server.kafkaserverstartable)
org.i0itec.zkclient.exception.zkexception: unable to connect to zk-cs.default.svc.cluster.local:2181
        at org.i0itec.zkclient.zkconnection.connect(zkconnection.java:72)
        at org.i0itec.zkclient.zkclient.connect(zkclient.java:1228)
        at org.i0itec.zkclient.zkclient.&lt;init&gt;(zkclient.java:157)
        at org.i0itec.zkclient.zkclient.&lt;init&gt;(zkclient.java:131)
        at kafka.utils.zkutils$.createzkclientandconnection(zkutils.scala:106)
        at kafka.utils.zkutils$.apply(zkutils.scala:88)
        at kafka.server.kafkaserver.initzk(kafkaserver.scala:326)
        at kafka.server.kafkaserver.startup(kafkaserver.scala:187)
        at kafka.server.kafkaserverstartable.startup(kafkaserverstartable.scala:39)
        at kafka.kafka$.main(kafka.scala:67)
        at kafka.kafka.main(kafka.scala)
caused by: java.net.unknownhostexception: zk-cs.default.svc.cluster.local: name or service not known
        at java.net.inet4addressimpl.lookupallhostaddr(native method)
        at java.net.inetaddress$2.lookupallhostaddr(inetaddress.java:928)
        at java.net.inetaddress.getaddressesfromnameservice(inetaddress.java:1323)
        at java.net.inetaddress.getallbyname0(inetaddress.java:1276)
        at java.net.inetaddress.getallbyname(inetaddress.java:1192)
        at java.net.inetaddress.getallbyname(inetaddress.java:1126)
        at org.apache.zookeeper.client.statichostprovider.&lt;init&gt;(statichostprovider.java:61)
        at org.apache.zookeeper.zookeeper.&lt;init&gt;(zookeeper.java:445)
        at org.apache.zookeeper.zookeeper.&lt;init&gt;(zookeeper.java:380)
        at org.i0itec.zkclient.zkconnection.connect(zkconnection.java:70)
        ... 10 more


crash-loop-kafka
kafka deployed manifest
",<kubernetes><apache-kafka><kubernetes-statefulset>,69627964,1,"your kafka and zookeeper deployments are running in the kaf namespace according to your screenshots, presumably you have set this up manually and applied the configurations while in that namespace? neither the kafka or zookeeper yaml files explicitly state a namespace in metadata, so will be deployed to the active namespace when created.
anyway, the kafka deployment yaml you have is hardcoded to assume zookeeper is setup in the default namespace, with the following line:
          --override zookeeper.connect=zk-cs.default.svc.cluster.local:2181 \

change this to:
          --override zookeeper.connect=zk-cs.kaf.svc.cluster.local:2181 \

and it should connect. whether that's by downloading and locally editing the yaml file etc.
alternatively deploy zookeeper into the default namespace.
i also recommend looking at other options like bitnami kafka helm charts which deploy zookeeper as needed with kafka, manages most of the connection details and allows for easier customisation. it is also kept far more up to date.
"
50969659,is there a kubernetes cronjob kind which allows multiple schedules for a single container image?,"if one has an image with a number of different executables, is it possible to have multiple cron entries with different commands that run at different times in the same kubernetes deployment.

e.g. for some single container image named ""jolly-roger"", i want to schedule the following crontab, without having to manage 4 separate kubernetes applications in different repositories.

*/30 * * * * /pirate-bin/rehoist-the-flag
0 7,19 * * * /pirate-bin/feed-the-sharks
45 20 * * * /pirate-bin/count-the-gold
0 12 * * 1,5 /pirate-bin/make-landlubbers-walk-the-plank

",<kubernetes><kubernetes-cronjob>,50970183,19,"you can:


create a single cronjob resource with exactly one crontab time (like */30 * * * *) and several containers to run
create several cronjob resources using the same container images but different command and args for each job


you can not:


create one cron job resource with several crontab times
consequently not using multiple containers with multiple crontab times


so in short, you can place all your binaries in a single container, but cannot solve your problem by defining one resource. the way to go is to use the same image in a distinct cronjob resource per crontab line of your example
"
77164356,failure deploy ingress nginx with helm,"i use a helm to deploy cluster and include ingress chart dependency.
apiversion: v2
name: aloco
description: a helm chart for kubernetes

type: application

version: 0.1.0

appversion: &quot;1.16.0&quot;

dependencies:
  - name: ingress-nginx
    version: &quot;4.7.*&quot;
    repository: &quot;https://kubernetes.github.io/ingress-nginx&quot;

helm when deploys ingress adds aloco to the service name and ingress becomes to aloco-ingress-nginx-controller-admission because helm adds chart name.
namespace     name                                       type           cluster-ip       external-ip       port(s)                      age
default       aloco-ingress-nginx-controller             loadbalancer   10.245.104.155   159.223.250.102   80:31357/tcp,443:30712/tcp   12m
default       aloco-ingress-nginx-controller-admission   clusterip      10.245.42.135    &lt;none&gt;            443/tcp                      12m

because helm adds the chart name to the ingress, i got an error that ingress-nginx-controller-admission not found
error: upgrade failed: failed to create resource: internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: failed to call webhook: post &quot;https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=29s&quot;: service &quot;ingress-nginx-controller-admission&quot; not found

is their option to remove aloco or change validate.nginx.ingress.kubernetes.io ?
",<kubernetes><kubernetes-helm><kubernetes-ingress><nginx-ingress>,77170244,1,"this error occurs if you have another nginx ingress controller installed on your cluster and the admission webhook pod for that chart is down or erroring. or, as in your case, looks like the other service was not torn down correctly
the cause is actually in your output:
failed to call webhook: post &quot;https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=29s&quot;: service &quot;ingress-nginx-controller-admission&quot; not found

check if you have an nginx chart installed in the ingress-nginx namespace.
did you remove it manually and not via helm delete? you likely did, since that's the most common reason for leaving configs around.
to remove the webhook config that's blocking your install:
kubectl get validatingwebhookconfigurations

this will list all the validatingwebhookconfigurations. there should be one in there labelled ingress-nginx-admission or similar.
edit it or use jq (or use -o jsonpath) to make sure its the one pointing at your removed service (you'll see the service the config points to under webhooks[0].clientconfig.service
kubectl edit validatingwebhookconfiguration {name of config}

or
kubectl get validatingwebhookconfigurations {name of config} -o json | jq .webhooks[0].clientconfig.service

if it is the one that is pointing at the deleted service, you can remove it
kubectl delete validatingwebhookconfiguration -n {namespace} {name of config}

"
59553001,kubernetes service selector used to select another service and not deployment?,"i just want to know, is it possible to refer to a service rather than a deployment (using service labels instead of deployment matchlabels) in a kubernetes service definition?
what i mean to say is suppose i have a service a defined which exposes a deployment a-d and now i want to define another service b but this time instead of its selector referring to a deployment a-d i want it to point to the previous service defined i.e. service a? is this even possible in kubernetes? for eg see the scenario below

**deployment a-d**
apiversion: apps/v1
kind: deployment
metadata:
  name: my-nginx
spec:
  selector:
    matchlabels:
      run: my-nginx
  replicas: 2
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      containers:
      - name: my-nginx
        image: nginx
        ports:
        - containerport: 80

**servicea**
apiversion: v1
kind: service
metadata:
  name: my-nginx
  labels:
    run: my-nginx-1
spec:
  ports:
  - port: 80
    protocol: tcp
  selector:
    run: my-nginx

**serviceb**
apiversion: v1
kind: service
metadata:
  name: my-nginx-wrapper-service
  labels:
    run: my-nginx-2
spec:
  ports:
  - port: 80
    protocol: tcp
  selector:
    run: my-nginx-1  //service label instead of deployment


update:

headless service
    apiversion: v1
    kind: service
    metadata:
      name: access-service
      annotations:
        getambassador.io/config: |
          ---
          apiversion: ambassador/v1
          kind: mapping
          name: productreadservice-mapping
          prefix: /apps/productreadservice/.*
          prefix_regex: true
          rewrite: """"
          service: access-service:80
    spec:
      clusterip: none
      ports:
      - name: http
        port: 80
        targetport: 8082

endpoint object
apiversion: v1
kind: endpoints
metadata:
  name: access-service
subsets:
- addresses:
  - ip: ip of the service i wish to access
  ports:
  - port: 8082
    protocol: tcp

",<kubernetes><kubernetes-service><kubernetes-deployment>,59554340,2,"yes, it is possible! not through selectors though.

ones you have the service pointing to the pods a-d, you have an ip address. you can create an endpoints object  with that ip address. then, you can create a headless service without selectors with the same name as the endpoints object.

example:

say your service ip address (the one pointing to the depoyments a-d) is 10.0.0.10. create the endpoints object:

apiversion: v1
kind: endpoints
metadata:
  name: my-headless-service
subsets:
- addresses:
  - ip: 10.0.0.10
  ports:
  - port: 80
    protocol: tcp


now, create the headless service with the same name as the endpointsobject. note that it has no label selectors, so it is not selecting any backend. when this happens, the request is send to the dns, and there it will search for  either en externalname type service with the same name or an endpoints object with the same name.

apiversion: v1
kind: service
metadata:
  name: my-headless-service
spec:
  clusterip: none
  ports:
  - name: http
    port: 80
    targetport: 80


the resolution happens at dns, not at iptables.
"
46783160,"how to change the severity level (info, error, warning, etc.) of log message in fluentd based on some keyword in the log payload?","i really hope somebody would help me out with this question, as i have been trying to figure it out for days.

i have container running in kubernetes in gke. in /var/log/containers/my_container.log, i have something like this (among some other logs with different formats):

{""log"":""17-oct-2017;04:36:29.744 : [main] [server:] [id:] [yt:] error no.myproject.service.server - call failed for some reason\n"",""stream"":""stdout"",""time"":""2017-10-17t04:36:29.750702216z""}


this log appears on stackdriver (fluentd output in gke) as info log and like:

23:02:32.000 17-oct-2017;04:36:29.744 : [main] [server:] [id:] [yt:] error no.myproject.service.server - call failed for some reason


so

23:02:32.000 


is added to it (which is the normal behavior of stackdriver). i will refer to this format as format 2. 

as this log message actually is an error log message (based on its payload content) i want it to appear as error in stackdriver (fluentd).

i am trying:

&lt;filter reform.**&gt;
  type parser
  format /^(?&lt;time&gt;\d{2} [^\s]*) : (?&lt;message2&gt;[^ \]]*)\] (?&lt;message3&gt;[^ \]]*)\] (?&lt;message4&gt;[^ \]]*)\] (?&lt;message5&gt;[^ \]]*)\] (?&lt;severity&gt;\w)\s+(?&lt;log2222&gt;.*)/
  reserve_data true
  suppress_parse_error_log false
  key_name log
&lt;/filter&gt;


hoping to get the severity of the message change to error and also getting the content of the [..] fields in the log as some new key/values (in this case message2: main, etc).

but after adding this filter to my config file, the output logs are still as before and i don't see any change.

what am i missing? when i am writting my regex pattern, i am not sure if i actually should consider the ""log"" field of the message in the log file in kubernetes or the one that i called format 2 (with the time added to it - on stackdriver).

i would really appreciate any advice, it would be a great help.
",<regex><logging><kubernetes><fluentd><google-kubernetes-engine>,46787605,1,"i don't know the tool you're using, but it looks like first part of your regex does not match the exact format of the prefixed time in your log string.

actually \d{2} will only match 2 digits.

to match the entire time prefix you may use (?:\d{2}:){2}\d{2}\.\d{3} instead.

one additional point regarding severity: you wrote (?&lt;severity&gt;\w) which captures only one word character. you may use (?&lt;severity&gt;\w+) to match several characters.

your regex would then become:

^(?&lt;time&gt;(?:\d{2}:){2}\d{2}\.\d{3} [^\s]*) : (?&lt;message2&gt;[^ \]]*)\] (?&lt;message3&gt;[^ \]]*)\] (?&lt;message4&gt;[^ \]]*)\] (?&lt;message5&gt;[^ \]]*)\] (?&lt;severity&gt;\w+)\s+(?&lt;log2222&gt;.*)


that demo shoes a match.
"
62930043,"getting ""x509: certificate signed by unknown authority"" by microk8s","i would like to use microk8s with private registry, but pull image is not working (i'm using self-signed cert):
root@master-1:/var/snap/microk8s/common/var/lib/containerd# microk8s.ctr --debug images pull priv.repo:5000/busybox/hellomicrok8s:latest
debu[0000] fetching                                      image=&quot;priv.repo:5000/busybox/hellomicrok8s:latest&quot;
debu[0000] resolving                                     host=&quot;priv.repo:5000&quot;
debu[0000] do request                                    host=&quot;priv.repo:5000&quot; request.header.accept=&quot;application/vnd.docker.distribution.manifest.v2+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.oci.image.index.v1+json, */*&quot; request.header.user-agent=containerd/v1.3.4 request.method=head url=&quot;https://priv.repo:5000/v2/busybox/hellomicrok8s/manifests/latest&quot;
ctr: failed to resolve reference &quot;priv.repo:5000/busybox/hellomicrok8s:latest&quot;: failed to do request: head &quot;https://priv.repo:5000/v2/busybox/hellomicrok8s/manifests/latest&quot;: x509: certificate signed by unknown authority

here is my containerd-template.tom:
root@master-1:/var/snap/microk8s/common/var/lib/containerd# cat /var/snap/microk8s/current/args/containerd-template.toml
version = 2
oom_score = 0

[grpc]
  uid = 0
  gid = 0
  max_recv_message_size = 16777216
  max_send_message_size = 16777216

[debug]
  address = &quot;&quot;
  uid = 0
  gid = 0

[metrics]
  address = &quot;127.0.0.1:1338&quot;
  grpc_histogram = false

[cgroup]
  path = &quot;&quot;

[plugins.&quot;io.containerd.grpc.v1.cri&quot;]

  stream_server_address = &quot;127.0.0.1&quot;
  stream_server_port = &quot;0&quot;
  enable_selinux = false
  sandbox_image = &quot;k8s.gcr.io/pause:3.1&quot;
  stats_collect_period = 10
  enable_tls_streaming = false
  max_container_log_line_size = 16384

  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]
    snapshotter = &quot;${snapshotter}&quot;
    no_pivot = false
    default_runtime_name = &quot;${runtime}&quot;

    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc]
      runtime_type = &quot;io.containerd.runc.v1&quot;

    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia-container-runtime]
      runtime_type = &quot;io.containerd.runc.v1&quot;

      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia-container-runtime.options]
        binaryname = &quot;nvidia-container-runtime&quot;

  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]
    bin_dir = &quot;${snap}/opt/cni/bin&quot;
    conf_dir = &quot;${snap_data}/args/cni-network&quot;

  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]

    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors]
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]
        endpoint = [&quot;https://registry-1.docker.io&quot;, ]
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;priv.repo:5000&quot;]
        endpoint = [&quot;https://priv.repo:5000&quot;]

i restarted microk8s via systemctl restart snap.microk8s.daemon-containerd.service &amp;&amp; microk8s.stop &amp;&amp; microk8s.start.
command docker login docker https://priv.repo:5000 is working and i can pull that image via docker pull priv.repo:5000/busybox/hellomicrok8s:latest. do you know why it is not working?
thanks in advance!
edit:
this is also set:
root@master-1:/var/snap/microk8s/common/var/lib/containerd# cat /etc/docker/daemon.json
{
    &quot;insecure-registries&quot; : [&quot;priv.repo:5000&quot;]
}

edit1:
this is working: microk8s.ctr --debug images pull -u ???:??? --skip-verify priv.repo:5000/busybox/hellomicrok8s:latest. how should i set --skip-verify, because when i create a pod via microk8s kubectl apply -f ... still getting x509: certificate signed by unknown authority.
",<docker><ssl><kubernetes><kubectl><microk8s>,62950579,7,"i added my crt file to /etc/ssl/certs (on master node) and it started working.
btw newly added rows in containerd-template.tom file are not needed for me.
"
58426493,"deployment in version ""v1"" cannot be handled as a deployment:","helm install failing with the below error 

command

helm install --name helloworld helm


below is the error once i ran above command 

error: release usagemetrics failed: deployment in version ""v1"" cannot be handled as a deployment: v1.deployment.spec: v1.deploymentspec.template: v1.podtemplatespec.spec: v1.podspec.containers: []v1.container: v1.container.livenessprobe: readobjectstart: expect { or n, but found 9, error found in #10 byte of ...|ssprobe"":9001,""name""|..., bigger context ...|""imagepullpolicy"":""ifnotpresent"",""livenessprobe"":9001,""name"":""usagemetrics-helm"",""ports"":[{""containe|...


below is the deployment.yaml file i feel the issue in liveness and probeness configuration . 

apiversion: apps/v1
kind: deployment
metadata:
  name: release-name-helm
spec:
  replicas: 1
  selector:
    matchlabels:
      app: release-name-helm
      release: release-name
  template:
    metadata:
      labels:
        app: release-name-helm
        release: release-name
    spec:
      containers:
        - name: release-name-helm
          imagepullpolicy: ifnotpresent
          image: hellworld
          ports:
            - name: ""http""
              containerport: 9001
          envfrom:
            - configmapref:
                name: release-name-helm
            - secretref:
                name: release-name-helm
          livenessprobe:
            9001
          readinessprobe:
            9001

",<kubernetes><kubernetes-helm><kubernetes-deployment>,58427227,6,"the problem seems to be related to the livenessprobe and readynessprobe that are both wrong.
an example of livenessprobe of http from the documentation here is:
livenessprobe

  httpget:
    path: /healthz
    port: 8080
    httpheaders:
      - name: custom-header
        value: awesome
    initialdelayseconds: 3
    periodseconds: 3

your yamls if you only want to have a check of the port should be like:
apiversion: apps/v1
kind: deployment
metadata:
  name: release-name-helm
spec:
  replicas: 1
  selector:
    matchlabels:
      app: release-name-helm
      release: release-name
  template:
    metadata:
      labels:
        app: release-name-helm
        release: release-name
    spec:
      containers:
        - name: release-name-helm
          imagepullpolicy: ifnotpresent
          image: hellworld
          ports:
            - name: &quot;http&quot;
              containerport: 9001
          envfrom:
            - configmapref:
                name: release-name-helm
            - secretref:
                name: release-name-helm
          livenessprobe:
            tcpsocket:
              port: 9001
            initialdelayseconds: 5
            periodseconds: 10
          readinessprobe:
            tcpsocket:
              port: 9001
            initialdelayseconds: 5
            periodseconds: 10

"
63756077,jenkins application is not starting because of efs driver issue,"i have an eks cluster of 2 nodes which i created by the below command
time eksctl create cluster --name=eks-spinnaker --ssh-access=true --ssh-public-key=testkeyg --nodes=2 --region=ap-southeast-2 --write-kubeconfig=false

i then ssh to the two newly created vm and added, efs as below so i can use it for persistencevolume
sudo  yum update -y
efs_file_system_dns_name=fs-efb24ad7.efs.ap-southeast-2.amazonaws.com
sudo mkdir /efs-data
sudo mount -t nfs -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport $efs_file_system_dns_name:/ /efs-data
df -ph
cd /efs-data/
chmod -r 777 .
touch abc

i see the below on both nodes clearly:
node01
[ec2-user@ip-192-168-74-31 efs-data]$ df -ph |grep -i efs
fs-efb24ad7.efs.ap-southeast-2.amazonaws.com:/  8.0e     0  8.0e   0% /efs-data
[ec2-user@ip-192-168-74-31 efs-data]$


node02
[ec2-user@ip-192-168-21-167 efs-data]$ df -ph |grep -i efs
fs-efb24ad7.efs.ap-southeast-2.amazonaws.com:/  8.0e     0  8.0e   0% /efs-data
[ec2-user@ip-192-168-21-167 efs-data]$

i am now spinning up my jenkins as k8s deployment and to use that /efs-data as pv but having no luck.
[centos@ip-10-0-0-61 storage]$ kubectl get pv,pvc -n jenkins
name                      capacity   access modes   reclaim policy   status   claim               storageclass   reason   age
persistentvolume/efs-pv   5gi        rwx            retain           bound    jenkins/efs-claim   efs-sc                  7h6m

name                              status   volume   capacity   access modes   storageclass   age
persistentvolumeclaim/efs-claim   bound    efs-pv   5gi        rwx            efs-sc         7h6m
[centos@ip-10-0-0-61 storage]$

added helm repo and installed it
helm repo add jenkinsci https://charts.jenkins.io
helm install jenkins jenkinsci/jenkins --set rbac.create=true,master.serviceport=8081,master.servicetype=loadbalancer,persistence.existingclaim=efs-claim -n jenkins

unfortunately, the kubectl describe pods &lt;od name&gt; -n jenkins gives no clue as to what is going wrong
kubectl describe pods jenkins-c7498bcdf-4jk9w -n jenkins


events:
  type     reason       age                    from                                                        message
  ----     ------       ----                   ----                                                        -------
  warning  failedmount  26m (x6 over 117m)     kubelet, ip-192-168-21-167.ap-southeast-2.compute.internal  unable to attach or mount volumes: unmounted volumes=[jenkins-home], unattached volumes=[plugin-dir jenkins-token-xgzf4 sc-config-volume tmp jenkins-home jenkins-config plugins]: timed out waiting for the condition
  warning  failedmount  17m (x8 over 110m)     kubelet, ip-192-168-21-167.ap-southeast-2.compute.internal  unable to attach or mount volumes: unmounted volumes=[jenkins-home], unattached volumes=[plugins plugin-dir jenkins-token-xgzf4 sc-config-volume tmp jenkins-home jenkins-config]: timed out waiting for the condition
  warning  failedmount  6m12s (x11 over 128m)  kubelet, ip-192-168-21-167.ap-southeast-2.compute.internal  unable to attach or mount volumes: unmounted volumes=[jenkins-home], unattached volumes=[tmp jenkins-home jenkins-config plugins plugin-dir jenkins-token-xgzf4 sc-config-volume]: timed out waiting for the condition
  warning  failedmount  110s (x72 over 132m)   kubelet, ip-192-168-21-167.ap-southeast-2.compute.internal  mountvolume.setup failed for volume &quot;efs-pv&quot; : kubernetes.io/csi: mounter.setupat failed: rpc error: code = internal desc = could not mount &quot;fs-efb24ad7:/efs-data&quot; at &quot;/var/lib/kubelet/pods/66e53953-8678-404c-beb6-d21908cc8dee/volumes/kubernetes.io~csi/efs-pv/mount&quot;: mount failed: exit status 32
mounting command: mount
mounting arguments: -t efs fs-efb24ad7:/efs-data /var/lib/kubelet/pods/66e53953-8678-404c-beb6-d21908cc8dee/volumes/kubernetes.io~csi/efs-pv/mount
output: mount.nfs4: mounting fs-efb24ad7.efs.ap-southeast-2.amazonaws.com:/efs-data failed, reason given by server: no such file or directory


so, i ssh on one of the eks clusters where i have mounted efs, there  also i get the same errors
sep  5 16:19:17 ip-192-168-21-167 kubelet: {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2020-09-05t16:19:17.390z&quot;,&quot;caller&quot;:&quot;/usr/local/go/src/runtime/proc.go:203&quot;,&quot;msg&quot;:&quot;cni plugin version: v1.6.3 ...&quot;}
sep  5 16:19:22 ip-192-168-21-167 kubelet: {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2020-09-05t16:19:22.415z&quot;,&quot;caller&quot;:&quot;/usr/local/go/src/runtime/proc.go:203&quot;,&quot;msg&quot;:&quot;cni plugin version: v1.6.3 ...&quot;}
sep  5 16:19:22 ip-192-168-21-167 su: (to root) ec2-user on pts/0
sep  5 16:19:27 ip-192-168-21-167 kubelet: {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2020-09-05t16:19:27.440z&quot;,&quot;caller&quot;:&quot;/usr/local/go/src/runtime/proc.go:203&quot;,&quot;msg&quot;:&quot;cni plugin version: v1.6.3 ...&quot;}
sep  5 16:19:27 ip-192-168-21-167 kubelet: i0905 16:19:27.732162    3861 csi_attacher.go:310] kubernetes.io/csi: attacher.mountdevice stage_unstage_volume capability not set. skipping mountdevice...
sep  5 16:19:27 ip-192-168-21-167 kubelet: i0905 16:19:27.732616    3861 operation_generator.go:587] mountvolume.mountdevice succeeded for volume &quot;efs-pv&quot; (uniquename: &quot;kubernetes.io/csi/efs.csi.aws.com^fs-efb24ad7:/efs-data&quot;) pod &quot;jenkins-c7498bcdf-4jk9w&quot; (uid: &quot;66e53953-8678-404c-beb6-d21908cc8dee&quot;) device mount path &quot;/var/lib/kubelet/plugins/kubernetes.io/csi/pv/efs-pv/globalmount&quot;
sep  5 16:19:29 ip-192-168-21-167 kubelet: e0905 16:19:29.715185    3861 nestedpendingoperations.go:301] operation for &quot;{volumename:kubernetes.io/csi/efs.csi.aws.com^fs-efb24ad7:/efs-data podname: nodename:}&quot; failed. no retries permitted until 2020-09-05 16:21:31.715151408 +0000 utc m=+86869.996160364 (durationbeforeretry 2m2s). error: &quot;mountvolume.setup failed for volume \&quot;efs-pv\&quot; (uniquename: \&quot;kubernetes.io/csi/efs.csi.aws.com^fs-efb24ad7:/efs-data\&quot;) pod \&quot;jenkins-c7498bcdf-4jk9w\&quot; (uid: \&quot;66e53953-8678-404c-beb6-d21908cc8dee\&quot;) : kubernetes.io/csi: mounter.setupat failed: rpc error: code = internal desc = could not mount \&quot;fs-efb24ad7:/efs-data\&quot; at \&quot;/var/lib/kubelet/pods/66e53953-8678-404c-beb6-d21908cc8dee/volumes/kubernetes.io~csi/efs-pv/mount\&quot;: mount failed: exit status 32\nmounting command: mount\nmounting arguments: -t efs fs-efb24ad7:/efs-data /var/lib/kubelet/pods/66e53953-8678-404c-beb6-d21908cc8dee/volumes/kubernetes.io~csi/efs-pv/mount\noutput: mount.nfs4: mounting fs-efb24ad7.efs.ap-southeast-2.amazonaws.com:/efs-data failed, reason given by server: no such file or directory\n&quot;
sep  5 16:19:32 ip-192-168-21-167 kubelet: {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2020-09-05t16:19:32.458z&quot;,&quot;caller&quot;:&quot;/usr/local/go/src/runtime/proc.go:203&quot;,&quot;msg&quot;:&quot;cni plugin version: v1.6.3 ...&quot;}
sep  5 16:19:35 ip-192-168-21-167 dhclient[2857]: xmt: solicit on eth0, interval 111090ms.
sep  5 16:19:37 ip-192-168-21-167 kubelet: {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2020-09-05t16:19:37.477z&quot;,&quot;caller&quot;:&quot;/usr/local/go/src/runtime/proc.go:203&quot;,&quot;msg&quot;:&quot;cni plugin version: v1.6.3 ...&quot;}


the permissions on /efs-data are below:
[root@ip-192-168-21-167 ~]# ls -ld /efs-data/
drwxrwxrwx 4 root root 6144 sep  5 13:19 /efs-data/
[root@ip-192-168-21-167 ~]#


exhausted... please let me know what the issue is and how to have it resolved...
",<kubernetes><amazon-eks><eksctl>,63760550,3,"the issue is that /efs-data doesn't eactually exist in your efs drive. jenkins is trying to mount that directory (from the log outout):
-t efs fs-efb24ad7:/efs-data /var/lib/kubelet/pods/66e53953-8678-404c-beb6-d21908cc8dee/volumes/kubernetes.io~csi/efs-pv/mount

so the message:
output: mount.nfs4: mounting fs-efb24ad7.efs.ap-southeast-2.amazonaws.com:/efs-data failed, reason given by server: no such file or directory

is correct.
when you run:
sudo mount -t nfs -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport $efs_file_system_dns_name:/ /efs-data

it actually mounts / on your local /efs-data directory, but that's not the efs directory. for that to exist you can simply run:
cd /efs-data
mkdir efs-data

then /efs-data will actually exist in the efs volume.
✌️
"
55732900,is it possible to start self-signed docker registry in kubernetes and have other service use that as the registry to get its image?,"problem statement


i want to deliver a private registry which all the images i need for my product bundled in them ( yes, it will be fat image, but i am fine with that) 
i would manually upload this image in some way 
i would run the docker private registry as a service in kubernetes (probably in some namespace)
when other services/deployments (in the same namespace as registry)  happen in kubernetes, they should refer to this registry using a consistent name


constraints


we want registry to be exposed only to the cluster and not outside
we want to use self signed certificate and not signed by ca


i followed some instructions from these links (do not know whether it was a right thing to do) 


https://kubernetes.io/docs/concepts/cluster-administration/certificates/
https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/#create-a-certificate-signing-request-object-to-send-to-the-kubernetes-api


create a certificate signed through kubernetes


create a server.key 
create a csr.info


[ req ]
default_bits = 2048
prompt = no
default_md = sha256
req_extensions = req_ext
distinguished_name = dn

[ dn ]
c = us
st = oh
l = cincinnati
o = engg
ou = prod
cn = prateek.svc.cluster.local

[ req_ext ]
subjectaltname = @alt_names

[ alt_names ]
dns.1 = registry.prateek.svc.cluster.local

[ v3_ext ]
authoritykeyidentifier=keyid,issuer:always
basicconstraints=ca:false
keyusage=keyencipherment,dataencipherment
extendedkeyusage=serverauth,clientauth
subjectaltname=@alt_names



created the server.csr (openssl req -new -key server.key -out server.csr -config csr.conf)
create the certificatesigningrequest in k8s


cat &lt;&lt;eof | kubectl apply -f -
apiversion: certificates.k8s.io/v1beta1
kind: certificatesigningrequest
metadata:
name: registry.prateek
spec:
groups:
- system:authenticated
request: $(cat server.csr | base64 | tr -d '\n')
usages:
- digital signature
- key encipherment
- server auth
eof



checked if the csr exists


kubectl describe csr registry.prateek
name: registry.prateek
labels: &lt;none&gt;
annotations: kubectl.kubernetes.io/last-applied-configuration={""apiversion"":""certificates.k8s.io/v1beta1"",""kind"":""certificatesigningrequest"",""metadata"":{""annotations"":{},""name"":""registry.prateek"",""namespace"":""""},""spec"":{""groups"":[""system:authenticated""],""request"":""ls0sdfsfsdsfd="",""usages"":[""digital signature"",""key encipherment"",""server auth""]}}

creationtimestamp: thu, 11 apr 2019 11:15:42 -0400
requesting user: docker-for-desktop
status: pending
subject:
common name: prateek.svc.cluster.local
serial number:
organization: engg
organizational unit: prod
country: us
locality: cincinnati
province: oh
subject alternative names:
dns names: registry.prateek.svc.cluster.local
events: &lt;none&gt;



approved the csr : kubectl certificate approve registry.prateek


start the registry internal service


added cert and key to the kind: secret


registry-secret.yml

apiversion: v1
kind: secret
metadata:
  name: registry-credentials
data:
  certificate: &lt;certificate in base64&gt;
  key: &lt;key in base64&gt;



create registry deployment and service (using those secrets)

registry-deployment.yml


apiversion: apps/v1
kind: deployment
metadata:
  name: registry
  namespace: prateek
  labels:
      app: registry
spec:
  replicas: 1
  selector:
    matchlabels:
      app: registry
  template:
    metadata:
      labels:
        app: registry
    spec:
      containers:
        - name: registry
          image: prateek/registry
          imagepullpolicy: ifnotpresent
          ports:
            - containerport: 443
          env:
            - name: registry_http_addr
              value: ""0.0.0.0:443""
            - name: registry_http_tls_certificate
              value: ""/certs/certificate""
            - name: registry_http_tls_key
              value: ""/certs/key""
          volumemounts:
            - name: cert-files
              mountpath: /certs
      volumes:
        - name: cert-files
          secret:
            secretname: registry-credentials


registry-service.yml

apiversion: v1
kind: service
metadata:
  name: registry
  namespace: prateek
spec:
  selector:
    app: registry
  ports:
  - protocol: tcp
    port: 443
    targetport: 443
  type: loadbalancer


test regsitry service is up


tried to this the registry endpoint thru a test pod. i had image of this test pod loaded in docker already. 


curl https://registry.prateek.svc.cluster.local/v2/_catalog -k
{""repositories"":[""prateek/echo""]}


deployment using image from the registry service


tried deployment with image: registry.prateek/prateek/echo:latest


apiversion: apps/v1
kind: deployment
metadata:
  name: hello
  namespace: cequence
  labels:
      app: hello
spec:
  replicas: 1
  selector:
    matchlabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
    spec:
      containers:
      - name: hello
        image: registry.prateek/prateek/echo:latest
        imagepullpolicy: ifnotpresent
        ports:
         - containerport: 5678
        args: [""-text=hello""]



the deployment gives the error 


normal pulling 10s (x2 over 25s) kubelet, docker-for-desktop pulling image ""registry.prateek/prateek/echo:latest""
warning failed 10s (x2 over 25s) kubelet, docker-for-desktop failed to pull image ""registry.prateek/prateek/echo:latest"": rpc error: code = unknown desc = error response from daemon: get https://registry.prateek/v2/: service unavailable 



changed deployment to have image: registry.prateek.svc.cluster.local/prateek/echo:latest


apiversion: apps/v1
kind: deployment
metadata:
  name: hello
  namespace: cequence
  labels:
      app: hello
spec:
  replicas: 1
  selector:
    matchlabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
    spec:
      containers:
      - name: hello
        image: registry.prateek.svc.cluster.local/prateek/echo:latest
        imagepullpolicy: ifnotpresent
        ports:
         - containerport: 5678
        args: [""-text=hello""]



get the similar error


warning failed 1s kubelet, docker-for-desktop failed to pull image ""registry.prateek.svc.cluster.local/prateek/echo:latest"": rpc error: code = unknown desc = error response from daemon: get https://registry.prateek.svc.cluster.local/v2/: service unavailable


i do not that this is even possible. run a docker registry as a service and point other service in the namespace to use that registry deployment in the cluster. any suggestion is welcome
",<docker><kubernetes><kubectl><docker-registry><kubelet>,55733318,4,"the container daemon is running outside of kubernetes.

therefore, if you want to pull the image, you need to make sure that the registry is reachable from the node directly, without using kubernetes mechanisms like a service. (not like you tested it in step 9 through a pod, you must be able to work directly on the node!)

the usual options are to create a dns entry or hosts.txt entry to point to a node where either through a hostport (container) or nodeport (service) the registry is accessible or you use an appropriate ingress.
"
48084506,how to import state created on another server?,"i setup my kubernetes cluster using kops, and i did so from local machine.  so my .kube directory is stored on my local machine, but i setup kops for state storage in s3.
i'm in the process of setting up my ci server now, and i want to run my kubectl commands from that box. how do i go about importing the existing state to that server?
",<kubernetes><kubectl><kops>,48086832,18,"to run kubectl command, you will need the cluster's apiserver url and related credentials for authentication. those data are by convention stored in ~/.kube/config file. you may also view it via kubectl config view command.

in order to run kubectl on your ci server, you need to make sure the ~/.kube/config file contains all the information that kubectl client needs. 

with kops, a simple naive solution is to:

1) install kops, kubectl on your ci server

2) config the aws access credential on your ci server (either via iam role or simply env vars), make sure it has access to your s3 state store path

3) set env var for kops to access your cluster:

  export name=${your_cluster_name}
  export kops_state_store=s3://${your_cluster_kops_state_store}


4) use kops export command to get the kubecfg needed for running kubectl

  kops export kubecfg ${your_cluster_name}


see https://github.com/kubernetes/kops/blob/master/docs/cli/kops_export.md

now the ~/.kube/config file on your ci server should contain all the information kubectl needs to access your cluster.

note that this will use the default admin account on your ci server. to implement a more secure ci/cd environment, you should create a service account bind to a required permission scope (a namespace or type or resources for example), and place its credential on your ci server machine.
"
65851775,how can i set up an ingress to connect to a clusterip service?,"objective
i am have deployed apache airflow on aws' elastic kubernetes service using airflow's stable helm chart. my goal is to create an ingress to allow others to access the airflow webserver ui via their browser. it's worth mentioning that i am deploying on eks using aws fargate. my experience with kubernetes is somewhat limited, and i have not set an ingress myself before.
what i have tried to do
i am currently able to connect to the airflow web-server pod via port-forwarding (like kubectl port-forward airflow-web-pod 8080:8080). i have tried setting the ingress through the helm chart (documented here). after which:
running kubectl get ingress -n dp-airflow i got:
name             class    hosts                      address   ports   age
airflow-flower   &lt;none&gt;   foo.bar.com             80      3m46s
airflow-web      &lt;none&gt;   foo.bar.com             80      3m46s

then running kubectl describe ingress airflow-web -n dp-airflow i get:
name:             airflow-web
namespace:        dp-airflow
address:
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host                      path  backends
  ----                      ----  --------
  foo.bar.com
                            /airflow   airflow-web:web (&lt;redacted_ip&gt;:8080)
annotations:                meta.helm.sh/release-name: airflow
                            meta.helm.sh/release-namespace: dp-airflow

i am not sure what did i need to put into the browser, so i have tried using http://foo.bar.com/airflow as well as the cluster endpoint/ip without success.
this is how the airflow webservice service looks like:
running kubectl get services -n dp-airflow, i get:
name          type        cluster-ip       external-ip   port(s)    age
airflow-web   clusterip   &lt;redacted_ip&gt;   &lt;none&gt;        8080/tcp   28m

other things i have tried
i have tried creating an ingress without the helm chart (i am using terraform), like:
resource &quot;kubernetes_ingress&quot; &quot;airflow_ingress&quot; {
  metadata {
    name = &quot;ingress&quot;
  }

  spec {
    backend {
      service_name = &quot;airflow-web&quot;
      service_port = 8080
    }

    rule {
      http {
        path {
          backend {
            service_name = &quot;airflow-web&quot;
            service_port = 8080
          }
          path = &quot;/airflow&quot;
        }
      }
    }
  }
}

however i was still not able to connect to the web ui. what are the steps that i need to take to set up an ingress? which address do i need to use in my browser to connect to the web ui?
i am happy to provide further details if needed.
",<amazon-web-services><kubernetes><kubernetes-ingress><amazon-elb><amazon-eks>,65851900,8,"it sound like you have created ingress resources. that is a good step. but for those ingress resources to have any effect, you also need an ingress controller than can realize your ingress to an actual load balancer.
in an aws environment, you should look at aws load balancer controller that creates an aws application load balancer that is configured according your ingress resources.

ingress to connect to a clusterip service?

first, the default load balancer is classic load balancer, but you probably want to use the newer application load balancer to be used for your ingress resources, so on your ingress resources add this annotation:
annotations:
    kubernetes.io/ingress.class: alb

by default, your services should be of type nodeport, but as you request, it is possible to use clusterip services as well, when you on your ingress resource also add this annotation (for traffic mode):
alb.ingress.kubernetes.io/target-type: ip

see the alb ingress documentation for more on this.
"
78050661,deploy elasticsearch with url and open port,"i use this yml file to deploy elasticsearch on kubernetes:
apiversion: apps/v1
kind: deployment
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  selector:
    matchlabels:
      app: elasticsearch
  replicas: 1
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:5.6.16
        resources:
          requests:
            memory: 2gi
          limits:
            memory: 4gi
        ports:
        - containerport: 9200
        - containerport: 9300
        env:
        - name: discovery.type
          value: single-node
        - name: cluster.name
          value: elasticsearch
        - name: node.name
          value: node-1

how i can set permanent internal url which can be used to access the elasticsearch pod from another pod.
i can make this successfully this request on port 9200:
 curl -x get 10.233.75.8:9200
{
  &quot;name&quot; : &quot;uzspw5e&quot;,
  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,
  &quot;cluster_uuid&quot; : &quot;ib59izzdrtypcaz3nhbcgw&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;5.6.16&quot;,
    &quot;build_hash&quot; : &quot;3a740d1&quot;,
    &quot;build_date&quot; : &quot;2019-03-13t15:33:36.565z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;6.6.1&quot;
  },
  &quot;tagline&quot; : &quot;you know, for search&quot;
}

but port 9300 is not working:
curl -x get 10.233.75.8:9300
curl: (7) failed to connect to 10.233.75.8 port 9300: connection refused

do you know how i can open this port?
",<elasticsearch><kubernetes><kubernetes-deployment>,78051044,2,"if you need to access the elasticsearch service from another pod, consider creating a kubernetes service object that targets your elasticsearch deployment. this will provide a stable endpoint (the service’s clusterip) that other pods can use to access the elasticsearch api on port 9200.
here’s an example of how you might define such a service:
apiversion: v1
kind: service
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  selector:
    app: elasticsearch
  ports:
    - protocol: tcp
      port: 9200
      targetport: 9200

with this service in place, other pods should be able to access the elasticsearch api via http://elasticsearch:9200.
"
71598131,kubernetes networking confusion on google cloud,"i'm fairly new to kubernetes and i have played around with it for a few days now to get a feeling for it. trying out to set up an nginx ingress controller on the google-cloud platform following this guide, i was able to set everything up as written there - no problems, i got to see the hello-app output.
however, when i tried replicating this in a slightly different way, i encountered a weird behavior that i am not able to resolve. instead of using the image --image=gcr.io/google-samples/hello-app:1.0 (as done in the tutorial) i wanted to deploy a standard nginx container with a custom index page to see if i understood stuff correctly. as far as i can tell, all the steps should be the same except for the exposed port: while the hello-app exposes port 8080 the standard port for the nginx container is 80. so, naively, i thought exposing (i.e., creating a service) with this altered command should do the trick:
kubectl expose deployment hello-app --port=8080 --target-port=80

where instead of having target-port=8080 as for the hello-app, i put target-port=80. as far as i can tell, all other thins should stay the same, right? in any way, this does not work and when i try to access the page i get a &quot;404 - not found&quot; although the container is definitely running and serving the index page (i checked by using port forwarding from the google cloud which apparently directly makes the page accessible for dev purposes). in fact, i also tried several other combinations of ports (although i believe the above one should be the correct one) to no avail. can anyone explain to my why the routing does not work here?
",<kubernetes><google-cloud-platform><network-programming><kubernetes-ingress><ingress-controller>,71599508,2,"if you notice the tutorial inside the ingress configuration path: &quot;/hello&quot;
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress-resource
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
spec:
  rules:
  - host: &quot;34.122.88.204.nip.io&quot;
    http:
      paths:
      - pathtype: prefix
        path: &quot;/hello&quot;
        backend:
          service:
            name: hello-app
            port:
              number: 8080

you might have updated port number and service name config however if path /hello which means you request is going to nginx container but not able to file the page hello.html so it's giving you 404.

you hit endpoint ip/hello (goes to nginx ingress controller)--&gt;
checked for path /hello and forwarded request to service --&gt;
hello-app (service forwarded request to pods) --&gt; nginx pod (it
doesn't have anything at path /hello so 404)

404 written by nginx side, in your case either it will be nginx ingress controller or else container(pod) itself.
so try you ingress config without setting path path: &quot;/&quot; and hit the endpoint you might see the output from nginx.
"
77284432,how to install loki on minikube,"i'm installing loki on my kubernetes minikube instance.
when i look at my pods i get one running out of three:
default       loki-write-0                                  1/1     running       0          83m
default       loki-write-1                                  0/1     pending       0          83m
default       loki-write-2                                  0/1     pending       0          83m

logs on the running pod gives:
at least 1 live replicas required, could only find 0 - unhealthy instances

describe gives on the running pod:
readiness probe failed: http probe failed with statuscode: 503

describe on the dead pods:
0/1 nodes are available: 1 node(s) didn't match pod anti-affinity rules. preemption: 0/1 nodes are available: 1 no preemption victims found for incoming pod..

so as you can see, it wants 3 pods but the affinity cannot be satisfied because i'm running minikube which is one node.
how do i tell loki to run one instance only?
i have this variables.yaml file that specified one pod replication_factor: 1:
cat values.yaml 
loki:
  auth_enabled: false
  commonconfig:
    replication_factor: 1
  storage:
    bucketnames:
      chunks: chunks
      ruler: ruler
      admin: admin
    type: s3
    minio:
      enabled: true
  singlebinary:
    replicas: 1

but as you can see it still makes 3 pods anyways.
how do i tell it to make one pod and give that pod the affinity:
  nodeselector:
    kubernetes.io/hostname: minikube


here is the helm file i used to install loki:
helm repo add grafana https://grafana.github.io/helm-charts
helm install --values values.yaml loki grafana/loki

and here is where i got the instruction in the first place.
",<kubernetes><kubernetes-helm><grafana><grafana-loki>,77290291,2,"the pods you listed in your question belong to the loki-write statefulset, which is controlled by a different parameter in the chart, namely write.replicas (see this reference in the chart code).
once you change this parameter to 1 a single replica of the write statefulset should be scheduled.
"
49858027,cannot query kubernetes (unauthorized): endpoints is forbidden: user cannot list endpoints in the namespace,"i am running kubernetes 1.9.4 on my gke cluster

i have two pods , gate which is trying to connect to coolapp, both written in elixir

i am using libcluster to connect my nodes
i get the following error:

[libcluster:app_name] cannot query kubernetes (unauthorized): endpoints is forbidden: user ""system:serviceaccount:staging:default"" cannot list endpoints in the namespace ""staging"": unknown user ""system:serviceaccount:staging:default""

here is my config in gate under config/prod:

 config :libcluster,
 topologies: [
   app_name: [
     strategy: cluster.strategy.kubernetes,
     config: [
       kubernetes_selector: ""tier=backend"",
       kubernetes_node_basename: system.get_env(""my_pod_namespace"") || ""${my_pod_namespace}""]]]


here is my configuration:

vm-args

## name of the node
-name ${my_pod_namespace}@${my_pod_ip}
## cookie for distributed erlang
-setcookie ${erlang_cookie}
# enable smp automatically based on availability
-smp auto


creating the secrets:

kubectl create secret generic erlang-config --namespace staging --from-literal=erlang-cookie=xxxxxx
kubectl create configmap vm-config --namespace staging --from-file=vm.args


gate/deployment.yaml

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: gate
  namespace: staging
spec:
  replicas: 1
  revisionhistorylimit: 1
  strategy:
      type: rollingupdate
  template:
    metadata:
      labels:
        app: gate
        tier: backend
    spec:
      securitycontext:
        runasuser: 0
        runasnonroot: false
      containers:
      - name: gate
        image: gcr.io/development/gate:0.1.7
        args:
          - foreground
        ports:
        - containerport: 80
        volumemounts:
        - name: config-volume
          mountpath: /beamconfig
        env:
        - name: my_pod_namespace
          value: staging
        - name: my_pod_ip
          valuefrom:
            fieldref:
              fieldpath: status.podip
        - name: my_pod_name
          valuefrom:
            fieldref:
              fieldpath: metadata.name
        - name: release_config_dir
          value: /beamconfig
        - name: erlang_cookie
          valuefrom:
            secretkeyref:
              name: erlang-config
              key: erlang-cookie
      volumes:
      - name: config-volume
        configmap:
          name: vm-config


coolapp/deployment.yaml:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: coolapp
  namespace: staging
spec:
  replicas: 1
  revisionhistorylimit: 1
  strategy:
      type: rollingupdate
  template:
    metadata:
      labels:
        app: coolapp
        tier: backend
    spec:
      securitycontext:
        runasuser: 0
        runasnonroot: false
     # volumes
      volumes:
      - name: config-volume
        configmap:
          name: vm-config
      containers:
      - name: coolapp
        image: gcr.io/development/coolapp:1.0.3
        volumemounts:
        - name: secrets-volume
          mountpath: /secrets
          readonly: true
        - name: config-volume
          mountpath: /beamconfig
        ports:
        - containerport: 80
        args:
          - ""foreground""
        env:
        - name: my_pod_namespace
          value: staging
        - name: my_pod_ip
          valuefrom:
            fieldref:
              fieldpath: status.podip
        - name: my_pod_name
          valuefrom:
            fieldref:
              fieldpath: metadata.name
        - name: replace_os_vars
          value: ""true""
        - name: release_config_dir
          value: /beamconfig
        - name: erlang_cookie
          valuefrom:
            secretkeyref:
              name: erlang-config
              key: erlang-cookie
        # proxy_container
      - name: cloudsql-proxy
        image: gcr.io/cloudsql-docker/gce-proxy:1.11
        command: [""/cloud_sql_proxy"", ""--dir=/cloudsql"",
            ""-instances=staging:us-central1:com-staging=tcp:5432"",
            ""-credential_file=/secrets/cloudsql/credentials.json""]
        volumemounts:
          - name: cloudsql-instance-credentials
            mountpath: /secrets/cloudsql
            readonly: true
          - name: cloudsql
            mountpath: /cloudsql

",<erlang><kubernetes><elixir><google-kubernetes-engine>,49859497,5,"the default service account for the staging namespace (in which apparently your pods using libcluster are running) lacks rbac permissions to get endpoints in that namespace.

likely your application requires a number of other permissions (that are not mentioned in the above error message) to work correctly; identifying all such permissions is out of scope for so.

a way to resolve this issue is to grant superuser permissions that service account. this is not a secure solution but a stop gap fix.

$ kubectl create clusterrolebinding make-staging-sa-cluster-admin \
    --serviceaccount=staging:default \
    --clusterrole=cluster-admin

clusterrolebinding ""make-staging-sa-cluster-admin"" created


to grant the specific permission only (get endpoints in the staging namespace) you would need to create a role first:

apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  name: some-permissions
  namespace: staging
rules:
- apigroups: [""""]
  resources: [""endpoints""]
  verbs: [""get"", ""list"", ""watch""]


and create a rolebinding for the default service account in the staging namespace:

apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: give-default-sa-some-permissions
  namespace: staging
subjects:
- kind: serviceaccount
  name: default
  namespace: staging
roleref:
  kind: role
  name: some-permissions
  apigroup: rbac.authorization.k8s.io

"
63191191,do services send traffic to local pods first?,"i have a daemonset with a service pointing to it.
when a pod will access the clusterip of the my service, will it get the local pod running on the same node or any pod in the service?
is there any way to achieve this? my understanding is that it would be the same thing than externaltrafficpolicy: local but for internal traffic.
",<kubernetes><kubernetes-service><kubernetes-networking>,63191313,3,"
by default, traffic sent to a clusterip or nodeport service may be routed to any backend address for the service. since kubernetes 1.7 it has been possible to route &quot;external&quot; traffic to the pods running on the node that received the traffic, but this is not supported for clusterip services, and more complex topologies — such as routing zonally — have not been possible. the service topology feature resolves this by allowing the service creator to define a policy for routing traffic based upon the node labels for the originating and destination nodes.

you need to use: service topology
an example service which prefers local pods:
apiversion: v1
kind: service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: tcp
      port: 80
      targetport: 9376
  topologykeys:
    - &quot;kubernetes.io/hostname&quot;
    - &quot;*&quot;


upd 1:
there is another option to make sure, that requests sent to a port of some particular node will be handled on the same node - it's hostport.
an example:
kind: pod
apiversion: v1
metadata:
  name: test-api
  labels:
    app: test-api
spec:
  containers:
  - name: testapicontainer
    image: myprivaterepo/testapi:latest
    ports:
    - name: web
      hostport: 55555
      containerport: 80      
      protocol: tcp

the above pod will expose container port 80 on a hostport: 55555 - if you have daemonset for those pods - then you can be sure, that they will be run on each node and each request will be handled on the node which received it.
but, please be careful using it and read this: configuration best practices
"
66434505,why must i explicitly set a namespace for the serviceaccount of clusterrolebinding.rbac.authorization.k8s.io resource?,"i'm deploying my chart with helm like this:
helm upgrade --install --namespace newnamespace --create-namespace testing mychart

my understanding is everything should be deployed into newnamespace
i have this in my chart:
apiversion: v1
kind: serviceaccount
metadata:
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}

---
apiversion: rbac.authorization.k8s.io/v1beta1
kind: clusterrole
metadata:
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}
rules:
- apigroups: [&quot;&quot;]
  resources: [&quot;services&quot;,&quot;endpoints&quot;,&quot;pods&quot;]
  verbs: [&quot;get&quot;,&quot;watch&quot;,&quot;list&quot;]
- apigroups: [&quot;extensions&quot;,&quot;networking.k8s.io&quot;]
  resources: [&quot;ingresses&quot;] 
  verbs: [&quot;get&quot;,&quot;watch&quot;,&quot;list&quot;]
- apigroups: [&quot;&quot;]
  resources: [&quot;nodes&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]

---
apiversion: rbac.authorization.k8s.io/v1beta1
kind: clusterrolebinding
metadata:
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}
subjects:
- kind: serviceaccount
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}

when deployed i get this error:
error: clusterrolebinding.rbac.authorization.k8s.io &quot;my-service-account&quot; is invalid: subjects[0].namespace: required value

then i add this and the deploy works:
...
    subjects:
    - kind: serviceaccount
      name: {{ include &quot;mychart.serviceaccountname&quot; . }}
      namespace: {{ .release.namespace }}

why is this? what is this requirement of clusterrolebinding? i can't it see the namespace where it's being deployed?
is it because clusterrolebinding is cluster wide it must have the namespace defined in its definition? are clusterrolebinding resources not created in any namespaces? if so where do they live kube-system?
does this mean that if i deleted the namespace containing my helm release before doing a helm uninstall the clusterrolebinding would be left behind?
",<kubernetes><kubernetes-helm>,66435039,3,"clusterrolebinding binds the clusterrole with you service account. clusterrolebinding gives the access in cluster-wide. in cluster role you basically tell that what actions can your service account perform. a clusterrole is a set of permissions that can be assigned to resources within a given cluster.
now by clusterrolebinding you are just binding the clusterrole with your service account, as service account is a namespace scoped object so you must need to provide the namespace name in your subject as you did in the second part.
btw, clusterrole is a non-namespaced resource. as far the k8s docs, you can use a clusterrole to:

define permissions on namespaced resources and be granted within individual namespace(s)
define permissions on namespaced resources and be granted across all namespaces
define permissions on cluster-scoped resources

another thing will also work is adding the apigroup like   apigroup: rbac.authorization.k8s.io.
when you created service account you created in basically in default namespace as it is the default thing, here:
apiversion: v1
kind: serviceaccount
metadata:
  name: {{ include &quot;mychart.serviceaccountname&quot; . }}

as your last question, clusterrole is cluster-scoped but clusterrolebinding and service account is namespace scoped and as far the rules if you delete a namespace then all the object of that namespace will be gone along with the namespace.
you can see the k8s doc for getting more clear idea.
i found another good tuto
"
55410470,adding news lines when defining collection,"i am trying to define a collection (dict), and i would like to add a new line on each definition (for readability), eg:

{{ $deployment := dict 
""release"" .release 
""chart"" .chart 
""values"" .values }}


but when i do this, helm respond a parse error : 

error: parse error in ""xxx"": template: xxx:2: unclosed action
error: upgrade failed: parse error in ""xxx"": template: xxx:2: unclosed action


is there a way in helm to do this?
",<kubernetes><yaml><kubernetes-helm>,55420914,1,"tldr;

it's impossible to declare dict in multiline way, like with perl fat comma operator. 
please check the reference of ""sprig: template functions for go templates.""

instead you could use this sort of hacky way to achieve similar result:


keep each key value pair in separate line, in global values file for readability:




# values.yaml
  -- 
  global:
  somemap:
    coffee: robusta
    origin: angola
    crema: yes





define helper template in _helpers.tpl:




{{- define ""mychart.labels.standard""}}
{{- $global := default (dict) .values.global.somemap -}}
release: {{ .release.name | quote }}
chart: {{ .chart.name }}
values:
{{- $global := default (dict) .values.global.somemap -}} 
{{- range $key, $value := $global }}
  {{ $key }}: {{ $value }}
{{- end }}
{{- end -}}





include it in another template:




helm_data:
  {{- $global := default (dict) .values.global -}}
  {{- range $key, $value := $global }}
    {{ $key }}: {{ $value }}
  {{- end }}
  {{ include ""mychart.labels.standard"" . | nindent 0 -}}





render it to verify the result (helm template --name dict-chart .)




---
# source: mychart/templates/data_type.yaml
helm_data:
    somemap: map[crema:true origin:angola coffee:robusta]
  
release: ""dict-chart""
chart: mychart
values:
    coffee: robusta
    crema: true
    origin: angol



"
68200635,how to delete every pod in a kubernetes namespace,"take this scenario:

i want to delete every running pod automatically using the commandline without having to type kubectl delete pod &lt;pod_name&gt; -n &lt;namespace&gt; for each pod.
",<linux><bash><shell><kubernetes><kubectl>,68203185,7,"you can use awk to filter pod names based on their status==running. below code will delete all(in running state) the pods from $namespace namespace.
 kubectl  get pod -n $namespace|awk '$3==&quot;running&quot;{print $1}'

example:
for pod in $(kubectl  get pod -n $namespace |awk '$3==&quot;running&quot;{print $1}'); do
    kubectl delete pod -n $namespace $pod
done

or
you may use jsonpath,
namespace=mynamespace
for pod in $(kubectl  get pod -n $namespace -o jsonpath='{.items[?(@.status.phase==&quot;running&quot;)].metadata.name}{&quot;\n&quot;}'); do
    kubectl delete pod -n $namespace &quot;$pod&quot;
done

note: above code will cause deletion of all the pods in $namespace variable.
example:
kubectl get pod -n mynamespace
name        ready   status      restarts   age
foo-mh6j7   0/1     completed   0          5d3h
nginx       1/1     running     2          7d10h
mongo       2/2     running     12         57d
busybox     1/1     running     187        61d

jsonpath query to print all pods in running state:
kubectl  get pod -n mynamespace -o jsonpath='{.items[?(@.status.phase==&quot;running&quot;)].metadata.name}{&quot;\n&quot;}'
nginx mongo busybox

although, you have not asked for ready state, but following query can be used to list pods in ready state.
kubectl  get pod -n mynamespace -o jsonpath='{range .items[*]}{.status.containerstatuses[*].ready.true}{.metadata.name}{ &quot;\n&quot;}{end}'
foo-mh6j7
nginx
mongo
busybox

similarly, this can be done via grep:
kubectl get pod -n $namespace |grep -p '\s+([1-9]+)\/\1\s+'

note: either of the solution will not prevent pods from getting respawned if they are created via replicaset or deployment  or statefulset etc. this means, they will get deleted and respawned.
"
61266532,configmap mounted on persistent volume claims,"in my deployment, i would like to use a persistent volume claim in combination with a config map mount. for example, i'd like the following:

volumemounts:
    - name: py-js-storage
        mountpath: /home/python
    - name: my-config
        mountpath: /home/python/my-config.properties
        subpath: my-config.properties
        readonly: true
...
    volumes:
    - name: py-storage
    {{- if .values.py.persistence.enabled }}
        persistentvolumeclaim:
        claimname: python-storage
    {{- else }}
        emptydir: {}
    {{- end }}


is this a possible and viable way to go? is there any better way to approach such situation? 
",<kubernetes><kubernetes-helm>,61272839,9,"since you didn't give your use case, my answer will be based on if it is possible or not. in fact: yes, it is.

i'm supposing you wish mount file from a configmap in a mount point that already contains other files, and your approach to use subpath is correct!

when you need to mount different volumes on the same path, you need specify subpath or the content of the original dir will be hidden.

in other words, if you want to keep both files (from the mount point and from configmap) you must use subpath.

to illustrate this, i've tested with the deployment code below. there i mount the hostpath /mnt that contains a file called filesystem-file.txt in my pod and the file /mnt/configmap-file.txt from my configmap test-pd-plus-cfgmap:


  note: i'm using kubernetes 1.18.1


configmap:

apiversion: v1
kind: configmap
metadata:
  name: test-pd-plus-cfgmap
data:
  file-from-cfgmap: file data


deployment:


apiversion: apps/v1
kind: deployment
metadata:
  name: test-pv
spec:
  replicas: 3
  selector:
    matchlabels:
      app: test-pv
  template:
    metadata:
      labels:
        app: test-pv
    spec:
      containers:
      - image: nginx
        name: nginx
        volumemounts:
        - mountpath: /mnt
          name: task-pv-storage
        - mountpath: /mnt/configmap-file.txt
          subpath: configmap-file.txt
          name: task-cm-file
      volumes:
        - name: task-pv-storage
          persistentvolumeclaim:
            claimname: task-pv-claim
        - name: task-cm-file
          configmap:
            name: test-pd-plus-cfgmap


as a result of the deployment, you can see the follow content in /mnt of the pod:

$ kubectl exec test-pv-5bcb54bd46-q2xwm -- ls /mnt
configmap-file.txt
filesystem-file.txt


you could check this github issue with the same discussion.

here you could read a little more about volumes subpath.
"
67473802,how can i find a pod's controller (deployment/daemonset) using the kubernetes go-client library?,"with the following code, i'm able to fetch all the pods running in a cluster. how can i find the pod controller (deployment/daemonset) using the kubernetes go-client library?
var kubeconfig *string
if home := homedir.homedir(); home != &quot;&quot; {
    kubeconfig = flag.string(&quot;kubeconfig&quot;, filepath.join(home, &quot;.kube&quot;, &quot;config&quot;), &quot;(optional) absolute path to the kubeconfig file&quot;)
} else {
    kubeconfig = flag.string(&quot;kubeconfig&quot;, &quot;&quot;, &quot;absolute path to the kubeconfig file&quot;)
}
flag.parse()
// use the current context in kubeconfig
config, err := clientcmd.buildconfigfromflags(&quot;&quot;, *kubeconfig)
if err != nil {
    panic(err.error())
}

// create the kubeclient
kubeclient, err := kubernetes.newforconfig(config)
metricsclient, err := metricsv.newforconfig(config)

if err != nil {
    panic(err.error())
}

pods, err := kubeclient.corev1().pods(&quot;&quot;).list(context.todo(), metav1.listoptions{})

if err != nil {
    panic(err.error())
}

for _, pod := range pods.items {
    fmt.println(pod.name)
    // how can i get the pod controller? (deployment/daemonset)
    // e.g. fmt.println(pod.controller.name)
}

",<kubernetes><kubernetes-go-client>,67497032,4,"by following @jonas suggestion i was able to get pod's manager. here's a fully working sample:
package main

import (
    &quot;context&quot;
    &quot;flag&quot;
    &quot;fmt&quot;
    metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;
    &quot;k8s.io/client-go/kubernetes&quot;
    &quot;k8s.io/client-go/tools/clientcmd&quot;
    &quot;k8s.io/client-go/util/homedir&quot;
    &quot;path/filepath&quot;
)

func main() {
    var kubeconfig *string
    if home := homedir.homedir(); home != &quot;&quot; {
        kubeconfig = flag.string(&quot;kubeconfig&quot;, filepath.join(home, &quot;.kube&quot;, &quot;config&quot;), &quot;(optional) absolute path to the kubeconfig file&quot;)
    } else {
        kubeconfig = flag.string(&quot;kubeconfig&quot;, &quot;&quot;, &quot;absolute path to the kubeconfig file&quot;)
    }
    flag.parse()
    // use the current context in kubeconfig
    config, err := clientcmd.buildconfigfromflags(&quot;&quot;, *kubeconfig)
    if err != nil {
        panic(err.error())
    }

    // create the kubeclient
    kubeclient, err := kubernetes.newforconfig(config)

    if err != nil {
        panic(err.error())
    }

    pods, err := kubeclient.corev1().pods(&quot;&quot;).list(context.todo(), metav1.listoptions{})

    if err != nil {
        panic(err.error())
    }

    for _, pod := range pods.items {
        if len(pod.ownerreferences) == 0 {
            fmt.printf(&quot;pod %s has no owner&quot;, pod.name)
            continue
        }

        var ownername, ownerkind string

        switch pod.ownerreferences[0].kind {
        case &quot;replicaset&quot;:
            replica, reperr := kubeclient.appsv1().replicasets(pod.namespace).get(context.todo(), pod.ownerreferences[0].name, metav1.getoptions{})
            if reperr != nil {
                panic(reperr.error())
            }

            ownername = replica.ownerreferences[0].name
            ownerkind = &quot;deployment&quot;
        case &quot;daemonset&quot;, &quot;statefulset&quot;:
            ownername = pod.ownerreferences[0].name
            ownerkind = pod.ownerreferences[0].kind
        default:
            fmt.printf(&quot;could not find resource manager for type %s\n&quot;, pod.ownerreferences[0].kind)
            continue
        }

        fmt.printf(&quot;pod %s is managed by %s %s\n&quot;, pod.name, ownername, ownerkind)
    }
}

"
59553878,why does a kubernetes ingress create *two* healthchecks by default on its load balancers?,"after i create a very basic ingress (yaml below) with no special definition of health checks (nor any in other kubernetes objects), the ingress creates a  gcp load balancer. 

why does this lb have two health checks (""backend services"") defined against different nodeports, one against root path / and one against /healthz? i would expect to see only one.

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress1
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: myservice
          serviceport: 80

",<kubernetes><google-kubernetes-engine><health-monitoring>,59554289,4,"reason for / health check 

one of the limitation of gke ingress controller is below:

for the gke ingress controller to use your readinessprobes as health checks, the pods for an ingress must exist at the time of ingress creation. if your replicas are scaled to 0 or pods don't exist when the ingress is created, the default health check using / applies.

because of the above it created two health checks.

there are lot of caveats for the health-check from readiness probe to work:


the pod's containerport field must be defined
the service's targetport field must point to the pod port's
containerport value or name. note that the targetport defaults to the
port value if not defined
the pods must exist at the time of ingress creation
the readiness probe must be exposed on the port matching the
serviceport specified in the ingress
the readiness probe cannot have special requirements like headers the
probe timeouts are translated to gce health check timeouts


based on above it makes sense to have a default fallback health check using /

reason for /healthz health check

as per this faq all gce url maps require at least one default backend, which handles all requests that don't match a host/path. in ingress, the default backend is optional, since the resource is cross-platform and not all platforms require a default backend. if you don't specify one in your yaml, the gce ingress controller will inject the default-http-backend service that runs in the kube-system namespace as the default backend for the gce http lb allocated for that ingress resource.

some caveats concerning the default backend:


it is the only backend service that doesn't directly map to a user
specified nodeport service
it's created when the first ingress is created, and deleted when the
last ingress is deleted, since we don't want to waste quota if the
user is not going to need l7 loadbalancing through ingress
it has a http health check pointing at /healthz, not the default /,
because / serves a 404 by design


so gke ingress deploys a default backend service using below yaml and setup a /healthz healthcheck for that service.

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: l7-default-backend
  namespace: kube-system
  labels:
    k8s-app: glbc
    kubernetes.io/name: ""glbc""
    kubernetes.io/cluster-service: ""true""
spec:
  replicas: 1
  selector:
    matchlabels:
      k8s-app: glbc
  template:
    metadata:
      labels:
        k8s-app: glbc
        name: glbc
    spec:
      containers:
      - name: default-http-backend
        # any image is permissible as long as:
        # 1. it serves a 404 page at /
        # 2. it serves 200 on a /healthz endpoint
        image: k8s.gcr.io/defaultbackend-amd64:1.5
        livenessprobe:
          httpget:
            path: /healthz
            port: 8080
            scheme: http
          initialdelayseconds: 30
          timeoutseconds: 5
        ports:
        - containerport: 8080
        resources:
          limits:
            cpu: 10m
            memory: 20mi
          requests:
            cpu: 10m
            memory: 20mi
---
apiversion: v1
kind: service
metadata:
  # this must match the --default-backend-service argument of the l7 lb
  # controller and is required because gce mandates a default backend.
  name: default-http-backend
  namespace: kube-system
  labels:
    k8s-app: glbc
    kubernetes.io/cluster-service: ""true""
    kubernetes.io/name: ""glbcdefaultbackend""
spec:
  # the default backend must be of type nodeport.
  type: nodeport
  ports:
  - port: 80
    targetport: 8080
    protocol: tcp
    name: http
  selector:
    k8s-app: glbc

"
51200159,how to bootstrap rbac privileges when bringing up a gke cluster with terraform,"i'm bring a gke cluster up with terraform, which works nicely. i then want terraform to perform some kubernetes-level operations on the cluster (using the k8s provider) - nothing massive, just installing a couple of deployments etc.

the problem i'm having is permissions. i'd like a neat, tidy, declarative way to make a cluster and have a set of credentials in hand that i can use short-term to do ""admin"" operations on it, including bootstrapping other users. i know how to make the google user that's running tf an admin of the cluster (that question comes up a lot), but that doesn't seem very nice. not least, the k8s tf provider doesn't support clusterolebinding (issue, partial pr) so you have to ""shell out"" with a local-exec provisioner to first run gcloud container clusters get-credentials and then kubectl create clusterrolebinding ....

similarly, i don't want to set a master password, because i don't want to run with http basic auth on. the nicest option looks to be the key/cert pair that's returned by the tf gke resource, but that has a cn of ""client"", and that user has no power. so again, the only way to use it is to shell out to kubectl, pass it the gcloud service account credentials, and get it to add a clusterrolebinding for ""client"", at which point i may as well just do everything as the service account like above.

for contrast, on eks the (aws iam) user that creates the cluster has cluster-admin out of the box (i assume the aws authn provider claim's the user is in ""system:masters"").

my actual question here is: is there a neat, fully declarative way in terraform to bring up a cluster and have available (ideally as output) a potent set of credentials to use and then drop? (yes i know they'll stay in the tfstate)

my options seem to be:


""shell out"" to give tf's google id (ideally a service account) cluster-admin (which is privilege escalation, but which works due to the gcloud authz plugin)
enable http basic auth and give the admin account a password, then have an aliased k8s provisioner use that to do minimal bootstrapping of another service account.
enable abac so that ""client"" (the cn of the output key/cert) has infinite power - this is what i'm currently running with, don't judge me!


and i don't like any of them!
",<kubernetes><google-compute-engine><terraform><google-kubernetes-engine>,56177536,5,"i've been running into a similar problem, which has gotten particularly nasty since a recent kubernetes issue unexpectedly disabled basic auth by default, which broke my previously-functioning terraform configuration as soon as i tried to build a new cluster from the same config.

finally found an answer in this so answer, which recommends a method of using terraform's google iam creds to connect to the cluster without needing the ""shell out"". note that this method allows cluster permissions to be bootstrapped in terraform with no external tooling/hacks/etc and without needing to have basic auth enabled.

the relevant part of that answer is:

data ""google_client_config"" ""default"" {}

provider ""kubernetes"" {
  host     = ""${google_container_cluster.default.endpoint}""

  token = ""${data.google_client_config.default.access_token}""
  cluster_ca_certificate = ""${base64decode(google_container_cluster.default.master_auth.0.cluster_ca_certificate)}""

  load_config_file = false
}

"
59860987,kubectl config view gives empty results,"configuration is stored in ~/.kube/config. but when i use the below command it gives empty results.
 kubectl config view

output:

apiversion: v1
clusters: []
contexts: []
current-context: """"
kind: config
preferences: {}
users: []

",<kubernetes><configuration><config><kubectl><azure-aks>,59861228,5,"
just to make sure, try running kubectl config view --kubeconfig &lt;path_to_your_config_file&gt;.
make sure your $kubeconfig is empty, (or that it points at ~/.kube/config).
if you installed kubectl via snap it might possibly be a sand-boxing issue.

"
48744530,how to refresh cluster access-token in gke,"i have three clusters in google kubernetes engine, and i am trying to see kubernetes dashboard but i get the same access-token for two different clusters.

using kubectl config view command i get:

- name: gke_project_zone_a_name_a
  user:
    auth-provider:
      config:
        access-token: token-a

- name: gke_project_zone_b_name_b
  user:
    auth-provider:
      config:
        access-token: token-b

- name: gke_project_zone_c_name_c
  user:
    auth-provider:
      config:
        access-token: token-b


when gke_project_zone_b_name_b and gke_project_zone_c_name_c share the same access token, hence when i connect via kubectl proxy and insert the token i get the same the dashboard.

how i can refresh the access token for cluster b or c so i'll get the desired dashboard?

i've tried to use gcloud container clusters get-credentials cluster-c --zone zone-c --project my_project, which returns 


  fetching cluster endpoint and auth data. kubeconfig entry generated
  for cluster-c.


and afterwards i don't get any access token for cluster-c

thank you
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,49833929,1,"restarting the ui service by running kubectl proxy, entering to the ui via http://localhost:8001/ui and refreshing the page cause the access token to refresh.
"
76943081,how hpa works in eks cluster,"we are using eks cluster and helm chart for deployment. helm charts contains the template yanl files for cpu and memory.
here is the yanl file
apiversion: autoscaling/v2
kind: horizontalpodautoscaler
metadata:
  name: hpa-{{ .release.name }}-memory
  namespace: {{ .release.namespace }}
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: {{ .release.name }}
  minreplicas: 2
  maxreplicas: 4
  metrics:
  - type: resource
    resource:
      name: memory
      target:
        type: utilization
        averageutilization: 200
  behavior:
    scaledown:
      policies:
      - periodseconds: 60
        type: pods
        value: 1
      - periodseconds: 30
        type: percent
        value: 30
      selectpolicy: min
      stabilizationwindowseconds: 120
    scaleup:
      policies:
      - periodseconds: 30
        type: pods
        value: 1
      - periodseconds: 30
        type: percent
        value: 200
      selectpolicy: max
      stabilizationwindowseconds: 60

when we run the kubectl get hpa command
root@sx-in:~# kubectl get hpa -a
namespace         name                                        reference                                   targets     minpods   maxpods   replicas   age
test1   hpa-abc-cpu      deployment/abc   2%/200%     2         4         2          23d
test2   hpa-abc-memory   deployment/abc   183%/200%   2         4    

kubectl top pods shows below
root@sx-in:~# kubectl top pods -n test1
name                          cpu(cores)    memory(bytes)
abcp1-78bb67d47f-lkwwr         5m           1148mi
abcp1-78bb67d47f-vd26b         5m           917mi

i read the docs but did not understand how this 183% in memory gets calculated . can someone please explain.
i tried searching formula for same but did not get
the machine size where pods are deployed is t2.xlarge(4 cpu , 16 gb ram)
please suggest
",<kubernetes><amazon-eks><hpa>,76946872,3,"the percentage is the ratio of the pod's actual memory usage to its resource requests.  from the kubernetes hpa documentation:

for per-pod resource metrics (like cpu), the controller fetches the metrics from the resource metrics api for each pod targeted by the horizontalpodautoscaler. then, if a target utilization value is set, the controller calculates the utilization value as a percentage of the equivalent resource request on the containers in each pod.

i can't exactly reproduce the 183% number, but i can come close.  let's say your deployment specifies that your pods request 512 mib of memory, with a hard limit of 2048 mib.  the actual memory (1148, 917 mib) gets divided by the resource request to get a percentage (224%, 179%), and then those percentages get averaged across the pods (202% in this specific calculation).
that percentage then gets fed into the hpa formula to compute the new target replicas: value.
note that it looks like you have two hpas trying to manage the same deployment.  this could be problematic in an example like what you show, where you have relatively high memory but low cpu: the memory autoscaler could want to scale up, but the cpu autoscaler would want to scale down to its minimum.  you can attach multiple metrics to a single autoscaler and that would be a better setup.
"
51408636,kubernetes : dial tcp 127.0.0.1:8080: connect: connection refused,"i've launched kubernetes cluster using kops. it was working find and i started facing the following problem:

kubectl get pods
the connection to the server localhost:8080 was refused - did you specify the right host or port?


how do i solve this?
it looks like kubernetes-apiserver is not running, how do i get this working?

kubectl run nginx --image=nginx:1.10.0
error: failed to discover supported resources: get http://localhost:8080/apis/apps/v1beta1?timeout=32s: dial tcp 127.0.0.1:8080: connect: connection refused


please suggest
",<kubernetes><devops><kubectl><kops>,51409172,12,"kubernetes uses a $kubeconfig file for connecting to clusters. it may be when provisioning your kops cluster, it didn't write the file correctly. i can't be sure as you haven't provided enough info.

assuming this is the issue, and you only have a single cluster, it can be resolved like so:

# find your cluster name
kops get clusters
# set the clustername as a var
clustername=&lt;clustername&gt;
# export the kubeconfig variable, which kubectl uses to find the kubeconfig file
export kubeconfig=~/.kube/${clustername}
# download the kubeconfig file locally using kops
kops export kubecfg --name ${clustername} --config=~$kubeconfig


you can find more information about the kubeconfig file here
"
66451166,ingress hostname wont change,"i have an ingress setup and initially i used a placeholder name, &quot;thesis.info&quot;. now i would like change this hostname but whenever i to change it i just end up getting 404 errors.

change the spec.tls.rules.host value in the yaml to the new hostname
change cn value which openssl uses for the crt and key that are generated for tls
edit the value /etc/hosts value on my local machine

is there a step i am missing that could be causing a problem. i am baffled by why it works with one value but not the other.
below is the ingress yaml
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: frontend-ingress
  namespace: thesis
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/add-base-url: &quot;true&quot;
    nginx.ingress.kubernetes.io/service-upstream: &quot;true&quot;
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;
spec:
  tls:
    - hosts:
        - thesis
      secretname: ingress-tls
  rules:
    - host: pod1out.ie
      http:
        paths:
        - path: /
          pathtype: prefix
          backend:
            service:
              name: frontend
              port:
                number: 3000
---

",<kubernetes><kubernetes-ingress>,66451643,1,"most likely, you can find a hint on what is going on in the nginx logs. if you have access, you can access the logs using something like this:
kubectl -n &lt;ingress-namespace&gt; get pods 
# should be one or more nginx pods
kubectl -n &lt;ingress-namespace&gt; logs &lt;nginx-pod&gt;

not sure if this is the only issue, but according to the documentation, the host in 'tls' has to match explicitly the host in the rules:
spec:
  tls:
    - hosts:
        - pod1out.ie
      secretname: ingress-tls
  rules:
    - host: pod1out.ie

before struggling with tls, i would recommend making the http route itself work (eg. by creating another ingress resource), and if this works with the host you want, go for tls.
"
54948471,jsonpath range not working when using kubectl,"i'm accessing kubernetes through the cli tool kubectl and i'm trying to get a list of all context names, one per line.

i know that jsonpath can be used to extract and format specific output.  i get really close to what i want with

kubectl config view -o=jsonpath=""{.contexts[*].name}""


but this puts all the names on the same line.  i'm trying to use range to list all names separated by newlines:

kubectl config view -o=jsonpath='{range .contexts[*]}{.name}{""\n""}{end}'


but this just gives me an error:

error: unexpected arguments: [.contexts[*]}{.name}{""\n""}{end}]
see 'kubectl config view -h' for help and examples.


i've reviewed the kubectl documentation and what i'm doing is really similar to https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-containers-by-pod, where the command is

kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{""\n""}{.metadata.name}{"":\t""}{range .spec.containers[*]}{.image}{"", ""}{end}{end}' |\
sort


but i can't see where i'm going wrong.
",<kubernetes><kubectl><jsonpath>,54953592,1,"i figured it out.  i had been using @ahmetb's kubectl-aliases script, which works fine with no problem, but one of the suggestions in the readme was:


  print the full command before running it: add this to your .bashrc or .zshrc file:
  
  function kubectl() { echo ""+ kubectl $@""; command kubectl $@; }


i had that function declaration in my .bashrc and it was stripping off the quotes for my jsonpath argument.  as soon as i commented out that declaration and opened a new shell, the command worked correctly.
"
71446454,command line arguments for container in kubernetes,"i'm trying to deploy a docker container to my kubernetes cluster, but i'm running into an issue with passing the required command-line arguments to the container. i need to pass two arguments called --provider local and --basedir /tmp. here is what the docker run command looks like (i can run this without any issues on my docker host):
docker run -d -p 8080:8080 --name transfer-sh -v /tmp:/tmp dutchcoders/transfer.sh:latest --provider local --basedir /tmp

however, when i apply the deployment yaml to my cluster the container fails with this error (i'm running kubectl apply -f deploy.yaml to apply my changes to the cluster):

incorrect usage. flag provided but not defined: -provider local

so my yaml specifies that the flag should be --provider, but for some reason i haven't been able to find yet the container only sees -provider which is indeed not a valid option. this is the full help message:
name:
transfer.sh - transfer.sh

description:
easy file sharing from the command line

usage:
transfer.sh [flags] command [arguments...]

commands:
version
help, h  shows a list of commands or help for one command

flags:
--listener value                     127.0.0.1:8080 (default: &quot;127.0.0.1:8080&quot;) [$listener]
--profile-listener value             127.0.0.1:6060 [$profile_listener]
--force-https                         [$force_https]
--tls-listener value                 127.0.0.1:8443 [$tls_listener]
--tls-listener-only                   [$tls_listener_only]
--tls-cert-file value                 [$tls_cert_file]
--tls-private-key value               [$tls_private_key]
--temp-path value                    path to temp files (default: &quot;/tmp&quot;) [$temp_path]
--web-path value                     path to static web files [$web_path]
--proxy-path value                   path prefix when service is run behind a proxy [$proxy_path]
--proxy-port value                   port of the proxy when the service is run behind a proxy [$proxy_port]
--email-contact value                email address to link in contact us (front end) [$email_contact]
--ga-key value                       key for google analytics (front end) [$ga_key]
--uservoice-key value                key for user voice (front end) [$uservoice_key]
--provider value                     s3|gdrive|local [$provider]
--s3-endpoint value                   [$s3_endpoint]
--s3-region value                    (default: &quot;eu-west-1&quot;) [$s3_region]
--aws-access-key value                [$aws_access_key]
--aws-secret-key value                [$aws_secret_key]
--bucket value                        [$bucket]
--s3-no-multipart                    disables s3 multipart puts [$s3_no_multipart]
--s3-path-style                      forces path style urls, required for minio. [$s3_path_style]
--gdrive-client-json-filepath value   [$gdrive_client_json_filepath]
--gdrive-local-config-path value      [$gdrive_local_config_path]
--gdrive-chunk-size value            (default: 16) [$gdrive_chunk_size]
--storj-access value                 access for the project [$storj_access]
--storj-bucket value                 bucket to use within the project [$storj_bucket]
--rate-limit value                   requests per minute (default: 0) [$rate_limit]
--purge-days value                   number of days after uploads are purged automatically (default: 0) [$purge_days]
--purge-interval value               interval in hours to run the automatic purge for (default: 0) [$purge_interval]
--max-upload-size value              max limit for upload, in kilobytes (default: 0) [$max_upload_size]
--lets-encrypt-hosts value           host1, host2 [$hosts]
--log value                          /var/log/transfersh.log [$log]
--basedir value                      path to storage [$basedir]
--clamav-host value                  clamav-host [$clamav_host]
--perform-clamav-prescan             perform-clamav-prescan [$perform_clamav_prescan]
--virustotal-key value               virustotal-key [$virustotal_key]
--profiler                           enable profiling [$profiler]
--http-auth-user value               user for http basic auth [$http_auth_user]
--http-auth-pass value               pass for http basic auth [$http_auth_pass]
--ip-whitelist value                 comma separated list of ips allowed to connect to the service [$ip_whitelist]
--ip-blacklist value                 comma separated list of ips not allowed to connect to the service [$ip_blacklist]
--cors-domains value                 comma separated list of domains allowed for cors requests [$cors_domains]
--random-token-length value          (default: 6) [$random_token_length]
--help, -h                           show help

here is the docker hub for the image i'm trying to deploy: dutchcoders/transfer.sh
here is the github: https://github.com/dutchcoders/transfer.sh
my cluster's version is 1.23.4 and the full deployment yaml is here:
apiversion: apps/v1
kind: deployment
metadata:
  name: transfer-sh
  namespace: transfer-sh
  labels:
    app: &quot;transfer-sh&quot;
spec:
  replicas: 1
  selector:
    matchlabels:
      app: transfer-sh
  template:
    metadata:
      labels:
        app: transfer-sh
    spec:
      containers:
      - name: transfer-sh
        image: dutchcoders/transfer.sh:latest
        args:
        - &quot;--provider local&quot;
        - &quot;--basedir /tmp&quot;
        ports:
        - containerport: 8080

i intentionally have not included any persistent volume claims yet. at this point i'm just testing to make sure the container will run.
initially, i though maybe it was some sort of escape sequence issue. after trying all manner of ways to potentially escape the two dashes nothing really changed. i also tried setting environment variables that contained those arguments, but that just resulted in the same behavior where --profile turned into -profile.
if anyone has any thoughts i could use the help. i'm a bit stuck at the moment (although still troubleshooting). i am curious if maybe there is a different way to pass in command flags as opposed to arguments (or maybe there isn't any difference as far as k8s is concerned).
",<kubernetes><kubernetes-deployment>,71446568,1,"try:
apiversion: apps/v1
kind: deployment
metadata:
  name: transfer-sh
  namespace: transfer-sh
  labels:
    app: transfer-sh
spec:
  replicas: 1
  selector:
    matchlabels:
      app: transfer-sh
  template:
    metadata:
      labels:
        app: transfer-sh
    spec:
      containers:
      - name: transfer-sh
        image: dutchcoders/transfer.sh:latest
        args:  # &lt;-- in this case each arg is individual
        - --provider
        - local
        - --basedir
        - /tmp
        ports:
        - containerport: 8080


name          ready   up-to-date   available   age
transfer-sh   1/1     1            1           91s

"
63531689,istio ingress 404 on docker desktop,"i have been trying to run a local cluster on kubernetes and istio on macos using docker desktop. i used the bookinfo example and everything runs fine.
i have one of my own service and i am unable to get it to run. i try to hit it using postman and always get a 404.
i am unable to debug it, i might just be missing something or doing something stupid.
these are my yaml files
gateway.yaml
apiversion: networking.istio.io/v1alpha3
kind: gateway
metadata:
  name: reeal-gateway
spec:
  selector:
    istio: ingressgateway # use istio default controller
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &quot;*&quot;
---
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: reeal
spec:
  hosts:
  - &quot;*&quot;
  gateways:
  - reeal-gateway
  http:
  - match:
    - uri:
        exact: /feed
    route:
    - destination:
        host: feed
        port:
          number: 8080

service.yaml
apiversion: v1
kind: service
metadata:
  name: feed
  labels:
    app: feed
    service: feed
spec:
  selector:
    app: feed
  ports:
    - port: 8080
      name: http
---
 apiversion: v1
 kind: serviceaccount
 metadata:
  name: reeal-feed
  labels:
    account: feed
---
apiversion: apps/v1
kind: deployment
metadata:
  name: feed-deployment
  labels:
    app: feed
    version: v1
spec:
  replicas: 1
  selector:
    matchlabels:
      app: feed
      version: v1
  template:
    metadata:
      labels:
        app: feed
        version: v1
    spec:
      serviceaccountname: reeal-feed
      volumes:
      - name: firestore-key
        secret:
          secretname: firestore-cred
      containers:
      - name: feed-service
        image: reealadmin/feed-service:latest
        imagepullpolicy: always
        ports:
        - containerport: 8080
        volumemounts:
        - name: firestore-key
          mountpath: /var/secrets/google
        env:
        - name: google_application_credentials
          value: /var/secrets/google/key.json
      imagepullsecrets:
        - name: regcred

i have tested the service by exposing it using nodeport and i can curl and get the respective response, however i am making some mistake to not be able to configure the ingress properly.
url
i am using below for my url. the url formed is localhost/feed
export ingress_port=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;http2&quot;)].port}')
export secure_ingress_port=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;https&quot;)].port}')


export ingress_host=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadbalancer.ingress[0].hostname}')

echo $ingress_host
echo $ingress_port
echo $secure_ingress_port

error
[2020-08-22t01:01:05.088z] &quot;get /feed http/1.1&quot; 404 - &quot;-&quot; &quot;-&quot; 0 19 29 22 &quot;192.168.65.3&quot; &quot;postmanruntime/7.26.3&quot; &quot;e5705c53-6e70-9dbe-b831-764f9c7be63e&quot; &quot;localhost&quot; &quot;10.1.0.41:8080&quot; outbound|8080||feed.default.svc.cluster.local 10.1.0.25:40654 10.1.0.25:8080 192.168.65.3:59050 - -

really need help here.
",<kubernetes><kubernetes-ingress><istio><envoyproxy><docker-desktop>,63532727,3,"if you get 404 error, this means that your application is reached but does not have a /feed page.
you either can change your app to serve all content on that contextpath or do a rewrite on your virtualservice:
http:
  - match:
    - uri:
        exact: /feed
    rewrite:
      uri: /
    route:
    - destination:
        host: feed
        port:
          number: 8080

"
76652300,k8s cronjob - get image (tag) from config map?,"in a k8s cronjob, can i pull the image (or just the tag) which is being used dynamically (at job execution time, not at deployment time using helm etc.) from a configmap (or something similar)?
apiversion: batch/v1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: &quot;* * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox:{my-dynamic-tag-here}

my use case is that i have a lot of cron jobs which are getting created at different times and i would need to make changes to the image/tag that is being used for them at a later time.
",<kubernetes><kubernetes-cronjob>,76653336,1,"the image: value must be directly specified in the kubernetes manifest.  nothing in kubernetes proper does any sort of lookup, substitution, or indirect reference to modify this value.
setting this image is one of the most useful abilities of wrapper tools like helm or kustomize.  i'm most familiar with helm.  there you'd use helm's templating language to inject the image tag at deployment time
# templates/cronjob.yaml
image: busybox:{{ .values.dynamictag }}

and then when you actually go to deploy it, you can specify that value at the command line
helm upgrade my-app . --set-string dynamictag=20230710

there is also a path to pass a file of yaml (or json) deploy-time configuration values, which can be clearer if your ci tool can write this file.
kustomize has a specific path to change the image: value.  again, this involves your ci tool writing out the kustomization bundle, or running the kustomize edit cli tool to modify it at deploy time.
"
48400966,access kubernetes gke cluster outside of gke cluster with client-go?,"
i have multiple kubernetes clusters running on gke (let's say clustera and clusterb)
i want to access both of those clusters from client-go in an app that is running in one of those clusters (e.g. access clusterb from an app that is running on clustera)


i general for authenticating with kubernetes clusters from client-go i see that i have two options:


incluster config
or from kube config file


so it is easy to access clustera from clustera but not clusterb from clustera.

what are my options here? it seems that i just cannot pass google_application_credentials and hope that client-go will take care of itself.

so my thinking:


create a dedicated iam service account
create kube config with tokens for both clusters by doing gcloud container clusters get-credentials clustera and gcloud container clusters get-credentials clusterb
use that kube config file in client-go via buildconfigfromflags on clustera


is this the correct approach, or is there a simpler way? i see that tokens have an expiration date?

update:

it seems i can also use cloudsdk_container_use_client_certificate=true gcloud beta container clusters get-credentials clusterb --zone. which would add certificates to kube conf which i could use. but afaik those certificates cannot be revoked
",<kubernetes><google-kubernetes-engine>,48412272,12,"client-go needs to know about:


cluster master’s ip address
cluster’s ca certificate


(if you're using gke, you can see these info in $home/.kube/config, populated by gcloud container clusters get-credentials command).

i recommend you to either:


have a kubeconfig file that contains these info for clusters a &amp; b
use gke api to retrieve these info for clusters a &amp; b (example here) (you'll need a service account to do this, explained below.)


once you can create a *rest.config object in client-go, client-go will use the auth plugin that's specified in the kubeconfig file (or its in-memory equivalent you constructed).  in gcp auth plugin, it knows how to retrieve a token.

then, create a cloud iam service account and give it ""container developer"" role. download its key.

now, you have two options:

option 1: your program uses gcloud

gcloud auth activate-service-account --key-file=key.json
kubeconfig=a.yaml gcloud container clusters get-credentials clustera
kubeconfig=b.yaml gcloud container clusters get-credentials clusterb


then create 2 different *rest.client objects, one created from a.yaml, another from b.yaml in your program.

now your program will rely on gcloud binary to retrieve token every time your token expires (every 1 hour).

option 2: use google_application_credentials


don't install gcloud to your program’s environment.
set your key.json to google_application_credentials environment 
variable for your program.
figure out a way to get cluster ip/ca (explained above) so you can
construct two different *rest.config objects for cluster a &amp; b.
now your program will use the specified key file to get an access_token
to google api every time it expires (every 1h).


hope this helps.

p.s. do not forget to import _ ""k8s.io/client-go/plugin/pkg/client/auth/gcp"" in your go program. this loads the gcp auth plugin!
"
70524978,missing default value in nested field of kubernetes custom resource,"i have a custom resource definition which has nested fields with default values (some boilerplate omitted for brevity):
apiversion: apiextensions.k8s.io/v1
kind: customresourcedefinition
spec:
  scope: namespaced
  group: thismatters.stackoverflow
  names:
    kind: baddefault
  versions:
  - name: v1alpha
    schema:
      openapiv3schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              regularthing:
                type: integer
                default: 6
              shoulddefault:
                type: object
                properties:
                  nestedthing:
                    type: integer
                    default: 12

whenever i create a resource of this kind without specifying the shoulddefault object:
apiversion: thismatters.stackoverflow/v1alpha
kind: baddefault
metadata:
  name: blank-demo
spec: 
  regularthing: 7

the default value for .shoulddefault.nestedthing doesn't appear when the resource is described:
apiversion: thismatters.stackoverflow/v1alpha
kind: baddefault
metadata:
  name: blank-demo
spec: 
  regularthing: 7

if i update the resource with this manifest:
apiversion: thismatters.stackoverflow/v1alpha
kind: baddefault
metadata:
  name: blank-demo
spec: 
  regularthing: 7
  shoulddefault: {}

then the nested field default value is populated when described:
apiversion: thismatters.stackoverflow/v1alpha
kind: baddefault
metadata:
  name: blank-demo
spec: 
  regularthing: 7
  shoulddefault:
    nestedthing: 12

is there anything i can do in the crd to remove the need for the shoulddefault: {} line in the resource manifest and have the default values populate in the nested fields?
my cluster is on kubernetes version 1.19.
",<kubernetes><kubernetes-custom-resources>,70538591,3,"adding a default property to the shoulddefault object fixes this:
apiversion: apiextensions.k8s.io/v1
kind: customresourcedefinition
spec:
  scope: namespaced
  group: thismatters.stackoverflow
  names:
    kind: baddefault
  versions:
  - name: v1alpha
    schema:
      openapiv3schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              regularthing:
                type: integer
                default: 6
              shoulddefault:
                type: object
                default: {}   #  &lt;-- this was added
                properties:
                  nestedthing:
                    type: integer
                    default: 12

"
67368523,edit applied resource configuration with kubectl apply -k,"i'm applying aws-efs-csi driver like this on a kubernates cluster:
kubectl apply -k &quot;github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.0&quot;

i need to edit the configuration file to add credentials for pulling docker images.
i couldn't find ways to edit via kubectl edit ..
this is the pod in the kube-system namespace:
# kubectl get pods --all-namespaces

namespace     name                ready status    restarts   age
...
kube-system   efs-csi-node-xxssqr  3/3   running   0          69d
...

",<amazon-web-services><kubernetes><kubectl><amazon-efs>,67375195,1,"it’s a daemonset.
kubectl -n kube-system edit ds/efs-csi-node
"
73781430,failing to set range loop of helm in istio virtual service http retry,"bug description
i can smoothly work on adding multiple destinations for canary deployment but when i try adding retry it fails with the custom-built helm chart. as i can't iterate over it.
this is a problem because retry is tied to each destination according to that whole should be iterated.
please find helm chart template below.
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: {{ .values.virtualservice.name }}
  namespace: {{ .values.namespace }} 
spec:
  hosts:
  - {{ .values.virtualservice.hosts }} 
  gateways:
  - {{ .values.virtualservice.gateways }} 
  http:
  - route:
      {{- range $key, $value := .values.destination }}
    - destination:
        host: {{ $value.host }}
        subset: {{ $value.subset }} 
      weight: {{ $value.weight }}
    retries:
      attempts: {{ $value.retries.attempts }}
      pertrytimeout: {{ $value.retries.pertrytimeout }}
      retryon: {{ $value.retries.retryon }}
    timeout: {{ $value.retries.timeout }}
    {{- end }}

error log
$ helm install asm-helm ./asm-svc-helm-chart -f values.yaml --dry-run
error: installation failed: yaml parse error on asmvrtsvc/templates/retry-svc.yaml: error converting yaml to json: yaml: line 21: did not find expected key

version
$ kubectl version --short
client version: v1.24.0
kustomize version: v4.5.4
server version: v1.22.12-gke.300

$ helm version
v3.9.4+gdbc6d8e

added example for reference
spec:
  hosts:
  - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
      weight: 75
    retries:
      attempts: 3
      pertrytimeout: 2s
    - destination:
        host: reviews
        subset: v2
      weight: 25
    retries:
      attempts: 3
      pertrytimeout: 2s

",<kubernetes><google-kubernetes-engine><kubernetes-helm><google-anthos-service-mesh>,73795021,1,"according to the schema of virtual service, the route field in virtual service can have one retries field.
so, the loop should include destination as array.
*: https://istio.io/latest/docs/reference/config/networking/virtual-service/
"
59060406,generate dynamic runtime yaml for container with k8s secrets,"i'm deploying a service which rigidly takes a yaml config that looks something like this:

# /config/srv.yaml

#
# ...
#
tenantid: '...'
clientid: '...'
certfile: '/config/client/client.crt'
keyfile:  '/config/client/client.key'
#
# ...
#


tl;dr; i want to only store the tenantid, clientid &amp; cert files in k8s secrets.

my current solution, stores the entire yaml file in secrets, which seems wasteful and also cumbersome to manage.



essentially i have this - which works well for the 2 cert files (/config/client/client.crt and /config/client/client.key):

spec:
  containers:
    - name: my-container
      image: ""my-image""
      imagepullpolicy: always
      ports:
        - containerport: 50100
      env:
      - name: conf_file
        value: ""/config/srv.yaml""
      volumemounts:
      - name: yaml-vol
        mountpath: ""/config"" # kludgy
        readonly: true
      - name: certs-vol
        mountpath: ""/config/client""
        readonly: true

    volumes:
    - name: yaml-vol
      secret:
        secretname: my-yamls # kludgy
    - name: certs-vol
      secret:
        secretname: my-certs # contains the *.crt/*.key cert files


however it involves storing the entire /config/srv.yaml in the kubernetes secrets my-yamls.

the k8s secrets docs suggest there's a way to create a dynamic yaml config for one's containers -  filling in the secrets precisely where needed, using stringdata e.g.

stringdata:
  config.yaml: |-
    apiurl: ""https://my.api.com/api/v1""
    username: {{username}}
    password: {{password}}


but the docs trail off with a very vague:


  your deployment tool could then replace the {{username}} and
  {{password}} template variables before running kubectl apply.


i just need to fill in two string items in a dynamic config: clientid and tenantid.

using just kubectl, how can one create a dynamic yaml for a container - storing the non-sensitive yaml template in the deploy.yaml - and have just the sensitive items in k8s secrets?
",<kubernetes><kubectl><kubernetes-secrets>,59084113,3,"an alternative will be to use another tool for secret management. one solution will be to use kamus. kamus support templating so you can do something like:

apiversion: v1
kind: configmap
metadata:
  name: encrypted-secrets-cm
data:
  tenantid: &lt;encrypted&gt;
  clientid: &lt;encrypted&gt;
  template.ejs: |
     tenantid: &lt;%- secrets[""tenantid""] %&gt;
     clientid: &lt;%- secrets[""clientid""] %&gt;
     certfile: '/config/client/client.crt'
     keyfile:  '/config/client/client.key'


where the values are encrypted using kamus.

and then either use clientsecret and store it the same way, or create a regular secret for both the crt and key. it's worth noticing that (assuming this is azure) client id and tenant id are not considered secrets, and can be committed to a private repository.

full disclosure: i'm kamus author.
"
44154425,kubernetes - find out service ip range cidr programatically,"i need a way to get service cluster ip range (as cidr) that works accross all kubernetes clusters.

i tried the following, which works fine for clusters created with kubeadm as it greps arguments of apiserver pod:

$ kubectl cluster-info dump  | grep service-cluster-ip-range
                        ""--service-cluster-ip-range=10.96.0.0/12"",


this does not work on all kubernetes clusters, i.e. gcloud

so the question is, what is the best way to get service ip range programatically?
",<kubernetes><gcloud><kubectl>,44176090,2,"i don't think there is a way to access such information through k8s api, there is an open issue to address lack of this functionality: https://github.com/kubernetes/kubernetes/issues/25533 . if you have access to the etcd of the k8s cluster in question, then there is a key with information about service cidr range: /registry/ranges/serviceips . you can get the value, by using etcdctl (assuming, you have the proper permissions): etcdctl --enpoints=&lt;your etcd&gt; --&lt;any authentication flags&gt; get ""/registry/ranges/serviceips"" --prefix=true.
"
59332672,how to set customized release name in helmchart,"after creating package in helm , i am facing difficulty in setting customized chart name i tried below commands

&gt; helm install --name example ./mychart --set service.type=nodeport 
&gt; helm install happy-panda stable/mariadb


also, tried commands from helm man page 

&gt; helm install -help 
&gt; --name-template string specify template used to name the release

",<kubernetes><kubernetes-helm>,59332673,2,"before setting your custom release name you've to check your helm version . above commands mentioned in question didn't worked in below helm version 

root@docker-slave:/home/mec/src/vmmanager/docker/vmmanager_chart# helm version
client: &amp;version.version{semver:""v2.9.1"", gitcommit:""20adb27c7c5868466912eebdf6664e7390ebe710"", gittreestate:""clean""}
server: &amp;version.version{semver:""v2.9.1"", gitcommit:""20adb27c7c5868466912eebdf6664e7390ebe710"", gittreestate:""clean""}


for helm 2 version.


  helm install --name your_customized_name chart_name


like , helm install --name vmchart vmmanager_chart

for helm 3 version,


  helm install   [--namespace ]  # per-default you need
  to provide a release name


for detailed description you can refer below link.

https://lzone.de/cheat-sheet/helm
"
69815972,error parsing command line: unrecognised option '--wiredtigercachesizegb 2',"i have a google kubernetes engine running and i'm trying to deploy a mongo container. everything works fine except when i try to use the argument &quot;--wiredtigercachesizegb&quot;, then the deployment fails because this command is not recognized. i'm using the latest mongo version (5.0) and i see nothing in the documentation saying that this should not work.
here is the yml configuration of the pod creation:
apiversion: apps/v1
kind: statefulset
spec:
  podmanagementpolicy: orderedready
  replicas: 1
  revisionhistorylimit: 10
  selector:
    matchlabels:
      environment: test
      role: mongo
  servicename: mongo
  template:
    metadata:
      creationtimestamp: null
      labels:
        environment: test
        role: mongo
      namespace: default
    spec:
      containers:
      - command:
        - mongod
        - --wiredtigercachesizegb 2
        image: mongo:5.0
        imagepullpolicy: always
        name: mongo
        ports:
        - containerport: 27017
          protocol: tcp
        resources: {}
        terminationmessagepath: /dev/termination-log
        terminationmessagepolicy: file
        volumemounts:
        - mountpath: /data/db
          name: mongo-persistent-storage
      dnspolicy: clusterfirst
      restartpolicy: always
      schedulername: default-scheduler
      securitycontext: {}
      terminationgraceperiodseconds: 10
      tolerations:
      - effect: noschedule
        key: dedicated
        operator: equal
        value: backend
  updatestrategy:
    type: ondelete
  volumeclaimtemplates:
  - apiversion: v1
    kind: persistentvolumeclaim
    metadata:
      annotations:
        volume.beta.kubernetes.io/storage-class: standard
      creationtimestamp: null
      name: mongo-persistent-storage
    spec:
      accessmodes:
      - readwriteonce
      resources:
        requests:
          storage: 20gi
      volumemode: filesystem

",<mongodb><kubernetes><google-kubernetes-engine>,69816770,2,"does it work if you remove the --wiredtigercachesizegb flag?
i would be surprised.

it does appear to work (see below) but i can't explain why. i am surprised!

if this is the correct dockerfile for the image, then it uses a docker cmd to run mongod.
if so, you'd need to run the image on kubernetes using args not command in order to correctly override the container image's cmd and not override the container image's entrypoint, i.e.
containers:
- name: mongo
  args:
  - mongod
  - --wiredtigercachesizegb=2


note the inclusion of = between the flag and value to avoid introducing yaml parsing issues.

i tested this hypothesis using podman; you can replace podman with docker in what follows if you use docker:
# does not work: override `entrypoint` with mongod+flag
# this is effectively what you're doing
podman run \
--interactive --tty --rm \
--entrypoint=&quot;mongod --wiredtigercachesizegb=2&quot; \
docker.io/mongo:5.0 \
error: executable file `mongod --wiredtigercachesizegb=2` not found in $path:
no such file or directory:
oci runtime attempted to invoke a command that was not found

# works: override `cmd`
# this is what i thought should work
podman run \
--interactive --tty --rm \
docker.io/mongo:5.0 \
  mongod \
  --wiredtigercachesizegb=2

# works: override `entrypoint` w/ mongod
# this is what i thought wouldn't work
podman run \
--interactive --tty --rm \
--entrypoint=mongod \
docker.io/mongo:5.0 \
  --wiredtigercachesizegb=2

"
52161883,large payload for custom objects,"while i can create custom objects just fine, i am wondering how one is supposed to handle large payloads (gigabytes) for an object.

crs are mostly used in order to interface with garbage collection/reference counting in kubernetes.

adding the payload via yaml does not work, though (out of memory for large payloads):

apiversion: ""data.foo.bar/v1"" 
kind: dump 
metadata:
  name: my-data
  ownerreferences:
    - apiversion: apps/v1
      kind: deploy
      name: my-deploy
      uid: d9607a69-f88f-11e7-a518-42010a800195
spec: 
  payload: dfewfawfjr345434hdg4rh4ut34gfgr_and_so_on_...


one could perhaps add the payload to a pv and just reference that path in the cr.
then i have the problem, that it seems like i cannot clean up the payload file, should the cr get finalized (could not find any info about custom finalizers).

have no clear idea how to integrate such a concept into kubernetes lifetimes.
",<kubernetes><openshift><custom-object><kubernetes-custom-resources>,52252316,1,"we still went with using the co. alongside, we created a kubernetes controller, which handles the lifetime in the pv. for us this works fine, since the controller can be the single writer to the pv, while the actual services only need read access to the pv.
combined with ownerreference, this makes for a good integration into the kubernetes lifetime.
"
70097170,alternatives to using `dt:replacedata()` when `server=false` on shiny application deployed via kubernetes,"for various reasons i want to be able to use a proxied data table and replacedata while client side processing is being used i.e. dt::renderdatatable(..., server = false).
context
i have a shiny application/dashboard that communicates to a database and presents information to a user. the user is able to fill out a form in the application which will be added to the database and then the shiny app updates the data by making a query to the database to fetch the new information.
the application is currently being deployed via kubernetes using a loadbalancer with the intention to use multiple replicas to scale up the application as needed. the application is not being run through shinyproxy.
caveats
currently, when the application is being run by a single replica (process) the application will behave perfectly fine and is able to use server=true. however when i increase the number of processes/replicas to run, the data is not able to be presented to users unless server=false is specified in renderdatatable. for a currently unknown reason but i suspect it might be due to the sessions not being sticky to ips
while the code is able to function fine when server = true if i want to allow multiple users to application they all cannot share a single process as the application will become very slow once multiple connections are made. as a result i likely need to use server=false so each user is able to see the data at the cost of a very important functional detail (replacedata stops working). the product owner of the application is insistent that this behaviour remains intact as the data present is often large and requires some column sorting and paging to find a piece of information you want to look at. and when submitting a form, if i do not use replacedata and reconstruct the table from scratch the users previous table state is lost.
so while i could tear down the datatable and regenerate it within an observeevent
observeevent(input$button, {
    ...
    output$table = renderdatatable({dt::datatable(df(), selection = 'single', callback = 
    js(&quot;$.fn.datatable.ext.errmode = 'none';&quot;))}, server = false)
    ...
})

this would provide a solution that would yield unfavourable behaviour even though it will update the table accordingly.
repoducible example
this will create an application with a button and a table. select a row on the table and then click the button. the expected behaviour would be that the table updates with 'new_content' on the row that is selected. this will only work when server=true, nothing will happen when server=false.
library(shiny)
library(dt)
data(iris)

server &lt;- function(input, output, session) {
  iris$new_col = ''
  df = reactive({iris})
  output$table = renderdatatable({
      dt::datatable(df(), selection = 'single', 
        callback = js(&quot;$.fn.datatable.ext.errmode = 'none';&quot;))}, server = false) # when true code works fine,,,
  proxy = datatableproxy('table')

  observeevent(input$button, {
    # this line would be replacing the write to a db
    iris[input$table_rows_selected, 'new_col'] &lt;- 'changed'
    # this line would be replacing the query to the db to reflect changes the user (and potentially other users have made between loading the data previously.
    df &lt;- reactive({iris})
    proxy %&gt;% replacedata(df(), rownames = true, resetpaging = false)
  })
}
    
ui &lt;- fluidpage(
  actionbutton('button', 'press me'),
  dt::dtoutput('table') 
)

shinyapp(ui, server)

i have done a fairly extensive search on so and this was the closest question i could find: dt editing in shiny application with client-side processing (server = f) throws json error however this isn't actually answered and provides an answer of &quot;it just does not work&quot;.
kubernetes.yaml (only look if you are a wizard)
i am including the yaml file incase there are some kubernetes boffins that know how to specifically solve the above issue with some clever trickery. the described problem might stem from sessions being swapped between replicas thus the data gets miscommunicated but i am honestly not the best at kubernetes... if that is the case and i would then be able to use server=true within the shiny application then this would also solve the problem.
apiversion: apps/v1
kind: deployment
metadata:
  name: deployment-appname
spec:
  replicas: 5
  selector:
    matchlabels:
      app: appname
  template:
    metadata:
      labels:
        app: appname
    spec:
      containers:
      - name: appname 
        securitycontext:
            privileged: false
        image: appname:latest
        ports: 
        - name: http
          containerport: 3838
---
apiversion: v1
kind: service
metadata:
  name: servive-appname
spec:
  ports:
  - name: http
    port: 3838
    protocol: tcp
    targetport: 3838
  selector:
    app: appname
  type: loadbalancer
---
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: ingress-appname
  annotations:
    nginx.org/websocket-services: &quot;service-appname&quot;
spec:
  tls:
  - hosts:
    - appname.url.com
  rules:
  - host: appname.url.com
    http:
      paths:
      - path: /
        backend:
          servicename: service-appname
          serviceport: 3838

",<r><kubernetes><shiny><kubernetes-pod><dt>,70217015,4,"here is a client-side approach, building up on @jpdugo17's answer and @tjgorrie's initial example, using the statesave option to maintain the table state on re-rendering. selectpage and updatesearch can be used along with datatableproxy - the state of input$table_state$order needs to be passed as an option:
library(shiny)
library(dt)
data(iris)

iris$new_col &lt;- ''

server &lt;- function(input, output, session) {
  
  df = reactivevalues(iris = iris)
  
  output$table &lt;- dt::renderdatatable(expr = {
    if (is.null(isolate(input$table_state))) {
      dt::datatable(
        df$iris,
        selection = 'single',
        callback = js(&quot;$.fn.datatable.ext.errmode = 'none';&quot;),
        options = list(statesave = true)
      )
    } else {
      # print(isolate(input$table_state$order))
      dt::datatable(
        df$iris,
        selection = 'single',
        callback = js(&quot;$.fn.datatable.ext.errmode = 'none';&quot;),
        options = list(
          statesave = true,
          order = isolate(input$table_state$order),
          paging = true,
          pagelength = isolate(input$table_state$length)
        )
      )
    }
  }, server = false)
  
  proxy &lt;- datatableproxy('table')
  
  observeevent(input$button, {
    df$iris[input$table_rows_selected, c('new_col')] &lt;- 'changed!'
  })

  observeevent(df$iris, {
    updatesearch(proxy, keywords = list(global = input$table_state$search$search, columns = null)) # see input$table_state$columns if needed
    selectpage(proxy, page = input$table_state$start/input$table_state$length+1)
  }, ignoreinit = true, priority = -1)
}

ui &lt;- fluidpage(
  actionbutton('button', 'press me'),
  dt::dtoutput('table') 
)

shinyapp(ui, server)

here is a related article.
"
65660833,aws eks and aws sso rbac authentication problem,"i have created a fresh aws sso (used internal idp as identity source, so no use of active directory). 
i am able to login to aws cli, aws gui, but unable to perform any kubectl ops.
error: you must be logged in to the server (unauthorized)

this has something to do with the rbac i think as i am able to get eks token via
aws eks get-token.
➜ cat ~/.aws/config

[profile team-sso-admin]
sso_start_url=https://team.awsapps.com/start
sso_region=us-west-2
sso_account_id=1111111111
sso_role_name=administratoraccess
region=us-west-2
credential_process = aws-vault exec team-sso-admin --json


➜ aws-vault exec team-sso-admin --debug -- zsh --login
➜ env | grep aws
aws_vault_prompt=pass
aws_vault_backend=pass
aws_vault=team-sso-admin
aws_default_region=us-west-2
aws_region=us-west-2
aws_access_key_id=xxx
aws_secret_access_key=xxx
aws_session_token=xxx
aws_security_token=yyy
aws_session_expiration=2021-01-11t05:55:51z
aws_sdk_load_config=1

➜ aws sts get-caller-identity --output yaml 

account: '111111111111'
arn: arn:aws:sts::111111111111:assumed-role/awsreservedsso_administratoraccess_6c71da2aa3076dfb/testuser
userid: xxx:testuser

➜ aws eks get-token --cluster-name team-shared-eks --role arn:aws:iam::111111111111:role/aws-reserved/sso.amazonaws.com/us-west-2/awsreservedsso_administratoraccess_67d1da2aa3076dfb

{&quot;kind&quot;: &quot;execcredential&quot;, &quot;apiversion&quot;: &quot;client.authentication.k8s.io/v1alpha1&quot;, &quot;spec&quot;: {}, &quot;status&quot;: {&quot;expirationtimestamp&quot;: &quot;2021-01-11t02:49:11z&quot;, &quot;token&quot;: &quot;xxx&quot;}}


kubeconfig
config

- name: arn:aws:eks:us-west-2:111111111111:cluster/team-shared-eks
  user:
    exec:
      apiversion: client.authentication.k8s.io/v1alpha1
      args:
      - --region
      - us-west-2
      - eks
      - get-token
      - --cluster-name
      - team-shared-eks
      - --role
      - arn:aws:iam::111111111111:role/aws-reserved/sso.amazonaws.com/us-west-2/awsreservedsso_administratoraccess_67d1da2aa3076dfb
      command: aws

aws-auth
maproles: |
    - &quot;groups&quot;:
      - &quot;system:bootstrappers&quot;
      - &quot;system:nodes&quot;
      &quot;rolearn&quot;: &quot;arn:aws:iam::111111111111:role/team-shared-eks20210110051740674200000009&quot;
      &quot;username&quot;: &quot;system:node:{{ec2privatednsname}}&quot;
    - &quot;groups&quot;:
      - &quot;system:master&quot;
      &quot;rolearn&quot;: &quot;arn:aws:iam::111111111111:role/team-saml-devops&quot;
      &quot;username&quot;: &quot;team-devops&quot;
    - &quot;groups&quot;:
      - &quot;system:master&quot;
      &quot;rolearn&quot;: &quot;arn:aws:iam::111111111111:role/aws-reserved/sso.amazonaws.com/us-west-2/awsreservedsso_administratoraccess_67d1da2aa3076dfb&quot;
      &quot;username&quot;: &quot;team-sso-devops&quot;


clusterrole binding for team-sso-devops user:
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  creationtimestamp: &quot;2021-01-11t01:37:51z&quot;
  name: team:sso:devops
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: cluster-admin
subjects:
- apigroup: rbac.authorization.k8s.io
  kind: user
  name: team-sso-devops
  namespace: default

",<kubernetes><amazon-eks><aws-sso><kubernetes-rbac>,65958467,16,"option #1 - try removing aws-reserved/sso.amazonaws.com/$region/ from the role_arn
option #2 - use aws-iam-authenticator, the official docs provide a thorough example of how to use sso and kubectl (kubeconfig)
"
74382804,get logs from all pods in namespace using xargs,"is there anyway to get all logs from pods in a specific namespace running a dynamic command like a combination of awk and xargs?
 kubectl get pods | grep running | awk '{print $1}' | xargs kubectl logs | grep value

i have tried the command above but it's failing like kubectl logs is missing pod name:

error: expected 'logs [-f] [-p] (pod | type/name) [-c container]'.
pod or type/name is a required argument for the logs command
see 'kubectl logs -h' for help and examples

do you have any suggestion about how get all logs from running pods?
",<shell><kubernetes><kubectl>,74382841,7,"think about what your pipeline is doing:
the kubectl logs command takes as an argument a single pod name, but through your use of xargs you're passing it multiple pod names. make liberal use of the echo command to debug your pipelines; if i have these pods in my current namespace:
$ kubectl get pods -o custom-columns=name:.metadata.name
name
c069609c6193930cd1182e1936d8f0aebf72bc22265099c6a4af791cd2zkt8r
catalog-operator-6b8c45596c-262w9
olm-operator-56cf65dbf9-qwkjh
operatorhubio-catalog-48kgv
packageserver-54878d5cbb-flv2z
packageserver-54878d5cbb-t9tgr

then running this command:
kubectl get pods | grep running | awk '{print $1}' | xargs echo kubectl logs

produces:
kubectl logs catalog-operator-6b8c45596c-262w9 olm-operator-56cf65dbf9-qwkjh operatorhubio-catalog-48kgv packageserver-54878d5cbb-flv2z packageserver-54878d5cbb-t9tgr


to do what you want, you need to arrange to call kubectl logs multiple times with a single argument. you can do that by adding -n1 to your xargs command line. keeping the echo command, running this:
kubectl get pods | grep running | awk '{print $1}' | xargs -n1 echo kubectl logs

gets us:
kubectl logs catalog-operator-6b8c45596c-262w9
kubectl logs olm-operator-56cf65dbf9-qwkjh
kubectl logs operatorhubio-catalog-48kgv
kubectl logs packageserver-54878d5cbb-flv2z
kubectl logs packageserver-54878d5cbb-t9tgr

that looks more reasonable. if we drop the echo and run:
kubectl get pods | grep running | awk '{print $1}' | xargs -n1 kubectl logs | grep value

then you will get the result you want. you may want to add the --prefix argument to kubectl logs so that you know which pod generated the match:
kubectl get pods | grep running | awk '{print $1}' | xargs -n1 kubectl logs --prefix | grep value


not directly related to your question, but you can lose that grep:
kubectl get pods | awk '/running/ {print $1}' | xargs -n1 kubectl logs --prefix | grep value

and even lose the awk:
kubectl get pods --field-selector=status.phase==running -o name | xargs -n1 kubectl logs --prefix | grep value

"
76712848,use kustomize replacements to replace values in one base with values from another base?,"i'm updating some of my kubernetes configurations to use 'replacements' and 'resources' in kustomize as 'vars' and 'bases' have been deprecated.
previously, i used 'vars' in a base (/base/secrets/) like this:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

secretgenerator:
- name: test_secret
  env: secret.env

vars:
- name : secret_value
  objref:
    kind: secret
    name: test_secret
    apiversion: v1
  fieldref:
    fieldpath: metadata.name


this base was used in various overlays for different services:
namespace: test-overlay

bases:
- ../../base/secrets/
- ../../base/service/

now, with 'resources' and 'replacements', my understanding is that it's not possible to replace values in /base/service/ from /base/secrets/ as before. i could apply the 'replacement' in the overlay itself and target the base i want to modify, but i would prefer to perform the operation from a base for reusability and ease of use.
here's what i'm trying to do:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

secretgenerator:
- name: test_secret
  env: secret.env

replacements:
- source:
    name: test_secret
    kind: secret
  targets:
  - select:
      kind: deployment
      name: service
    fieldpaths:
    - spec.template.spec.&lt;field&gt;

in the 'replacements' directive, spec.template.spec.&lt;field&gt; is the field in the deployment resource that i'm trying to replace.
i'm using kustomize version v5.1.0.
how can i get 'replacements' to target other bases so that they can be used from any overlay? what's the best practice for this scenario?
i've attempted to apply the 'replacements' in the overlay itself and target the base i want to modify like this:
namespace: test-overlay

resources:
- ../../base/secrets/
- ../../base/service/

replacements:
- source:
    kind: secret
    name: test_secret
  targets:
  - select:
      kind: deployment
      name: service
    fieldpaths:
    - spec.template.spec.&lt;field&gt;

while this does apply the replacement to the service, it's not a satisfactory solution for me because i have multiple overlays that all need to use the same replacement for various deployments. i would prefer to define the replacement once in a base, rather than having to define it in each overlay.
edit: a more clear minimal reproducible example
/base
  /secrets
    kustomization.yaml
  /service
    deployment.yaml
    kustomization.yaml
/overlays
  /test-overlay
    kustomization.yaml

with the /secrets/ implemented as:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

secretgenerator:
- name: test_secret
  env: secret.env

replacements:
- source:
    name: test_secret
    kind: secret
  targets:
  - select:
      kind: deployment
      name: service
    fieldpaths:
    - spec.template.spec.volumes.name

this would be the /service/:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization
    
resources:
- deployment.yaml

---

apiversion: apps/v1
kind: deployment
metadata:
  name: service
spec:
  template:
    spec:
      volumes:
      - name: placeholder_value
        emptydir: {}

with /test-overlay/
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

namespace: test-overlay

resources:
- ../../base/secrets/
- ../../base/service/

i've tried including the 'replacements' in the test-overlays kustomization file which did work but is less desirable then letting the replacement be defined in a base
",<kubernetes><kubernetes-secrets><configuration-management><kustomize>,76713665,9,"thanks for updating your question with an example.
the answer i've posted here is still the correct solution in terms of sharing a replacement configuration among multiple overlays, but there are some errors in your replacement syntax: you cannot target spec.template.spec.volumes.name, because volumes is a list and has no name attribute.
you can only target list elements with a [name=value] style selector, so:
replacements:
  - source:
      name: test_secret
      kind: secret
    targets:
      - select:
          kind: deployment
          name: service
        fieldpaths:
          - spec.template.spec.volumes.[name=placeholder_value].name


a kustomization.yaml can only apply transformations (labels, patches, replacements, etc) to resources that are emitted by that kustomization.yaml -- which means that if you want a transformation to affect all resources, it needs to be applied in the &quot;outermost&quot; kustomization.
this means that you can't place something in a &quot;base&quot; that will modify resources generated in your overlays.
but don't worry, there is a solution! components allow you to reuse kustomization fragments. if we move your replacement configuration into a component, we can get the behavior you want.
for example, here is a project with a base and two overlays:
.
├── base
│   ├── deployment.yaml
│   └── kustomization.yaml
├── components
│   └── replace-username-password
│       └── kustomization.yaml
└── overlay
    ├── env1
    │   └── kustomization.yaml
    └── env2
        └── kustomization.yaml

base/deployment.yaml looks like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: example
spec:
  replicas: 2
  template:
    spec:
      containers:
        - name: example
          image: docker.io/alpine:latest
          command:
            - sleep
            - inf
          env:
            - name: user_name
              value: update-via-replacement
            - name: user_password
              value: update-via-replacement

and base/kustomization.yaml looks like:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization
commonlabels:
  app: replacement-example

resources:
  - deployment.yaml

secretgenerator:
  - name: example
    literals:
      - password=secret

configmapgenerator:
  - name: example
    literals:
      - username=alice

so the base directory results in a deployment, a secret, and a configmap. there are two overlays, env1 and env2. in both overlays i want to apply the same replacement configuration, so i put that into components/replace-username-password/kustomization.yaml:
apiversion: kustomize.config.k8s.io/v1alpha1
kind: component

replacements:
  - source:
      kind: configmap
      name: example
      fieldpath: data.username
    targets:
      - select:
          kind: deployment
          name: example
        fieldpaths:
          - spec.template.spec.containers.[name=example].env.[name=user_name].value
  - source:
      kind: secret
      name: example
      fieldpath: data.password
    targets:
      - select:
          kind: deployment
          name: example
        fieldpaths:
          - spec.template.spec.containers.[name=example].env.[name=user_password].value

now in overlays/env1/kustomization.yaml i can make use of this component:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization
commonlabels:
  envname: env1

resources:
  - ../../base

components:
  - ../../components/replace-username-password

and the same in overlays/env2:
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization
commonlabels:
  envname: env2

resources:
  - ../../base

components:
  - ../../components/replace-username-password

"
46406596,how to identify unused secrets in kubernetes?,"i want to rename my k8s secrets and want to check if there are unused secrets. also i would like to know how many and which containers reference a secret.

is there a easier way to do this than search for the secret names in all deployments?
",<kubernetes><kubectl>,46412286,30,"thanks simon. based on your answer i created a diff, which shows secrets that are not referenced in the containers env section. secrets can also be referenced in:

tls section of ingresses
pods volumes spec, like simon mentioned
imagepullsecrets for private repositories
crds custom resource definitions

but for me it is enough to find secrets that are not referenced in environment variables:
diff \
&lt;(kubectl get pods -o jsonpath='{.items[*].spec.containers[*].env[*].valuefrom.secretkeyref.name}' | xargs -n1 | sort | uniq) \
&lt;(kubectl get secrets -o jsonpath='{.items[*].metadata.name}' | xargs -n1 | sort | uniq)

update 16.04.2018
i created a more advanced version to find also secrets referenced in volumes, ingress tls and imagepullsecrets. the following snippet will show you all unused secrets for the current namespace.
caution: the script does not cover all options where secrets can be referenced (e.g. custom resource definitions).
update 15.06.2021: added secrets from pod container spec envfrom[*].secretref.name as secret source
update 06.07.2023: added secrets that are used as service account tokens
envsecrets=$(kubectl get pods -o jsonpath='{.items[*].spec.containers[*].env[*].valuefrom.secretkeyref.name}' | xargs -n1)
envsecrets2=$(kubectl get pods -o jsonpath='{.items[*].spec.containers[*].envfrom[*].secretref.name}' | xargs -n1)
volumesecrets=$(kubectl get pods -o jsonpath='{.items[*].spec.volumes[*].secret.secretname}' | xargs -n1)
pullsecrets=$(kubectl get pods -o jsonpath='{.items[*].spec.imagepullsecrets[*].name}' | xargs -n1)
tlssecrets=$(kubectl get ingress -o jsonpath='{.items[*].spec.tls[*].secretname}' | xargs -n1)
sasecrets=$(kubectl get secrets --field-selector=type=kubernetes.io/service-account-token -o jsonpath='{range .items[*]}{.metadata.name}{&quot;\n&quot;}{end}' | xargs -n1)


diff \
&lt;(echo &quot;$envsecrets\n$envsecrets2\n$volumesecrets\n$pullsecrets\n$tlssecrets\n$sasecrets&quot; | sort | uniq) \
&lt;(kubectl get secrets -o jsonpath='{.items[*].metadata.name}' | xargs -n1 | sort | uniq)

"
61270789,kubectl vs aws eks - which one to use when?,"we host docker containers on aws infrastructure using aws eks.  my reading so far shows that the kubectl command-line tool gives me commands to query and manipulate the eks cluster.  the aws eks command-line tool also gives me commands to do this.  to my inexperienced eye, they look like they offer the same facilities.

are there certain situations when it's better to use one or the other?
",<amazon-web-services><kubernetes><kubectl><amazon-eks>,61271120,4,"aws eks command is for interacting with aws eks proprietary apis to perform administrative tasks such as creating cluster, updating kubeconfig with correct credentials etc.
kubectl is an open source cli tool which let you interact with kubernetes api server to perform tasks such create pods, deployments etc.
you can not use aws eks command to interact with kubernetes api server and perform any kubernetes specific operations because it does not understand kubernetes apis.
similarly you can not use kubectl to interact with aws eks proprietary apis because kubectl does not understand it.
"
75005784,how determine helm server version,"i'm sorry if it is noob question, but i can't find an explanation for this anywhere.
i need to know which version of the helm server are running on the cluster. in my machine i have the helm client in both versions (helm2 and helm3), when i run the command helm2 version or helm3 version, i'm not sure if i am getting the client or the server version.
for example, on kubectl it describes both client and server version:
kubectl version
client version: version.info{major:&quot;1&quot;, minor:&quot;10&quot;, gitversion:&quot;v1.10.7&quot;, gitcommit:&quot;0c38c362511b20a098d7cd855f1314dad92c2780&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2018-08-20t10:09:03z&quot;, goversion:&quot;go1.9.3&quot;, compiler:&quot;gc&quot;, platform:&quot;darwin/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;11&quot;, gitversion:&quot;v1.11.4&quot;, gitcommit:&quot;bf9a868e8ea3d3a8fa53

what could be the best way to determine it?
",<kubernetes><kubernetes-helm>,75005839,1,"helm3 does not have a server version unlike helm v2.
you can run helm version for helm v2.
here is the tiller removal doc.
"
70016660,kubectl logs deploy/my-deployment does not show logs from all pods,"what is the purpose of kubectl logs deploy/my-deployment shown at https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-deployments-and-services?
i would think it will show me logs from all the pods deployed as part of the my-deployment object. however, even though i have 2 pods in my deployment, that command shows logs from only one of them.
",<kubernetes><kubectl>,70017559,3,"if your deployment has multiple pod replicas, then kubectl logs deployment/... will just pick one on its own.
here is an example:
kubectl  get pods -n kube-system | grep coredns
coredns-78fcd69978-dqf95       1/1     running   0          42h
coredns-78fcd69978-vgvf2       1/1     running   0          42h

kubectl logs deployment/coredns -n kube-system 
found 2 pods, using pod/coredns-78fcd69978-vgvf2

"
72761673,why i do not see any nodes in kubernetes cluster with role master or worker?,"i did kubeadm init on one machine. i followed all the instructions on network etc and end up with this:
kubectl get nodes:
name              status   roles           age    version
slchvdvcybld001   ready    control-plane   140m   v1.24.2
slchvdvcydtb001   ready    &lt;none&gt;          136m   v1.24.2
slchvdvcytst001   ready    &lt;none&gt;          137m   v1.24.2

as you can see, no nodes are master or worker or similar.
i don't have some special setup, all i did is install it and did init.
there are no errors in logs file. dashboard is in green and everything is in green.
these are versions of kubectl and so on:
client version: v1.24.2
kustomize version: v4.5.4
server version: v1.24.2

",<kubernetes><kubernetes-ingress><nginx-ingress>,72762033,6,"labelling of master node is deprecated.  that's where when  using kubectl get nodes its showing role as &quot;control-plane&quot; instead of &quot;control-plane,master&quot;
more details are in following link
kubeadm: http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/readme.md
"
68590914,"ingress uses wildcard, although i didn't specify that","i have the following ingress:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: my-ingress
  namespace: apps
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/custom-http-errors: '404'
spec:
  tls:
    - hosts:
        - mywebsite.com
      secretname: my-secret-tls
  rules:
  - host: mywebsite.com
  - http:
      paths:
        - path: /api/events
          pathtype: implementationspecific
          backend:
            service:
              name: my-events-api-svc
              port:
                number: 80

when i kubectl describe this ingress, i see the following
name:             my-ingress
namespace:        apps
address:          52.206.112.10
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  my-secret-tls terminates mywebsite.com
rules:
  host        path  backends
  ----        ----  --------
  *           
              /api/events   my-events-api-svc:80 (10.244.4.145:4000,10.244.5.118:4000)
annotations:  kubernetes.io/ingress.class: nginx
              nginx.ingress.kubernetes.io/custom-http-errors: 404
events:
  type    reason  age                from                      message
  ----    ------  ----               ----                      -------
  normal  update  9s (x7 over 153m)  nginx-ingress-controller  ingress apps/my-ingress


the issue is that the specified path doesn't work, i'm getting 404. i noticed that in the output above, there is a * under the host. my other ingresses are configured pretty much the same (only have different paths set), and there is no * in the kubectl describe output. instead, in my other ingresses the proper host - &quot;mywebsite.com&quot; - is shown.
the output above also has some error (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;), but i see it as well in my other ingresses (that do work).
what could be the problem?
",<kubernetes><kubernetes-ingress><nginx-ingress>,68620763,1,"its your indentation, please check official example
spec:
  rules:
    - host: hello-world.info
      http:
        paths:

try
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: my-ingress
  namespace: apps
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/custom-http-errors: '404'
spec:
  tls:
    - hosts:
        - mywebsite.com
      secretname: my-secret-tls
  rules:
  - host: mywebsite.com
    http:
      paths:
        - path: /api/events
          pathtype: implementationspecific
          backend:
            service:
              name: my-events-api-svc
              port:
                number: 80

"
58028761,pass array in helm values property,"i would like to pass array as property in yaml (values file) in helm. what i tried:


attempt.

elasticsearch:
  uri: ""[\""127.0.0.1:9200\"",\""127.0.0.2:9200\""]""


error:


  readstring: expects "" or n, but found [, error found in #10 byte of
  ...|rch_url"":[""127.0.0.1|..., bigger context
  ...|{""apiversion"":""v1"",""data"":{""elastic_search_url"": [""127.0.0.1:9200"",""127.0.0.2:9200""],""logs_env_prefi|...

attempt. according to official helm site how to pass array

elasticsearch:
  --set uri={127.0.0.1:9200,127.0.0.2:9200}


with error:


  error converting yaml to json: yaml: line 15: mapping values are not
  allowed in this context

attempt.

 elasticsearch:
   uri: 
   - 127.0.0.1:9200
   - 127.0.0.2:9200


failed with the same exception as 1.


edit:
actually in my case the helm values were not used in yaml file then, so i needed another format and finally solution was to pass uri as string with single quote: 

 elasticsearch:
   uri: '[""127.0.0.1:9200"",""127.0.0.2:9200""]'


nevertheless @marcin answer was correct.
",<kubernetes><kubernetes-helm>,58030379,29,"you pass an array of values by using either flow syntax:
elasticsearch:
  uri: [&quot;127.0.0.1:9200&quot;, &quot;127.0.0.2:9200&quot;]

or block syntax:
elasticsearch:
  uri: 
  - 127.0.0.1:9200
  - 127.0.0.2:9200

you can then access the values in helm templates using range:
uris:{{- range .values.elasticsearch.uri }}
{{.}}{{- end }}

resolves to:
uris:
127.0.0.1:9200
127.0.0.2:9200

"
68266107,ingress not enabled in minikube,"i enabled ingress on minikube
c:\windows\system32&gt;minikube addons enable ingress
  - using image k8s.gcr.io/ingress-nginx/controller:v0.44.0
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
* verifying ingress addon...
* the 'ingress' addon is enabled

but when i list it, i don't see it
c:\windows\system32&gt;minikube kubectl -- get pod -n kube-system
name                               ready   status    restarts   age
coredns-74ff55c5b-px725            1/1     running   0          13d
etcd-minikube                      1/1     running   0          13d
kube-apiserver-minikube            1/1     running   6          13d
kube-controller-manager-minikube   1/1     running   0          13d
kube-proxy-h7r79                   1/1     running   0          13d
kube-scheduler-minikube            1/1     running   0          13d
storage-provisioner                1/1     running   76         13d

is the ingress not enabled? how can i check?
",<kubernetes><kubernetes-ingress><minikube>,68269965,1,"i have recreated this situation and got the same situation. after execution the command:
minikube addons enable ingress

i have same output as yours:
  - using image k8s.gcr.io/ingress-nginx/controller:v0.44.0
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
* verifying ingress addon...
* the 'ingress' addon is enabled

i have also the same output, when i have executed:
minikube kubectl -- get pod -n kube-system


solution:
first you can list namespaces with command:
minikube kubectl get namespaces

and your output should be as follow:
name              status   age
default           active   4m46s
ingress-nginx     active   2m28s
kube-node-lease   active   4m47s
kube-public       active   4m47s
kube-system       active   4m47s

the ingress should be in the ingress-nginx namespace. execute:
minikube kubectl -- get pods --namespace ingress-nginx

and then your output should be as follow:
name                                        ready   status      restarts   age
ingress-nginx-admission-create-nqnvj        0/1     completed   0          2m56s
ingress-nginx-admission-patch-62z9z         0/1     completed   0          2m55s
ingress-nginx-controller-5d88495688-ssv5c   1/1     running     0          2m56s

summary - your ingress controller should work, just in a different namespace.
"
58474678,how to cleanup failed cronjob spawned jobs once a more recent job passes,"i am running management tasks using kubernetes cronjobs and have prometheus alerting on when one of the spawned jobs fails using kube-state-metrics:

kube_job_status_failed{job=""kube-state-metrics""}  &gt; 0


i want to have it so that when a more recent job passes then the failed ones are cleaned up so that the alert stops firing.

does the cronjob resource support this behaviour on its own?

workarounds would be to make the job clean up failed ones as the last step or to create a much more complicated alert rule to take the most recent job as the definitive status, but they are not the nicest solutions imo.

kubernetes version: v1.15.1
",<kubernetes><prometheus><kubernetes-cronjob><kube-state-metrics>,58476631,3,"as a workaround the following query would show cronjobs where the last finished job has failed

(max by(owner_name, namespace) (kube_job_status_start_time * on(job_name) group_left(owner_name) ((kube_job_status_succeeded / kube_job_status_succeeded == 1) + on(job_name) group_left(owner_name) (0 * kube_job_owner{owner_is_controller=""true"",owner_kind=""cronjob""}))))
&lt; bool
(max by(owner_name, namespace) (kube_job_status_start_time * on(job_name) group_left(owner_name) ((kube_job_status_failed / kube_job_status_failed == 1) + on(job_name) group_left(owner_name) (0 * kube_job_owner{owner_is_controller=""true"",owner_kind=""cronjob""})))) == 1

"
57346671,helm init 'target machine actively refuses' error,"i'm trying to start using helm and when i type helm init
it shows me the following error:

creating c:\users\username\.helm\repository\repositories.yaml
adding stable repo with url: https://kubernetes-charts.storage.googleapis.com
error: error initializing: looks like ""https://kubernetes-charts.storage.googleapis.com"" is not a valid chart repository or cannot be reached: get https://kubernetes-charts.storage.googleapis.com/index.yaml: dial tcp 74.125.193.128:443: connectex: no connection could be made because the target machine actively refused it.


tried pinging to 74.125.193.128:443 as well and it won't work too.
i thought it was a proxy issue but it's not it so i tried looking online for similar issues and haven't encountered any with the same error.
",<kubernetes><kubernetes-helm>,57354071,1,"what eventually was the problem is that a repositories.yaml file didn't exist in the .helm/repository folder.
it worked when i created the file with the following content:

apiversion: v1
repositories:
  - name: charts
    url: ""https://kubernetes-charts.storage.googleapis.com""
  - name: local
    url: ""http://localhost:8879/charts""


then i could do helm init with no problem.
"
64013958,why is my externalname type service configuration not working in kubernetes?,"i created two namespaces and services in each namespace:

namespace: app-layer

rest-app
db-service-externalname


namespace: data-layer

db-service



when i try to connect to the mysql database in db service from the rest-app, i get the error:

mysql.data.mysqlclient.mysqlexception (0x80004005): unable to connect to any of the specified mysql hosts.
---&gt; system.aggregateexception: one or more errors occurred. (name or service not known)

i printed out in logs, and it correctly has db-service as the service name, and has the right user/pass.
here's what i defined:
db-service
apiversion: v1
kind: service
metadata:
  name: db-service
  namespace: data-layer
spec:
  selector:
    app: db-service
  ports:
   - port: 3306
  clusterip: none

db-service-externalname
apiversion: v1
kind: service
metadata:
  name: db-service
  namespace: app-layer
spec:
  type: externalname
  externalname: db-service.data-layer.service.cluster.local
  ports:
    - port: 3306

rest-app
apiversion: apps/v1
kind: deployment
metadata:
  name: rest-app
  namespace: app-layer
  labels:
    app: rest-app
spec:
  replicas: 1
  selector:
    matchlabels:
      app: rest-app
  template:
    metadata:
      labels:
        app: rest-app
    spec:
      containers:
        - name: rest-app
          image: restapp:latest
          imagepullpolicy: always
          ports:
            - containerport: 5000
          env:
            # these are from a secret i defined, and the logs show
            # the rest app gets them correctly
            - name: mysql_root_username
              valuefrom:
                secretkeyref:
                  name: db-credentials
                  key: db-username
            - name: mysql_root_password
              valuefrom:
                secretkeyref:
                  name: db-credentials
                  key: db-password
            # i hard-coded this to the externalname i created. 
            # is that right?
            - name: mysql_url
              value: db-service

questions:

am i correct to make the externalname in the app-layer namespace?
do i need to define it differently?
can the c# app in the docker container not refer to db-service which is the name of the externalname service?

",<mysql><docker><kubernetes><kubernetes-networking><kubernetes-namespace>,64013991,2,"the externalname type service should be as below. notice usage of svc instead of service.
apiversion: v1
kind: service
metadata:
  name: db-service
  namespace: app-layer
spec:
  type: externalname
  externalname: db-service.data-layer.svc.cluster.local
  ports:
    - port: 3306

"
31094465,how do i run more than 5 containers in a kubernetes pod on gce?,"i've got a pod configuration from docker that involves 7 nodes. it gets stuck in pending state unless i remove two of the containers from the config. it doesn't matter which two i remove. it only works with five containers, which seems like a hard limit that i can't find documented.

how do i run more than 5 containers in a kubernetes pod on google container engine?
",<kubernetes><google-kubernetes-engine>,31095145,1,"i'm fairly sure there isn't a hard cap of 5 containers per pod, so there's likely some other reason why the scheduler can't find a node to run your pod on.

you should be able find a message saying why the pod is still pending by running kubectl describe pod $podname to see the most recent 'event' that happened to the pod, or by running kubectl get events to see all the recent events from the cluster.
"
57104822,kubernetes secret items not mounted as file path,"i have the following yaml:

        volumemounts:
        - name: app-secret
          mountpath: /app
          readonly: true
      volumes:
      - name: app-secret
        secret:
          secretname: app-secret
          items:
          - key: app-secret.json
            path: appsettings.secret.json


i expect the secret is mounted on /app/appsettings.secret.json but it isn't. i don't know where it is mounted and the container crashes and i don't have a chance to kubectl exec into the container to inspect where the secret is mounted. my guess is that it wipes out the content of /app. any advice and insight is appreciated.
",<kubernetes><mount-point><kubernetes-secrets><app-secret>,57125035,15,"this works:

 volumemounts:
        - name: app-secret
          mountpath: /app/appsettings.secret.json
          subpath: appsettings.secret.json
          readonly: true
      volumes:
      - name: app-secret
        secret:
          secretname: app-secret
          items:
          - key: app-secret.json
            path: appsettings.secret.json

"
52384119,helm deployments with readynessprobe,"i am using helm in my ci to upgrade deployments with newer versions of charts.

helm upgrade --wait --install .


expected behavior:
the --wait flag should wait for the readinessprobe defined in the new chart.
see also:
https://docs.helm.sh/helm/#helm-upgrade

however, it does not wait and simply deploys the new chart, even if the readinessprobe is failing.

which results in a failed new chart and a killed old chart.

it has nothing to do with 
https://github.com/helm/helm/issues/3173, as the readinessprobe is properly executed and fails. but helm does simply not wait for this.

did anybody face issues like that? 
thanks!
",<kubernetes><kubernetes-helm>,52475783,2,"the issue was fixed by setting the following kubernetes yaml description inside the deployment ressource:

  strategy:
   type: rollingupdate
   rollingupdate:
    maxsurge: 1
    maxunavailable: 0


kubernetes deployment documentation:


  note: the deployment controller will stop the bad rollout
  automatically, and will stop scaling up the new replicaset. this
  depends on the rollingupdate parameters (maxunavailable specifically)
  that you have specified. kubernetes by default sets the value to 1 and
  .spec.replicas to 1 so if you haven’t cared about setting those
  parameters, your deployment can have 100% unavailability by default!
  this will be fixed in kubernetes in a future version.

"
64880763,deploy kong api gateway in gke via helm and use google managed certificates,"we're currently trying to deploy kong in a gke cluster and the goal is to delegate the certificate management to google's load balancer (the ssl termination should be made here).
the problem we faced is that all google's documentation is focus on deploying some service and use their exclusive load balancer that connects directly to the ingress declared.
the configuration which currently works (without kong) is the following:
# values.yml (from service x inside gke, using helm)
...
ingress:
  enabled: true
  hostname: example.com
  annotations:
    kubernetes.io/ingress.class: gce
    kubernetes.io/ingress.allow-http: &quot;false&quot;
    kubernetes.io/ingress.global-static-ip-name: example-static-ip
    ingress.gcp.kubernetes.io/pre-shared-cert: example-cert
...

however, when we change gce for kong as the ingress.class, all other annotations don't continue to work. this is expected, as now kong's proxy is the one being the load balancer and should be the one that tells google's lb how to generate itself.
according to this documentation, it should be fairly simple to add those annotations to kong proxy service.
based on this chain of events:

k8s ingress creates kong proxy service
kong proxy service generates google's lb

the configuration to customize the lb should be made inside kong's service (as i understand):
# values.yml (kong, using helm)
...
proxy:
  type: loadbalancer
  annotations: {} &lt;-- here
  http:
    ...
  tls:
    ...
...

however, for gcp there are only a few according to the docs, and none of them have the desire effect (cannot set certificate to use, define which type of lb to create, etc.)
all things into account, is there any way to achieve our main goal which would be:
&quot;deploy kong api gateway through helm inside gke and delegate ssl termination to custom google's lb.&quot;
",<kubernetes><google-cloud-platform><google-kubernetes-engine><kong><google-cloud-load-balancer>,64897009,1,"tl;dr
unfortunately there is no possibility to use google managed certificates with kong ingress.
to be exact google managed certificates in gke can be used only with:

ingress for external http(s) load balancing

as pointed by documentation:

note: this feature is only available with ingress for external http(s) load balancing.
-- cloud.google.com: kubernetes engine: docs: how to: managed certs



explanation
according to the documentation (slightly modified):

when you create an ingress object with below class:

kubernetes.io/ingress.class: gce

the gke ingress controller creates a google cloud http(s) load balancer and configures it according to the information in the ingress and its associated services.
-- cloud.google.com: kubernetes engine: ingress: ingress for external and internal traffic

using different ingress controllers like (nginx-ingress, traefik, kong) require you to use service of type loadbalancer.
using above service in gke will automatically create external tcp/udp network load balancer (l4) pointing to your ingress controller. from this point the traffic will be redirected to specific services based on the ingress resource with appropriate ingress.class.

a tip!
you can see in the helm chart of kong that it's using the same way!

helm install kong/kong kong-ingress --dry-run --debug


to have the secure connection between the client and kong you will need to either:

use cert-manager to provision the certificates for the ingress controller.

cert-manager.io: docs


provision the certificates in other way and provide them as a secret to be used by ingress controller.

kubernetes.io: secret: tls secrets




side note: in both ways the ssl termination will happen at the ingress controller.


answering the part of the question:

the configuration to customize the lb should be made inside kong's service (as i understand):
# values.yml (kong, using helm)
...
proxy:
  type: loadbalancer
  annotations: {} &lt;-- here
...

however, for gcp there are only a few according to the docs, and none of them have the desire effect (cannot set certificate to use, define which type of lb to create, etc.)

as said earlier service of type loadbalancer in gke will configure l4 tcp/udp loadbalancer which is not designed to be responsible for handling ssl traffic (ssl termination).

additional resources:

cloud.google.com: load balancing: docs: network
github.com: kong: kubernetes ingress controller

"
63830490,helm install time out,"running helm install for my chart gives my time out error. i have no idea why. running this in a simple aws instance, no firewall or anything like that. i worked previously and suddenly stopped working.
# helm install xxxx-services-1 chart/ --values chart/values.yaml
error: failed pre-install: timed out waiting for the condition

already tried:

restarting kubernetes
rebooting the machine
kubeadm reset &amp; kubeadm init

update:

using helm 3

when i run with --debug, these are last lines, and it's stuck there:
client.go:463: [debug] watching for changes to job xxxx-services-1-ingress-nginx-admission-create with timeout of 5m0s
client.go:491: [debug] add/modify event for xxxx-services-1-ingress-nginx-admission-create: added
client.go:530: [debug] xxxx-services-1-ingress-nginx-admission-create: jobs active: 0, jobs failed: 0, jobs succeeded: 0
client.go:491: [debug] add/modify event for xxxx-services-1-ingress-nginx-admission-create: modified
client.go:530: [debug] xxxxx-services-1-ingress-nginx-admission-create: jobs active: 1, jobs failed: 0, jobs succeeded: 0

when i do kubectl get jobs i did see an active job, i deleted it, ran the install again - still same result


",<kubernetes><kubernetes-helm>,63836806,3,"found the issue, i didn't taint my master node...
kubectl taint nodes --all node-role.kubernetes.io/master-
i can't believe how much time i spent on this little thing...
"
65023547,how to set server snippets config in nginx ingress with helm,"related github issue : https://github.com/kubernetes/ingress-nginx/issues/6519
apiversion: v1
data:
  server-snippet: |
    if ($http_x_azure_fdid !~* &quot;55ce4ed1-4b06-4bf1-b40e-4638452104da&quot; ) {
        return 403;
    }
  use-forwarded-headers: &quot;true&quot;
kind: configmap

how to achieve the above config using helm when setting the values in the following approach?
helm upgrade --install nginx-ingress-controller ingress-nginx/ingress-nginx \
    --namespace &quot;${namespace}&quot; \
    --version &quot;${chart_version}&quot; \
    --set controller.replicacount=&quot;${replicas}&quot; \
    --set-string controller.config.use-forwarded-headers=true \
    --set-string controller.config.server-snippet=&lt;?&gt; \
    --debug

",<kubernetes><kubernetes-helm><nginx-ingress><azure-aks><azure-front-door>,65034216,5,"you can define a multiline environment variable as below,
read -d '' conf &lt;&lt; eof
if ($http_x_azure_fdid !~* &quot;55ce4ed1-4b06-4bf1-b40e-4638452104da&quot; ) {
       return 403;
}
 eof

once the environment variable is defined, refer it in the helm --set-string controller.config.server-snippet= arg as below,
helm upgrade --install nginx-ingress-controller ingress-nginx/ingress-nginx \
    --namespace &quot;${namespace}&quot; \
    --version &quot;${chart_version}&quot; \
    --set controller.replicacount=&quot;${replicas}&quot; \
    --set-string controller.config.use-forwarded-headers=true \
    --set-string controller.config.server-snippet=$conf \
    --debug

"
63525889,how to run a https secured app in kubernetes cluster,"i want to run my app inside kubernetes cluster on https and expose it outside the cluster also over https. i created the pod and exposed the port 443. after that i created a clusterip service which connects to the pod on port 443 and expose also port 443. lastly, i created an ingress which connects to the service on port 443. i deployed all of these resources using helm chart on gke. i use nginx ingress controller. you can find the chart here.
when i access the app internally in the cluster over https it works.
curl https://my-nginx.https-app-64-production --cacert /etc/nginx/ssl/tls.crt
&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: tahoma, verdana, arial, sans-serif;
    }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;welcome to nginx!&lt;/h1&gt;
&lt;p&gt;if you see this page, the nginx web server is successfully installed and
working. further configuration is required.&lt;/p&gt;

&lt;p&gt;for online documentation and support please refer to
&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
commercial support is available at
&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;

but when i access it using external url then i get below error.
curl https://staging.vs-creator.iotcrawler.eu/
&lt;html&gt;
&lt;head&gt;&lt;title&gt;400 the plain http request was sent to https port&lt;/title&gt;&lt;/head&gt;
&lt;body bgcolor=&quot;white&quot;&gt;
&lt;center&gt;&lt;h1&gt;400 bad request&lt;/h1&gt;&lt;/center&gt;
&lt;center&gt;the plain http request was sent to https port&lt;/center&gt;
&lt;hr&gt;&lt;center&gt;nginx/1.9.1&lt;/center&gt;
&lt;/body&gt;
&lt;/html&gt;

i am not able to figure out what is going wrong. i suspect it is to do with ingress controller configuration. please help me on this.
",<kubernetes><kubernetes-ingress><nginx-ingress>,63526144,6,"use below annotation in ingress resourece
nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;

from the docs

using backend-protocol annotations is possible to indicate how nginx
should communicate with the backend service. (replaces secure-backends
in older versions) valid values: http, https, grpc, grpcs, ajp and
fcgi

by default nginx uses http while forwarding the request to backend pod which leads to 400 the plain http request was sent to https port because the backend pod is expecting https request.
"
67014857,how can i package and run a react single page app using bitnami?,"i have a react spa (single page application) and want to deploy it to a kubernetes environment.
for the sake of keeping it simple, assume the spa is stand alone.
i've been told bitnami's repo for helm charts are a good place to start to solve this problem.
so my question is what bitnami chart should i use to deploy a react spa to a kubernetes cluster? and where can i find the steps explained?
what i want
the desired solution should be a helm chart that serves up static content.  typically app.js and index.html page, and other static content.  and lets me specify the sub-directory to use as the contents of the website.  in react, the build subdirectory holds the website.
what i currently do (how to deploy a spa to k8s my steps)
what i currently do is described below.  i'm starting from a new app created by create-react-app so that others could follow along and do this if needed to helm answer the question.
this assumes you have docker, kubernetes and helm installed (as well as node and npm for react).
the following commands do the following:

create a new react application
create a docker container for it.
build and test the spa running in a local docker image .
create a helm chart to deploy the image to k8s.
configure the helm chart so it uses the docker image created in step 3.
using the helm cli deploy the spa app to the k8s cluster.
test the spa running in k8s cluster.

#1 create a new react application
npx create-react-app spatok8s
cd spatok8s
npm run build

at this point the static spa website is created an is in the build directory.
2. create a docker container for it.
next, create dockerfile with the following.  for example, vi dockerfile and put the following in it.    the dockerfile was what is described here https://hub.docker.com/_/nginx.
from nginx
copy build /usr/share/nginx/html

these commands say to use the nginx docker image (from dockerhub) and copy my website onto the image so my website will be self contained within the image.  when the image starts (nginx starts) and the only content to be served will be my index.html file in the /usr/share/nginx/html/index.html file.
3. build and test the spa running in a local docker image .
next build the docker image spatok8s and run it locally, and open your browser to http://localhost:8082 (used in this example).
docker build -t spatok8s .
docker run -d -p8082:80 spatok8s

after you've verified it works stop it using docker stop # where the # is the container number from docker ps -q --filter ancestor=spatok8s.
4. create a helm chart to deploy the image to k8s.
now create a helm chart so i can deploy this docker image to kubernetes:
helm create spatok8schart

5. configure the helm chart so it uses the docker image created in step 3.
update the helm chart for this application vi spatok8schart
the lines changed are included below:
  # update the repo to use the docker image just built
  repository: spatok8s
. . .
   # update the url to use to access the spa when it is deployed to kubernetes
   - host: spatok8s.local
. . .
          servicename: spatok8s.local

6. using the helm cli deploy the spa app to the k8s cluster.
deploy it
helm install spatok8s spatok8schart

the output for the last command is:
name: spatok8s
last deployed: thu apr  8 22:50:26 2021
namespace: default
status: deployed
revision: 1
notes:
1. get the application url by running these commands:
  http://spatok8s.local/


7. test the spa running in k8s cluster.
open the browser to http://spatok8s.local.
if you are doing local development and your kubernetes environment is not automatically setting up your dns names, then you'll have to manually set the hostname spatok8s.local to the ip address of the kubernetes cluster.
the files /etc/hosts or c:\windows\system32\drivers\etc\hosts can be used to hold that information.
searching for a solution
so it works but it isn't as easy as i've been told it could be, so i'm searching for the bitnami chart that will make this easier.
i searched helm chart for deploying a single page app? and found:

https://developer.ibm.com/depmodels/cloud/tutorials/convert-sample-web-app-to-helmchart/ - which requires an ibm private cloud (a non-starter for me).

https://wkrzywiec.medium.com/how-to-deploy-application-on-kubernetes-with-helm-39f545ad33b8 - a medium article which looked overly complicated for what i want to do.

https://opensource.com/article/20/5/helm-charts - good article but not what i'm looking for


",<nginx><kubernetes><kubernetes-helm>,67014858,1,"a search for &quot;what bitnami chart should i use to deploy a react spa?&quot; is what worked for me.
see https://docs.bitnami.com/tutorials/deploy-react-application-kubernetes-helm/.
i'll summarize the steps below but this website should be around for a while.
the binami approach
step 1: build and test a custom docker image
step 2: publish the docker image
step 3: deploy the application on kubernetes
step 1: build and test a custom docker image
the website provides a sample react app
git clone https://github.com/pankajladhar/gfontsspace.git
cd gfontsspace
npm install

create a dockerfile with the following:
from bitnami/apache:latest
copy build /app

build and test it.  build the docker image, replacing the username placeholder in the command below with your docker hub username:
docker build -t username/react-app .

run it to verify it works:
docker run -p 8080:8080 username/react-app

step 2: publish the docker image
docker login
docker push username/react-app

again use your docker hub username
step 3: deploy the application on kubernetes
make sure that you can to connect to your kubernetes cluster by executing the command below:
kubectl cluster-info

update your helm repository list:
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

deploy the application by executing the following (replace the username placeholder with your docker username):
helm install apache bitnami/apache \
    --set image.repository=username/react-app \
    --set image.tag=latest \
    --set image.pullpolicy=always

if you wish to access the application externally through a domain name and you have installed the nginx ingress controller, use this command instead and replace the domain placeholder with your domain name:
helm install apache bitnami/apache \
    --set image.repository=username/react-app \
    --set image.tag=latest \
    --set image.pullpolicy=always \
    --set ingress.enabled=true \
    --set ingress.hosts[0].name=domain

you were actually doing the same steps, so your manual approach was &quot;spot on&quot;!
thanks again to vikram vaswani, and this website https://docs.bitnami.com/tutorials/deploy-react-application-kubernetes-helm that had this answer!
"
66588719,"unknown field ""sethostnameasfqdn"" despite using latest kubectl client","i have a deployment yaml file that looks like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: hello-kubernetes
spec:
  replicas: 1
  selector:
    matchlabels:
      app: hello-kubernetes
  template:
    metadata:
      labels:
        app: hello-kubernetes
    spec:
      sethostnameasfqdn: true
      hostname: hello
      subdomain: world
      containers:
      - name: hello-kubernetes
        image: redis 

however, i am getting this error:
$ kubectl apply -f dep.yaml  

error: error validating &quot;dep.yaml&quot;: error validating data: validationerror(deployment.spec.template.spec): unknown field &quot;sethostnameasfqdn&quot; in io.k8s.api.core.v1.podspec; if you choose to ignore these errors, turn validation off with --validate=false

my kubectl version:
$ kubectl version --client
client version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.0&quot;, gitcommit:&quot;af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2020-12-08t17:59:43z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;darwin/amd64&quot;}

after specifying --validate=falsee, hostname and hostname -f still return different values.
i believe i missunderstood something. doc says that sethostnameasfqdn will be available from kubernetes v1.20
",<kubernetes><deployment><kubectl><podspec>,66588940,3,"you showed kubectl version. your kubernetes version also need to be v1.20.  make sure you are using kubernetes version v1.20.
use kubectl version for seeing both client and server version. where client version refers to kubectl version and server version refers to kubernetes version.
as far the k8s v1.20 release note doc: previously introduced in 1.19 behind a feature gate, sethostnameasfqdn  is now enabled by default. more details on this behavior is available in documentation for dns for services and pods
"
71065233,can you avoid the pod to be restarted after kubectl attach?,"i have an ubuntu image that i use for debugging.
i do kubectl attach my-app -c my-app -it and then many apt-get install and other configurations i need.
the problem is when i exit ctrl+c the pod seems to get restarted and i loose all what i did
is there a way like --restart=never to avoid the container to be recreated
",<kubernetes><kubectl>,71065279,2,"run another shell session kubectl exec my-app -c my-app -it -- bash to prepare your container. alternately, if your pod spec has the following set to true:
stdin: true 
tty: true 

you use the escape sequence ctrl+p followed by ctrl+q to detach from the container after kubectl attach -it to the container.
"
75020282,why this legacy sa has access to resources,"i am failing to understand why a particular google cloud service account has access to resources in a specific namespace inside gke.
there seem to be no evidence it should have access. alternatively, it could be me who's misinterpreting iam / rbac integration.
is there any logs i could check to see what access policies are in use inside kubernetes when this sa attempts to access specific resources in it?
for context, i have this service account:
github@my-project.iam.gserviceaccount.com

the account is assigned the following:

on google cloud iam level, i have roles/container.developer assigned to the said service account,

on kubernetes (gke) level, i have a role + role binding created:
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  name: ci-cd
  namespace: default
rules:
- apigroups:
  - apps
  resourcenames:
  - my-backend
  resources:
  - deployments
  verbs:
  - list
  - watch
  - patch
  - get

apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: ci-cd
  namespace: default
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: ci-cd
subjects:
- apigroup: rbac.authorization.k8s.io
  kind: user
  name: github@my-project.iam.gserviceaccount.com
  namespace: default



this sa can perform patch on deployment as expected:
kubectl auth can-i patch deployment/my-backend \
  --namespace default \
  --as github@my-project.iam.gserviceaccount.com
yes

what's confusing, and what i am failing to explain to myself, is why this account's attempts to patch a deployment with a different name in different namespace are successful (as observed), which i am able to cross-check by confirming with cloud audit logs:
insertid: 10f277c5-041c-4e61-afa6-5ca669393a50
labels:
  authorization.k8s.io/decision: allow
  authorization.k8s.io/reason: access granted by iam permissions.
logname: projects/my-project/logs/cloudaudit.googleapis.com%2factivity
operation:
  first: true
  id: 10fc17c5-041c-4e61-afa6-5ca661793a50
  last: true
  producer: k8s.io
protopayload:
  '@type': type.googleapis.com/google.cloud.audit.auditlog
  authenticationinfo:
    principalemail: github@my-project.iam.gserviceaccount.com
  authorizationinfo:
  - granted: true
    permission: io.k8s.apps.v1.deployments.patch
    resource: apps/v1/namespaces/review-apps/deployments/my-backend-5005
  methodname: io.k8s.apps.v1.deployments.patch
  request:
# ...

...all the while this returns no:
kubectl auth can-i patch deployment/my-backend-5005 \
  --namespace review-apps \
  --as github@my-project.iam.gserviceaccount.com
no

i am at a loss here. send help.
",<kubernetes><google-cloud-platform><google-kubernetes-engine><google-cloud-iam>,75029910,1,"the problem was me misinterpreting a item 2 from &quot;applications within google cloud&quot; section of &quot;authenticating to the kubernetes api server&quot; article.
particularly, i found this wording to be confusing:

you can also use rbac to grant the iam...

my mistake was that i've implemented suggestions from the item entirely, e.g. both granted an iam permission and added a kubernetes-level rbac. because of this, i observed the following:

due to iam permission, the service account can effectively perform actions to most objects across namespaces, disregarding any kubernetes-level rbac rules,

due to rbac policy i have, i had results coming from kubectl auth can-i that contradicted previous item,


i wish the you can also use rbac to grant the iam... could be reworded to *alternatively, use rbac to grant the iam...&quot;. filed a documentation update request for google cloud for that page.
"
54631039,google cloud kubernetes unable to connect to cluster,"i'm getting unable to connect to the server: dial tcp &lt;ip&gt; i/o timeout when trying to run kubectl get pods when connected to my cluster in google shell. this  started out of the blue without me doing any changes to my cluster setup. 

gcloud beta container clusters create tia-test-cluster \
    --create-subnetwork name=my-cluster\
    --enable-ip-alias \
    --enable-private-nodes \
    --master-ipv4-cidr &lt;ip&gt; \
    --enable-master-authorized-networks \
    --master-authorized-networks &lt;ip&gt; \
    --no-enable-basic-auth \
    --no-issue-client-certificate \
    --cluster-version=1.11.2-gke.18 \
    --region=europe-north1 \
    --metadata disable-legacy-endpoints=true \
    --enable-stackdriver-kubernetes \
    --enable-autoupgrade


this is the current cluster-config. 
i've run gcloud container clusters get-credentials my-cluster --zone europe-north1-a --project &lt;my project&gt; before doing this aswell.

i also noticed that my compute instances have lost their external ips. in our staging environment, everything works as it should based on the same config.

any pointers would be greatly appreciated.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,54631200,3,"from what i can see of what you've posted you've turned on master authorized networks for the network &lt;ip&gt;.

if the ip address of the google cloud shell ever changes that is the exact error that you would expect.

as per https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#cloud_shell: you need to update the allowed ip address.

gcloud container clusters update tia-test-cluster \
    --region europe-north1 \
    --enable-master-authorized-networks \
    --master-authorized-networks [existing_auth_nets],[shell_ip]/32

"
69366275,how to access a service deployed as nodeport in minikube in ec2 from outside,"i have installed minikube in ec2 linux instance.
minikube ip : 192.168.49.2, 
ec2 instance ip: 10.x.x.x

i've deployed an application as nodeport service type where
port: 80
targetport: 80
nodeport: 32768
and able to access it with curl http://192.168.49.2:32768 within the cluster.

how should i expose this application to the outside world?
if port forwarding is the option then i tried the below ways:
kubectl port-forward --address &lt;instanceip&gt; svc/my-service 8888:80

this always gives error:
unable to listen on port 5000: 
listeners failed to create with the following errors: 
[unable to create listener] error: 
unable to listen on any of the requested ports: [{8888 80}]

i made sure there is no service running on port 8888.
kubectl port-forward --address &lt;instanceip&gt; svc/my-service 8888:32768

this says, error:
service my-service does not have a service port 32768.

any help is appreciated
",<kubernetes><kubernetes-helm><kubernetes-ingress><minikube>,69366408,2,"
how should i expose this application to the outside world?

you should use a service with a type: loadbalancer
loadbalancer will give you an external ip that will allow you to connect to it from outside the cluster.
if you only need it for testing and this is why you are using minikube then port forward should cover the requirements.
using loadbalancer with minikube
in order to use loadbalanacer with minikube you should open a new terminal and execute minikube tunnel
# port forward to the desired service, 
# dont forget to add the namespace if any

#
# you should forward to port 80 which is the port defined in your service
#     port : 80
#     targetport : 80
kubectl port-forward svc/my-service 8888:80 -n &lt;namespace&gt;

# as you mentioned you tried it already and it's not working
# so follow below and try to expose your service with

kubectl expose

now you should be able to connect to your service.

here is a full example which generates service
https://github.com/nirgeier/kuberneteslabs/tree/master/labs/02-deployments-imperative
the sample generates the service on the fly with
kubectl expose deployment -n codewizard multitool --port 80 --type nodeport

"
56881355,"ror: error validating ""deployment.yaml"": error validating data: the server could not find the requested resource;","i wrote down a simple deploymnet yaml and it fails with the error

kubectl create -f deployment.yaml
error: error validating ""deployment.yaml"": error validating data: the server could not find the requested resource; if you choose to ignore these errors, turn validation off with --validate=false


this used to work in the previous versions and if i turn --validate=false it still helps but i would like to understand why the error is seen.

my deployment.yaml file

apiversion: apps/v1
kind: deployment
metadata:
  name: httpd-deployment
  labels:
    app: httpd
spec:
  replicas: 1
  selector:
    matchlabels:
      app: httpd
  template:
    metadata:
      labels:
        app: httpd
    spec:
      containers:
      - name: httpd
        image: httpd:latest
        ports:
        - containerport: 80
        resources:
          requests:
          cpu: ""0.3""
          memory: ""500mi""


i'm running thsi on minikube and the minikube version is:
    minikube version: v1.2.0

are there any standards that we need to follow for the new version for creating the deployment yaml file. 

there are no errors that are displayed except these warning so troubeshooting this is becoming a pain.

so if there is anything that can help me fix could you please help.

thank you
",<kubernetes><google-kubernetes-engine><kubernetes-helm><kubectl><minikube>,56886050,3,"this is an issue with kubectl validating what is going to be sent into the api server rather than minikube itself.

the error is in the indentation as cpu and memory properties should be nested within requests and not in resources:

spec:
      containers:
      - name: httpd
        image: httpd:latest
        ports:
        - containerport: 80
        resources:
          requests:
            cpu: ""0.3""
            memory: ""500mi""


i've tested it using kubectl v1.15.0 and the error was correctly displayed:

$ kubectl apply -f test.yaml
$ error: error validating ""test.yaml"": error validating data: [validationerror(deployment.spec.template.spec.containers[0].resources): unknown field ""cpu"" in io.k8s.api.core.v1.resourcerequirements, validationerror(deployment.spec.template.spec.containers[0].resources): unknown field ""memory"" in io.k8s.api.core.v1.resourcerequirements]; if you choose to ignore these errors, turn validation off with --validate=false

"
40408321,what's the cli authentication process as of google container engine/kubernetes 1.4.5?,"which steps must one currently go through in order to authenticate against google container engine/kubernetes 1.4.5?

as i set up a third google cloud project today, i experienced that my previous gke cluster setup flow no longer worked. my flow was the following:

gcloud auth login
gcloud config set compute/region europe-west1
gcloud config set compute/zone europe-west1-d
gcloud config set project myproject
gcloud container clusters get-credentials staging
# an example of a typical kubectl command to see that you've got the right cluster
kubectl get pods --all-namespaces


whereas this used to work perfectly, i was now getting permission errors while trying to query the cluster, e.g. kubectl get pods would emit the following error message: the server does not allow access to the requested resource (get pods)

after googling back and forth, i realized that kubectl depends on something called application default credentials. at some point i also noticed by chance that gcloud auth login emits the following:

warning: `gcloud auth login` no longer writes application default credentials.
if you need to use adc, see:
  gcloud auth application-default --help


so i realized eventually, that with the current gcloud/kubernetes version i also need to call gcloud auth application-default in order to use the credentials of my current account rather than that of the previously activated project.

so, i am hoping someone can please clarify what is the actual authentication workflow for google container engine/kubernetes version 1.4.5??
",<kubernetes><google-kubernetes-engine>,40408592,1,"you found out the right answer. kubectl's gcp authentication plugin only supports application default credentials, which were recently decoupled from gcloud's standard credentials. so, in 1.4.5 you need to run gcloud auth application-default login to ensure that kubectl is using the credentials you expect.

we think that most users just expect to use the same credentials as gcloud, with adc being useful for some service account scenarios where gcloud might not even be installed. so, there is a pull request to kubernetes to add a ""use gcloud credentials"" option to the kubectl gcp authentication plugin. this should be available in kubectl 1.5.
"
59002247,how to customize the security group ingress rules created by a kubernetes loadbalancer type service that uses aws nlb for tcp services,"i have a tcp service that runs on via a kubernetes deployment on an aws eks cluster and is exposed to the internet by a service of type loadbalancer using the following definition

apiversion: v1
kind: service
metadata:
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
  name: tcpservice
spec:
  selector:
    app: tcpapp
  type: loadbalancer
  ports:
  - port: 4453
    targetport: 4453
    name: tcpport


because the load balancer type is nlb, the ingress traffic has to be explicitly allowed on the security group that is applied to the nodes themselves.  the security group was created like this:

✔ ~$ aws ec2 describe-security-groups --group-ids sg-2645567125762c6e2 | jq '.securitygroups[0].ippermissions[0]'
{
  ""fromport"": 32163,
  ""ipprotocol"": ""tcp"",
  ""ipranges"": [
    {
      ""cidrip"": ""10.20.0.0/20"",
      ""description"": ""kubernetes.io/rule/nlb/health=afd5427b6058811ea989512627425a2e""
    },
    {
      ""cidrip"": ""0.0.0.0/0"",
      ""description"": ""kubernetes.io/rule/nlb/client=afd5427b6058811ea989512627425a2e""
    }
  ],
  ""ipv6ranges"": [],
  ""prefixlistids"": [],
  ""toport"": 32163,
  ""useridgrouppairs"": []
}


so now i need to change the cidrip in the ""0.0.0.0/0"" to a different block. how can i do this using kubernetes manifests? i've looked at the networkpolicy and calico documentation, but this controls traffic to pods not services. i can change it with the aws api or manually, but those changes are lost when the service is redeployed.
",<amazon-web-services><kubernetes><amazon-eks>,59084785,5,"you need to add in your service manifest the loadbalancersourceranges parameter.

from documentation: 

in order to limit which client ip’s can access the network load balancer, specify loadbalancersourceranges.

spec:
  loadbalancersourceranges:
  - ""143.231.0.0/16""


https://v1-13.docs.kubernetes.io/docs/concepts/services-networking/service/

how code is implemented can be found here:

https://github.com/kubernetes/kubernetes/blob/9d6ebf6c78f406d8639aae189901e47562418071/pkg/api/service/util.go
"
68319231,enable endpoints for kube-controller-manager & kube-scheduler,"i am new to the kubernetes world and i am currently stuck with figuring out how to enable endpoints for kube-controller-manager &amp; kube-scheduler. in some future, i'll be using the helm kube-prometheus-stack to scrape those endpoints for metrics. however, for now what would be the right approach to set up those endpoints?
$  kubectl get ep  -n kube-system
name                                        endpoints                 age
kube-controller-manager                     &lt;none&gt;                    105d
kube-scheduler                              &lt;none&gt;                    105d

",<kubernetes><amazon-eks><kube-state-metrics>,68377190,1,"
no need to create endpoints for kube-controller-manage and kube-scheduler because they use hostnetwork and uses ports 10257 and 10259 respectively.

you can verify it checking the manifests &quot;/etc/kubernetes/manifests/&quot; and netstat -nltp or ss -nltp on masternode


ss -nltp | grep kube
listen   0         128                127.0.0.1:10257            0.0.0.0:*       users:((&quot;kube-controller&quot;,pid=50301,fd=7))
listen   0         128                127.0.0.1:10259            0.0.0.0:*       users:((&quot;kube-scheduler&quot;,pid=50400,fd=7))


so they should be accessible over &lt; masternodeip &gt;:&lt;10257/10259&gt;

"
66082312,how to connect to a minikube cluster from a docker container?,"i have a running minikube cluster. i can easily connect to it and apply changes using kubectl. but i want to run kubectl from a docker container. here is the dockerfile:
from alpine:latest

run apk --no-cache add curl

# install and configure kubectl
run curl -lo &quot;https://dl.k8s.io/release/$(curl -l -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;
run mkdir -p ~/.local/bin/kubectl
run mv ./kubectl ~/.local/bin/kubectl
run chmod +x ~/.local/bin/kubectl/ -r

it's basically a simple alpine image with kubectl installed.
how can i connect to my minikube cluster from this container?
",<docker><kubernetes><kubectl><minikube><kubeconfig>,66086483,2,"i had to copy ~/.kube and ~/.minikube folders into the image. this is the new dockerfile:
from alpine:latest

run apk --no-cache add curl

# install and configure kubectl
run curl -lo &quot;https://dl.k8s.io/release/$(curl -l -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;
run mkdir -p ~/.local/bin/kubectl
run mv ./kubectl ~/.local/bin/kubectl
copy .kube /root/.kube
copy .minikube /root/.minikube
run chmod +r ~/.kube/config
run chmod +x ~/.local/bin/kubectl/ -r
workdir /root/.local/bin/kubectl/

you can use the image like this:
docker build . -t username/kubectl:latest
docker run username/kubectl:latest ./kubectl get pods

attention
the .kube/config file is created for the host system. so you need to change some paths in .kube/config file to point to the .minikube folder in the container.
also note that
~/.minikube and ~/.kube are huge folders. adding them to your docker build context could make your builds really slow.
you might want to mount volumes for that purpose.
"
67346166,why kubectl exec --username=root does not work?,"i deployed istio/bookinfo on kubernetes, and i want to install stress on the microservice container to inject fault. however, when i use
kubectl exec -it reviews-v1-f55d74d54-kpxr2 -c reviews --username=root -- /bin/bash

to log in the container, it show that the user is still default. and the command 'apt-get' got
default@reviews-v2-6f4995984d-4752v:/$ apt-get update
reading package lists... done
e: list directory /var/lib/apt/lists/partial is missing. - acquire (13: permission denied)

i tried to use 'su root' but i don't know the answer.
i searched some answer say that i can use 'docker exec', it works but it is not convenient, so i want to know how to log in the container by use the command kubectl exec.
",<kubernetes><root><kubectl>,67380413,10,"this is not supported.
source code suggests it's a todo feature: kubernetes/kubectl/pkg/cmd/exec/exec.go
the --username flag explained by kubectl:
➜  ~ kubectl options  | grep user    
  --user='': the name of the kubeconfig user to use
  --username='': username for basic authentication to the api server

as you probably see, none of the user flags can change user/uid for exec.
all flags supported by exec command:
➜  ~ kubectl exec --help
[...]

options:
  -c, --container='': container name. if omitted, the first container in the pod will be chosen
  -f, --filename=[]: to use to exec into the resource
      --pod-running-timeout=1m0s: the length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one
pod is running
  -i, --stdin=false: pass stdin to the container
  -t, --tty=false: stdin is a tty

additionally, apt-get update is best to be run at build time, not at a run time.
it is a good practise to keep your containers immutable. for testing purpouses you should stick with docker exec because ther is no other known alternative.
also, if you have a specific problem to solve, explain the problem, not the solution. xyproblem
"
42692380,kubernetes services not reachable after introducing ingress with nginx ingress controller,"i have some services with external ip addresses in kubernetes that i was able to reach by navigating to the ip. i then configured an ingress with a nginx ingress-controller:

  annotations:
    kubernetes.io/ingress.class: ""nginx""


i can now reach the service over the static ip of the ingress, as expected. but can no longer reach the service directly over its external ip, nor any other services in k8s... why can't i reach the services with ingress configured?
",<nginx><kubernetes><google-kubernetes-engine>,43128089,2,"the ingress controller needs to be configured to allow access via its rules. see the documentation here: https://kubernetes.io/docs/user-guide/ingress/
"
66453952,how to force delete resources in a non-existant namespace?,"this question is a follow up of: how to list really all objects of a nonexistant namespace?
long story short:
$ kubectl get namespaces
name              status   age
argo              active   27d
default           active   27d
kube-node-lease   active   27d
kube-public       active   27d
kube-system       active   27d

$ kubectl get eventbus -n argo-events
name      age
default   17h

$ kubectl get eventsource -n argo-events
name                  age
pubsub-event-source   14h

there are two resources in namespace argo-events which actually no longer exits because i deleted it and expected it to be gone with all resources in it. obviously something didn't work as expected.
now (after listing potentially more objects - first question) i want to really get rid of those resources because they seem to block a redeployment.
but this ...
$ kubectl delete eventbus default -n argo-events
eventbus.argoproj.io &quot;default&quot; deleted
^c
$ kubectl delete eventsource pubsub-event-source -n argo-events
eventsource.argoproj.io &quot;pubsub-event-source&quot; deleted
^c

... doesn't work.
so, how do i force their deletion?

update:
$ kubectl describe eventbus default -n argo-events | grep -a 3 final
        f:finalizers:
          .:
          v:&quot;eventbus-controller&quot;:
      f:status:
$ kubectl describe eventsource pubsub-event-source -n argo-events | grep -a 3 final
        f:finalizers:
          .:
          v:&quot;eventsource-controller&quot;:
      f:spec:

",<kubernetes><google-kubernetes-engine>,66454235,7,"this worked:
$ kubectl create namespace argo-events
namespace/argo-events created

$ kubectl patch eventsource/pubsub-event-source -p '{&quot;metadata&quot;:{&quot;finalizers&quot;:[]}}' --type=merge -n argo-events
eventsource.argoproj.io/pubsub-event-source patched

$ kubectl patch eventbus/default -p '{&quot;metadata&quot;:{&quot;finalizers&quot;:[]}}' --type=merge -n argo-events
eventbus.argoproj.io/default patched

$ kubectl delete namespace argo-events
namespace &quot;argo-events&quot; deleted

if somebody stumbles upon this answer and knows why this works - please add an explanation in a comment. that would be cool, thanks.
"
56284836,is there any less hacky way of passing an ordinal index to statefulset environment variable?,"i'm trying to run a zookeeper ensemble and am having an issue passing a unique id as envrionment varible zoo_my_id as required by official zookeeeper image found here. 

i've tried reading about this and found similar overflow questions but none seems to be working. 

kubernetes statefulsets index/ordinal exposed in template
is there a way to get ordinal index of a pod with in kubernetes statefulset configuration file?

for some reason, i am still seeing the id for all servers to be the default id of 1

2019-05-24 01:38:31,648 [myid:1] - info  [quorumpeer[myid=1]/0:0:0:0:0:0:0:0:2181:fastleaderelection@847] - notification time out: 60000
2019-05-24 01:38:31,649 [myid:1] - info  [workersender[myid=1]:quorumcnxmanager@347] - have smaller server identifier, so dropping the connection: (2, 1)
2019-05-24 01:38:31,649 [myid:1] - info  [workerreceiver[myid=1]:fastleaderelection@595] - notification: 1 (message format version), 1 (n.leader), 0x0 (n.zxid), 0x1 (n.round), looking (n.state), 1 (n.sid), 0x0 (n.peerepoch) looking (my state)
2019-05-24 01:38:31,649 [myid:1] - info  [/0.0.0.0:3888:quorumcnxmanager$listener@743] - received connection request /10.24.1.64:37382
2019-05-24 01:38:31,650 [myid:1] - warn  [recvworker:1:quorumcnxmanager$recvworker@1025] - connection broken for id 1, my id = 1, error = 
java.io.eofexception
        at java.io.datainputstream.readint(datainputstream.java:392)
        at org.apache.zookeeper.server.quorum.quorumcnxmanager$recvworker.run(quorumcnxmanager.java:1010)
2019-05-24 01:38:31,651 [myid:1] - warn  [recvworker:1:quorumcnxmanager$recvworker@1028] - interrupting sendworker


running the following command shows that no id is passed however i am using the hacky way shown here: https://stackoverflow.com/a/48086813/5813215

kubectl exec -it zoo-2 -n kafka-dev printenv | grep ""zoo_""

zoo_user=zookeeper
zoo_conf_dir=/conf
zoo_data_dir=/data
zoo_data_log_dir=/datalog
zoo_log_dir=/logs
zoo_port=2181
zoo_tick_time=2000
zoo_init_limit=5
zoo_sync_limit=2
zoo_autopurge_purgeinterval=0
zoo_autopurge_snapretaincount=3
zoo_max_client_cnxns=60

",<kubernetes><google-kubernetes-engine><kubernetes-statefulset>,68960893,3,"not quite sure how useful this is anymore, but this will work for zookeeper in my case:
   env:
      - name: pod_id_of_statefulset
        valuefrom:
          fieldref:
            fieldpath: metadata.name
   lifecycle:
      poststart:
         exec:
            command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo ${pod_id_of_statefulset##*-} &gt; ${zoo_data_dir}/myid&quot;]

it turned out the only thing that zoo_my_id does is being passed to ${zoo_data_dir}/myid file. i'm doing it &quot;manualy&quot; and setting the file before entrypoint.
"
71973947,initializing a dynamically provisioned shared volume with readonlymany access mode,"my gke deployment consists of n pods (possibly on different nodes) and a shared volume, which is dynamically provisioned by pd.csi.storage.gke.io and is a persistent disk in gcp. i need to initialize this disk with data before the pods go live.
my problem is i need to set accessmodes to readonlymany and be able to mount it to all pods across different nodes in read-only mode, which i assume effectively would make it impossible to mount it in write mode to the initcontainer.
is there a solution to this issue? answer to this question suggests a good solution for a case when each pod has their own disk mounted, but i need to have one disk shared among all pods since my data is quite large.
",<kubernetes><google-kubernetes-engine><persistent-volumes><gce-persistent-disk>,71986625,1,"with gke 1.21 and later, you can enable the managed filestore csi driver in your clusters.  you can enable the driver for new clusters
gcloud container clusters create cluster_name \
    --addons=gcpfilestorecsidriver ...

or update existing clusters:
gcloud container clusters update cluster_name \
   --update-addons=gcpfilestorecsidriver=enabled

once you've done that, create a storage class (or have or platform admin do it):
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  name: filestore-example
provisioner: filestore.csi.storage.gke.io
volumebindingmode: waitforfirstconsumer
allowvolumeexpansion: true
parameters:
  tier: standard
  network: default

after that, you can use pvcs and dynamic provisioning:
kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: podpvc
spec:
  accessmodes:
  - readwritemany
  storageclassname: filestore-example
  resources:
    requests:
      storage: 1ti

"
40764400,rest api alternative for describe command,"how i can call via rest api this commands:

$ kubectl describe po xyz

$ kubectl describe svc xyz

$ kubectl describe node zyx


i need get service endpoints and node capacity usage. but i can't find in docs how i can do this. get command not provides this information.
",<kubernetes><google-kubernetes-engine>,40765541,3,"use kubectl --v=8 ... for fun and profit!

for eg: a describe pod is actually a combination of results from the pod and the events apis:

get /api/v1/namespaces/default/pods/xyz
get /api/v1/namespaces/default/events?fieldselector=involvedobject.name%3dxyz%2cinvolvedobject.namespace%3ddefault%2cinvolvedobject.uid%3dd4605fd6-b152-11e6-a208-02e9103bab42

"
73033111,how to re-trigger completed pods of k8s cronjob if running still exists?,"k8s version: 1.23
i have an hourly cronjob with 5 inner pods. after some time, part of these pods goes to shutdown and moved to the completed state (it's expected), but the rest - still works, so have a running state.
at the next hour, this cronjob will not be triggered due to the running pods (it's also expected). but i need to force recreate pods with the completed state if a running still exists. is it possible?
",<kubernetes><kubernetes-pod><kubernetes-cronjob>,73035953,1,"it appears that the reason you're letting the running pods exist is that you expect those pods to take a long time before finishing. this means that the scheduling of those pods should be different from others, since they can take a longer time to finish.
you can split your cronjob into two cronjobs. one of these will run every hour and will only have the pods that get completed. the other will run less frequently (maybe every 2 hours?) allowing the running pods to finish.
this way, you will be able to manage your cron tasks separately.

note: for k8s version, we usually mention the api version which is of the form v1.xx. it appears you are reporting the version of a public cloud offering of k8s like aks, eks or gke. just fyi.

"
55117000,"helm + kubernetes, load and enable extensions or modules in php","i've problem when i run a php deployment with kubernetes becouse don't load the modules or extensions libraries.

my deployment file is this:

apiversion: apps/v1
kind: deployment
metadata:
  name: php
  labels:
    app: php
spec:
  selector:
    matchlabels:
      app: php
  replicas: 1
  template:
    metadata:
      labels:
        app: php
    spec:
      containers:
      - name: php
        image: php:7-fpm
        env:
          - name: php_ini_scan_dir
            value: :/usr/local/etc/php/conf.custom
        ports:
        - containerport: 9000
        lifecycle:
          poststart:
            exec:
              command: [""/bin/sh"",""-c"",""docker-php-ext-install pdo pdo_mysql mysqli &amp;&amp; docker-php-ext-enable pdo pdo_mysql mysqli""]
        volumemounts:
          - name: php-conf
            mountpath: /usr/local/etc/php/conf.custom
      volumes:
        - name: php-conf
          configmap:
            name: php


and my configmap is this:

apiversion: v1
kind: configmap
metadata:
  name: php
  labels:
    app: php
data:
  wordpress-custom.ini: |-
    upload_max_filesize = 100m
    post_max_size = 100m
  default.ini: |-
    extension=pdo_mysql.so
    extension=mysqli.so


later i go into the pod with command ""exec -it"" and i put again ""docker-php-ext-enable mysqli"" to check it, but i receive the message ""warning: mysqli (mysqli.so) is already loaded!"", but when i run the ""phpinfo()"" command, i see ""upload_max_filesize = 100m"" and ""post_max_size = 100m"" updated, but i can't see modules enabled.

what i can do? very thank's
",<php><docker><kubernetes><php-extension><kubernetes-helm>,55117368,1,"the problem is that your docker cmd is to run php-fpm 

https://github.com/docker-library/php/blob/bb16de8a711d1ba1dc76adf4665b3b1c06a06922/7.3/stretch/fpm/dockerfile#l266

and after container started you cannot change loaded to memory php configuration. 

you need to restart php-fpm to apply changes, but restart kills container and you loose all changes. to add some libraries for php you should to create your own docker image and install all your libraries into the image instead of installing it in runtime.

check also this issue on github
https://github.com/docker-library/php/issues/331

so answer is to create your own image and install all required extensions with docker run command

from php:7-fpm

run apt-get install php-pdo php-mysql 


after that you have to build this image

docker build -t php:7-fpm-mysql .


push it to some docker registry. for example hub.docker.com

docker push php:7-fpm-mysql


note: php mysql extension is deprecated since php 5.5.*, use pdo instead
"
48372991,how can i make a google kubernetes engine load balancer serve different sets of pods?,"i have am using google kubernetes engine 1.8.6 and have a load balancer configured as below:

apiversion: v1
kind: service
metadata:
  name: my-load-balancer
spec:
  ports:
  - port: 19222
    name: my-test-port
    protocol: tcp
    targetport: 19222
  - port: 9222
    name: my-prod-port
    protocol: tcp
    targetport: 9222
  selector:
    app: test-app-stateful-set
  type: loadbalancer


this allows someone connecting to the load balancer's external ip to be routed to my test-app-stateful-set when they use port 19222. however i would like connections to port 9222 from the same external ip sent to my prod-app-stateful-set instead. how can i configure my service to do this?
",<kubernetes><google-kubernetes-engine>,48376163,1,"you can't do this directly, because a service has a single nodeselector that is valid for all its ports. 

one option you have is to run a third pod that acts as a proxy. it receives connections on both ports and forwards the traffic to your backend a based on the port the incoming traffic is coming through.

you could use nginx for this proxy pod.

a sample configuration for your nginx could be the following:

stream {
  server { 
    listen 19222;
    proxy_pass &lt;test-service-name&gt;:19222;
  }
  server { 
    listen 9222;
    proxy_pass &lt;prod-service-name&gt;:9222;
  }
}


of course, your load balancer service has to be adjusted as well in order to make the selector match your new nginx pod and you need to create two different services for your production and test pods
"
65916344,change public gke to private gke cluster using terraform,"how to change the existing gke cluster to gke private cluster? will i be able to connect to the kubectl api from internet based on firewall rules or should i have a bastion host? i don't want to implement cloud nat or nat gateway. i have a  squid proxy vm that can handle internet access for pods. i just need to be able to connect to kubectl to apply or modify anything.
i'm unsure how to modify the existing module i wrote to make the nodes private and i'm not sure if the cluster will get deleted if i try and apply the new changes related to private gke cluster.
resource &quot;google_container_cluster&quot; &quot;primary&quot; {
  name     = &quot;prod&quot;
  network  = &quot;prod&quot;
  subnetwork = &quot;private-subnet-a&quot;
  location               = &quot;us-west1-a&quot;
  remove_default_node_pool = true
  initial_node_count = 1

  depends_on = [var.depends_on_vpc]
}

resource &quot;google_container_node_pool&quot; &quot;primary_nodes&quot; {
  depends_on = [var.depends_on_vpc]

  name       = &quot;prod-node-pool&quot;
  location   = &quot;us-west1-a&quot;
  cluster    = google_container_cluster.primary.name
  node_count = 2

  node_config {
    preemptible  = false
    machine_type = &quot;n1-standard-2&quot;

    metadata = {
      disable-legacy-endpoints = &quot;true&quot;
    }

    oauth_scopes = [
      &quot;https://www.googleapis.com/auth/logging.write&quot;,
      &quot;https://www.googleapis.com/auth/monitoring&quot;,
      &quot;https://www.googleapis.com/auth/devstorage.read_only&quot;,
      &quot;https://www.googleapis.com/auth/compute&quot;,
    ]
  }
}

",<kubernetes><terraform><google-kubernetes-engine>,65918865,2,"answering the part of the question:

how to change the existing gke cluster to gke private cluster?


gke setting: private cluster is immutable. this setting can only be set during the gke cluster provisioning.
to create your cluster as a private one you can either:

create a new gke private cluster.
duplicate existing cluster and set it to private:

this setting is available in gcp cloud console -&gt; kubernetes engine -&gt; cluster-name -&gt; duplicate
this setting will clone the configuration of your infrastructure of your previous cluster but not the workload (pods, deployments, etc.)




will i be able to connect to the kubectl api from internet based on firewall rules or should i have a bastion host?

yes, you could but it will heavily depend on the configuration that you've chosen during the gke cluster creation process.
as for ability to connect to your gke private cluster, there is a dedicated documentation about it:

cloud.google.com: kubernetes engine: docs: how to: private clusters


as for how you can create a private cluster with terraform, there is the dedicated site with configuration options specific to gke. there are also parameters responsible for provisioning a private cluster:

registry.terraform.io: providers: hashicorp: google: latest: docs: resources: container cluster

as for a basic example of creating a private gke cluster with terraform:

main.tf

provider &quot;google&quot; {
  project = &quot;insert_project_here&quot; 
  region  = &quot;europe-west3&quot;
  zone    = &quot;europe-west3-c&quot;
}


gke.tf

resource &quot;google_container_cluster&quot; &quot;primary-cluster&quot; {
  name               = &quot;gke-private&quot;
  location           = &quot;europe-west3-c&quot;
  initial_node_count = 1

  private_cluster_config {
    enable_private_nodes = &quot;true&quot;
    enable_private_endpoint = &quot;false&quot; # this option will make your cluster available through public endpoint 
    master_ipv4_cidr_block = &quot;172.16.0.0/28&quot;
  }

  ip_allocation_policy {
    cluster_secondary_range_name = &quot;&quot; 
    services_secondary_range_name = &quot;&quot;
  }

  
  node_config {
    machine_type = &quot;e2-medium&quot;
  }
}


a side note!
i've created a public gke cluster, modified the .tf responsible for it's creation to support private cluster. after running: $ terraform plan terraform responded with the information that the cluster will be recreated.

"
61746449,ansible can't handle kubectl proxy command,"i have an ansible script that installs a kubernetes cluster and is supposed to enable the dashboard. one task is giving me issues: 

- name: expose dashboard ui
  shell: kubectl proxy --port=8001 --address={{ hostvars['master'].master_node_ip }} --accept-hosts=""^*$"" &gt;&gt; dashboard_started.txt
  args:
    chdir: $home
    creates: dashboard_started.txt


the problem is that this works, but the command kubectl proxy is blocking: you can't type in another command until you ctrl+c out of the command, at which point the dashboard is inaccessible. my ansible script freezes from performing this command. i can successfully connect to the dashboard in my browser while ansible is frozen. but i need ansible to perform other tasks after this one as well. i have tried adding an ampersand &amp; at the end of my command: 

kubectl proxy --port=8001 --address={{ hostvars['master'].master_node_ip }} --accept-hosts=""^*$"" &gt;&gt; dashboard_started.txt &amp;

or

kubectl proxy --port=8001 --address={{ hostvars['master'].master_node_ip }} --accept-hosts=""^*$"" &amp; &gt;&gt; dashboard_started.txt

and while both these commands cause ansible to execute and pass over my task, i can't reach the dashboard. using the jobs command on the machine the command is run on shows no background tasks, either for root or the ansible user. 

what am i doing wrong? 

edit: 

to those reading this: do not do this unless you can access the dashboard from localhost. if you are running kubernetes dashboard in a vm or on some external server, and are trying to access it from another machine (the vm host for example), you will not be able to log in. see here: 

https://github.com/kubernetes/dashboard/blob/master/docs/user/accessing-dashboard/1.7.x-and-above.md


  note: dashboard should not be exposed publicly using kubectl proxy
  command as it only allows http connection. for domains other than
  localhost and 127.0.0.1 it will not be possible to sign in. nothing
  will happen after clicking sign in button on login page.

",<kubernetes><ansible><kubectl>,61747721,4,"you could run the task with the asynchronous option. for example:

- name: expose dashboard ui
  shell: ""(kubectl proxy --port=8001 --address={{ hostvars['master'].master_node_ip }} --accept-hosts=""^*$"" &gt;&gt; dashboard_started.txt &gt;/dev/null 2&gt;&amp;1 &amp;)""
  args:
    chdir: $home
    creates: dashboard_started.txt
  async: 10
  poll: 0


when poll is 0, ansible will start the task and immediately move on to the next one without waiting for a result.

i personally added the subshell parentheses though i suppose that there is no need to use them, async itself does the trick i hope!

hope it helps!

https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html
"
54904069,how to schedule a cronjob which executes a kubectl command?,"how to schedule a cronjob which executes a kubectl command?

i would like to run the following kubectl command every 5 minutes:

kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test


for this, i have created a cronjob as below:

apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: ""*/5 * * * *""
  jobtemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test
          restartpolicy: onfailure


but it is failing to start the container, showing the message : 

back-off restarting failed container


and with the error code 127:

state:          terminated
      reason:       error
      exit code:    127


from what i checked, the error code 127 says that the command doesn't exist. how could i run the kubectl command then as a cron job ? am i missing something?

note: i had posted a similar question ( scheduled restart of kubernetes pod without downtime ) , but that was more of having the main deployment itself as a cronjob, here i'm trying to run a kubectl command (which does the restart) using a cronjob - so i thought it would be better to post separately

kubectl describe cronjob hello -n jp-test:

name:                       hello
namespace:                  jp-test
labels:                     &lt;none&gt;
annotations:                kubectl.kubernetes.io/last-applied-configuration={""apiversion"":""batch/v1beta1"",""kind"":""cronjob"",""metadata"":{""annotations"":{},""name"":""hello"",""namespace"":""jp-test""},""spec"":{""jobtemplate"":{""spec"":{""templ...
schedule:                   */5 * * * *
concurrency policy:         allow
suspend:                    false
starting deadline seconds:  &lt;unset&gt;
selector:                   &lt;unset&gt;
parallelism:                &lt;unset&gt;
completions:                &lt;unset&gt;
pod template:
  labels:  &lt;none&gt;
  containers:
   hello:
    image:      busybox
    port:       &lt;none&gt;
    host port:  &lt;none&gt;
    args:
      /bin/sh
      -c
      kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test
    environment:     &lt;none&gt;
    mounts:          &lt;none&gt;
  volumes:           &lt;none&gt;
last schedule time:  wed, 27 feb 2019 14:10:00 +0100
active jobs:         hello-1551273000
events:
  type    reason            age   from                message
  ----    ------            ----  ----                -------
  normal  successfulcreate  6m    cronjob-controller  created job hello-1551272700
  normal  successfulcreate  1m    cronjob-controller  created job hello-1551273000
  normal  sawcompletedjob   16s   cronjob-controller  saw completed job: hello-1551272700


kubectl describe job hello -v=5 -n jp-test

name:           hello-1551276000
namespace:      jp-test
selector:       controller-uid=fa009d78-3a97-11e9-ae31-ac1f6b1a0950
labels:         controller-uid=fa009d78-3a97-11e9-ae31-ac1f6b1a0950
                job-name=hello-1551276000
annotations:    &lt;none&gt;
controlled by:  cronjob/hello
parallelism:    1
completions:    1
start time:     wed, 27 feb 2019 15:00:02 +0100
pods statuses:  0 running / 0 succeeded / 0 failed
pod template:
  labels:  controller-uid=fa009d78-3a97-11e9-ae31-ac1f6b1a0950
           job-name=hello-1551276000
  containers:
   hello:
    image:      busybox
    port:       &lt;none&gt;
    host port:  &lt;none&gt;
    args:
      /bin/sh
      -c
      kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test
    environment:  &lt;none&gt;
    mounts:       &lt;none&gt;
  volumes:        &lt;none&gt;
events:
  type     reason                age              from            message
  ----     ------                ----             ----            -------
  normal   successfulcreate      7m               job-controller  created pod: hello-1551276000-lz4dp
  normal   successfuldelete      1m               job-controller  deleted pod: hello-1551276000-lz4dp
  warning  backofflimitexceeded  1m (x2 over 1m)  job-controller  job has reached the specified backoff limit

name:           hello-1551276300
namespace:      jp-test
selector:       controller-uid=ad52e87a-3a98-11e9-ae31-ac1f6b1a0950
labels:         controller-uid=ad52e87a-3a98-11e9-ae31-ac1f6b1a0950
                job-name=hello-1551276300
annotations:    &lt;none&gt;
controlled by:  cronjob/hello
parallelism:    1
completions:    1
start time:     wed, 27 feb 2019 15:05:02 +0100
pods statuses:  1 running / 0 succeeded / 0 failed
pod template:
  labels:  controller-uid=ad52e87a-3a98-11e9-ae31-ac1f6b1a0950
           job-name=hello-1551276300
  containers:
   hello:
    image:      busybox
    port:       &lt;none&gt;
    host port:  &lt;none&gt;
    args:
      /bin/sh
      -c
      kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test
    environment:  &lt;none&gt;
    mounts:       &lt;none&gt;
  volumes:        &lt;none&gt;
events:
  type    reason            age   from            message
  ----    ------            ----  ----            -------
  normal  successfulcreate  2m    job-controller  created pod: hello-1551276300-8d5df

",<kubernetes><busybox><kubernetes-cronjob>,54908449,30,"long story short busybox doesn' have kubectl installed.

you can check it yourself using kubectl run -i --tty busybox --image=busybox -- sh which will run a busybox pod as interactive shell.

i would recommend using bitnami/kubectl:latest.

also keep in mind that you will need to set proper rbac, as you will get error from server (forbidden): services is forbidden

you could use something like this:

kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  namespace: jp-test
  name: jp-runner
rules:
- apigroups:
  - extensions
  - apps
  resources:
  - deployments
  verbs:
  - 'patch'

---
kind: rolebinding
apiversion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: jp-runner
  namespace: jp-test
subjects:
- kind: serviceaccount
  name: sa-jp-runner
  namespace: jp-test
roleref:
  kind: role
  name: jp-runner
  apigroup: """"

---
apiversion: v1
kind: serviceaccount
metadata:
  name: sa-jp-runner
  namespace: jp-test

---
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: ""*/5 * * * *""
  jobtemplate:
    spec:
      template:
        spec:
          serviceaccountname: sa-jp-runner
          containers:
          - name: hello
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - kubectl patch deployment runners -p '{""spec"":{""template"":{""spec"":{""containers"":[{""name"":""jp-runner"",""env"":[{""name"":""start_time"",""value"":""'$(date +%s)'""}]}]}}}}' -n jp-test
          restartpolicy: onfailure

"
59467026,helm 3 install multi config files,"we are using helm of prometheus operator chart stable, see this link for the source 

and we use our values.yaml which works ok,
in the value.yaml we are configing prometheus (men cpu etc) and the alertmanger.

now i need to add the prometheus alert manger config, but not sure how to provide it via the values.yaml (tried, it doesn’t work)

any idea how to pass the config of the alert manager ? 

this is the value.yaml

grafana:
  enabled: true
alertmanager:
  enabled: false
  alertmanagerspec:
    replicas: 3



now i need to  provide in addition file which contain the alert manager rules

like the following:

file: alerts.yaml


apiversion: monitoring.coreos.com/v1
kind: prometheusrule
metadata:
  creationtimestamp: null
  labels:
    prometheus: prometheus
    role: alert-rules
  name: prometheus-prometheus-rules
  namespace: mon
spec:
  groups:
    - name: ./prometheus.rules
      rules:
        - alert: critical -  nodes disk pressure
          expr: 'kube_node_labels{label_workern_cloud_io_group=“ds""} * on(node)kube_node_status_condition{condition=""diskpressure"", status=""true""} == 1'
          for: 5m
          labels:
            severity: critical


how should i pass also the alerts.yaml via the helm installation ? 

helm install prom stable/prometheus-operator -n mon -f values.yaml  

should i create my own chart and put it on template ? if so how it’s recommended for clean implementation ? 
",<azure><kubernetes><kubernetes-helm>,59529676,2,"there is no way to reference a external yaml file while running helm install.

the best way to achieve this is to copy the chart and include it to templates folder. 

from helm documentation we can read: 


  templates
  
  the most important piece of the puzzle is the  templates/ 
  directory. this is where helm finds the yaml definitions for your
  services, deployments and other kubernetes objects. if you already
  have definitions for your application, all you need to do is replace
  the generated yaml files for your own. what you end up with is a
  working chart that can be deployed using the  helm install  command.


$ git clone https://github.com/helm/charts.git

$ cp alerts.yaml ./charts/stable/prometheus-adapter/templates

$ helm install --name my-release stable/prometheus-adapter

"
56324746,"cant schedule prometheus-server pod on kubernetes, pod reports taints but nodes dont have any taint","i am getting 

0/7 nodes are available: 2 node(s) had taints that the pod didn't tolerate, 5 node(s) had volume node affinity conflict. 


for my prometheus server pod but if i check each nodes there are no taints. and there is enough cpu and memory to be allocated.. what am i missing here?

i tried deleting the pods and even the deployment object but the error still persists

all nodes have 0 taints..
this is a fresh prometheus install on a new kubernetes cluster
the yaml files that i have used to work until now when i needed to deploy a new kubernetes cluster
",<kubernetes><prometheus><kubernetes-pod>,56330509,1,"
  0/7 nodes are available: 2 node(s) had taints that the pod didn't tolerate, 5 node(s) had volume node affinity conflict. 


the message is specific: it's not the taints that are keeping your prometheus pods off of your workers, it's the volume that is the problem. if you are in aws, it's because your volume is in an availability zone that your workers are not (so, a us-west-2a volume and us-west-2c workers, for example)

the shortest path to success in your situation may be to either recreate the volume in the correct a.z. if it was empty, or manually create a new volume and copy the data into an a.z. that matches your workers, or (of course) spin up a new worker in the a.z. that matches the volume


  all nodes have 0 taints..


is for sure not true for two reasons: because the scheduler clearly says there are two nodes with taints, and because unless you specifically stripped them off, the masters are almost always(?) provisioned with node.kubernetes.io/master:noschedule taints explicitly to keep workloads off of them
"
62472224,"what is, and what use cases have the dot ""."" in helm charts?","im currently going through the docs of helm, and there have been at least 3 different uses for the dot (.), is there any specific definition for it? and does it have something in common with the bash use (actual folder/files)?

some cases in the documentation 

this print the accesed files in the range called before?

  {{- $files := .files }}
  {{- range tuple ""config1.toml"" ""config2.toml"" ""config3.toml"" }}
  {{ . }}: |-
    {{ $files.get . }}
  {{- end }}


this tells ""mychart.app"" to use the files in the current folder (bash-like behaviour)

{{ include ""mychart.app"" . | indent 4 }}


and this, i guess it takes the values from the whole folder??? i guess this is not correct since is not working (it has been made by another employee back then and i have to fix it)

{{- define ""read.select-annot"" -}}
{{- range $key, $value := . }}
{{ $key }}: {{ $value }}
{{- end }}
{{- end }}


thanks for the help
",<kubernetes><kubernetes-helm><go-templates>,62476328,59,"in general, . in helm templates has nothing to do with files or directories.

the helm templating language uses go's text/template system.  there are a couple of different ways a period character can appear there.

first of all, . can be a character in a string:

{{- range tuple ""config1.toml"" ""config2.toml"" ""config3.toml"" }}
{{/*             ^^^^^^^^^^^^
       this is a literal string ""config1.toml""             */}}
...
{{- end }}


secondly, . can be a lookup operator.  there aren't any solid examples in your question, but a typical use is looking up in values.  if your values.yaml file has

root:
  key: value


then you can expand

{{ .values.root.key }}


and the . before root and key navigates one level down in the dictionary structure.

the third use, and possibly the one that's confusing you, is that . on its own is a variable.

{{ . }}


you can do field lookups on it, and you have some examples of that: .files is the same as index . ""files"", and looks up the field ""files"" on the object ..

you use . as a variable in several places:

{{- $files := .files }}        {{/* get ""files"" from . */}}
{{ . }}                        {{/* write . as a value */}}
{{ include ""mychart.app"" . }}  {{/* pass . as the template parameter */}}


. is tricky in that it has somewhat contextual meaning:


at the top level, helm initializes . to an object with keys files, release, values, and chart.
in a defined template, . is the parameter to the template.  (so when you include or template, you need to pass . down as that parameter.)
in a range loop, . is the current item being iterated on.
in a with block, . is the matched item if it exists.


in particular, the interaction with range can be tricky.  let's look at a simplified version of your loop:

# {{ . }}
{{- range tuple ""config1.toml"" ""config2.toml"" ""config3.toml"" }}
- {{ . }}
{{- end }}


outside the range loop, . is probably the top-level helm object.  but inside the range loop, . is the file name (each value from the tuple in turn).  that's where you need to save values from . into local variables:

{{/* we're about to invalidate ., so save .files into a variable. */}}
{{- $files := .files }}

{{- range tuple ""config1.toml"" ""config2.toml"" ""config3.toml"" }}
{{/* this . is the filename from the ""tuple"" call */}}
{{ . }}: |-
  {{/* call .get, from the saved $files, passing the filename .
       as the parameter */}}
  {{ $files.get . }}
{{- end }}

"
63565142,how to run airflow cli commands with airflow/kubernetes installed from helm stable/airflow?,"difficulty running airflow commands when running airflow on kubernetes that i installed from the helm stable/airflow repo. for instance i try to exec into the scheduler pod and run airflow list and i get the following error:
airflow.exceptions.airflowconfigexception: error: cannot use sqlite with the kubernetesexecutor airlow

ok so i switch to the celery executor.
same thing
airflow.exceptions.airflowconfigexception: error: cannot use sqlite with the celeryexecutor

so what is the correct way to run airflow cli commands when running on k8s?
",<kubernetes><airflow><kubernetes-helm>,63566195,7,"make sure you are using bash. /home/airflow/.bashrc imports the environment variables from /home/airflow/airflow_env.sh to setup the connection. the following are some examples:
kubectl exec -ti airflow-scheduler-nnn-nnn -- /bin/bash
$ airflow list_dags

or with shell you can import the env vars yourself:
kubectl exec -ti airflow-scheduler-nnn-nnn -- sh -c &quot;. /home/airflow/airflow_env.sh &amp;&amp; airflow list_dags&quot;

"
64578072,server-side validation of kubernetes yaml,"i would like to do server-side validation of kubernetes yaml files before applying them.
i know that in my jenkins agent, i could use the following kubectl command for validating yaml files at the server-side but i am a bit concerned about access-control:

kubernetes &lt; v1.18:
kubectl apply --server-dry-run -f ...
kubernetes &gt;= v1.18:
kubectl apply --dry-run=server -f ...

the kubernetes documentation says the following:

authorization for dry-run and non-dry-run requests is identical. thus,
to make a dry-run request, the user must be authorized to make the
non-dry-run request.

i don't want any jenkins agents to have super powers over my eks cluster. a bad actor could use my jenkins agent maliciously and apply any manifests they wanted. right now for security/stability/management reasons, creating kubernetes objects is done by a different system not jenkins.
i checked a few other options but i can see drawbacks:

kubeval is not aware of any crds installed in the actual cluster.
client validation is not really end-to-end validation
i could develop a rest api that exposes a validation rest endpoint and hits kubernetes apis or runs a kubectl --run-dry under the hood. however, this requires more dev work than we have capacity for.

do you have any ideas or are you aware of any validation tools that i could use in our ci system securely for the purpose of validating end-2-end kubernetes yaml files?
",<jenkins><kubernetes><kubectl>,64578294,2,"i've been looking for this myself and did not find a sufficient tooling. however, there are few workarounds:

deploy all objects to a temporary ci-job-id namespace in dev/stage clusters. they should be the same as a prod, but will not impose the security risks you mentioned. this gives an additional benefit - you can check if everything got created, all pods are running. it helps to catch issues like insufficient resource requests, missing images, misconfigured service selectors, etc. also it let's you add a smoke test on top.
spin a small minikube with all the crds specifically for ci validations. this approach gives you less coverage, but it is much cheaper to maintain.

"
54884735,how to use configmap configuration with helm nginx ingress controller - kubernetes,"i've found a documentation about how to configure your nginx ingress controller using configmap: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/

unfortunately i've no idea and couldn't find it anywhere how to load that configmap from my ingress controller.

my ingress controller:

helm install --name ingress --namespace ingress-nginx --set rbac.create=true,controller.kind=daemonset,controller.service.type=clusterip,controller.hostnetwork=true stable/nginx-ingress


my config map:

kind: configmap
apiversion: v1
metadata:
  name: ingress-configmap
data:
  proxy-read-timeout: ""86400s""
  client-max-body-size: ""2g""
  use-http2: ""false""


my ingress:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: ""https""
spec:
  tls:
    - hosts:
        - my.endpoint.net
      secretname: ingress-tls
  rules:
    - host: my.endpoint.net
      http:
        paths:
          - path: /
            backend:
              servicename: web
              serviceport: 443
          - path: /api
            backend:
              servicename: api
              serviceport: 443


how do i make my ingress to load the configuration from the configmap? 
",<kubernetes><kubernetes-helm><kubernetes-ingress><nginx-ingress>,54888611,28,"i've managed to display what yaml gets executed by helm using the: --dry-run --debug options at the end of helm install command. then i've noticed that there controller is executed with the: --configmap={namespace-where-the-nginx-ingress-is-deployed}/{name-of-the-helm-chart}-nginx-ingress-controller.
in order to load your configmap you need to override it with your own (check out the namespace).

kind: configmap
apiversion: v1
metadata:
  name: {name-of-the-helm-chart}-nginx-ingress-controller
  namespace: {namespace-where-the-nginx-ingress-is-deployed}
data:
  proxy-read-timeout: ""86400""
  proxy-body-size: ""2g""
  use-http2: ""false""


the list of config properties can be found here.
"
62651374,how do i access my cassandra/kubernetes cluster from outside the cluster?,"i have started using cass-operator and the setup worked like a charm! https://github.com/datastax/cass-operator.
i have an issue though. my cluster is up and running on gcp. but how do i access it from my laptop (basically from outside)? sorry, i'm new to kubernetes so i do not know how to access the cluster from outside?
i can see the nodes are up on the gcp dashboard. i can ping the external ip of the nodes from my laptop but when i run cqlsh external_ip 9042 then the connection fails.
how do i go about connecting the k8s/cassandra cluster to outside work so that my web application can access it?
i would like to:

have a url so that my web application uses that url to connect to the cassandra/k8s cluster instead of ip address. thus, i need a dns. does it come by default in k8s? would would be the url? would k8s managing the dns mapping for me in some nodes get restarted?
my web application should be able to reach cassandra on 9042. it seems load balancing is done for http/https. the cassandra application is not a http/https request. so i don't need port 80 or 443

i have read few tutorials which talk about service, loadbalancer and ingress. but i am unable to make a start.
i created a service like this
kind: service
apiversion: v1
metadata:
  name: cass-operator-service
spec:
  type: loadbalancer
  ports:
    - port: 9042
  selector:
    name: cass-operator

then created the service - kubectl apply -f ./cass-operator-service.yaml
i checked if the service was created using kubectl get svc and got output
name                    type           cluster-ip      external-ip     port(s)          age 
cass-operator-service   loadbalancer   10.51.249.224   34.91.214.233   9042:30136/tcp   4m17s 
kubernetes              clusterip      10.51.240.1     &lt;none&gt;          443/tcp          10h. 

but when i run cqlsh 34.91.214.233 9042 then the connection fails
it seems that the requests to port 9042 would be forwarded to 30136. but they should be forwarded to 9042 as that is where the cassandra image in the pods is listening for incoming requests
update
tried targetport but still no luck
manuchadha25@cloudshell:~ (copper-frame-262317)$ cat cass-operator-service.yaml
kind: service
apiversion: v1
metadata:
  name: cass-operator-service
spec:
  type: loadbalancer
  ports:
    - port: 9042
      targetport: 9042
  selector:
    name: cass-operator
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl get service
name         type        cluster-ip    external-ip   port(s)   age
kubernetes   clusterip   10.51.240.1   &lt;none&gt;        443/tcp   11h
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl apply -f ./cass-operator-service.yaml
service/cass-operator-service created
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl get service
name                    type           cluster-ip      external-ip   port(s)          age
cass-operator-service   loadbalancer   10.51.255.184   &lt;pending&gt;     9042:30024/tcp   12s
kubernetes              clusterip      10.51.240.1     &lt;none&gt;        443/tcp          11h
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl get service
name                    type           cluster-ip      external-ip   port(s)          age
cass-operator-service   loadbalancer   10.51.255.184   &lt;pending&gt;     9042:30024/tcp   37s
kubernetes              clusterip      10.51.240.1     &lt;none&gt;        443/tcp          11h
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl get service
name                    type           cluster-ip      external-ip     port(s)          age
cass-operator-service   loadbalancer   10.51.255.184   34.91.214.233   9042:30024/tcp   67s
kubernetes              clusterip      10.51.240.1     &lt;none&gt;          443/tcp          11h
manuchadha25@cloudshell:~ (copper-frame-262317)$ ping 34.91.214.233
ping 34.91.214.233 (34.91.214.233) 56(84) bytes of data.
64 bytes from 34.91.214.233: icmp_seq=1 ttl=109 time=7.89 ms


querying all names spaces reveal the following

but querying pods with namespace cass-operator returns empty result
manuchadha25@cloudshell:~ (copper-frame-262317)$ kubectl get pods -l name=cass-operator
no resources found in default namespace.

",<kubernetes><google-kubernetes-engine>,62659265,6,"
since you are new to kubernetes, you probably are not familiar with statefulsets:


statefulset is the workload api object used to manage stateful applications.
manages the deployment and scaling of a set of  pods,  and provides guarantees about the ordering and uniqueness  of these pods.
like a deployment, a statefulset manages pods that are based on an identical container spec. unlike a deployment, a statefulset maintains a sticky identity for each of their pods. these pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.


i recommend you to read these articles to learn more about it's mechanisms:

kubernetes.io - statefulsets
megalix - statefulsets 101
itnext - exposing statefulsets in kubernetes





how do i go about connecting the k8s/cassandra cluster to outside work so that my web application can access it?


i found out that datastax/cass-operator is still developing their documentation, i found this document that is not merged to master yet, but it explains very well about how to connect to cassandra, i strongly recommend reading.
there are several open issues for documenting methods for connection from outside the cluster.

i followed the guide in https://github.com/datastax/cass-operator to deploy the cass-operator + cassandra datacenter example as from your images i believe you followed as well:
$ kubectl create -f https://raw.githubusercontent.com/datastax/cass-operator/v1.2.0/docs/user/cass-operator-manifests-v1.15.yaml
namespace/cass-operator created
serviceaccount/cass-operator created
secret/cass-operator-webhook-config created
customresourcedefinition.apiextensions.k8s.io/cassandradatacenters.cassandra.datastax.com created
clusterrole.rbac.authorization.k8s.io/cass-operator-cluster-role created
clusterrolebinding.rbac.authorization.k8s.io/cass-operator created
role.rbac.authorization.k8s.io/cass-operator created
rolebinding.rbac.authorization.k8s.io/cass-operator created
service/cassandradatacenter-webhook-service created
deployment.apps/cass-operator created
validatingwebhookconfiguration.admissionregistration.k8s.io/cassandradatacenter-webhook-registration created

$ kubectl create -f https://raw.githubusercontent.com/datastax/cass-operator/v1.2.0/operator/k8s-flavors/gke/storage.yaml
storageclass.storage.k8s.io/server-storage created

$ kubectl -n cass-operator create -f https://raw.githubusercontent.com/datastax/cass-operator/v1.2.0/operator/example-cassdc-yaml/cassandra-3.11.6/example-cassdc-minimal.yaml
cassandradatacenter.cassandra.datastax.com/dc1 created

$ kubectl get all -n cass-operator
name                                ready   status    restarts   age
pod/cass-operator-78c6469c6-6qhsb   1/1     running   0          139m
pod/cluster1-dc1-default-sts-0      2/2     running   0          138m
pod/cluster1-dc1-default-sts-1      2/2     running   0          138m
pod/cluster1-dc1-default-sts-2      2/2     running   0          138m

name                                          type           cluster-ip    external-ip    port(s)             age
service/cass-operator-metrics                 clusterip      10.21.5.65    &lt;none&gt;         8383/tcp,8686/tcp   138m
service/cassandradatacenter-webhook-service   clusterip      10.21.0.89    &lt;none&gt;         443/tcp             139m
service/cluster1-dc1-all-pods-service         clusterip      none          &lt;none&gt;         &lt;none&gt;              138m
service/cluster1-dc1-service                  clusterip      none          &lt;none&gt;         9042/tcp,8080/tcp   138m
service/cluster1-seed-service                 clusterip      none          &lt;none&gt;         &lt;none&gt;              138m

name                            ready   up-to-date   available   age
deployment.apps/cass-operator   1/1     1            1           139m

name                                      desired   current   ready   age
replicaset.apps/cass-operator-78c6469c6   1         1         1       139m

name                                        ready   age
statefulset.apps/cluster1-dc1-default-sts   3/3     138m

$ cass_user=$(kubectl -n cass-operator get secret cluster1-superuser -o json | jq -r '.data.username' | base64 --decode)
$ cass_pass=$(kubectl -n cass-operator get secret cluster1-superuser -o json | jq -r '.data.password' | base64 --decode)

$ echo $cass_user
cluster1-superuser

$ echo $cass_pass
_5rowp851l0e_2cgun_n753e-zvemo5oy31i6c0dbcyiwh5vfjb8_g


from the kubectl get all command above we can see there is an statefulset called statefulset.apps/cluster1-dc1-default-sts which controls the cassandra pods.
in order to create a loadbalancer service that makes available all the pods managed by this statefulset we need to use the same labels assigned to them:

$ kubectl describe statefulset cluster1-dc1-default-sts -n cass-operator
name:               cluster1-dc1-default-sts
namespace:          cass-operator
creationtimestamp:  tue, 30 jun 2020 12:24:34 +0200
selector:           cassandra.datastax.com/cluster=cluster1,cassandra.datastax.com/datacenter=dc1,cassandra.datastax.com/rack=default
labels:             app.kubernetes.io/managed-by=cass-operator
                    cassandra.datastax.com/cluster=cluster1
                    cassandra.datastax.com/datacenter=dc1
                    cassandra.datastax.com/rack=default


now let's create the loadbalancer service yaml and use the labels as selectors for the service:

apiversion: v1
kind: service
metadata:
  name: cassandra-loadbalancer
  namespace: cass-operator
  labels:
    cassandra.datastax.com/cluster: cluster1
    cassandra.datastax.com/datacenter: dc1
    cassandra.datastax.com/rack: default
spec:
  type: loadbalancer
  ports:
  - port: 9042
    protocol: tcp
  selector:
    cassandra.datastax.com/cluster: cluster1
    cassandra.datastax.com/datacenter: dc1
    cassandra.datastax.com/rack: default


&quot;my web application should be able to reach cassandra on 9042. it seems load balancing is done for http/https. the cassandra application is not a http/https request. so i don't need port 80 or 443.&quot;


when you create a service of type  loadbalancer, a google cloud controller wakes up and configures a  network load balancer  in your project. the load balancer has a stable ip address that is accessible from outside of your project.

the network load balancer supports any and all ports. you can use network load balancing to load balance tcp and udp traffic. because the load balancer is a pass-through load balancer, your backends terminate the load-balanced tcp connection or udp packets themselves.

now let's apply the yaml and note the endpoint ips of the pods being listed:


$ kubectl apply -f cassandra-loadbalancer.yaml 
service/cassandra-loadbalancer created

$ kubectl get service cassandra-loadbalancer -n cass-operator 
name                     type           cluster-ip    external-ip    port(s)          age
cassandra-loadbalancer   loadbalancer   10.21.4.253   146.148.89.7   9042:30786/tcp   5m13s

$ kubectl describe svc cassandra-loadbalancer -n cass-operator
name:                     cassandra-loadbalancer
namespace:                cass-operator
labels:                   cassandra.datastax.com/cluster=cluster1
                          cassandra.datastax.com/datacenter=dc1
                          cassandra.datastax.com/rack=default
annotations:              selector:  cassandra.datastax.com/cluster=cluster1,cassandra.datastax.com/datacenter=dc1,cassandra.datastax.com/rack=default
type:                     loadbalancer
ip:                       10.21.4.253
loadbalancer ingress:     146.148.89.7
port:                     &lt;unset&gt;  9042/tcp
targetport:               9042/tcp
nodeport:                 &lt;unset&gt;  30786/tcp
endpoints:                10.24.0.7:9042,10.24.2.7:9042,10.24.3.9:9042
session affinity:         none
external traffic policy:  cluster
events:                   &lt;none&gt;


to test it, i'll use my cloud shell with a cassandra container to emulate your notebook using the loadbalancer ip provided above:

$ docker run -it cassandra /bin/sh

# cqlsh -u cluster1-superuser -p _5rowp851l0e_2cgun_n753e-zvemo5oy31i6c0dbcyiwh5vfjb8_g 146.148.89.7 9042                

connected to cluster1 at 146.148.89.7:9042.
[cqlsh 5.0.1 | cassandra 3.11.6 | cql spec 3.4.4 | native protocol v4]
use help for help.
cluster1-superuser@cqlsh&gt; select * from system.peers;

 peer      | data_center | host_id                              | preferred_ip | rack    | release_version | rpc_address | schema_version                       | tokens
-----------+-------------+--------------------------------------+--------------+---------+-----------------+-------------+--------------------------------------+--------------------------
 10.24.3.9 |         dc1 | bcec6c12-49a1-41d5-be58-5150e99f5dfb |         null | default |          3.11.6 |   10.24.3.9 | e84b6a60-24cf-30ca-9b58-452d92911703 |  {'2248175870989649036'}
 10.24.0.7 |         dc1 | 68409f08-9d6e-4e40-91ff-f43581c8b6f3 |         null | default |          3.11.6 |   10.24.0.7 | e84b6a60-24cf-30ca-9b58-452d92911703 | {'-1105923522927946373'}

(2 rows)



&quot;have a url so that my web application uses that url to connect to the cassandra/k8s cluster instead of ip address. so i need a dns. does it come by default in k8s? would would be the url? would k8s managing the dns mapping for me in some nodes get restarted?&quot;


that documentation on cassandra-operator also has a section about ingress, i recommend reading as well.
kubernetes does not come with a default dns name.
you will have to register a domain, point the dns to the ip of the load balancer this way it will resolve the ip of the network loadbalancer.
the network loadbalancer is bound to a static public ip,  any changes in kubernetes nodes will not cause service unavailability.

if you have any question, let me know in the comments.
"
61641979,generating a kubeconfig for access to an amazon eks cluster,"given a scenario where i have two kubernetes clusters, one hosted on aws eks and the other on another cloud provider, i would like to manage the eks cluster from the other cloud provider. what's the easiest way to authenticate such that i can do this?

would it be reasonable to generate a kubeconfig, where i embed the result from aws get-token (or something like that) to the cluster on the other cloud provider? or are these tokens not persistent?

any help or guidance would be appreciated!
",<amazon-web-services><kubernetes><amazon-eks><kubeconfig>,61795903,6,"i believe the most correct  is the way described in create a kubeconfig for amazon eks

yes, you create kubeconfig with aws eks get-token and later add newly created config to kubeconfig environment variable , eg

export kubeconfig=$kubeconfig:~/.kube/config-aws


or you can add it to .bash_profile for your convenience

echo 'export kubeconfig=$kubeconfig:~/.kube/config-aws' &gt;&gt; ~/.bash_profile


for detailed steps please refer to provided url. 
"
56265433,apache reverse proxy in front of an ingress-gce (gke),"i´m trying to overcome the ingress-gce limitation of redirect traffic from http to https.

so, the easiest configuration whould be a reverse proxy with apache2 but isn't working for me, this apache is in another vm apart from my kubernetes cluster, i just want to ""proxy"" the traffic so i can manipulate the request, redirect to https, etc

i´m need this specific solution to work as i can´t configure a nginx ingress at this point, it has to be done with this gce ingress

my ingress yaml configuration is:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    kubernetes.io/ingress.global-static-ip-name: my-reserved-address
    kubernetes.io/ingress.allow-http: ""false""
spec:
  tls:
  - hosts:
    - mycustom.domain.com
    secretname: mydomain-com-certificate
  rules:
  - host: mycustom.domain.com
    http:
      paths:
      - path: /*
        backend:
          servicename: tomcat-service
          serviceport: 80
      - path: /app/*
        backend:
          servicename: spring-boot-app-service
          serviceport: 80


my apache virtualhost configuration is:

&lt;virtualhost *:80&gt;
        servername myother.domain.com
        redirect permanent / https://myother.domain.com/
&lt;/virtualhost&gt;

&lt;virtualhost *:443&gt;
        servername myother.domain.com

        proxypreservehost on
        proxyrequests on
        proxypass / https://mycustom.domain.com/
        proxypassreverse / https://mycustom.domain.com/

        sslengine on
        sslproxyengine on
        sslprotocol all -sslv2 -sslv3
        sslciphersuite all:!anull:!adh:!enull:!low:!exp:!rc4:+high:+medium
        sslcertificatekeyfile /etc/ssl/domain.com/domain.com-privatekey-nopass.pem
        sslcertificatefile /etc/ssl/domain.com/domain.com.crt
        sslcacertificatefile /etc/ssl/domain.com/intermediateca.crt
&lt;/virtualhost&gt;


every piece of the puzzle is working independent as expected, i mean, if i go to any of the following

a) https://mycustom.domain.com/tomcat_context 
b) https://mycustom.domain.com/app/hello


i get the desired results, a) i get my web page and b) i get a simple response from my app

however, when i use the proxy http://myother.domain.com/tomcat_context i can see how it transform to  but i always get a text response from the cluster, always is 

default backend - 404

i´m also checking the apache2 logs and i can see how the correct invocation is being made internally by apache

[wed may 22 18:39:40.757619 2019] [proxy:debug] [pid 14196:tid 140335314564864] proxy_util.c(2213): [client xxx.xxx.xxx.xxx:52636] ah00944: connecting https://mycustom.domain.com/tomcat_context to mycustom.domain.com:443


i can´t find an explanation why this is happening if all the pieces are working properly, at the end of the day my ingress-gce is like an external service to my apache proxy, it should be working already.

also both configurations, the ingress and the apache have ssl configured and its the same exact certificate as both are running on the same domain 

any help will be appreciated
",<apache><kubernetes><google-compute-engine><kubernetes-ingress>,56266264,2,"the ingress controller doesn't have a handler for myother.domain.com so produces a 404. 

you either need to setup an additional ingress host for myother.domain.com or turn proxypreservehost off so the proxy sends the mycustom.domain.com host name from the proxypass config. 

how the tomcat application make use of the host header is usually the decider for which way you need to map the header through the proxy. 
"
57303440,how to trigger a container to start another container and terminate it when a rest query is passed to it?,"i have two separate containers having docker images where one is running the rest application and the other one is running the process for downloading satellite images. my aim is that when i click on the download button after passing the query with defined parameters in my main application, it should start the container for download and once downloaded, it should stop the container.currently i am able to run the container for download independently by providing all the necessary environment variables for it's docker image in it's deployment file but in the long run these variables should be coming as the parameters from the query.how can i make this happen?
here is the current deployment file and the parameters required for running image :

---
kind: deployment
apiversion: apps/v1
metadata:
  name: back
spec:
  replicas: 1
  selector:
    matchlabels:
      app: back
  template:
    metadata:
      creationtimestamp: 
      labels:
        app: back
    spec:
      containers:
      - name: back
        image: back:latest
        imagepullpolicy: never
        env:
        - name: scihub_username
          value: test
        - name: scihub_password
          value: test
        - name: cdinrw_base_url
          value: 10.1.40.11:8081/swagger-ui.html
        - name: cdinrw_job_id
          value: 3fa85f64-5717-4562-b3fc-2c963f66afa6
        ports:
        - containerport: 8081
          protocol: tcp
        volumemounts:
        - mountpath: /data
          name: test-volume
      volumes:
      - name: test-volume
        hostpath:
          # directory location on host
          path: /back
          # this field is optional
          type: directory


docker run --rm -v $(pwd):/out_data \
-e scihub_username=test \
-e scihub_password=test \
-e producttype=s2msi2a \
-e platformname=sentinel-2 \
-e start_date=2019-06-09t00:00:00.000z \
-e end_date=2019-06-12t00:00:00.000z \
-e days_back=7 \
-e footprint=""polygon((5.8664000 50.3276000,9.4623000 50.3276000,9.4623000 52.5325000,5.8664000 52.5325000,5.8664000 50.3276000))"" \
-e max_cloud_cover_percentage=10 \
-e cdinrw_base_url=10.1.40.11:8081/swagger-ui.html \
-e cdinrw_job_id=3fa85f64-5717-4562-b3fc-2c963f66afa6 \
ingestion

",<docker><kubernetes><containers><minikube><kubernetes-pod>,57305863,3,"for a workload like this, a better design is to deploy a job queue system like rabbitmq and have two long-running containers (deployments, since you're using kubernetes).  one of them runs the rest server, and when it receives a request, writes the details of the request into a queue.  the second listens to the queue, pulls off messages one at a time, and does the network fetch.

especially in kubernetes, this approach has a couple of advantages.  you can easily build and test it without requiring docker or kubernetes.  if you get swamped with requests, they back up in the job queue instead of launching dozens or hundreds of containers.  if you see you have a long queue and want to do fetches faster, you can kubectl scale deployment very easily and run more workers.

if you don't want to go that approach, you should use the kubernetes api to create a job, which can restart if it fails, isn't tightly bound to the same node, and doesn't require root-level permission on the host to launch.  you should not run docker commands from inside a kubernetes pod basically ever.  (and since running docker commands raises the potential of rooting the whole host, you want to be very very careful about doing it from a web server in any case.)
"
66317214,"pilosa k8s pod crashloopbackoff with error ""server : executable file not found in $path""","i am preparing a helm chart for pilosa. after installing the chart (or while creating the deployment),
the pilosa pod enters to a crashloopbackoff.
this is the rendered yaml file for the k8s deployment.
# source: pilosa/templates/deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: release-name-pilosa
  labels:
    helm.sh/chart: pilosa-0.1.0
    app.kubernetes.io/name: pilosa
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: &quot;1.16.0&quot;
    app.kubernetes.io/managed-by: helm
spec:
  replicas: 1
  selector:
    matchlabels:
      app.kubernetes.io/name: pilosa
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pilosa
        app.kubernetes.io/instance: release-name
    spec:
      imagepullsecrets:
        - name: my-cr-secret
      serviceaccountname: default
      securitycontext:
        {}
      initcontainers:
        - command:
          - /bin/sh
          - -c
          - |
            sysctl -w net.ipv4.tcp_keepalive_time=600
            sysctl -w net.ipv4.tcp_keepalive_intvl=60
            sysctl -w net.ipv4.tcp_keepalive_probes=3
          image: busybox
          name: init-sysctl
          securitycontext:
            privileged: true
      containers:
        - name: pilosa
          securitycontext:
            {}
          image: &quot;mycr.azurecr.io/pilosa:v1.4.0&quot;
          imagepullpolicy: ifnotpresent
          command:
            - server
            - --data-dir
            - /data
            - --max-writes-per-request
            - &quot;20000&quot;
            - --bind
            - http://pilosa:10101
            - --cluster.coordinator=true
            - --gossip.seeds=pilosa:14000
            - --handler.allowed-origins=&quot;*&quot;
          ports:
            - name: http
              containerport: 10101
              protocol: tcp
          livenessprobe:
            httpget:
              path: /
              port: http
          readinessprobe:
            httpget:
              path: /
              port: http
          volumemounts:
            - name: &quot;pilosa-pv-storage&quot;
              mountpath: /data
          resources:
            {}
      volumes:
      - name: pilosa-pv-storage
        persistentvolumeclaim:
          claimname: pilosa-pv-claim

when checked the reason for that i found:
$ kubectl describe pod pilosa-57cb7b8764-knsmw
.

.

events:
  type     reason     age                from               message
  ----     ------     ----               ----               -------
  normal   scheduled  48s                default-scheduler  successfully assigned default/pilosa-57cb7b8764-knsmw to 10.0.10.3
  normal   pulling    47s                kubelet            pulling image &quot;busybox&quot;
  normal   pulled     45s                kubelet            successfully pulled image &quot;busybox&quot;
  normal   created    45s                kubelet            created container init-sysctl
  normal   started    45s                kubelet            started container init-sysctl
  normal   pulling    45s                kubelet            pulling image &quot;mycr.azurecr.io/pilosa:v1.2.0&quot;
  normal   pulled     15s                kubelet            successfully pulled image &quot;mycr.azurecr.io/pilosa:v1.2.0&quot;
  normal   created    14s (x2 over 15s)  kubelet            created container pilosa
  warning  failed     14s (x2 over 15s)  kubelet            error: failed to start container &quot;pilosa&quot;: error response from daemon: oci runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \&quot;server\&quot;: executable file not found in $path&quot;: unknown
  normal   pulled     14s                kubelet            container image &quot;mycr.azurecr.io/pilosa:v1.2.0&quot; already present on machine
  warning  backoff    10s                kubelet            back-off restarting failed container

that means the problem is it cannot run command server :
 error: failed to start container &quot;pilosa&quot;: error response from daemon: oci runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \&quot;server\&quot;: executable file not found in $path&quot;: unknown

but that command is available in pilosa as specified here : https://www.pilosa.com/docs/latest/installation/
can anyone help me to find a solution for this?
",<kubernetes><executable><kubernetes-helm><file-not-found><pilosa>,66318566,3,"the issue here is that kubernetes is overriding the entrypoint in the pilosa docker image. the server command is actually a subcommand of pilosa, which works because of how the pilosa dockerfile defines the command:
entrypoint [&quot;/pilosa&quot;]
cmd [&quot;server&quot;, &quot;--data-dir&quot;, &quot;/data&quot;, &quot;--bind&quot;, &quot;http://0.0.0.0:10101&quot;]

because you are using the command: declaration, it overrides both the entrypoint and the cmd when invoking the container.
i think the simple solution is to replace command: with args:, and i believe k8s will no longer override the entrypoint. or you could instead add /pilosa to the front of the command.
you may also take a look at this pilosa helm chart, which is unmaintained but might work for you. note that it uses a statefulset instead of a deployment, which should fit pilosa better: https://github.com/pilosa/helm
"
51138144,any way to prevent k8s pod eviction?,"i have a set of daemons i need to run, generally, they do not consume much memory or cpu and i have their limits to cpu: 150m and memory: 150m. 

occasionally they will spike to quite a bit higher than this and this seems to be causing evictions and unstable node.

it is critical that the daemons remain running 24/7, even if they are throttled by cpu and/or memory when they spike. is it possible to prevent their eviction and to cap their resources?

as i understand the cpu usage is throttled but over memory use results in an oom eviction, is there any way to prevent this eviction?
",<docker><kubernetes><google-cloud-platform><google-kubernetes-engine>,51143234,2,"sounds like you need to track the resources consumption trends with something like prometheus + grafana to check what sort of spikes you expect from your daemonsets. 

then you can allocate more resources to these pods or remove this config (which, by default, will leave them in unbounded mode). but, of course, you don't want to risk a full node / host crash so you can consider tweaking your eviction threshold:
https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#eviction-thresholds

more details:
https://kubernetes-v1-4.github.io/docs/admin/limitrange/
"
53764944,copy command crash pod startup on kubernetes,"i'm new with kubernetes and i'm trying to understand about the commands.
basically what i'm trying to do is to create a tomcat deployment, add an nfs and after that i copy the war file to the tomcat webapps.
but its failing

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: webapp11-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp11
    spec:
      volumes:
        - name: www-persistent-storage
          persistentvolumeclaim:
            claimname: claim-webapp11
      containers:
      - name: webapp11-pod
        image: tomcat:8.0
        volumemounts:
          - name: www-persistent-storage
            mountpath: /apps/build
        command: [""sh"",""-c"",""cp /apps/build/v1/sample.war /usr/local/tomcat/webapps""]
        ports:
        - containerport: 8080


as far as i understand when the image when an image has a command, like catalina.sh run on the tomcat image, it will have a conflict with a command from the kubernetes.
is that correct?
there is anyway to run a command after the pod starts?
thanks
",<kubernetes><command><kubernetes-pod>,53768964,1,"no, what you want is probably something like this:

command: [""sh"",""-c"",""cp /apps/build/v1/sample.war /usr/local/tomcat/webapps &amp;&amp; exec /whatever/catalina.sh""]


or you could move the cp into an initcontainer so you don't have to override the default command for your tomcat container.
"
65308780,disable default dashboards in the prometheus community helm chart,"i deployed the kube-prometheus-stack helm chart. while this chart offers a really nice starting point it has lots of default dashboards which i do not want to use. in the values.yaml of the chart, there is an option defaultdashboardsenabled: true, which seems to be what i am looking for but if i set it to false using the code below in my values file, which i mount into the helm chart, the dashboards are still there. does anyone know why this does not work?
a possibility which i thought of is that the chart has both a subchart called grafana and an option  grafana, but i do not know how i could fix it or test if this is the issue.
grafana: 
  defaultdashboardsenabled: false 

",<kubernetes><prometheus><grafana><kubernetes-helm>,65338448,1,"i`m placing this answer to better visibility as community might interested in other solutions.

first way would be setting grafana.enable: to false in values.yaml.

## using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
grafana:
  enabled: true

with this your chart will not install grafana.

another way would be to helm pull the chart to your local directory and then just delete the template.grafana directory (to launch the chart locally you just need to helm install &lt;name&gt; ./prometheus-stack)

"
58447111,how to reference kubernetes secrets in helm chart?,"i want to make some deployments in kubernetes using helm charts. here is a sample override-values yaml that i use:

imagerepository: """"

ocbb:
    imagepullpolicy: ifnotpresent
    tz: utc
    logdir: /oms_logs
    tnsadmin: /oms/ora_k8
    log_level: 3
    wallet:
        client: 
        server: 
        root:
    db:
        deployment:
            imagename: init_db
            imagetag:
        host: 192.168.88.80
        port:
        service:
        alias:
        schemauser: pincloud
        schemapass:
        schematablespace: pincloud
        indextablespace: pincloudx
        nls_lang: american_america.al32utf8
        charset: al32utf8
        pipelineschemauser: ifwcloud
        pipelineschemapass:
        pipelineschematablespace: ifwcloud
        pipelineindextablespace: ifwcloudx
        pipelinealias:
        queuename:



in this file i have to set some values involving credentials, for example schemapass, pipelineschemapass...
documentation states i have to generate kubernetes secrets to do this and add this key to my yaml file with the same path hierarchy.

i generated some kubernetes secrets, for example:

kubectl create secret generic schemapass --from-literal=password='pincloud'


now i don't know how to reference this newly generated secret in my yaml file. any tip about how to set schemapass field in yaml chart to reference kubernetes secret?
",<kubernetes><kubernetes-helm><kubernetes-secrets>,58482769,40,"you cannot use kubernetes secret in your values.yaml. in values.yaml you only specify the input parameters for the helm chart, so it could be the secret name, but not the secret itself (or anything that it resolved).

if you want to use the secret in your container, then you can insert it as an environment variable:

env:
- name: secret_value_env
  valuefrom:
    secretkeyref:
      name: schemapass
      key: password


you can check more in the hazelcast enterprise helm chart. we do exactly that. you specify the secret name in values.yaml and then the secret is injected into the container using environment variable.
"
57922713,eks logs to cloudwatch stream as string,"i'm having this issue, i have an eks cluster which sends logs to cloudwatch, then firehose stream the logs to s3 bucket.

my goal is to get these logs from s3 and forward them to elasticsearch in bulks.
i wrote a python lambda function and its working perfectly when logs are jsons.
my problem is some logs are strings or ""kind of"" json.

exmaple : 

kube-authenticator :

time=""2019-09-13t09:30:50z"" level=error msg=""watch channel closed.""

kube-apiserver : 

e0912 10:19:10.649757 1 watcher.go:208] watch chan error: etcdserver: mvcc: required revision has been compacted

i'm wondering if i should try to wrap these messages and convert them to json or there is any way to change the log format to json.i thought about writing regex but i don't have enough knowledge with regex . 
",<python><amazon-web-services><elasticsearch><kubernetes><amazon-eks>,57970861,1,"as mentioned in comments, ended up writing 2 functions that handle the logs and convert them to json.

the first one handle kube-apiserver,kube-controller-manager and kube-scheduler logs groups :

def convert_text_logs_to_json_and_add_loggroup(message,loggroup):
    month_and_day = message.split(' ')[0][1:]
    month_and_day = insert_dash(month_and_day,2)
    log_time_regex = r""\s+((?:\d{2})?:\d{1,2}:\d{1,2}.\d{1,})""
    log_time = re.findall(log_time_regex, message)[0]
    currentyear = datetime.now().year
    full_log_datetime = ""%s-%st%sz"" %(currentyear,month_and_day,log_time)
    log_contnet = (re.split(log_time_regex,message)[2])
    message = '{""timestamp"": ""%s"", ""message"":""%s"",""loggroup"" :""%s""}' %(full_log_datetime,log_contnet.replace('""',''),loggroup)
    return message


the second function handles authenticator log group : 

def chunkwise(array, size=2):
    it = iter(array)
    return izip(*[it]*size)

def wrap_text_to_json_and_add_loggroup(message,loggroup):
    regex = r""\"".*?\""|\w+""
    matches = re.findall(regex, message)
    key_value_pairs = chunkwise(matches)
    json_message= {}
    for key_value in key_value_pairs:
        key = key_value[0]
        if key == 'time':
            key = 'timestamp'
        value = key_value[1].replace('""','')
        json_message[key] = value
    json_message['loggroup'] = loggroup
    log_to_insert = json.dumps(json_message)
    return log_to_insert


i hope these functions are useful for those who might need to insert logs from cloudwatch to elasticsearch.
"
56051884,"port forward is working, but not able to access the port from other pods in the same gke cluster","i have a stateful set for mq, exposed two ports 1414 for tcp and 9443 for https and created service of type loadbalancer.    1414 for tcp is working fine, able to telnet from other pods in the same cluster using service name/cluster ip..also able to connect 1414 from outside gke cluster. 

but the problem is port 9443 is not accessible from other pod in the cluster (service name/cluster ip) or outside the cluster (external ip).     the telnet is working fine when exec to the pod and test locally..  telnet 127.0.01 9443

is there any configuration missing for https service..   

note: port forward is working fine and able to connect to the api.  kubectl port-forward svc/mq-qmdtest 9443:9443

service definition 

apiversion: v1
kind: service
metadata:
  name: {{.values.name}}
  namespace: {{.values.namespace}}
  annotations:
    cloud.google.com/load-balancer-type: ""internal""
  labels : 
    run: {{.values.name}}
spec:
  type: loadbalancer
  loadbalancerip: {{.values.loadbalancerip}}
  ports:
  - name: webui
    port: 9443
    protocol: tcp
  - name: mq
    port: 1414
    protocol: tcp
  selector:
    run: {{.values.name}}


stateful set – container port configuration 

    ports:
    - containerport: 9443
      protocol: tcp
      name: webui
    - containerport: 1414
      protocol: tcp
      name: mq

",<kubernetes><google-kubernetes-engine>,56053059,9,"
  the telnet is working fine when exec to the pod and test locally.. telnet 127.0.01 9443
  ...
   port forward is working fine and able to connect to the api. kubectl port-forward svc/mq-qmdtest 9443:9443


is almost certainly caused by the pod only listening on localhost; port-forward also engages with localhost, so the fact that you cannot reach it from other pods in the cluster but you can from itself and you can from port-forward means the service is only listening for local connections.

without knowing more about the software i can't offer you a ""open this file, change this value"" type instructions, but be on the lookout for ""bind host"" or any ""listen"" configuration that would accept both a host and a port, and in that case set the ""bind host"" to 0.0.0.0 or the ""listen"" configuration to 0.0.0.0:9443
"
78974924,golang k8s operator - what is causing a nil pointer error?,"i'm developing a custom k8s operator that utilizes this go-client library: https://github.com/newrelic/newrelic-client-go/tree/main to makes api calls to new relic (3rd party service). i've created a shared interface that i want to reuse between controllers that allows to interact with that api, but i'm receiving the following error when testing the operator:
2024-09-11t11:43:33-04:00   error   reconciler error    {&quot;controller&quot;: &quot;nrqlcondition&quot;, &quot;controllergroup&quot;: &quot;alerts.k8s.newrelic.com&quot;, &quot;controllerkind&quot;: &quot;nrqlcondition&quot;, &quot;nrqlcondition&quot;: {&quot;name&quot;:&quot;nrqlcondition-example&quot;,&quot;namespace&quot;:&quot;default&quot;}, &quot;namespace&quot;: &quot;default&quot;, &quot;name&quot;: &quot;nrqlcondition-example&quot;, &quot;reconcileid&quot;: &quot;04f43b77-c342-46ed-acbd-d066e059a4c2&quot;, &quot;error&quot;: &quot;panic: runtime error: invalid memory address or nil pointer dereference [recovered]&quot;}

my question (being new to developing custom k8s operators) is - do operators support concurrent patterns like this during the reconciliation process? the exact implementation of the shared interface works fine in controller #1 (policy), but throws above error on controller #2 (nrqlcondition). the stack trace points to the alertclient being nil within the nrqlcondition_controller.go - specifically line
alertclient, erralertclient := r.alertclient(r.apikey, condition.spec.region)
go.mod:
go 1.22.0

require (
    github.com/go-logr/logr v1.4.2
    github.com/newrelic/newrelic-client-go/v2 v2.44.0
    github.com/onsi/ginkgo/v2 v2.19.0
    github.com/onsi/gomega v1.33.1
    k8s.io/apimachinery v0.31.0
    k8s.io/client-go v0.31.0
    sigs.k8s.io/controller-runtime v0.19.0
)

code snippets below:
interfaces/client.go:
package interfaces

import (
    &quot;fmt&quot;

    &quot;github.com/newrelic/newrelic-client-go/v2/newrelic&quot;
    &quot;github.com/newrelic/newrelic-client-go/v2/pkg/alerts&quot;
    &quot;github.com/newrelic/newrelic-client-go/v2/pkg/config&quot;
)

// newrelicclientinterface defines the methods for interacting with the nr api
type newrelicclientinterface interface {
    alerts() *alerts.alerts
}

// newrelicclientwrapper wraps the new relic client and implements newrelicclientinterface
type newrelicclientwrapper struct {
    client *newrelic.newrelic
}

// alerts returns the alerts client
func (n *newrelicclientwrapper) alerts() *alerts.alerts {
    return &amp;n.client.alerts
}

// newclient initializes a new instance of nr client
func newclient(apikey string, regionval string) (*newrelic.newrelic, error) {
    cfg := config.new()

    client, err := newrelic.new(
        newrelic.configpersonalapikey(apikey),
        newrelic.configloglevel(cfg.loglevel),
        newrelic.configregion(regionval),
    )

    if err != nil {
        return nil, err
    }

    return client, nil
}

// initnewclient initalizes all alerts crud functionality
func initnewclient(apikey string, regionname string) (newrelicclientinterface, error) {
    client, err := newclient(apikey, regionname)
    if err != nil {
        return nil, fmt.errorf(&quot;unable to create new relic client with error: %s&quot;, err)
    }

    return &amp;newrelicclientwrapper{client: client}, nil
}

controller/alertpolicy_controller.go:
// alertpolicyreconciler reconciles a alertpolicy object
type alertpolicyreconciler struct {
    client.client
    scheme      *runtime.scheme
    log         logr.logger
    alerts      interfaces.newrelicclientinterface
    alertclient func(string, string) (interfaces.newrelicclientinterface, error)
    apikey      string
}

func (r *alertpolicyreconciler) reconcile(ctx context.context, req ctrl.request) (ctrl.result, error) {
    _ = log.fromcontext(ctx)

    //fetch alertpolicy instance
    var policy alertsv1.alertpolicy
    err := r.get(ctx, req.namespacedname, &amp;policy)
    if err != nil {
        if errors.isnotfound(err) {
            r.log.info(&quot;policy 'not found' after being deleted. this is expected and no cause for alarm&quot;, &quot;error&quot;, err)
            return ctrl.result{}, nil
        }
        r.log.error(err, &quot;failed to get policy&quot;, &quot;name&quot;, req.namespacedname.string())
        return ctrl.result{}, err
    }

    r.log.info(&quot;starting policy reconcile&quot;)

    //get api key
    r.apikey, err = r.getapikeyorsecret(policy)
    if err != nil {
        return ctrl.result{}, err
    }

    if r.apikey == &quot;&quot; {
        return ctrl.result{}, err
    }

    //init client
    alertclient, erralertclient := r.alertclient(r.apikey, policy.spec.region)
    if erralertclient != nil {
        r.log.error(erralertclient, &quot;failed to create alert client&quot;)
        return ctrl.result{}, erralertclient
    }
    r.alerts = alertclient

    ...

}

controllers/nrqlcondition_controller.go:
// nrqlconditionreconciler reconciles a nrqlcondition object
type nrqlconditionreconciler struct {
    client.client
    scheme      *runtime.scheme
    log         logr.logger
    alerts      interfaces.newrelicclientinterface
    alertclient func(string, string) (interfaces.newrelicclientinterface, error)
    apikey      string
}

func (r *nrqlconditionreconciler) reconcile(ctx context.context, req ctrl.request) (ctrl.result, error) {
    _ = log.fromcontext(ctx)

    //fetch nrqlcondition instance
    var condition alertsv1.nrqlcondition
    err := r.get(ctx, req.namespacedname, &amp;condition)
    if err != nil {
        if errors.isnotfound(err) {
            r.log.info(&quot;condition 'not found' after being deleted. this is expected and no cause for alarm&quot;, &quot;error&quot;, err)
            return ctrl.result{}, nil
        }
        r.log.error(err, &quot;failed to get nrql condition&quot;, &quot;name&quot;, req.namespacedname.string())
        return ctrl.result{}, err
    }

    r.log.info(&quot;starting condition reconcile&quot;)

    //get api key
    r.apikey, err = r.getapikeyorsecret(condition)
    if err != nil {
        return ctrl.result{}, err
    }

    if r.apikey == &quot;&quot; {
        return ctrl.result{}, err
    }

    //init client
    alertclient, erralertclient := r.alertclient(r.apikey, condition.spec.region)
    if erralertclient != nil {
        r.log.error(erralertclient, &quot;failed to create alert client&quot;)
        return ctrl.result{}, erralertclient
    }
    r.alerts = alertclient

    ...

}

",<go><kubernetes><kubernetes-operator>,78974993,1,"figured it out finally - the problem was that the alertclient was not registered in main.go:
before:
    if err = (&amp;controller.nrqlconditionreconciler{
        client:      mgr.getclient(),
        scheme:      mgr.getscheme(),
    }).setupwithmanager(mgr); err != nil {
        setuplog.error(err, &quot;unable to create controller&quot;, &quot;controller&quot;, &quot;nrqlcondition&quot;)
        os.exit(1)
    }

after:
    if err = (&amp;controller.nrqlconditionreconciler{
        client:      mgr.getclient(),
        scheme:      mgr.getscheme(),
        alertclient: interfaces.initnewclient,
    }).setupwithmanager(mgr); err != nil {
        setuplog.error(err, &quot;unable to create controller&quot;, &quot;controller&quot;, &quot;nrqlcondition&quot;)
        os.exit(1)
    }

"
57222210,how can i view pods with kubectl and filter based on having a status of imagepullbackoff?,"i'd like to do a kubectl get pods and filter where the pod  is in a status of imagepullbackoff.

i've tried kubectl get pods --field-selector=status.phase=waiting and kubectl get pods --field-selector=status.phase=imagepullbackoff but that returns no results.

i've had a look at the json output with -o json:

...
            {
                ""image"": ""zzzzzzzzzzzzzzzz"",
                ""imageid"": """",
                ""laststate"": {},
                ""name"": ""nginx"",
                ""ready"": false,
                ""restartcount"": 0,
                ""state"": {
                    ""waiting"": {
                        ""message"": ""back-off pulling image \""zzzzzzzzzzzzzzzz\"""",
                        ""reason"": ""imagepullbackoff""
                    }
                }
            }
...


if i try target that value:

kubectl get pods --field-selector=state.waiting=imagepullbackoff 
error from server (badrequest): unable to find ""/v1, resource=pods"" that match label selector """", field selector ""state.waiting=imagepullbackoff"": field label not supported: state.waiting

",<kubernetes><kubectl>,57222958,19,"using json output and piping through jq:

kubectl get pod -o=json | jq '.items[]|select(any( .status.containerstatuses[]; .state.waiting.reason==""imagepullbackoff""))|.metadata.name'


last chunk |.metadata.name means it'll list pod names instead of the entire structures. 
"
63575855,multiple vue.js containers in kubernetes and terraform setup returns 404 or 502,"i have an ingress / terraform / nginx / kubernetes setup that has issues with properly redirecting, it's currently serving a vue.js frontend and a .net core backend, both of these work online. however, when adding another vue.js instance it doesn't seem to properly redirect to said url.
my terraform setup
resource &quot;kubernetes_ingress&quot; &quot;ingress&quot; {
    metadata {
     name      = &quot;ingress&quot;
     namespace = var.namespace_name
     annotations = {
       &quot;nginx.ingress.kubernetes.io/force-ssl-redirect&quot; = true
       &quot;nginx.ingress.kubernetes.io/from-to-www-redirect&quot; = true
       &quot;nginx.ingress.kubernetes.io/ssl-redirect&quot;: true
       &quot;kubernetes.io/ingress.class&quot;: &quot;nginx&quot;
     }
    }

spec {
 tls {
  hosts = [var.domain_name, &quot;*.${var.domain_name}&quot;]
  secret_name = &quot;tls-secret&quot;
 }
rule {
  host = var.domain_name
  http {
    path {
      path = &quot;/&quot;
      backend {
        service_name = &quot;frontend&quot;
        service_port = 80
      }
    }

    path {
      path = &quot;/api&quot;
      backend {
        service_name = &quot;api&quot;
        service_port = 80
      }
    }

    path {
      path = &quot;/backend/*&quot;
      backend {
        service_name = &quot;backend&quot;
        service_port = 80
      }
    }

    path {
      path = &quot;/payment/*&quot;
      backend {
        service_name = &quot;payment&quot;
        service_port = 80
      }
    }

  }
}
}

wait_for_load_balancer = true
}

when running kubectl describe the following is returned
name:             ingress
namespace:        [redacted]
address:          [ip-address]
default backend:  default-http-backend:80 (&lt;none&gt;)
tls:
 tls-secret terminates [url-name],*.[url-name]
rules:
  host            path  backends
  ----            ----  --------
  [url-name]
              /           frontend:80 (10.244.0.97:80)
              /api        api:80 (10.244.0.121:80)
              /backend/   backend:80 (10.244.0.96:80)
              /payment/   payment:80 (10.244.0.32:80)
  annotations:
    nginx.ingress.kubernetes.io/force-ssl-redirect:    true
    nginx.ingress.kubernetes.io/from-to-www-redirect:  true
    nginx.ingress.kubernetes.io/ssl-redirect:          true

i was thinking i might be missing proxy settings but i have no idea how to redirect that. furthermore, this entire solution is deployed with ci and to digital ocean. i've tried various other configurations such as removing the asterix in the paths /backend/ but this didn't change anything.
in annotations adding nginx.ingress.kubernetes.io/rewrite-target: / only broke the /api url and didn't fix the others.
edit* adding &quot;kubernetes.io/ingress.class&quot;: &quot;nginx&quot; like @vitalii mentioned unfortunately did not fix the issue. question has been updated for completeness sake
",<docker><vue.js><kubernetes><terraform><kubernetes-ingress>,63614507,1,"adding nginx.ingress.kubernetes.io/rewrite-target: / was actually part of the solution, it did break the .net c# api which made me ask a separate question that can be found here for consistency &amp; future searches sake the solution i've used was as follows. apart from adding the rewrite target line in my annotations changing the api path from
 path {
  path = &quot;/api(.*)&quot;
  backend {
    service_name = &quot;api&quot;
    service_port = 80
  }
}

into
     path {
      path = &quot;/(api.*)&quot;
      backend {
        service_name = &quot;olc-api&quot;
        service_port = 80
      }
    }

with this it matches the /api to my .net core app, instead of it trying to find a url within the vue.js container(s)
"
37555281,create kubernetes pod with volume using kubectl run,"i understand that you can create a pod with deployment/job using kubectl run.  but is it possible to create one with a volume attached to it?  i tried running this command:

kubectl run -i --rm --tty ubuntu --overrides='{ ""apiversion"":""batch/v1"", ""spec"": {""containers"": {""image"": ""ubuntu:14.04"", ""volumemounts"": {""mountpath"": ""/home/store"", ""name"":""store""}}, ""volumes"":{""name"":""store"", ""emptydir"":{}}}}' --image=ubuntu:14.04 --restart=never -- bash


but the volume does not appear in the interactive bash.

is there a better way to create a pod with volume that you can attach to?
",<kubernetes><kubectl>,37621761,61,"your json override is specified incorrectly. unfortunately kubectl run just ignores fields it doesn't understand.

kubectl run -i --rm --tty ubuntu --overrides='
{
  ""apiversion"": ""batch/v1"",
  ""spec"": {
    ""template"": {
      ""spec"": {
        ""containers"": [
          {
            ""name"": ""ubuntu"",
            ""image"": ""ubuntu:14.04"",
            ""args"": [
              ""bash""
            ],
            ""stdin"": true,
            ""stdinonce"": true,
            ""tty"": true,
            ""volumemounts"": [{
              ""mountpath"": ""/home/store"",
              ""name"": ""store""
            }]
          }
        ],
        ""volumes"": [{
          ""name"":""store"",
          ""emptydir"":{}
        }]
      }
    }
  }
}
'  --image=ubuntu:14.04 --restart=never -- bash


to debug this issue i ran the command you specified, and then in another terminal ran:

kubectl get job ubuntu -o json


from there you can see that the actual job structure differs from your json override (you were missing the nested template/spec, and volumes, volumemounts, and containers need to be arrays).
"
64665690,kubernetes/rancher: networkpolicy with traefik,"we are using rancher to setup clusters with canal as the cni. we decided to use traefik as an ingress controller and wanted to create a networkpolicy. we disabled projectisolation and traefik is running in the system project in the kube-system namespace.
i created this policy:
# deny all ingress traffic
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: default-deny-all
spec:
  podselector: {}
  ingress:
  - from:
    - podselector: {}

---
# allow traefik
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: ingress-allow-traefik
spec:
  podselector: {}
  ingress:
    - from:
      - namespaceselector:
          matchlabels:
            namespace: kube-system
        podselector:
          matchlabels:
            app: traefik

---
# allow backnet
kind: networkpolicy
apiversion: networking.k8s.io/v1
metadata:
  name: ingress-allow-backnet
spec:
  podselector: {}
  ingress:
    - from:
      - ipblock:
          cidr: 10.0.0.0/24
      - ipblock:
          cidr: 10.1.0.0/24
      - ipblock:
          cidr: 10.2.0.0/24
      - ipblock:
          cidr: 192.168.0.0/24

but somehow we can't get this to work. the connection gets time-outed and that's it. is there a major problem with this policy? something i didn't understand about networkpolicies?
thanks in advance
",<kubernetes><traefik><rancher><kubernetes-networkpolicy>,64682353,1,"i solved the problem. it was a plain beginner mistake:
- namespaceselector:
    matchlabels:
      namespace: kube-system

i didn't add the label namespace: kube-system to the namespace kube-system.
after adding the label it worked instantly.
"
72148067,update node condition type in status,"i am trying to patch, clear node conditions in openshift and/or kubernetes cluster on a worker node. patch isn't working, trying even workarounds, maybe update the key in etcd.
main problem that i created new node conditions and then i removed them but they are not removed from list although they are no longer there or being updated by the controller.
$ oc describe node node1.example.com

conditions:                 
  type             status  lastheartbeattime                 lasttransitiontime                reason                       message
  ----             ------  -----------------                 ------------------                ------                       -------
  exampletoremove        false   wed, 13 feb 2019 15:09:42 -0500   wed, 13 feb 2019 11:05:57 -0500   kubelethassufficientdisk     kubelet has sufficient disk space available
  memorypressure   false   wed, 13 feb 2019 15:09:42 -0500   wed, 13 feb 2019 11:05:57 -0500   kubelethassufficientmemory   kubelet has sufficient memory available
  diskpressure     false   wed, 13 feb 2019 15:09:42 -0500   wed, 13 feb 2019 11:05:57 -0500   kubelethasnodiskpressure     kubelet has no disk pressure
  pidpressure      false   wed, 13 feb 2019 15:09:42 -0500   wed, 13 feb 2019 11:05:57 -0500   kubelethassufficientpid      kubelet has sufficient pid available
  ready            true    wed, 13 feb 2019 15:09:42 -0500

",<kubernetes><openshift><kubernetes-pod><openshift-origin><openshift-enterprise>,72181319,1,"posting answer from comment as community wiki.
i found the fix, you can edit whatever you want in the node description by updating the etcd key /kubernetes.io/minions/&lt;node-name&gt;
edit:
finally i found a way to patch and update the node condition type status, add new or even delete
example:
curl -k -h &quot;authorization: bearer $token&quot; -h &quot;content-type: application/json-patch+json&quot; -x patch https://apiserver:6443/api/v1/nodes/name-of-node-update-condition/status --data '[{ &quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/status/conditions/2&quot;}]'

note: each condition has an index number, so try to know what is the index number and then target it in /status/condition/
"
59065279,"error: failed to prepare subpath for volumemount ""postgres-storage"" of container ""postgres""","i am trying to use persistent volume claims and facing this issue
this is my postgres-deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: postgres-deployment
spec:
  replicas: 1
  selector:
    matchlabels:
      component: postgres
  template:
    metadata:
      labels:
        component: postgres
    spec:
      volumes:
        - name: postgres-storage
          persistentvolumeclaim:
            claimname: database-persistent-volume-claim
      containers:
      - name: postgres
        image: postgres
        ports:
        - containerport: 5432
        volumemounts:
          - mountpath: /var/lib/postgresql/data
            name: postgres-storage
            subpath: postgres

when i debug pod using describe
kubectl describe pod postgres-deployment-8576df7bfc-8mp5t

events:
  type     reason     age                  from                     message
  ----     ------     ----                 ----                     -------
  normal   scheduled  3m4s                 default-scheduler        successfully assigned default/postgres-deployment-8576df7bfc-8mp5t to docker-desktop
  normal   pulled     67s (x8 over 2m58s)  kubelet, docker-desktop  successfully pulled image &quot;postgres&quot;
  warning  failed     67s (x8 over 2m58s)  kubelet, docker-desktop  error: failed to prepare subpath for volumemount &quot;postgres-storage&quot; of container &quot;postgres&quot;
  normal   pulling    53s (x9 over 3m3s)   kubelet, docker-desktop  pulling image &quot;postgres&quot;

my pod is showing me this error
$ kubectl get pods
name                                   ready   status                       restarts   age
postgres-deployment-8576df7bfc-8mp5t   0/1     createcontainerconfigerror   0          5m5

i am not sure where is the problem in the config. but i am sure this is related to volumes because after adding volumes this problem appears
",<postgresql><kubernetes><kubernetes-pvc>,59065369,4,"remove subpath. can you try below yaml

apiversion: apps/v1
kind: deployment
metadata:
  name: postgres-deployment
spec:
  replicas: 1
  selector:
    matchlabels:
      component: postgres
  template:
    metadata:
      labels:
        component: postgres
    spec:
      volumes:
        - name: postgres-storage
          persistentvolumeclaim:
            claimname: database-persistent-volume-claim
      containers:
      - name: postgres
        image: postgres
        ports:
        - containerport: 5432
        volumemounts:
          - mountpath: /var/lib/postgresql/data
            name: postgres-storage


i just deployed and it works

master $ kubectl get deploy
name                  ready   up-to-date   available   age
postgres-deployment   1/1     1            1           4m13s
master $ kubectl get po
name                                   ready   status    restarts   age
postgres-deployment-6b66bdd748-5q76h   1/1     running   0          4m13s

"
52839920,get array of strings from helm config,"ultimately i'm trying to get an array of strings e.g. ['foo', 'bar'] in my js app from my helm config.

./vars/dev/organizations.yaml

...
organizations:
  - 'foo'
  - 'bar'
...


./templates/configmap.yaml

...
data:
  organizations.yaml: |
    organizations: ""{{ toyaml .values.organizations | indent 4 }}""
...


./templates/deployment.yaml

...
containers:
    args:
       - ""--organizations-config""
       - ""/etc/app/cfg/organizations.yaml""
...


index.js

...
const default_organizations_path = './vars/local/organizations.yaml'
const program = require('commander')

program
  .option(
    '--organizations-config &lt;file path&gt;',
    'the path to the organizations config file.', default_organizations_path)
  .parse(process.argv)

function readconfigs () {
  return promise.all(configs.map(path =&gt; {
    return new promise((resolve, reject) =&gt; {
      fs.readfile(path, (err, data) =&gt; {
        err ? reject(err) : resolve(yaml.safeload(data))
      })
    })
  }))
}

readconfigs()
  .then(configs =&gt; {
    let organizationsconfig = configs[3]

    console.log('organizationsconfig = ', organizationsconfig)
    console.log('organizationsconfig.organizations = ', organizationsconfig.organizations)
...


the output from above is:

organizationsconfig =  { organizations: '    - foo - bar' }
organizationsconfig.organizations =      - foo - bar


how can i modify my helm config so that organizationsconfig.organizations will be ['foo', 'bar']
",<kubernetes><kubernetes-helm>,52840704,28,"one way to get the output you're looking for is to change:

...
organizations:
  - 'foo'
  - 'bar'
...


to:

organizations: |
  [ 'foo', 'bar']


so helm treats it as a single string. we happen to know that it contains array content but helm just thinks it's a string. then we can set that string directly in the configmap:

organizations: {{ .values.organizations | indent 4 }}

what this does is what the grafana chart does in that it forces the user to specify the list in the desired format in the first place. perhaps you'd prefer to take an array from the helm values and convert it to your desired format, which appears to me to be json format. to do that you could follow the example of the vault chart. so the configmap line becomes:

organizations: {{ .values.organizations | tojson | indent 4 }}

then the yaml that the user puts in can be as you originally had it i.e. a true yaml array. i tried this and it works but i notice that it gives double-quoted content like [""foo"",""bar""]

the other way you can do it is with:

organizations:
  {{- range .values.organizations }}
    - {{ . }}
  {{- end }}

"
47021469,how to set google_application_credentials on gke running through kubernetes,"with the help of kubernetes i am running daily jobs on gke, on a daily basis based on cron configured in kubernetes a new container spins up and try to insert some data into bigquery.

the setup that we have is we have 2 different projects in gcp in one project we maintain the data in bigquery in other project we have all the gke running so when gke has to interact with different project resource my guess is i have to set an environment variable with name  google_application_credentials which points to a service account json file, but since every day kubernetes is spinning up a new container i am not sure how and where i should set this variable.

thanks in advance!

note: this file is parsed as a golang template by the drone-gke plugin.

---
apiversion: v1
kind: secret
metadata:
  name: my-data-service-account-credentials
type: opaque
data:
  sa_json: ""bas64jsonserviceaccount""
---
apiversion: v1
kind: pod
metadata:
  name: adtech-ads-apidata-el-adunit-pod
spec:
  containers:
  - name: adtech-ads-apidata-el-adunit-container
    volumemounts:
    - name: service-account-credentials-volume
     mountpath: ""/etc/gcp""
     readonly: true
  volumes:
  - name: service-account-credentials-volume
    secret:
      secretname: my-data-service-account-credentials
      items:
      - key: sa_json
        path: sa_credentials.json




this is our cron jobs for loading the adunit data

apiversion: batch/v2alpha1
kind: cronjob
metadata:
  name: adtech-ads-apidata-el-adunit
spec:
  schedule: ""*/5 * * * *""
  suspend: false
  concurrencypolicy: replace
  successfuljobshistorylimit: 10
  failedjobshistorylimit: 10
  jobtemplate:
    spec:
      template:
        spec:
          containers:
          - name: adtech-ads-apidata-el-adunit-container
            image: {{.image}}
            args:
            - -cp
            - opt/nyt/dfpdataingestion-1.0-jar-with-dependencies.jar
            - com.nyt.cron.adunitjob
            env:
              - name: env_app_name
                value: ""{{.env_app_name}}""
              - name: env_app_context_name
                value: ""{{.env_app_context_name}}""
              - name: env_google_projectid
                value: ""{{.env_google_projectid}}""
              - name: env_google_datasetid
                value: ""{{.env_google_datasetid}}""
              - name: env_reporting_datasetid
                value: ""{{.env_reporting_datasetid}}""
              - name: env_adbridge_datasetid
                value: ""{{.env_adbridge_datasetid}}""
              - name: env_salesforce_datasetid
                value: ""{{.env_salesforce_datasetid}}""
              - name: env_cloud_platform_url
                value: ""{{.env_cloud_platform_url}}""
              - name: env_smtp_host
                value: ""{{.env_smtp_host}}""
              - name: env_to_email
                value: ""{{.env_to_email}}""
              - name: env_from_email
                value: ""{{.env_from_email}}""
              - name: env_aws_username
                value: ""{{.env_aws_username}}""
              - name: env_client_id
                value: ""{{.env_client_id}}""
              - name: env_refresh_token
                value: ""{{.env_refresh_token}}""
              - name: env_network_code
                value: ""{{.env_network_code}}""
              - name: env_application_name
                value: ""{{.env_application_name}}""
              - name: env_salesforce_username
                value: ""{{.env_salesforce_username}}""
              - name: env_salesforce_url
                value: ""{{.env_salesforce_url}}""
              - name: google_application_credentials
                value: ""/etc/gcp/sa_credentials.json""
              - name: env_cloud_sql_url
                valuefrom:
                  secretkeyref:
                    name: secrets
                    key: cloud_sql_url
              - name: env_aws_password
                valuefrom:
                  secretkeyref:
                    name: secrets
                    key: aws_password
              - name: env_client_secret
                valuefrom:
                  secretkeyref:
                    name: secrets
                    key: dfp_client_secret
              - name: env_salesforce_password
                valuefrom:
                  secretkeyref:
                    name: secrets
                    key: salesforce_password


          restartpolicy: onfailure



",<kubernetes><google-kubernetes-engine>,47023291,60,"so, if your gke project is project my-gke, and the project containing the services/things your gke containers need access to is project my-data, one approach is to:


create a service account in the my-data project. give it whatever gcp roles/permissions are needed (ex. roles/bigquery.
dataviewer if you have some bigquery tables that your my-gke gke containers need to read).


create a service account key for that service account. when you do this in the console following https://cloud.google.com/iam/docs/creating-managing-service-account-keys, you should automatically download a .json file containing the sa credentials.

create a kubernetes secret resource for those service account credentials. it might look something like this:

apiversion: v1
kind: secret
metadata:
  name: my-data-service-account-credentials
type: opaque
data:
  sa_json: &lt;contents of running 'base64 the-downloaded-sa-credentials.json'&gt;

mount the credentials in the container that needs access:

[...]
spec:
  containers:
  - name: my-container
    volumemounts:
    - name: service-account-credentials-volume
      mountpath: /etc/gcp
      readonly: true
[...]
  volumes:
  - name: service-account-credentials-volume
    secret:
      secretname: my-data-service-account-credentials
      items:
      - key: sa_json
        path: sa_credentials.json

set the google_application_credentials environment variable in the container to point to the path of the mounted credentials:

[...]
spec:
  containers:
  - name: my-container
    env:
    - name: google_application_credentials
      value: /etc/gcp/sa_credentials.json



with that, any official gcp clients (ex. the gcp python client, gcp java client, gcloud cli, etc. should respect the google_application_credentials env var and, when making api requests, automatically use the credentials of the my-data service account that you created and mounted the credentials .json file for.
"
63615417,kubernetes not allowing to delete a deployment - the server could not find the requested resource,"i get  the server could not find the requested resource error when i try to delete a deployment, event when it is listed.
d:\cmd
λ kubectl -n gdpr-tr get all
name                                              ready     status             restarts   age
pod/scv-turkey-iys-integration-6dd784689f-z6hqc   0/1       invalidimagename   0          1m
pod/scv-turkey-iys-integration-79c4d7ffcd-pwmq4   0/1       errimagepull       0          6m

name                                         desired   current   up-to-date   available   age
deployment.apps/scv-turkey-iys-integration   1         2         1            0           1h

name                                                    desired   current   ready     age
replicaset.apps/scv-turkey-iys-integration-6998c5b5f9   0         0         0         1h
replicaset.apps/scv-turkey-iys-integration-6dd784689f   1         1         0         34m
replicaset.apps/scv-turkey-iys-integration-79c4d7ffcd   1         1         0         25m

d:\cmd
λ kubectl -n gdpr-tr delete deployment.apps/scv-turkey-iys-integration
error from server (notfound): the server could not find the requested resource

",<kubernetes><kubectl>,63615474,3,"you can use any of below commands to delete the deployment but make sure kubectl client and kubernetes api server version matches
because in 1.16 version deployments is migrated to apps/v1 from extensions/v1beta1. so if you have a kubectl client which is of older version it will not be able to find the deployment in apps api version.
kubectl -n gdpr-tr delete deployment scv-turkey-iys-integration 
kubectl -n gdpr-tr delete deployments/scv-turkey-iys-integration

"
50584091,"helm export yaml files locally (just use templating engine, do not send to kubernetes)","i want to export already templated helm charts as yaml files. i can not use tiller on my kubernetes cluster at the moment, but still want to make use of helm charts. basically, i want helm to export the yaml that gets send to the kubernetes api with values that have been templated by helm. after that, i will upload the yaml files to my kubernetes cluster.

i tried to run .\helm.exe install --debug --dry-run incubator\kafka but i get the error error: unauthorized.  

note that i run helm on windows (version helm-v2.9.1-windows-amd64).
",<kubernetes><kubernetes-helm>,50584968,78,"we need logs to check the unauthorized issue.
but you can easily generate templates locally:
helm template mychart


render chart templates locally and display the output.
this does not require tiller. however, any values that would normally
be looked up or retrieved in-cluster will be faked locally.
additionally, none of the server-side testing of chart validity (e.g.
whether an api is supported) is done.

more info: https://helm.sh/docs/helm/helm_template/
"
68938781,kubectl hangs when running python with restart=never,"i am running the command:
kubectl run testbox -it --rm --restart=never --image=python:buster -- python3

which will launch a python session and then i input exit() to quit the session. but the session hangs forever there. if i do kubectl get po testbox i can see the pod is already completed.
then if i hit enter key the console will then output:
e0826 22:43:38.790348 1551782 v2.go:105] eof

i noticed that this will not happen if i set --restart=always. not sure if it is expected?
thanks!
",<python><kubernetes><kubectl>,68950728,1,"there is a similar issue posted on kubectl gtihub page (run commands don't return when using kubectl 1.22.x #1098), created 3 days ago. currently awaiting triage.
this is most probably a bug in 1.22 version of kubectl. if this issue causes you problems, i suggest downgrading to 1.21, as this bug does not occurs in older versions.
"
65948141,kubernetes memory limit : containers with and without memory limit on same pod,"i have two containers withing my pod (poda)
the first container (c1) has the following limits
limits:                                                                                                                                                                                                
  cpu:     2                                                                                                                                                                                           
  memory:  1gi                                                                                                                                                                                         requests:                                                                                        
  cpu:     100m                                                                                  
  memory:  128mi

the second container (c2) has no requests/limits specified
i have the following questions

from what i can see with a kubectl describe nodes, the memory/cpu request/limits for the poda are the same as the one from c1. is that correct?
what are the memory/cpu limits for c2? is it unbounded? limited to the limits of poda (e.g. limits of c1)?
follow up of #2 -&gt; what happens if c2 asks for more than 1gi of memory? will the container run out of memory, and cause the whole pod to crash? or will it be able to grab more memory, as long as the node has free memory?

i tried to google, but all the examples i saw where some where resource limits are set for both of the containers
",<kubernetes><memory><kubernetes-pod><docker-container>,65949334,8,"kubernetes places your pods in quality of service classes based on whether you have added requests and limits.
if all your containers in the pods have limits set, the pod falls under guaranteed class.
if at least one container in the pod has requests(or limits) set, the pod comes under burstable class.
if there are no requests or limits set for all container, the pods comes under best effort class.
in your example, your pod falls under burstable class because c2 does not have limits set.

these requests and limits are used in two contexts - scheduling and resource exhaustion.
scheduling
during scheduling, requests are considered to select node based on available resources. limits can be over-comitted and are not considered for scheduling`decisions.
resource exhaustion
there are two resources on which you can specify the requests and limits natively  - cpu and memory
cpu is a compressible resource i.e., kernel can throttle cpu usage of a process if required by allocating less cpu time. so a process is allowed to use as much cpu as it wants if other processes are idle. if another process needs the cpu, os can just throttle the cpu time for the process using more cpu. the unused cpu time will be split in the ratio of their requests. if you don't want this behaviour of unlimited cpu usage i.e., you want your container to not cross certain threshold, you can set the limit.
memory is not a compressible resource. once allocated to a process, kernel cannot regain the memory. so if a limit is set, a process gets oom killed if it tries to use more than the limit. if no limit is set, process can allocate as much as it wants but if there is a memory exhaustion, the only way to regain some free memory is to kill a process. this is where the qos class come into picture. a besteffort class container would be the first in line to get oom killed. next burstable class containers would be killed before any guaranteed class container gets killed. in situations where the containers are of same qos class, the container using higher percentage of memory compared to its request would be oom killed.


from what i can see with a kubectl describe nodes, the memory/cpu request/limits for the poda are the same as the one from c1. is that correct?

yes

what are the memory/cpu limits for c2? is it unbounded? limited to the limits of poda (e.g. limits of c1)?

cpu as a compressible resource is unbounded for all containers(or upto the limit if the limit is specified). c2 would get throttled when the other containers with requests set needs more cpu time.

follow up of #2 -&gt; what happens if c2 asks for more than 1gi of memory? will the container run out of memory, and cause the whole pod to crash? or will it be able to grab more memory, as long as the node has free memory?

it can grab as much memory it wants. but it would be the first to get oom killed if the nodes has no more free memory to allocate to other processes.
"
56231176,kubernetes client-go: convert labelselector to label string,"in the kubernetes client-go api (or another library that uses it), is there a utility function to convert a k8s.io/apimachinery/pkg/apis/meta/v1/labelselector to a string to fill the field labelselector in k8s.io/apimachinery/pkg/apis/meta/v1/listoptions?

i digged through the code of client-go but i can't find a function like that.

the labelselector.marshall() nor labelselector.string() give me that (unsurprisingly, because that's not their purpose, but i tried it anyway).

background

i have spec descriptions like k8s.io/api/extensions/v1beta1/deployment, and want to use it's set of selector labels (i.e. the selector field) to query it's pods using 

options := metav1.listoptions{
    labelselector: &lt;stringified labels&gt;,
}

podlist, err := clientset.corev1().pods(&lt;namespace&gt;).list(options)

",<go><kubernetes><kubernetes-go-client>,56232153,12,"you can use labelselectorasmap(labelselector) function to convert the labelselector into map[string]string map. 

then, use selectorfromset function of package k8s.io/apimachinery/pkg/labels to convert map to selector/strings.

pseudo code:

import (
    ""k8s.io/apimachinery/pkg/labels""
    metav1 ""k8s.io/apimachinery/pkg/apis/meta/v1""
)

func listpod(labelselector metav1.labelselector) {

    labelmap := metav1.labelselectorasmap(labelselector)

    options := metav1.listoptions{
        labelselector: labels.selectorfromset(labelmap).string(),
    }

    podlist, err := clientset.corev1().pods(""&lt;namespace&gt;"").list(options)

}

"
71446704,how to check if a namespace is active,"i'm using the following command to check if the namespace is active
kubectl wait --for=condition=items.status.phase=active namespace/mynamespace --timeout=2s

this always returns &quot;error: timed out waiting for the condition on namespaces/mynamespace&quot; although the namespace is active.
is there a correct way to wait for the namespace to be active?  this script is part of a job to check the namespace is active after a aks cluster restart.
",<kubernetes><kubectl>,71446787,2,"to date status is not a recognized condition. try:
while ! [ &quot;$(kubectl get ns &lt;change to your namespace&gt; -o jsonpath='{.status.phase}')&quot; == &quot;active&quot; ]; do echo 'waiting for namespace to come online. ctrl-c to exit.'; sleep 1; done
"
45915402,restricted kubernetes dashboard?,"is it possible to have a restricted kubernetes dashboard? the idea is to have a pod running kubectl proxy in the cluster (protected with basic http authentication) to get a quick overview of the status:


log output of the pods
running services and pods
current cpu/memory usage


however, i do not want users to be able to do ""privileged"" actions, like creating new pods, deleting pods or accessing secrets.

is there some option to start the dashboard with a specified user or with restricted permissions?
",<kubernetes><dashboard><kubernetes-security>,45930235,2,"it should be possible in kubernetes with rbac enabled.
you do not need to run a pod with kubectl proxy.
i'm not sure whether it is possible to have 2 different sets of permissions for the same pod, but worst case you have to run 2 dashboards.

basically, what you need to do is:


deploy dashboard in your cluster with read-only permissions in rbac
expose your running dashboard service
add ingress with basic http auth

"
66334225,kubectl reports namespace value required in manifest file,"what is the issue with my manifest file?
cat manifests/node-exporter-clusterrolebinding.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: node-exporter
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: node-exporter
subjects:
- kind: serviceaccount
  name: node-exporter

cat manifests/kube-state-metrics-clusterrolebinding.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrolebinding
metadata:
  name: kube-state-metrics
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: kube-state-metrics
subjects:
- kind: serviceaccount
  name: kube-state-metrics

if i apply these manifest with namespace i get an error as like below:

kubectl -f manifests/kube-state-metrics-clusterrolebinding.yaml -n test-monitoring

the clusterrolebinding &quot;node-exporter&quot; is invalid: subjects[0].namespace: required value

kubectl apply -f manifests/kube-state-metrics-clusterrolebinding.yaml -n test-monitoring

the clusterrolebinding &quot;kube-state-metrics&quot; is invalid: subjects[0].namespace: required value

any issue with manifests files?
",<kubernetes><kubectl>,66334262,3,"as a serviceaccount is a namespaced object, you need to explicitly add the namespace of the serviceaccount as:
subjects:
- kind: serviceaccount
  name: kube-state-metrics
  namespace: &lt;namespace-of-kube-state-metrics-serviceaccount&gt;

"
72724981,print/return python app docker image output in aws eks without using flask,"here, i have a python file with the name main.py that i want to execute.
the main.py file contains:
import time
import sys
def hello():
    for i in range(10):
         print(“\n”*4, “hello from aman!”, “\n”*4)
         time.sleep(2)
sys.exit(0)
if __name__ == “__main__”:
     hello()

and i have created a docker image with name docker file
from python:3.7
run mkdir /app
workdir /app
add . /app/
run pip install -r requirements.txt
cmd [“python”, “/app/main.py”]

i want to know that is there any way to run the python-app image on aws eks cluster in pods and get the output “hello from aman!” (whatever this code prints ) back to my system / print it in console .
since i am not using flask i cannot see the application on web browser so this app will run  in pods ,but i am not able to figure out how to get the output back to the terminal /ssh or in form of some file  .
please help me in finding a way to get the output of app running back without using any web framework like flask /node etc .
",<python><docker><kubernetes><amazon-eks>,72725306,2,"you can use the command
kubectl logs &lt;pod name&gt;

it show you the output.
if pod running on an eks you can use different ways to get the logs, write to file, push logs to aws cloud watch other external logging systems like elk, using kubectl check logs.
k8s by default store container logs stdin and stdout
"
61939499,timeout when creating ingress resource on gke private cluster,"created a gke cluster, setup cloud-nat for internet connectivity. then i deployed the kubernetes ingress-nginx kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/cloud/deploy.yaml.

everything is fine till here but when i try to deploy the ingress resource i get this  error from server (timeout): error when creating ""manifests/backend/service/be-nginx-ingress-serivce.yaml"": timeout: request did not complete within requested timeout 30s.

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: ingress-resource
  namespace: sap
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  tls:
    - hosts:
      - mywebname.com
      secretname: ingress-tls
  rules:
    - host: mywebname.com
      http:
        paths:
        - path: /
          backend:
            servicename: app
            serviceport: 5000
        - path: /v1
          backend:
            servicename: web
            serviceport: 8081


my manifest was running fine on public gke but today i switched it to private and i faced this issue, this is my first time with vpc, any help or guidance would be appreciated, thanks
",<nginx><kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-ingress>,61948453,8,"i pretty sure it's firewall things. did your follow the document?

https://kubernetes.github.io/ingress-nginx/deploy/#gce-gke


  for private clusters, you will need to either add an additional firewall rule that allows master nodes access port 8443/tcp on worker nodes, or change the existing rule that allows access to ports 80/tcp, 443/tcp and 10254/tcp to also allow access to port 8443/tcp.


https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#add_firewall_rules

gcloud compute firewall-rules create firewall-rule-name \
    --action allow \
    --direction ingress \
    --source-ranges master-cidr-block \
    --rules protocol:port \
    --target-tags target

"
61528135,"when using a nginx kubernetes routing loadbalancer with path redirects, why can i not access my service correctly?","i am using aks with helm v2.2 to try deploying a chart that utilizes an nginx loadbalancer pod to control all ingress into my services via a single ip address. this is very much in the experimental phase but i have proven that when i use the following helm ingress configuration for my .net core webapi service:

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - host:
      paths:
        - /


that i can indeed then visit my exposed api and see the swagger ui at

http://[my external ip]/index.html 


what i then want to do is place several services behind the same loadbalancer (as you are intended to) so my expectations were that i could then change the above service configuration to something like this:

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - host:
      paths:
        - /servicea


which should then mean i can access the same service via the now updated url:

http://[my external ip]/servicea/index.html


is this what i should be expecting to work? do i need to use any sort of re-write system as so far i get errors back from this url saying that it cannot find certain missing resources. any attempts at using the re-write annotation have not resulted in helping me here either. could someone help me out and point out what i may be doing wrong? with the new url path i end up with the following types of errors on what appears to be the files that the index.html page is trying to load suggesting it is half working but needs some re-writing or something?

failed to load resource: the server responded with a status of 404 ()


as a result of the helm chart template engine the following ingress yaml file is created:

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: myrelease-release-manager
  labels:
    app.kubernetes.io/name: release-manager
    helm.sh/chart: release-manager-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: ""1.0""
    app.kubernetes.io/managed-by: tiller
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/force-ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/rewrite-target: /servicea
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""

spec:
  rules:
    - host:
      http:
        paths:
          - path: /servicea
            backend:
              servicename: myrelease-release-manager
              serviceport: 80


as a result of this ingress file i want to visit this service when i go to my external ip address with the path /servicea/index.html.
",<kubernetes><kubernetes-helm><nginx-ingress><azure-aks>,61603608,2,"close, you need to update the rewrite target to /$2

nginx.ingress.kubernetes.io/rewrite-target: /$2


rewrites

/serviceb/foo -> /foo 

/servicea/foo -> /foo 

but each one will be directed to the services for that path 

apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: myrelease-release-manager
  labels:
    app.kubernetes.io/name: release-manager
    helm.sh/chart: release-manager-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: ""1.0""
    app.kubernetes.io/managed-by: tiller
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/force-ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
    nginx.ingress.kubernetes.io/rewrite-target: /$2
 spec:
   rules:
   - http:
       paths:
       - backend:
           servicename: serviceb
           serviceport: 80
         path: /serviceb(/|$)(.*)
       - backend:
           servicename: servicea
           serviceport: 80
         path: /servicea(/|$)(.*)

"
67570303,kubernetes - ingress - caught by a more general rule,"i'm trying to set up an ingress rule for a service (kibana) running in my microk8s cluster but i'm having some problems.
the first rule set up is
name:             web-ingress
namespace:        default
address:          127.0.0.1
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  k8s-ingress-tls terminates web10
rules:
  host        path  backends
  ----        ----  --------
  *
              /   web-service:8080 (10.1.72.26:8080,10.1.72.27:8080)
annotations:  nginx.ingress.kubernetes.io/rewrite-target: /
              nginx.ingress.kubernetes.io/ssl-redirect: false
events:       &lt;none&gt;

i'm trying to set kibana service to get served on path /kibana
name:             kibana
namespace:        default
address:          127.0.0.1
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
tls:
  k8s-ingress-tls terminates web10
rules:
  host        path  backends
  ----        ----  --------
  *
              /kibana(/|$)(.*)   kibana:5601 (10.1.72.39:5601)
annotations:  nginx.ingress.kubernetes.io/ssl-redirect: false
events:
  type    reason  age   from                      message
  ----    ------  ----  ----                      -------
  normal  create  17m   nginx-ingress-controller  ingress default/kibana
  normal  update  17m   nginx-ingress-controller  ingress default/kibana

my problem is that first thing kibana does is returns a 302 redirect to host/login?next=%2f which gets resolved by the first ingress rule because now i've lost my /kibana path.
i tried adding nginx.ingress.kubernetes.io/rewrite-target: /kibana/$2 but redirect then just looks like host/login?next=%2fkibana%2f which is not what i want at all.
if i delete the first rule, i just get 404 once kibana does a redirect to host/login?next=%2f
",<kubernetes><kubernetes-ingress><nginx-ingress><microk8s>,67571067,2,"add the following annotation to the kibana ingress so that nginx-ingress interprets the /kibana(/|$)(.*) path using regex:
 nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;

additional detail:
to let kibana know that it runs on /kibana path, add the following env variable to the kibana pod/deployment:
        - name: server_basepath
          value: /kibana

"
52279187,google container cluster as config,"i am trying to use the kubernetes go-client with cloud.google.com/go/container. i create the cluster using the google cloud go container package, then i want to deploy on that cluster using go-client. the out of cluster example given by the go-client uses the kube config file to get the credentials for the cluster. but since i just created this cluster within my application i don’t have that config file.

how can i setup a “k8s.io/client-go/rest” config with a ""google.golang.org/genproto/googleapis/container/v1"" cluster? what are the required fields? the code below is what i currently have (without showing the actual ca certificate).

func getconfig(cluster *containerproto.cluster) *rest.config {
    return &amp;rest.config{
        host:     ""https://"" + cluster.getendpoint(),
        tlsclientconfig: rest.tlsclientconfig{
            insecure: false,
            cadata: []byte(`-----begin certificate-----
                ...
                -----end certificate-----`),
        },
    }


it results in this error: x509: certificate signed by unknown authority. so there is obviously something missing.
any other approach is more than welcome! thanks in advance
",<go><kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-go-client>,52394693,5,"the clientcertificate, clientkey and clustercacertificate need to be decoded as described here

func createk8sclientfromcluster(cluster *gkev1.cluster) {
    decodedclientcertificate, err := base64.stdencoding.decodestring(cluster.masterauth.clientcertificate)
    if err != nil {
        fmt.println(""decode client certificate error:"", err)
        return
    }
    decodedclientkey, err := base64.stdencoding.decodestring(cluster.masterauth.clientkey)
    if err != nil {
        fmt.println(""decode client key error:"", err)
        return
    }
    decodedclustercacertificate, err := base64.stdencoding.decodestring(cluster.masterauth.clustercacertificate)
    if err != nil {
        fmt.println(""decode cluster ca certificate error:"", err)
        return
    }

    config := &amp;rest.config{
        username: cluster.masterauth.username,
        password: cluster.masterauth.password,
        host:     ""https://"" + cluster.endpoint,
        tlsclientconfig: rest.tlsclientconfig{
            insecure: false,
            certdata: decodedclientcertificate,
            keydata:  decodedclientkey,
            cadata:   decodedclustercacertificate,
        },
    }

    clientset, err := kubernetes.newforconfig(config)
    if err != nil {
        fmt.printf(""failed to get k8s client set from config: %s\n"", err)
        return
    }
}

"
66669589,nginx ingress rewrite-target problem with redirection,"i have a kibana dashboard that i currently access through the root of my host : https://my.host.com/. i want to change it so i can access it through the path https://my.host.com/kibana/. for this, i used the rewrite-target annotation as provided in the main documentation:
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: kibana-ing
  annotations:
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      kubernetes.io/ingress.class: kibana-ingress-class
      nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;
spec:
  rules:
    - host: my.host.com
      http:
        paths:
          - path: /kibana(/|$)(.*)
            backend:
              servicename: kibana-svc
              serviceport: 5601

i think this works to some extent because when hitting https://my.host.com/kibana/, i get redirected to the login page. but the login page is returned to my browser without the kibana prefix : https://my.host.com/app/login and i get a 404.
how can i fix this?
edit:
this is currently what is happening when i hit https://my.host.com/kibana/ :

this sends back a http 302 with a redirection to app/login as you can see in the location header. but when my browser asks back nginx to fetch for this app/login, it rightfully gives a 404 since this path is unkown to it.
is there a way (through an ingress annotation maybe) to append the '/kibana' prefix to all the location headers that are being returned?
edit2:
i managed to append the /kibana/ part in the location header by adding these 2 annotations:
nginx.ingress.kubernetes.io/proxy-redirect-from: &quot;/&quot;
nginx.ingress.kubernetes.io/proxy-redirect-to: &quot;/kibana/&quot;

this makes the redirection point to kibana/app/login, resulting in a 200 status. however more objects are being loaded by the page like a bootsrap.js and their location are hardcoded within the html page being sent back like this:
&lt;/script&gt;&lt;script src=&quot;/bootstrap.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;

obviously this hits back with another 404 error on my browser end... i think i will have to deal with this on the application end instead.
",<kubernetes><kubernetes-ingress><nginx-ingress>,66687024,4,"i managed to fix this at the application level. in my kibana.yml config file, i had to tell kibana that it was running behind a reverse proxy. so i set server.basepath: /kibana.
note that the configuration i made above for the ingress is still needed, as the application is still reacheable at the root of server but only the responses urls will include the /kibana/ prefix.
"
76492480,hashicorp vault: multiple applications and multiple service accounts - prevent another app from using different svc account,"i have a vault deployment in my cluster that i use to store secrets. additionally, i have created roles, policies, and a serviceaccount. my applications will retrieve secrets from vault using this service account. however, i am concerned that another application could use the service account meant for a different application. what measures can i take to prevent this from happening?
say, i have assigned different policies to application a and application b, so i need a way to ensure that application b cannot use the serviceaccount meant for application a.
",<kubernetes><hashicorp-vault><kubernetes-security>,76511784,6,"using the kubernetes auth method, this is how it works. you don't need to do anything else. assuming you are using the default behavior of kubernetes where it creates a service account per app, you're good.
when an app logins to vault using a serviceaccount, it provides its token and authenticates for a specific role, e.g
curl \
    --request post \
    --data '{&quot;jwt&quot;: &quot;&lt;your service account jwt&gt;&quot;, &quot;role&quot;: &quot;demo&quot;}' \
    http://127.0.0.1:8200/v1/auth/kubernetes/login

the sa token is available only to your service. kubernetes creates a sa for each app. it means appa doesn't have the access for appb serviceaccount token (unless you explicitly specify that).
the way to integrate that with vault is to config a named role with a bounded service account and namespace
vault write auth/kubernetes/role/demo \
    bound_service_account_names=myapp \
    bound_service_account_namespaces=default \
    policies=default \
    ttl=1h

the above role can be used to authenticate only for myapp from the default namespace. no other app can login using this role.
to address your question, you would need a different vault role for each app, with different bounded service account and namespace.
check out vault documentation on kubernetes auth method for full example
"
52932146,kubectl does not work with multiple clusters config,"i have ~/.kube/config with following content:

apiversion: v1
clusters:
- cluster:
    certificate-authority-data: redacted
    server: https://redacted.yl4.us-east-1.eks.amazonaws.com
  name: kubernetes-jenkins
- cluster:
    certificate-authority-data: redacted
    server: https://redacted.sk1.us-east-1.eks.amazonaws.com
  name: kuberntes-dev
contexts:
- context:
    cluster: kubernetes-dev
    user: aws-dev
  name: aws-dev
- context:
    cluster: kubernetes-jenkins
    user: aws-jenkins
  name: aws-jenkins
current-context: aws-dev
kind: config
preferences: {}
users:
- name: aws-dev
  user:
    exec:
      apiversion: client.authentication.k8s.io/v1alpha1
      args:
      - token
      - -i
      - eks_dev_cluster
      command: heptio-authenticator-aws
      env: null
- name: aws-jenkins
  user:
     exec:
       apiversion: client.authentication.k8s.io/v1alpha1
       args:
       - token
       - -i
       - eks_jenkins_cluster
       command: heptio-authenticator-aws
       env: null


but when i'm trying to kubectl cluster-info i get:

kubernetes master is running at http://localhost:8080

to further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
the connection to the server localhost:8080 was refused - did you specify the right host or port?


as far as i understand something wrong in my kubeconfig, but i don't see what exactly. 
also i tried to find any related issues, but with no luck.

could you suggest me something?

thanks.
",<kubernetes><kubectl>,52939243,3,"your cluster name has a typo in it (name: kuberntes-dev) compared with the reference in the context (cluster: kubernetes-dev)
"
73064270,how to install prometheus exporter plugin to opensearch in helm managed environment,"i want to collect metrics from my  opensearch
i've found this plugin https://github.com/aiven/prometheus-exporter-plugin-for-opensearch
but i have no idea how to connect it to my opensearch:
my current definition looks like this:
chart.yaml:
  - name: opensearch
    version: 1.8.0
    repository: https://opensearch-project.github.io/helm-charts/

values.yaml:
opensearch:
  plugins:
    enabled: true
    installlist:
      - what should i write here ?

  addindexedat: true
  clustername: ...
  masterservice:...
  resources:
    requests:
      cpu: 500m
      memory: 1000mi
    limits:
      cpu: 3000m
      memory: 2000mi
  config:
    opensearch.yml: ...

could you please help me how to connetc plugin to opensearch ?
",<kubernetes><plugins><kubernetes-helm><metrics><opensearch>,73064623,1,"- what should i write here ?
try specify the plugin download url:
...
installlist:
- &quot;https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.1.0.0/prometheus-exporter-2.1.0.0.zip&quot;
...

the url you passed gets to here for installation.
"
68973803,is there a kubernetes role definition to allow the command `kubectl rollout restart deploy <deployment>`?,"i want a deployment in kubernetes to have the permission to restart itself, from within the cluster.
i know i can create a serviceaccount and bind it to the pod, but i'm missing the name of the most specific permission (i.e. not just allowing '*') to allow for the command
kubectl rollout restart deploy &lt;deployment&gt;

here's what i have, and ??? is what i'm missing
apiversion: v1
kind: serviceaccount
metadata:
  name: restart-sa
---
kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: restarter
rules:
  - apigroups: [&quot;apps&quot;]
    resources: [&quot;deployments&quot;]
    verbs: [&quot;list&quot;, &quot;???&quot;]
---
kind: rolebinding
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: testrolebinding
  namespace: default
subjects:
  - kind: serviceaccount
    name: restart-sa
    namespace: default
roleref:
  kind: role
  name: restarter
  apigroup: rbac.authorization.k8s.io
---
apiversion: v1
kind: pod
metadata:
  name: example
spec:
  containers:
  - image: nginx
    name: nginx
  serviceaccountname: restart-sa

",<kubernetes><google-kubernetes-engine><rbac>,68980720,14,"i believe the following is the minimum permissions required to restart a deployment:
rules:
 - apigroups: [&quot;apps&quot;, &quot;extensions&quot;]
   resources: [&quot;deployments&quot;]
   resourcenames: [$deployment]
   verbs: [&quot;get&quot;, &quot;patch&quot;]

"
50022728,deploy elastic search on kubernetes,"i have pulled a es image and run that in a host.
 it works fine.

 docker pull elasticsearch
 docker run -t  -p 9200:9200 -p 9300:9300 --rm elasticsearch


i need to have the same es image in the kubernetes.

i have created a kubernetes cluster as below:

gcloud container clusters create elasticsearch --num-nodes=1


i have written a manifest file(elasticsearch.yaml) as below:

apiversion: v1
kind: replicationcontroller
metadata:
  name: elasticsearch
spec:
  replicas: 2
  selector:
    app: elasticsearch
  template:
    metadata:
      name: elasticsearch
      labels:
        app: elasticsearch
    spec:
       containers:
         - name: elasticsearch
           image: elasticsearch
           ports:
             - containerport: 9200
             - containerport: 9300


created a rc as below:

kubectl create -f elasticsearch.yaml

kubectl get pods


it shows imagebackoff error

kubectl get rc


it shows as not ready

how to deploy this es image in kubernetes with 2 pods in one server cluster
",<kubernetes><google-cloud-platform><kubectl>,50031768,2,"well, the official image for es 

docker pull docker.elastic.co/elasticsearch/elasticsearch:6.2.4


as the documentation is mentioning.
    https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html

if you use just elasticsearch, kubernetes will assume that you're using a local registry and i guess you don't want to do that.

also if you run 

kubectl describe pods &lt;pod_name&gt;


you can easily find if there's an issue pulling the image or not.
if there're no issues with pulling the image, them most probably there's an issue inside the pods. my suggestion would be, use the log command to check what's going on.
"
68297446,introducing delay for running helm test suite over installed release,"i'm using helm charts to deploy several rest services with into k8s with spring boot inside deployed container.
however, to be able to do final stage testing i need to introduce some sort of smart liveness probe - i.e. that the target application is actually running properly inside given container.
this can be easily justified by successful return code of simple curl command, however, here's the trick - command needs to be executed with some delay after particular release deployment to give application time to bootstrap.
here's what i've figured for a test suite:
apiversion: v1
kind: pod
metadata:
  name: &quot;{{ include &quot;chart.fullname&quot; . }}-test&quot;
  labels:
  {{- include &quot;chart.fullname&quot; . | nindent 4 }}
  annotations:
    &quot;helm.sh/hook&quot;: test-success
spec:
  containers:
    - name: test-curl
      image: curl
      command: ['curl']
      args: [' -x post -i -h &quot;accept: application/json&quot; -h &quot;content-type:application/json&quot; -d ''{&quot;foo&quot;:[&quot;bar&quot;]}'' {{ include &quot;chart.fullname&quot; . }}:{{ .values.service.port }}']
  restartpolicy: never

the key problem is that this test will be executed when service is not really started yet and thus fail anyway.
is there some mechanism or workaround to introduce delay of execution for this test?
setting some sleep step in separate test container comes to mind but i'm not sure if this will work properly for this case
",<kubernetes><kubernetes-helm>,68397273,4,"thanks to @emruz hossain, i've figured the solution out:
apiversion: batch/v1
kind: job
metadata:
  name: &quot;{{ .release.name }}-test&quot;
  labels:
    app: {{ .release.name }}
    release: {{ .release.name }}
  annotations:
    &quot;helm.sh/hook&quot;: test-success
spec:
  ttlsecondsafterfinished: 0
  template:
    spec:
      containers:
        - name: test-curl
          image: target-image:1.2.3
          imagepullpolicy: &quot;ifnotpresent&quot;
          command:
            - /bin/bash
            - -ec
            - |
              curl --connect-timeout 5 --max-time 10 --retry 5 --retry-delay 5 --retry-max-time 30 --retry-all-errors http://{{ .release.name }}:{{ .values.service.port }}/v1/rest -x post -h &quot;content-type: application/json&quot; -d &quot;{\&quot;foo\&quot;:[\&quot;bar\&quot;]}&quot;
      restartpolicy: never

requires k8s api server 1.20+ (due to this) and curl 7.71+ (due to this)
"
69381242,how to expose nginx in minikube to outside,"i have deployed nginx in minikube in aws ec2 instance using the below commands:
kubectl create deployment --image=nginx nginx-app
kubectl expose deployment nginx-app --port=80 --name=nginx-http --type=nodeport

it is available on nodeport: 31568
i have added this port in security group and able to access it on browser in another laptop with http://ec2-publicip:31568
i have many microservices which are to be exposed to outside.
is there any way to deploy an api gateway (nginx or ingress) and expose on a port and should be able to access other microservices like
http://ec2-publicip:31568/helloworld          
http://ec2-publicip:31568/mainpage           
http://ec2-publicip:31568/editorspage  
       
etc

i have tried adding metallb, accordingly, an ip is allocated to ingress (load balancer type). i was able to access all the microservices specified in ingress.yaml only inside the ec2 instance.
this should be accessible from the outside. if yes, then how to configure it?
any help is appreciated.
",<nginx><kubernetes><kubernetes-ingress><minikube><nginx-ingress>,69381542,1,"you should be able to do so since you are using nginx.
the configuration should like something like:
annotation comes to help
the &quot;trick&quot; is to set annotations to support regexp &amp; rewrite-target with:
  annotations:
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    #
    # the value can be set to  `/` or `$1` or `$2` and so on
    nginx.ingress.kubernetes.io/rewrite-target: &quot;/$1&quot;

this is the &quot;important&quot; annotation - the rewrite one
# without a rewrite any request will return 404
nginx.ingress.kubernetes.io/rewrite-target: &quot;/$1&quot;


apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: ingress
  annotations:
    #
    # this is the expected line
    # 
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: &quot;/$1&quot;
spec:
  rules:
  - host: test.com # &lt;- set your host
    http:
      paths:
        #
        # list of desired paths
        # 
      - path: /path1
        backend:
          servicename: nginx-http
          serviceport: 80
      - path: /path2/[a-z0-9]{3}
        backend:
          servicename: nginx-http
          serviceport: 80

"
66419906,"how to create a ""certificatesigningrequest"" with apiversion ""certificates.k8s.io/v1"" for a webhook","i have a wehook running in my cluster.
i created a certificate and signed it successfully.
certificate configuration:
cat &gt; csr.conf &lt;&lt;eof
[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicconstraints = ca:false
keyusage = nonrepudiation, digitalsignature, keyencipherment
extendedkeyusage = serverauth
subjectaltname = @alt_names
[alt_names]
dns.1 = s-controller.ns-controller
dns.2 = s-controller.ns-controller.svc
eof

i them create the certificate as following:
openssl genrsa -out server-key.pem 2048
openssl req -new -key server-key.pem -subj &quot;/cn=s-controller.ns-controller.svc&quot; -out server.csr -config csr.conf


certificate signing request (v1beta1)
cat &lt;&lt;eof | kubectl create -f -
apiversion: certificates.k8s.io/v1beta1
kind: certificatesigningrequest
metadata:
    name: csr-controller
spec:
    groups:
    - system:authenticated
    request: $(cat server.csr | base64 | tr -d '\n')
    usages:
    - digital signature
    - key encipherment
    - server auth
eof

this worked just fine!
since i updated my kubernetes version, i get the following warning: warning: certificates.k8s.io/v1beta1 certificatesigningrequest is deprecated in v1.19+, unavailable in v1.22+; use certificates.k8s.io/v1, i updated the certificatesigningrequest so now it is as following:
cat &lt;&lt;eof | kubectl create -f -
apiversion: certificates.k8s.io/v1
kind: certificatesigningrequest
metadata:
    name: csr-controller
spec:
    groups:
    - system:authenticated
    request: $(cat server.csr | base64 | tr -d '\n')
    signername: kubernetes.io/kube-apiserver-client
    usages:
    - digital signature
    - key encipherment
    - client auth
eof

and now the api server fails to connect to my webhook: post &quot;https://s-controller.ns-controller.svc:443/mutate?timeout=30s&quot;: x509: certificate specifies an incompatible key usage
i tried updateding the certificate configuration to extendedkeyusage = clientauth but it didnt help.
any idea what is the correct signername and configuration to the certificates.k8s.io/v1 apiversion
",<kubernetes><kubernetes-apiserver>,66580151,1,"i haven't managed to create a certificatesigningrequest as i wished, however i bypassed the issue by create my own ca as following:
first, i edited my certificate configurations file so it will include a commonname and currect extendedkeyusage :
cat &gt; csr.conf &lt;&lt;eof
[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
prompt = no
[req_distinguished_name]
cn = s-controller.ns-controller.svc
[ v3_req ]
basicconstraints = ca:false
keyusage = nonrepudiation, digitalsignature, keyencipherment
extendedkeyusage = clientauth, serverauth
subjectaltname = @alt_names
[alt_names]
dns.1 = s-controller.ns-controller
dns.2 = s-controller.ns-controller.svc
eof

generate ca certificate (notice the -days 365)
openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -days 365 -out ca.crt -subj &quot;/cn=admission_ca&quot;

generate tls key and certificdate
openssl genrsa -out server.key 2048
openssl req -new -key server.key -out server.csr -config csr.conf
openssl x509 -req -in server.csr -ca ca.crt -cakey ca.key -cacreateserial -out server.crt -days 365 -extensions v3_req -extfile csr.conf

create a kubernetes tls secret for the webhook
kubectl create secret tls webhook-tls --cert=server.crt --key=server.key

set the ca_bundle
export ca_bundle=$(cat ca.crt | base64 | tr -d '\n')

remove all generated files
rm ca.crt 
rm ca.key 
rm server.key
rm server.csr
rm server.crt


in my webhhok, i have a volume volumemount:
volume:
volumes:
- name: tls-vol
    secret:
      secretname: webhook-tls

volumemount:
volumemounts:
- name: tls-vol
  mountpath: /etc/webhook/certs
  readonly: true

and the comantainer args
args:
- -tlscertfile=/etc/webhook/certs/tls.crt
- -tlskeyfile=/etc/webhook/certs/tls.key

"
62889225,how to install a particular version of helm?,"i am installing helm through a script which uses these commands to install the latest version -
curl -fssl -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3.2.0
chmod 700 get_helm.sh
./get_helm.sh

however , i don't want it to install the latest versions always. how can i install the version v3.2.4 always?
",<shell><kubernetes><command><version><kubernetes-helm>,62896709,15,"you can find all the versions of helm binaries on helm releases page
if you want to install v3.2.4
$ wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz
$ tar -zxvf helm-v3.2.4-linux-amd64.tar.gz
$ sudo mv linux-amd64/helm /usr/local/bin/helm
$ helm version
version.buildinfo{version:&quot;v3.2.4&quot;, gitcommit:&quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688&quot;, gittreestate:&quot;clean&quot;, goversion:&quot;go1.13.12&quot;}

documentation
"
62923487,"(nginx + skaffold) - running micro-services system on local machine produces always 404, even though compiles properly?","i'm running a multiservices system on my local machine and when i type the domain in chrome i always get :
404 not found
nginx/1.19.1

consider the client:
dockerfile.dev :
from node:13.14.0
workdir /app
copy package.json .
run npm i
copy . .
cmd [&quot;npm&quot;,&quot;run&quot;,&quot;start&quot;]

client-deployment.yaml :
apiversion: apps/v1
kind: deployment
metadata:
  name: client-depl
spec:
  replicas: 1
  selector:
    matchlabels:
      app: multi-client
  template:
    metadata:
      labels:
        app: multi-client
    spec:
      containers:
        - name: multi-client
          image: mydockerid/multi-client
                
---
apiversion: v1
kind: service
metadata:
  name: client-cluster-ip-service
spec:
  selector:
    app: multi-client
  ports:
    - name: multi-client
      protocol: tcp
      port: 3000
      targetport: 3000

skaffold.yaml :
apiversion: skaffold/v2alpha3
kind: config
deploy:
  kubectl:
    manifests:
      - ./k8s/*
build:
  local:
    push: false
  artifacts:
    - image: mydockerid/multi-client
      context: client
      docker:
        dockerfile: dockerfile.dev
      sync:
        manual:
          - src: 'src/**/*.js'
            dest: .


// ... more services , they work ok  

i've added in my hosts file the following entry:
# copyright (c) 1993-2009 microsoft corp.
#
# this is a sample hosts file used by microsoft tcp/ip for windows.
#
# this file contains the mappings of ip addresses to host names. each
# entry should be kept on an individual line. the ip address should
# be placed in the first column followed by the corresponding host name.
# the ip address and the host name should be separated by at least one
# space.
#
# additionally, comments (such as these) may be inserted on individual
# lines or following the machine name denoted by a '#' symbol.
#
# for example:
#
#      102.54.94.97     rhino.acme.com          # source server
#       38.25.63.10     x.acme.com              # x client host
# localhost name resolution is handled within dns itself.
#   127.0.0.1       localhost
#   ::1             localhost

127.0.0.1 fibonacci.dot

when i type fibonacci.dot in my chrome i get :

and here is the console output:
c:\development-t410\docker\fibonacci&gt;skaffold dev
[34mlisting files to watch...[0m

[34mstarting deploy...[0m
 - deployment.apps/client-depl configured
 - service/client-cluster-ip-service configured
 - persistentvolumeclaim/database-persistent-volume-claim configured
 - ingress.extensions/ingress-fibonacci-service configured
 - service/postgres-cluster-ip-service configured
 - deployment.apps/postgres-deployment configured
 - service/redis-cluster-ip-service configured
 - deployment.apps/redis-deployment configured
 - deployment.apps/server-deployment configured
 - service/server-cluster-ip-service configured
 - deployment.apps/worker-deployment configured
[34mwaiting for deployments to stabilize...[0m
 - deployment/client-depl:
 - deployment/postgres-deployment:
 - deployment/redis-deployment:
 - deployment/server-deployment:
 - deployment/worker-deployment:
 - deployment/server-deployment: waiting for rollout to finish: 1 out of 3 new replicas have been updated...
 - deployment/worker-deployment: waiting for rollout to finish: 0 out of 1 new replicas have been updated...
 - deployment/client-depl: waiting for rollout to finish: 1 old replicas are pending termination...
 - deployment/redis-deployment: waiting for rollout to finish: 1 old replicas are pending termination...
 - deployment/postgres-deployment: waiting for rollout to finish: 1 old replicas are pending termination...
 - deployment/worker-deployment: waiting for rollout to finish: 1 old replicas are pending termination...
 - deployment/client-depl is ready. [4/5 deployment(s) still pending]
 - deployment/server-deployment: waiting for rollout to finish: 2 out of 3 new replicas have been updated...
 - deployment/postgres-deployment is ready. [3/5 deployment(s) still pending]
 - deployment/worker-deployment is ready. [2/5 deployment(s) still pending]
 - deployment/redis-deployment is ready. [1/5 deployment(s) still pending]
 - deployment/server-deployment: waiting for rollout to finish: 2 old replicas are pending termination...
 - deployment/server-deployment: waiting for rollout to finish: 1 old replicas are pending termination...
 - deployment/server-deployment is ready.
[34mdeployments stabilized in 34.4563547s[0m
[33mwatching for changes...[0m

[client-depl-f646b85cd-bgmm5 multi-client] ℹ ｢wds｣: project is running at http://10.1.1.203/
[client-depl-f646b85cd-bgmm5 multi-client] ℹ ｢wds｣: webpack output is served from
[client-depl-f646b85cd-bgmm5 multi-client] ℹ ｢wds｣: content not from webpack is served from /app/public
[client-depl-f646b85cd-bgmm5 multi-client] ℹ ｢wds｣: 404s will fallback to /
[client-depl-f646b85cd-bgmm5 multi-client] starting the development server...
[client-depl-f646b85cd-bgmm5 multi-client]

how can we fix this? why am i getting 404?
",<docker><nginx><kubernetes><kubernetes-ingress><skaffold>,62925715,2,"based on the logs

 - ingress.extensions/ingress-fibonacci-service configured

it sounds like your application is served by an ingress so it's likely that it's going through a path that is not /. you can see what you have in the ingress.
you can check the configs of the ingress and logs of the ingress controller (depending on what you are using)
$ kubectl get ingress ingress-fibonacci-service -o=yaml
$ kubectl logs &lt;ingress-controller-pod&gt;

if you are using an nginx ingress controller. check the configs
$ kubectl exec -t &lt;ingress-pod&gt; cat nginx.conf

"
63054574,able to patch ingress when specifically provided json in -p arg but not when provided through a variable,"i'm trying to patch ingress when i specify json like below, i'm able to (all below commands have --dry-run enabled, i know):
kubectl patch ing ing-routing '--type=json'  '--patch=[{&quot;op&quot;: &quot;add&quot;,&quot;path&quot;: &quot;/spec/rules/0/http/paths/-&quot;,&quot;value&quot;: {&quot;path&quot;: &quot;/path/to/patch/service&quot;, &quot;backend&quot;: {&quot;servicename&quot;: &quot;patch-svc-cip&quot;,&quot;serviceport&quot;: 8443}}}]' --dry-run -o yaml -n namespace

but if i try to do it like:
value=&quot;$(&lt;/tmp/ingress-route-patch.json)&quot;
kubectl patch ing ing-routing '--type=json'  '--patch=$value' --dry-run -o yaml -n namespace

i get this error: error: json: cannot unmarshal string into go value of type jsonpatch.patch
i have also tried
ingressroute=$(cat /tmp/ingress-routing-patch.json)
kubectl patch ing ing-routing '--type=json'  '--patch=$ingressroute' --dry-run -o yaml -n namespace

&amp;
kubectl patch ing ing-routing '--type=json'  '--patch=$(cat /tmp/ingress-routing-patch.json)' --dry-run -o yaml -n namespace

&amp;
kubectl patch ing ing-routing --type='json'  -p='$(cat /tmp/ingress-routing-patch.json)' --dry-run -o yaml -n namespace

but same error came everytime. i need to patch it from a file since we need to add endpoints dynamically.
",<json><kubernetes><kubernetes-ingress><nginx-ingress>,63055049,1,"you should use &quot; in -p flag instead of '.
following works for me
kubectl patch ing ing-routine --type='json'  -p=&quot;$(cat /tmp/ingress-routing-patch.json)&quot; --dry-run -o yaml

"
66462924,promtail basic auth using kubernetes secret in helm values.yaml,"i am using the promtail helm chart to connect to a loki server running on a different stack. i have loki behind an nginx ingress secured with basic auth.
i can't find any documentation on this, and it's very possible it's just my admittedly limited understanding of helm.
i'm simply trying to use basic auth to connect to the loki instance while using a kubernetes secret instead of plaintext credentials in the helm values
this works perfect:
  snippets:
    extraclientconfigs: |
      basic_auth:
        username: myusername
        password: mypassword

i created a secret like this:
kubectl create secret generic loki-credentials -n monitoring --from-literal=password=&quot;mypassword&quot; --from-literal=username=&quot;myusername&quot;

and now i want to use that in the values.yaml file.
this is what i got so far:
extraenv:
  - name: loki_username
    valuefrom:
      secretkeyref:
        name: loki-credentials
        key: username
  - name: loki_password
    valuefrom:
      secretkeyref:
        name: loki-credentials
        key: password

extraargs:
  - -client.external-labels=stack=development
  - -config.expand-env

config:
  serverport: 3101
  lokiaddress: myurl
  snippets:
    extraclientconfigs: |
      basic_auth:
        username: ${loki_username}
        password: ${loki_password}

i just get a 401 response.
 chart version: 3.1.0
 promtail version: 2.1.0

edit
here is my ingress yaml:
controller:
  replicacount: 1

  config:
    force-ssl-redirect: &quot;true&quot;
    use-forwarded-headers: &quot;true&quot;

  service:
    targetports:
      http: http
      https: http
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-ssl-cert: &quot;arn:aws:acm:us-west-2:123456:certificate/123456&quot;
      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: &quot;http&quot;
      service.beta.kubernetes.io/aws-load-balancer-ssl-ports: &quot;https&quot;

    enablehttp: false
    enablehttps: true
    type: loadbalancer
    loadbalancersourceranges:
      - &quot;0.0.0.0/0&quot;

   ## name of the ingress class to route through this controller
  ingressclass: nginx-external

...and my loki values.yaml
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: &quot;nginx-external&quot;
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: loki-ingress-auth
    nginx.ingress.kubernetes.io/auth-realm: &quot;authentication required&quot;
  hosts:
    - host: loki.mydomain.com
      paths: 
        - &quot;/&quot;
  tls: []

config:
  auth_enabled: false
  ingester:
    chunk_idle_period: 3m
    chunk_block_size: 262144
    chunk_retain_period: 1m
    max_transfer_retries: 3
    lifecycler:
      ring:
        kvstore:
          store: inmemory
        replication_factor: 1
  
  schema_config:
    configs:
    - from: 2021-03-06
      store: boltdb-shipper
      object_store: aws
      schema: v11
      index:
        prefix: loki_index_
        period: 24h
        
  server:
    http_listen_port: 3100

  storage_config:
    aws:
      bucketnames: my-bucket-name
      region: us-west-2
      s3forcepathstyle: true

    boltdb_shipper:
      active_index_directory: /data/loki/boltdb-shipper-active
      cache_location: /data/loki/boltdb-shipper-cache
      shared_store: s3

  chunk_store_config:
    max_look_back_period: 0s
  
  table_manager:
    retention_deletes_enabled: false
    retention_period: 0s

  compactor:
    working_directory: /data/loki/boltdb-shipper-compactor
    shared_store: aws

replicas: 1

podannotations:
  iam.amazonaws.com/role: &quot;arn:aws:iam::123456:role/my-loki-role&quot;

resources:
  limits:
    cpu: 500m
    memory: 2g
  requests:
    cpu: 250m
    memory: 1g

# the values to set in the poddisruptionbudget spec
# if not set then a poddisruptionbudget will not be created
poddisruptionbudget:
  minavailable: 1

my logs from the nginx pod that loki is sitting behind:
2021/03/09 04:23:44 [error] 37#37: *925 user &quot;myusername&quot;: password mismatch, client: xxx.xx.xxx.xxx, server: loki.mydomain.com, request: &quot;post /loki/api/v1/push http/1.1&quot;, host: &quot;loki.mydomain.com&quot;
2021/03/09 04:23:44 [error] 37#37: *921 user &quot;myusername&quot;: password mismatch, client: xxx.xx.xxx.xxx, server: loki.mydomain.com, request: &quot;post /loki/api/v1/push http/1.1&quot;, host: &quot;loki.mydomain.com&quot;
xx.xxx.xxx.xx - myusername [09/mar/2021:04:23:44 +0000] &quot;post /loki/api/v1/push http/1.1&quot; 401 172 &quot;-&quot; &quot;promtail/2.1.0&quot; 326 0.000 [monitoring-loki-3100] [] - - - - 63294b16fe010a8c9ec1d4684f0472f5
xxx.xx.xxx.xxx: - myusername [09/mar/2021:04:23:44 +0000] &quot;post /loki/api/v1/push http/1.1&quot; 204 0 &quot;-&quot; &quot;promtail/2.1.0&quot; 2744 0.003 [monitoring-loki-3100] [] xxx.xx.xxx.xxx:3100 0 0.004 204 029e0a9d1ee6242cad8b9a6d2ee50940
2021/03/09 04:23:44 [error] 37#37: *925 user &quot;myusername&quot;: password mismatch, client: xx.xxx.xxx.xx, server: loki.mydomain.com, request: &quot;post /loki/api/v1/push http/1.1&quot;, host: &quot;loki.mydomain.com&quot;
xxx.xx.xxx.xxx - myusername [09/mar/2021:04:23:44 +0000] &quot;post /loki/api/v1/push http/1.1&quot; 401 172 &quot;-&quot; &quot;promtail/2.1.0&quot; 325 0.000 [monitoring-loki-3100] [] - - - - b75a2cfcf6c62b81953dd4fb26f1a844
xxx.xx.xxx.xxx - myusername [09/mar/2021:04:23:44 +0000] &quot;post /loki/api/v1/push http/1.1&quot; 204 0 &quot;-&quot; &quot;promtail/2.1.0&quot; 1513 0.014 [monitoring-loki-3100] [] xxx.xx.xxx.xxx:3100 0 0.016 204 0049965a49877cb5d336ac6ec869feb4
2021/03/09 04:23:45 [error] 36#36: *941 user &quot;myusername&quot;: password mismatch, client: xxx.xx.xxx.xxx, server: loki.mydomain.com, request: &quot;post /loki/api/v1/push http/1.1&quot;, host: &quot;loki.mydomain.com&quot;
xxx.xx.xxx.xxx - myusername [09/mar/2021:04:23:45 +0000] &quot;post /loki/api/v1/push http/1.1&quot; 401 172 &quot;-&quot; &quot;promtail/2.1.0&quot; 326 0.000 [monitoring-loki-3100] [] - - - - e5954bd055db5b3e9bd3227f57651847

",<kubernetes><logging><prometheus><kubernetes-helm>,66543018,1,"to give a bit of background to anyone new to loki, as stated in the documentation: loki does not come with any included authentication layer. operators are expected to run an authenticating reverse proxy in front of your services, such as nginx using basic auth or an oauth2 proxy.
this basically means that you'll have to place something in between the client(s) and loki to enforce e.g. basic authentication. in this case there's a ingress (nginx) acting as a reverse proxy with basic authentication.
to troubleshoot problems with authentication using nginx there's a number of things to check:

logs of the nginx ingress pod, check for authentication errors.
that the added kubernetes secret contains what you expect.
that you have configured the ingress object with the needed annotations.

when it comes to using nginx as ingress and adding basic authentication this resource from the official docs is really helpful.
in general when creating kubernetes secrets, especially from the command line using kubectl you'll have to single quote the password if it contains special characters. this is so that the special characters wont be interpreted by your shell. more info here.
"
52183750,error while using local persistent volumes in statefulset pod,"i am trying to use local persistent volume mentioned in https://kubernetes.io/blog/2018/04/13/local-persistent-volumes-beta/ for creating my statefulset pod. but when my pod tries to claim volume. i am getting following error :

events:
  type     reason            age                 from               message
  ----     ------            ----                ----               -------
  warning  failedscheduling  4s (x243 over 20m)  default-scheduler  0/2 nodes are available: 1 node(s) didn't find available persistent volumes to bind, 1 node(s) had taints that the pod didn't tolerate.


following are storage classes and persistent volumes i have created:

storageclass-kafka-broker.yml

kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: kafka-broker
provisioner: kubernetes.io/no-provisioner
volumebindingmode: waitforfirstconsumer


storageclass-kafka-zookeeper.yml

kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: kafka-zookeeper
provisioner: kubernetes.io/no-provisioner
volumebindingmode: waitforfirstconsumer


pv-zookeeper.yml

apiversion: v1
kind: persistentvolume
metadata:
  name: example-local-pv-zookeeper
spec:
  capacity:
    storage: 2gi
  accessmodes:
  - readwriteonce
  persistentvolumereclaimpolicy: retain
  storageclassname: kafka-zookeeper
  local:
    path: /d/kubernetes-mount-path
  nodeaffinity:
    required:
      nodeselectorterms:
      - matchexpressions:
        - key: kubernetes.io/hostname
          operator: in
          values:
          - my-node


pv-kafka.yml

apiversion: v1
kind: persistentvolume
metadata:
  name: example-local-pv
spec:
  capacity:
    storage: 200gi
  accessmodes:
  - readwriteonce
  persistentvolumereclaimpolicy: retain
  storageclassname: kafka-broker
  local:
    path: /d/kubernetes-mount-path
  nodeaffinity:
    required:
      nodeselectorterms:
      - matchexpressions:
        - key: kubernetes.io/hostname
          operator: in
          values:
          - my-node


following is the pod 50pzoo.yml using this volume :

apiversion: apps/v1
kind: statefulset
metadata:
  name: pzoo
  namespace: kafka
spec:
  selector:
    matchlabels:
      app: zookeeper
      storage: persistent
  servicename: ""pzoo""
  replicas: 1
  updatestrategy:
    type: ondelete
  template:
    metadata:
      labels:
        app: zookeeper
        storage: persistent
      annotations:
    spec:
      terminationgraceperiodseconds: 10
      initcontainers:
      - name: init-config
        image: solsson/kafka-initutils@sha256:18bf01c2c756b550103a99b3c14f741acccea106072cd37155c6d24be4edd6e2
        command: ['/bin/bash', '/etc/kafka-configmap/init.sh']
        volumemounts:
        - name: configmap
          mountpath: /etc/kafka-configmap
        - name: config
          mountpath: /etc/kafka
        - name: data
          mountpath: /var/lib/zookeeper/data
      containers:
      - name: zookeeper
        image: solsson/kafka:2.0.0@sha256:8bc5ccb5a63fdfb977c1e207292b72b34370d2c9fe023bdc0f8ce0d8e0da1670
        env:
        - name: kafka_log4j_opts
          value: -dlog4j.configuration=file:/etc/kafka/log4j.properties
        command:
        - ./bin/zookeeper-server-start.sh
        - /etc/kafka/zookeeper.properties
        ports:
        - containerport: 2181
          name: client
        - containerport: 2888
          name: peer
        - containerport: 3888
          name: leader-election
        resources:
          requests:
            cpu: 10m
            memory: 100mi
        readinessprobe:
          exec:
            command:
            - /bin/sh
            - -c
            - '[ ""imok"" = ""$(echo ruok | nc -w 1 -q 1 127.0.0.1 2181)"" ]'
        volumemounts:
        - name: config
          mountpath: /etc/kafka
        - name: data
          mountpath: /var/lib/zookeeper/data
      volumes:
      - name: configmap
        configmap:
          name: zookeeper-config
      - name: config
        emptydir: {}
  volumeclaimtemplates:
  - metadata:
      name: data
    spec:
      accessmodes: [ ""readwriteonce"" ]
      storageclassname: kafka-zookeeper
      resources:
        requests:
          storage: 1gi


following is the kubectl get events command output 

[root@quagga kafka-kubernetes-testing-single-node]# kubectl get events --namespace kafka
last seen   first seen   count     name                           kind                    subobject   type      reason                 source                        message
1m          1m           1         pzoo.15517ca82c7a4675          statefulset                         normal    successfulcreate       statefulset-controller        create claim data-pzoo-0 pod pzoo-0 in statefulset pzoo success
1m          1m           1         pzoo.15517ca82caed9bc          statefulset                         normal    successfulcreate       statefulset-controller        create pod pzoo-0 in statefulset pzoo successful
13s         1m           9         data-pzoo-0.15517ca82c726833   persistentvolumeclaim               normal    waitforfirstconsumer   persistentvolume-controller   waiting for first consumer to be created before binding
9s          1m           22        pzoo-0.15517ca82cb90238        pod                                 warning   failedscheduling       default-scheduler             0/2 nodes are available: 1 node(s) didn't find available persistent volumes to bind, 1 node(s) had taints that the pod didn't tolerate.


output of kubectl get pv is :

[root@quagga kafka-kubernetes-testing-single-node]# kubectl get pv
name                         capacity   access modes   reclaim policy   status      claim     storageclass      reason    age
example-local-pv             200gi      rwo            retain           available             kafka-broker                4m
example-local-pv-zookeeper   2gi        rwo            retain           available             kafka-zookeeper             4m

",<kubernetes><kubectl><minikube>,52209502,3,"it was a silly mistake. i was mentioning my-node in node name values in pv files. modifying it to correct node name solved my issue.
"
55009028,configure ssl certificates in kubernetes with cert-manager istio ingress and letsencrypt,"i'm trying to configure ssl certificates in kubernetes with cert-manager, istio ingress and letsencrypt. i have installed istio with helm, cert-manager, created clusterissuer and then i'm trying to create a certificate. the acme challenge can't be validated, i'm trying to do it with http01 and can't figure it out how to use istio ingress for this. istio is deployed with following options:



helm install --name istio install/kubernetes/helm/istio `
--namespace istio-system `
--set global.controlplanesecurityenabled=true `
--set grafana.enabled=true`
--set tracing.enabled=true 
--set kiali.enabled=true `
--set ingress.enabled=true




certificate configuration:



apiversion: certmanager.k8s.io/v1alpha1
kind: certificate
metadata:
  name: example.com
  namespace: istio-system
spec:
  secretname: example.com
  issuerref:
    name: letsencrypt-staging
    kind: clusterissuer
  commonname: 'example.com'
  dnsnames:
  - example.com
  acme:
    config:
    - http01:
        ingress: istio-ingress
      domains:
      - example.com




when trying this way, for some reason, istio-ingress can't be found, but when trying to specify ingressclass: some-name, instead of ingress: istio-ingress, i get 404 because example.com/.well-known/acme-challenge/token can't be reached.
how can this be solved? thank you!
",<ssl><kubernetes><kubernetes-ingress><istio><cert-manager>,55139188,1,"the solution was to move dns to azure and use dns validation for generating the certificate. i also used istio-1.1.0-rc.3 and configured the gateway in the following way:



apiversion: networking.istio.io/v1alpha3
kind: gateway
metadata:
  name: mygateway
spec:
  selector:
    istio: ingressgateway # use istio default ingress gateway
  servers:
  - hosts:
    - 'mydomain.com'
    port:
      name: http-bookinfo
      number: 80
      protocol: http
    tls:
      httpsredirect: true
  - hosts:
    - 'mydomain.com'
    port:
      name: https-bookinfo
      number: 443
      protocol: https
    tls:      
      mode: simple
      servercertificate: ""use sds"" #random string, because servercertificate and 
      #privatekey are required for tls.mode=simple
      privatekey: ""use sds"" 
      credentialname: ""istio-bookinfo-certs-staging"" #this must match the secret name 
      #from the certificate



in order to work enable sds at ingress gateway:



helm template install/kubernetes/helm/istio/ --name istio `
--namespace istio-system -x charts/gateways/templates/deployment.yaml `
--set gateways.istio-egressgateway.enabled=false `
--set gateways.istio-ingressgateway.sds.enabled=true &gt; `
$home/istio-ingressgateway.yaml

 kubectl apply -f $home/istio-ingressgateway.yaml



"
67551961,haproxy ingress controller service changed ip on gcp,"i am using haproxy as the ingress-controller in my gke clusters. and exposing haproxy service as loadbalancer service(internal).
recently, i experienced an issue, where the ha-proxy service changed its external-ip, and traffic stopped routing to haproxy. this issue occurred multiple times on different days(now it has stopped). i had to manually add that new external-ip to the frontend of that loadbalancer to allow traffic to haproxy.
there were two pods running for haproxy, and both had been running for days, and there was nothing in their logs. i assume it was something related to service or gcp lb and not haproxy itself.
i am afraid that i don't have any logs related to that.
i still don't know, what caused the service ip to change. as there were no recent changes, and the cluster and all services were running for many days properly, and suddenly this occurred.
has anyone faced a similar issue earlier? or what can i do to avoid such issue in future?
what could have caused the ip to change?
this is how my service is configured:
---
apiversion: v1
kind: service
metadata:
  labels:
    run: haproxy-ingress
  name: haproxy-ingress
  namespace: haproxy-controller
  annotations:
    cloud.google.com/load-balancer-type: &quot;internal&quot;
    networking.gke.io/internal-load-balancer-allow-global-access: &quot;true&quot;
    cloud.google.com/network-tier: &quot;premium&quot;
spec:
  selector:
    run: haproxy-ingress
  type: loadbalancer
  ports:
  - name: http
    port: 80
    protocol: tcp
    targetport: 80
  - name: https
    port: 443
    protocol: tcp
    targetport: 443
  - name: stat
    port: 1024
    protocol: tcp
    targetport: 1024


found some logs:
warning syncloadbalancerfailed 30m (x3570 over 13d) service-controller error syncing load balancer: failed to ensure load balancer: googleapi: error 409: ip_in_use_by_another_resource - ip '10.17.129.17' is already being used by another resource.
normal ensuringloadbalancer 3m33s (x3576 over 13d) service-controller ensuring load balancer

",<kubernetes><google-kubernetes-engine><kubernetes-ingress><kubernetes-service><haproxy-ingress>,67584911,1,"the short answer is: external ip for the service are ephemeral.
because ha-proxy controller pods are recreated the ha-proxy service is created with an ephemeral ip.
to avoid this issue, i would recommend using a static ip that you can reference in the loadbalancerip field.
this can be done by following steps:

reserve a static ip. (link)
use this ip, to create a service (link)

example yaml:
apiversion: v1
kind: service
metadata:
  name: helloweb
  labels:
    app: hello
spec:
  selector:
    app: hello
    tier: web
  ports:
  - port: 80
    targetport: 8080
  type: loadbalancer
  loadbalancerip: &quot;your.ip.address.here&quot;

"
72080184,eks cluster not reachable through kubectl during major scale up,"i have a cluster running on aws eks with kubernetes cluster autoscaler.
a few days ago i had a major scale up in which my cluster got to 50 nodes in a very short period of time. when that happened i tried to reach my cluster using kubectl and got no response for a few minutes.
i know that eks cluster autoscaler provides ha for the control plane node by having 3 nodes in different az just for this kind of high load on the cluster.
so i'm trying to understand what may be the cause for this unresponsiveness of the api server (that resided in the control plane)?
sorry of the lack of details but i'm just looking for a general direction what to look for before i do more research.
",<kubernetes><kubectl><amazon-eks>,72094290,1,"...cluster autoscaler provides ha for the control plane node by having 3 nodes in different az
the control plane is managed by aws and serves with ha features without you install cluster-autoscaler:

amazon eks runs and scales the kubernetes control plane across
multiple aws availability zones to ensure high availability. amazon
eks automatically scales control plane instances based on load,
detects and replaces unhealthy control plane instances, and
automatically patches the control plane.

...trying to understand what may be the cause for this unresponsiveness of the api server (that resided in the control plane)?
you should raise support case to aws support if you encounter issue with the control plane, the control plane is not managed by the cluster autoscaler that you deployed.
the cluster autoscaler automatically adjusts the number of worker node so that all pods can run. likewise, when there is less pods running in the cluster, the component can also automate to terminate excessive worker node.

the kubernetes cluster autoscaler automatically adjusts the number of
nodes in your cluster when pods fail or are rescheduled onto other
nodes. the cluster autoscaler is typically installed as a deployment
in your cluster.

"
64908709,kubernetes ingress-controller crashloopbackoff error,"i've set up a kubernetes (1.17.11) cluster (azure), and i've installed nginx-ingress-controller via
helm install nginx-ingress --namespace z1 stable/nginx-ingress --set controller.publishservice.enabled=true
the setup seems to be ok and it's working but every now and then it fails, when i check running pods (kubectl get pod -n z1) i see there is a number of restarts for the ingress-controller pod.
i thought maybe there is a huge load so better to increase replicas so i ran helm upgrade --namespace z1 stable/ingress --set controller.replicascount=3 but still only one of the pods (out of 3) seems to be in use and one has fails due to crashloopbackoff sometimes (not constantly).
one thing worth mentioning, installed nginx-ingress version is 0.34.1 but 0.41.2 is also available, do you think the upgrade will help, and how can i upgrade the installed version to the new one (afaik helm upgrade won't replace the chart with a newer version, i may be wrong) ?
any idea?
kubectl describe pod  result:
name:         nginx-ingress-controller-58467bccf7-jhzlx
namespace:    z1
priority:     0
node:         aks-agentpool-41415378-vmss000000/10.240.0.4
start time:   thu, 19 nov 2020 09:01:30 +0100
labels:       app=nginx-ingress
              app.kubernetes.io/component=controller
              component=controller
              pod-template-hash=58467bccf7
              release=nginx-ingress
annotations:  &lt;none&gt;
status:       running
ip:           10.244.1.18
ips:
  ip:           10.244.1.18
controlled by:  replicaset/nginx-ingress-controller-58467bccf7
containers:
  nginx-ingress-controller:
    container id:  docker://719655d41c1c8cdb8c9e88c21adad7643a44d17acbb11075a1a60beb7553e2cf
    image:         us.gcr.io/k8s-artifacts-prod/ingress-nginx/controller:v0.34.1
    image id:      docker-pullable://us.gcr.io/k8s-artifacts-prod/ingress-nginx/controller@sha256:0e072dddd1f7f8fc8909a2ca6f65e76c5f0d2fcfb8be47935ae3457e8bbceb20
    ports:         80/tcp, 443/tcp
    host ports:    0/tcp, 0/tcp
    args:
      /nginx-ingress-controller
      --default-backend-service=z1/nginx-ingress-default-backend
      --election-id=ingress-controller-leader
      --ingress-class=nginx
      --configmap=z1/nginx-ingress-controller
    state:          running
      started:      thu, 19 nov 2020 09:54:07 +0100
    last state:     terminated
      reason:       error
      exit code:    143
      started:      thu, 19 nov 2020 09:50:41 +0100
      finished:     thu, 19 nov 2020 09:51:12 +0100
    ready:          true
    restart count:  8
    liveness:       http-get http://:10254/healthz delay=10s timeout=1s period=10s #success=1 #failure=3
    readiness:      http-get http://:10254/healthz delay=10s timeout=1s period=10s #success=1 #failure=3
    environment:
      pod_name:       nginx-ingress-controller-58467bccf7-jhzlx (v1:metadata.name)
      pod_namespace:  z1 (v1:metadata.namespace)
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from nginx-ingress-token-7rmtk (ro)
conditions:
  type              status
  initialized       true
  ready             true
  containersready   true
  podscheduled      true
volumes:
  nginx-ingress-token-7rmtk:
    type:        secret (a volume populated by a secret)
    secretname:  nginx-ingress-token-7rmtk
    optional:    false
qos class:       besteffort
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason     age                   from                                        message
  ----     ------     ----                  ----                                        -------
  normal   scheduled  &lt;unknown&gt;             default-scheduler                           successfully assigned z1/nginx-ingress-controller-58467bccf7-jhzlx to aks-agentpool-41415378-vmss000000
  normal   killing    58m                   kubelet, aks-agentpool-41415378-vmss000000  container nginx-ingress-controller failed liveness probe, will be restarted
  warning  unhealthy  57m (x4 over 58m)     kubelet, aks-agentpool-41415378-vmss000000  readiness probe failed: http probe failed with statuscode: 500
  warning  unhealthy  57m                   kubelet, aks-agentpool-41415378-vmss000000  readiness probe failed: get http://10.244.1.18:10254/healthz: read tcp 10.244.1.1:54126-&gt;10.244.1.18:10254: read: connection reset by peer
  normal   pulled     57m (x2 over 59m)     kubelet, aks-agentpool-41415378-vmss000000  container image &quot;us.gcr.io/k8s-artifacts-prod/ingress-nginx/controller:v0.34.1&quot; already present on machine
  normal   created    57m (x2 over 59m)     kubelet, aks-agentpool-41415378-vmss000000  created container nginx-ingress-controller
  normal   started    57m (x2 over 59m)     kubelet, aks-agentpool-41415378-vmss000000  started container nginx-ingress-controller
  warning  unhealthy  57m                   kubelet, aks-agentpool-41415378-vmss000000  liveness probe failed: get http://10.244.1.18:10254/healthz: dial tcp 10.244.1.18:10254: connect: connection refused
  warning  unhealthy  56m                   kubelet, aks-agentpool-41415378-vmss000000  liveness probe failed: http probe failed with statuscode: 500
  warning  unhealthy  23m (x10 over 58m)    kubelet, aks-agentpool-41415378-vmss000000  liveness probe failed: get http://10.244.1.18:10254/healthz: net/http: request canceled (client.timeout exceeded while awaiting headers)
  warning  unhealthy  14m (x6 over 57m)     kubelet, aks-agentpool-41415378-vmss000000  readiness probe failed: get http://10.244.1.18:10254/healthz: dial tcp 10.244.1.18:10254: connect: connection refused
  warning  backoff    9m28s (x12 over 12m)  kubelet, aks-agentpool-41415378-vmss000000  back-off restarting failed container
  warning  unhealthy  3m51s (x24 over 58m)  kubelet, aks-agentpool-41415378-vmss000000  readiness probe failed: get http://10.244.1.18:10254/healthz: net/http: request canceled (client.timeout exceeded while awaiting headers)

some logs from the controller
  nginx ingress controller
  release:       v0.34.1
  build:         v20200715-ingress-nginx-2.11.0-8-gda5fa45e2
  repository:    https://github.com/kubernetes/ingress-nginx
  nginx version: nginx/1.19.1

-------------------------------------------------------------------------------

i1119 08:54:07.267185       6 main.go:275] running in kubernetes cluster version v1.17 (v1.17.11) - git (clean) commit 3a3612132641768edd7f7e73d07772225817f630 - platform linux/amd64
i1119 08:54:07.276120       6 main.go:87] validated z1/nginx-ingress-default-backend as the default backend.
i1119 08:54:07.430459       6 main.go:105] ssl fake certificate created /etc/ingress-controller/ssl/default-fake-certificate.pem
w1119 08:54:07.497816       6 store.go:659] unexpected error reading configuration configmap: configmaps &quot;nginx-ingress-controller&quot; not found
i1119 08:54:07.617458       6 nginx.go:263] starting nginx ingress controller
i1119 08:54:08.748938       6 backend_ssl.go:66] adding secret &quot;z1/z1-tls-secret&quot; to the local store
i1119 08:54:08.801385       6 event.go:278] event(v1.objectreference{kind:&quot;ingress&quot;, namespace:&quot;z2&quot;, name:&quot;zalenium&quot;, uid:&quot;8d395a18-811b-4852-8dd5-3cdd682e2e6e&quot;, apiversion:&quot;networking.k8s.io/v1beta1&quot;, resourceversion:&quot;13667218&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'create' ingress z2/zalenium
i1119 08:54:08.801908       6 backend_ssl.go:66] adding secret &quot;z2/z2-tls-secret&quot; to the local store
i1119 08:54:08.802837       6 event.go:278] event(v1.objectreference{kind:&quot;ingress&quot;, namespace:&quot;z1&quot;, name:&quot;zalenium&quot;, uid:&quot;244ae6f5-897e-432e-8ec3-fd142f0255dc&quot;, apiversion:&quot;networking.k8s.io/v1beta1&quot;, resourceversion:&quot;13667219&quot;, fieldpath:&quot;&quot;}): type: 'normal' reason: 'create' ingress z1/zalenium
i1119 08:54:08.839946       6 nginx.go:307] starting nginx process
i1119 08:54:08.840375       6 leaderelection.go:242] attempting to acquire leader lease  z1/ingress-controller-leader-nginx...
i1119 08:54:08.845041       6 controller.go:141] configuration changes detected, backend reload required.
i1119 08:54:08.919965       6 status.go:86] new leader elected: nginx-ingress-controller-58467bccf7-5thwb
i1119 08:54:09.084800       6 controller.go:157] backend successfully reloaded.
i1119 08:54:09.096999       6 controller.go:166] initial sync, sleeping for 1 second.

",<kubernetes><kubernetes-helm><kubernetes-ingress>,65006249,1,"as op confirmed in comment section, i am posting solution for this issue.

yes i tried and i replaced the deprecated version with the latest version, it completely solved the nginx issue.

in this setup op used helm chart from stable repository. in github page, dedicated to stable/nginx-ingress there is an information that this specific chart is deprecated. it was updated 12 days ago so this is a fresh change.

this chart is deprecated as we have moved to the upstream repo ingress-nginx the chart source can be found here: https://github.com/kubernetes/ingress-nginx/tree/master/charts/ingress-nginx

in nginx ingress controller deploy guide using helm option is already with new repository.
to list current repository on the cluster use command $ helm repo list.
$ helm repo list
name            url
stable          https://kubernetes-charts.storage.googleapis.com
ingress-nginx   https://kubernetes.github.io/ingress-nginx

if you don't have new ingress-nginx repository, you have to:

add new repository:

$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx


update it:

$ helm update


deploy nginx ingress controller:

$ helm install my-release ingress-nginx/ingress-nginx 



disclaimer!
above commands are specific to helm v3.
"
67153897,use key file with application running on kubernetes cluster,"i'm trying to use a key file in my kubernetes application and i can't seem to find an example of this anywhere. i want to use firebase authentication in my nodejs backend. when running my application locally i was using the following
admin.initializeapp({
  credential: admin.credential.cert(service_account_key_path),
});

my initial thought was to create a secret from a key file like
$ gcloud container clusters get-credentials my-cluster --zone us-central1-c --project my-project
$ kubectl create secret generic service-account-key \
    --from-file=${service_account_key_path}

however, since i am creating a secret there is not a path for me to set my service_account_key_path to when running my application in a kubernetes container. what is the correct method for doing this in kubernetes?
",<node.js><firebase><kubernetes><google-cloud-platform><google-kubernetes-engine>,67155962,3,"you can save the serviceaccount file inside the secret and mount the secret into the deployment volume.
so the secret will be accessible to deployment's volume and your pod can access it.
for example :
apiversion: v1
kind: deployment
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: nginx
    volumemounts:
    - name: foo
      mountpath: &quot;/etc/foo&quot;
      readonly: true
  volumes:
  - name: foo
    secret:
      secretname: mysecret

you can check out the :
https://kubernetes.io/docs/concepts/configuration/secret/#use-case-pod-with-ssh-keys
another example : https://kubernetes.io/docs/concepts/configuration/secret/#use-case-dotfiles-in-a-secret-volume
so basic idea is to mount the secret into the volume of the deployment and it will be used by the code.
"
57787343,debugging colissioncount on kubernetes,"i have a statefulset in openshift that keeps restarting, but only on a single node. i don't see anything in pods logs. in /var/log/messages i see only messages that container is restarting, volume is unmounted etc and some more cryptic 'error: container is already stopped' and 'cleanup: failed to unmount secrets: invalid argument'.

however, when i look and yaml for statefulset i see the following:

status:
  collisioncount: 1
  currentreplicas: 1


i suppose this is what is the real cause.
but how can i find out what has generated that collision? 
",<kubernetes><openshift><kubernetes-statefulset>,57793418,1,"statefulsets internally perform an snapshot of the data via controllerrevisions and generate a hash for each version.

what the collisioncount indicates is that the controllerrevision hash collided, likely due to an implementation issue.

you can try to rule this out by getting the controller revisions:

$ kubectl get controllerrevisions

since this is an internal mechanism in the object, there is little to do other than recreate the object to generate new hashes that don't collide. there is a merged pr that suggests that newer versions shouldn't face this issue. however, it might be the case that you're running a version without this patch.
"
64440761,k8s api cloud.google.com not available in gke v1.16.13-gke.401,"i am trying to create a backendconfig resource on a gke cluster v1.16.13-gke.401 but it gives me the following error:
unable to recognize &quot;backendconfig.yaml&quot;: no matches for kind &quot;backendconfig&quot; in version &quot;cloud.google.com/v1&quot;

i have checked the available apis with the kubectl api-versions command and cloud.google.com is not available. how can i enable it?
i want to create a backendconfig whit a custom health check like this:
apiversion: cloud.google.com/v1
kind: backendconfig
metadata:
  name: my-backendconfig
spec:
  healthcheck:
    checkintervalsec: 8
    timeoutsec: 1
    healthythreshold: 1
    unhealthythreshold: 3
    type: http
    requestpath: /health
    port: 10257

and attach this backendconfig to a service like this:
apiversion: v1
kind: service
metadata:
  annotations:
    cloud.google.com/backend-config: '{&quot;default&quot;: &quot;my-backendconfig&quot;}'

",<kubernetes><google-kubernetes-engine>,64500771,1,"as mentioned in the comments, issue was caused due to the lack of http load balancing add-on in your cluster.
when you are creating gke cluster with all default setting, feature like http load balancing is enabled.

the http load balancing add-on is required to use the google cloud load balancer with kubernetes ingress. if enabled, a controller will be installed to coordinate applying load balancing configuration changes to your gcp project

more details can be found in gke documentation.
for test i have created cluster-1 without http load balancing add-on. there was no backendconfig crd - custom resource definition.

the customresourcedefinition api resource allows you to define custom resources. defining a crd object creates a new custom resource with a name and schema that you specify. the kubernetes api serves and handles the storage of your custom resource. the name of a crd object must be a valid dns subdomain name.

without backendconfig and without cloud apiversion like below
user@cloudshell:~ (k8s-tests-xxx)$ kubectl get crd | grep backend
user@cloudshell:~ (k8s-tests-xxx)$ kubectl api-versions | grep cloud

i was not able to create any backendconfig.
user@cloudshell:~ (k8s-tests-xxx) $ kubectl apply -f bck.yaml
error: unable to recognize &quot;bck.yaml&quot;: no matches for kind &quot;backendconfig&quot; in version &quot;cloud.google.com/v1&quot;

to make it work, you have to enable http load balancing you can do it via ui or command.
using ui:

navigation menu &gt; clusters &gt; [cluster-name] &gt; details &gt; clikc on
edit &gt; scroll down to add-ons and expand &gt; find http load balancing and change from disabled to enabled.

or command:
gcloud beta container clusters update &lt;clustername&gt; --update-addons=httploadbalancing=enabled --zone=&lt;your-zone&gt;

$ gcloud beta container clusters update cluster-1 --update-addons=httploadbalancing=enabled --zone=us-central1-c
warning: warning: basic authentication is deprecated, and will be removed in gke control plane versions 1.19 and newer. for a list of recommended authentication methods, see: https://cloud.google.com/kubernetes-engine/docs/how-to/api-server-authentication

after a while, when add-on was enabled:
$ kubectl get crd | grep backend
backendconfigs.cloud.google.com             2020-10-23t13:09:29z
$ kubectl api-versions | grep cloud
cloud.google.com/v1
cloud.google.com/v1beta1
$ kubectl apply -f bck.yaml 
backendconfig.cloud.google.com/my-backendconfig created

"
77324222,"unable to communicate with another pod using service cluster ip, using pod ip able to communicate","i have nginx pod and other pod contains gunicorn pod api which i am trying to connect via nginx pod.
when i use pod ip of gunicorn pod in nginx pod, i am able to connect with nginx pod.
output:
root@nginx:/etc/nginx# curl -v http://10.244.1.155:20000/_ems/plant
*   trying 10.244.1.155:20000...
* connected to 10.244.1.155 (10.244.1.155) port 20000 (#0)

when i used service, instead of pod ip, its failing.
error:
root@nginx:/etc/nginx# curl -v http://ems-service.default.svc.cluster.local:20000/_ems/plant;
*   trying 10.106.43.2:20000...
* connect to 10.106.43.2 port 20000 failed: connection refused
* failed to connect to ems-service.default.svc.cluster.local port 20000: connection refused
* closing connection 0
curl: (7) failed to connect to ems-service.default.svc.cluster.local port 20000: connection refused

logs:
name                                                         ready   status             restarts         age
pod/ems                                                      1/1     running            0                5m56s
pod/nginx                                                    1/1     running            0                4h46m
name                       type        cluster-ip     external-ip   port(s)          age
service/ems-service        clusterip   10.106.43.2    &lt;none&gt;        20000/tcp        103m
[eds@rnd-4 pod-4px]$ kubectl describe service -n default ems-service
name:              ems-service
namespace:         default
labels:            &lt;none&gt;
annotations:       &lt;none&gt;
selector:          name=ems
type:              clusterip
ip family policy:  singlestack
ip families:       ipv4
ip:                10.106.43.2
ips:               10.106.43.2
port:              &lt;unset&gt;  20000/tcp
targetport:        80/tcp
endpoints:         &lt;none&gt;
session affinity:  none
events:            &lt;none&gt;

yaml file:
apiversion: v1
kind: pod
metadata:
  name: ems
  labels:
    app: ems
spec:
  containers:
    - name: ems
      image: 
      command: [&quot;/bin/sh&quot;]
      args: [&quot;-c&quot;, &quot;chmod +x /root/code/run.sh &amp;&amp; /root/code/run.sh&quot;]
      env:
      - name: logs_dir
        value: /root/code/logs
      imagepullpolicy: always
      ports:
      - containerport: 20000
----------------------------------
apiversion: v1
kind: service
metadata:
  name: ems-service
spec:
  selector:
    name: ems
  ports:
    - protocol: tcp
      port: 20000
      targetport: 80

",<kubernetes><nginx><kubernetes-ingress>,77330275,1,"if kubectl describe service says endpoints: &lt;none&gt; that's usually a clear sign that the service's selector: doesn't match the pod's labels:.  in your setup you have
# pod.yaml
metadata:
  labels:
    app: ems

# service.yaml
spec:
  selector:
    name: ems

and these need to match.  the most likely fix is to change name to app in the service.
you usually shouldn't run a bare pod, for a couple of reasons beyond the scope of this question.  i'd recommend changing the pod to a deployment, assuming you don't need access to persistent storage.  the service needs to match the spec: { template: { metadata: { labels: } } } per-pod labels in this case.
"
58764509,"why container object in pod yaml file has ""list value"" rather than a ""map value""","in the pod creation yaml files or in the deployment yaml files in kubernetes, why containers key has a list value - name: memory-demo-ctr rather than we can simply provide the map value name: memory-demo-ctr (why we're providing - symbol)?

i tried looking at over the web but couldn't find a solution.

apiversion: v1
kind: pod
metadata:
  name: memory-demo
  namespace: mem-example
spec:
  containers:
  - name: memory-demo-ctr
    image: polinux/stress

",<kubernetes><yaml><containers><kubernetes-pod>,58767260,2,"pod is capable of running multiple containers. that's the reason containers object is a list instead of map.

kind: pod
...
spec:
  containers:
  - name: busybox
    image: busybox:latest
  - name: nginx
    image: nginx:1.7.9
  - name: redis
    image: redis:latest


if containers is a map object, you cannot write a configuration file to run multiple containers inside a pod. i hope this answer solved your doubt.
"
58097994,helm error: release requires a rollback before it can be upgraded,"in my cluster im using weave flux along with their flux-helm-operator to manage my cluster the gitops way.

however, when i make a change to the chart at flux git repository, i often come across the following error msg:

ts=2019-09-25t11:54:37.604506452z caller=chartsync.go:328 component=chartsync
warning=""unable to proceed with release"" 
resource=mychart:helmrelease/mychart release=mychart
err=""release requires a rollback before it can be upgraded (failed)""


im not sure what does it mean in helm, but anyway, i am not supposed to run any helm command since the releases are managed by flux so i am wondering what is the correct way to deal with this error on production

(besides deleting the release and waiting for flux to recreate it)

a well-explained answer will be very much accepted, thanks.
",<kubernetes><kubernetes-helm><fluxcd>,58100773,5,"let's dive into the code of helm-operator

warning unable to proceed with release arises after getupgradablerelease


    // getupgradablerelease returns a release if the current state of it
    // allows an upgrade, a descriptive error if it is not allowed, or
    // nil if the release does not exist.



it returns error release requires a rollback before it can be upgraded if release has status_failed state (see release.go#89 )

unhealthy state blocks release

as flux developers mentioned in #2265, there is no way to roll to unhealthy state.


  this is not a bug but i can see where your expectation is coming from.
  
  flux will only move healthy releases forward, one of the reasons for this is to ensure we do not end up in a loop of failure, the --force flag is thus not intended to be used to force the upgrade of an unhealthy resource (you should use the rollback feature for this) but was developed to make it possible to upgrade charts with e.g. backwards incompatible changes (changes on immutable fields for example, which require a resource to be removed first, see #1760).
  
  conclusion: the forceupgrade is honoured, but can not be used to force the upgrade of a release in an unhealthy state. 


rollback

as author recommends, you should use rollback feature


  from time to time a release made by the helm operator may fail, it is possible to automate the rollback of a failed release by setting .spec.rollback.enable to true on the helmrelease resource.

note: a successful rollback of a helm chart containing a statefulset resource is known to be tricky, and one of the main reasons automated rollbacks are not enabled by default for all helmreleases. verify a manual rollback of your helm chart does not cause any problems before enabling it.

  
  when enabled, the helm operator will detect a faulty upgrade and perform a rollback, it will not attempt a new upgrade unless it detects a change in values and/or the chart.


apiversion: flux.weave.works/v1beta1
kind: helmrelease
# metadata: ...
spec:
  # listed values are the defaults.
  rollback:
    # if set, will perform rollbacks for this release.
    enable: false
    # if set, will force resource update through delete/recreate if
    # needed.
    force: false
    # prevent hooks from running during rollback.
    disablehooks: false
    # time in seconds to wait for any individual kubernetes operation.
    timeout: 300
    # if set, will wait until all pods, pvcs, services, and minimum
    # number of pods of a deployment are in a ready state before
    # marking the release as successful. it will wait for as long
    # as the set timeout.
    wait: false

"
64533410,"kubernetes dashboard an error on the server (""unknown"") has prevented the request from succeeding","after getting my k8s cluster up and going i faithfully deployed the following webui dashboard
using the command:
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml

when i try to access it i get the following error:
metric client health check failed: an error on the server (&quot;unknown&quot;) has prevented the request from succeeding (get services dashboard-metrics-scraper)

if i get all the services i get:
k get services --all-namespaces
namespace              name                        type        cluster-ip    external-ip   port(s)         age
default                kubernetes                  clusterip   10.96.0.1     &lt;none&gt;        443/tcp         8d
kube-system            kube-dns                    clusterip   10.96.0.10    &lt;none&gt;        53/udp,53/tcp   8d
kubernetes-dashboard   dashboard-metrics-scraper   clusterip   10.96.0.65    &lt;none&gt;        8000/tcp        6m10s
kubernetes-dashboard   kubernetes-dashboard        clusterip   10.96.0.173   &lt;none&gt;        443/tcp         6m10s

can someone shed some light? what am i missing?
more info:
in the dashboard yaml i found these roles:
kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
rules:
  - apigroups: [&quot;&quot;]
    resources: [&quot;secrets&quot;]
    resourcenames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]
   
 map.
  - apigroups: [&quot;&quot;]
    resources: [&quot;configmaps&quot;]
    resourcenames: [&quot;kubernetes-dashboard-settings&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;]
    
  - apigroups: [&quot;&quot;]
    resources: [&quot;services&quot;]
    resourcenames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;]
    verbs: [&quot;proxy&quot;]
  - apigroups: [&quot;&quot;]
    resources: [&quot;services/proxy&quot;]
    resourcenames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;]
    verbs: [&quot;get&quot;]

    ---
    
    kind: clusterrole
    apiversion: rbac.authorization.k8s.io/v1
    metadata:
      labels:
        k8s-app: kubernetes-dashboard
      name: kubernetes-dashboard
    rules:
      
      - apigroups: [&quot;metrics.k8s.io&quot;]
        resources: [&quot;pods&quot;, &quot;nodes&quot;]
        verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
    
    ---
    
    apiversion: rbac.authorization.k8s.io/v1
    kind: rolebinding
    metadata:
      labels:
        k8s-app: kubernetes-dashboard
      name: kubernetes-dashboard
      namespace: kubernetes-dashboard
    roleref:
      apigroup: rbac.authorization.k8s.io
      kind: role
      name: kubernetes-dashboard
    subjects:
      - kind: serviceaccount
        name: kubernetes-dashboard
        namespace: kubernetes-dashboard
    
    ---
    
    apiversion: rbac.authorization.k8s.io/v1
    kind: clusterrolebinding
    metadata:
      name: kubernetes-dashboard
    roleref:
      apigroup: rbac.authorization.k8s.io
      kind: clusterrole
      name: kubernetes-dashboard
    subjects:
      - kind: serviceaccount
        name: kubernetes-dashboard
        namespace: kubernetes-dashboard

looks like the kubernetes-dashboard user has access to the metrics service i might be wrong
",<kubernetes><kubernetes-ingress><kubernetes-pod><kubernetes-dashboard>,64533593,1,"it looks like the kubernetes-dashboard's serviceaccount doesn't have access to all kubernetes resources (in particular, it can't access the metric server service).
to fix this you should create a new serviceaccount for the dashboard and give it more permissions.
here's one that i found on another similar post (be careful since it will give admin privileges to the dashboard, and whoever uses it will be able to destroy/create new or existing resources on your kubernetes cluster):
   apiversion: rbac.authorization.k8s.io/v1beta1
kind: clusterrolebinding
metadata:
   name: kubernetes-dashboard
   labels:
       k8s-app: kubernetes-dashboard
roleref:
   apigroup: rbac.authorization.k8s.io
   kind: clusterrole
   name: cluster-admin
subjects:
- kind: serviceaccount
  name: kubernetes-dashboard
  namespace: kube-system

if you don't have a cluster-admin serviceaccount, create one following this template:
apiversion: v1
kind: serviceaccount
metadata:
  name: admin
  namespace: kube-system
  labels:
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: reconcile

admin clusterrole:
kind: clusterrole
apiversion: rbac.authorization.k8s.io/v1alpha1
metadata:
  name: admin
rules:
  - apigroups: [&quot;*&quot;]
    resources: [&quot;*&quot;]
    verbs: [&quot;*&quot;]
    nonresourceurls: [&quot;*&quot;]

"
67417306,"the ingress controller is not created when running the ""minikube addons enable ingress""","i have minikube installed on windows10, and i'm trying to work with ingress controller
i'm doing:

$ minikube addons enable ingress

* after the addon is enabled, please run &quot;minikube tunnel&quot; and your ingress resources would be available at &quot;127.0.0.1&quot;
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
  - using image k8s.gcr.io/ingress-nginx/controller:v0.44.0
  - using image docker.io/jettech/kube-webhook-certgen:v1.5.1
* verifying ingress addon...
* the 'ingress' addon is enabled


minikube addons list

 minikube addons list
|-----------------------------|----------|--------------|
|         addon name          | profile  |    status    |
|-----------------------------|----------|--------------|
| ambassador                  | minikube | disabled     |
| auto-pause                  | minikube | disabled     |
| csi-hostpath-driver         | minikube | disabled     |
| dashboard                   | minikube | disabled     |
| default-storageclass        | minikube | enabled ✅   |
| efk                         | minikube | disabled     |
| freshpod                    | minikube | disabled     |
| gcp-auth                    | minikube | disabled     |
| gvisor                      | minikube | disabled     |
| helm-tiller                 | minikube | disabled     |
| ingress                     | minikube | enabled ✅   |
| ingress-dns                 | minikube | disabled     |
| istio                       | minikube | disabled     |
| istio-provisioner           | minikube | disabled     |
| kubevirt                    | minikube | disabled     |
| logviewer                   | minikube | disabled     |
| metallb                     | minikube | disabled     |
| metrics-server              | minikube | disabled     |
| nvidia-driver-installer     | minikube | disabled     |
| nvidia-gpu-device-plugin    | minikube | disabled     |
| olm                         | minikube | disabled     |
| pod-security-policy         | minikube | disabled     |
| registry                    | minikube | disabled     |
| registry-aliases            | minikube | disabled     |
| registry-creds              | minikube | disabled     |
| storage-provisioner         | minikube | enabled ✅   |
| storage-provisioner-gluster | minikube | disabled     |
| volumesnapshots             | minikube | disabled     |
|-----------------------------|----------|--------------|

note:
i ran minikube tunnel after the addon was enabled
but can't see the nginx controller anywhere:

$ kubectl get pods -n kube-system

name                               ready   status    restarts   age
coredns-74ff55c5b-8gkwj            1/1     running   0          2m35s
etcd-minikube                      1/1     running   0          2m48s
kube-apiserver-minikube            1/1     running   0          2m48s
kube-controller-manager-minikube   1/1     running   0          2m48s
kube-proxy-jq4wm                   1/1     running   0          2m35s
kube-scheduler-minikube            1/1     running   0          2m48s
storage-provisioner                1/1     running   2          2m47s


$ kubectl get pods

no resources found in default namespace.

",<kubernetes><kubernetes-ingress><minikube>,67434691,11,"as already discussed in the comments the ingress controller will be created in the ingress-nginx namespace instead of the kube-system namespace. other than that the rest of the tutorial should work as expected.
"
54425924,nodes are available 3 insufficient cpu,"i’m trying to run the following example: https://kubernetes.io/docs/tutorials/stateful-application/cassandra/
when i run on minikube, it runs well. but when i run on gke, i see an error, 0/3 nodes are available: 3 insufficient cpu.

anyone can help me please?

where i can increase cpu? on stateful_set or on kluster config?

i created my cluster with terraform, with the following configurations:

resource ""google_container_cluster"" ""gcloud_cluster"" {
  name               = ""gcloud-cluster-${var.workspace}""
  zone               = ""us-east1-b""
  initial_node_count = 3
  project            = ""${var.project}""

  addons_config {
    network_policy_config {
      disabled = true
    }
  }

  master_auth {
    username = ""${var.username}""
    password = ""${var.password}""
  }

  node_config {
    oauth_scopes = [
      ""https://www.googleapis.com/auth/devstorage.read_only"",
      ""https://www.googleapis.com/auth/logging.write"",
      ""https://www.googleapis.com/auth/monitoring"",
      ""https://www.googleapis.com/auth/service.management.readonly"",
      ""https://www.googleapis.com/auth/servicecontrol"",
      ""https://www.googleapis.com/auth/trace.append"",
      ""https://www.googleapis.com/auth/compute"",
    ]
  }
}


thanks


",<cassandra><kubernetes><terraform><google-kubernetes-engine><elassandra>,54430035,3,"what is happening here is that by default your cluster is being created using n1-standard-1 machines which have only 1vcpu. 

you should add to your config information about machine type you want to use i.e:

resource ""google_container_cluster"" ""gcloud_cluster"" {
  name               = ""gcloud-cluster-${var.workspace}""
  zone               = ""us-east1-b""
  initial_node_count = 3
  project            = ""${var.project}""

  addons_config {
    network_policy_config {
      disabled = true
    }
  }

  master_auth {
    username = ""${var.username}""
    password = ""${var.password}""
  }

  node_config {
    machine_type = ""${var.machine_type}""
    oauth_scopes = [
      ""https://www.googleapis.com/auth/devstorage.read_only"",
      ""https://www.googleapis.com/auth/logging.write"",
      ""https://www.googleapis.com/auth/monitoring"",
      ""https://www.googleapis.com/auth/service.management.readonly"",
      ""https://www.googleapis.com/auth/servicecontrol"",
      ""https://www.googleapis.com/auth/trace.append"",
      ""https://www.googleapis.com/auth/compute"",
    ]
  }
}


and declare it in variable.tf file using either n1-standard-2 or n1-standard-4 i.e:

variable ""machine_type"" {
    type = ""string""
    default = ""n1-standard-4""
}

"
68643009,how do i make helm chart hooks post-install work if other charts are in running state,"i have a couple of helm charts in a myapp/templates/ directory, and they deploy as expected with helm install myapp.
these two templates are for example:

database.yaml
cronjob.yaml

i'd like for the cronjob.yaml to only run after the database.yaml is in a running state.  i currently have an issue where database.yaml fairly regularly fails in a way we half expect (it's not ideal, but it is what it is).
i've found hooks, but i think i'm either using them incorrectly, or they don't determine whether the pod is in running, pending, some state of crashed, etc...
there are no changes i've made to database.yaml in order to use hooks, but my cronjob.yaml which i only want to run if database.yaml is in a running state, i added the annotations as follows:
cronjob.yaml
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: database
  annotations:
    &quot;helm.sh/hook&quot;: &quot;post-install&quot;
  labels:
    app: database
    service: database
spec:
  schedule: &quot;* * * * *&quot;
  successfuljobshistorylimit: 1
  failedjobshistorylimit: 1
  jobtemplate:
    spec:
      template:
        spec:
          containers:
            - name: customtask
              image: &quot;{{ .values.myimage }}&quot;
              command:
                - /bin/sh
                - -c
                - supercooltask.sh
          restartpolicy: never

how can i change this hook configuration to allow cronjob.yaml to only run if database.yaml deploys and runs successfully?
",<kubernetes><kubernetes-helm>,68645219,3,"use init containers in the pod spec of cron job to check db is up and running.
https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#podspec-v1-core
example:
spec:
  template:
    spec:
      initcontainers:
        ..
      containers:
        ..
      restartpolicy: onfailure

"
31870222,how can i keep a container running on kubernetes?,"i'm now trying to run a simple container with shell (/bin/bash) on a kubernetes cluster.

i thought that there was a way to keep a container running on a docker container by using pseudo-tty and detach option (-td option on docker run command).

for example,

$ sudo docker run -td ubuntu:latest


is there an option like this in kubernetes?

i've tried running a container by using a kubectl run-container command like:

kubectl run-container test_container ubuntu:latest --replicas=1


but the container exits for a few seconds (just like launching with the docker run command without options i mentioned above). and replicationcontroller launches it again repeatedly.

is there a way to keep a container running on kubernetes like the -td options in the docker run command?
",<docker><kubernetes><google-kubernetes-engine>,31879013,76,"a container exits when its main process exits. doing something like:

docker run -itd debian


to hold the container open is frankly a hack that should only be used for quick tests and examples. if you just want a container for testing for a few minutes, i would do:

docker run -d debian sleep 300


which has the advantage that the container will automatically exit if you forget about it. alternatively, you could put something like this in a while loop to keep it running forever, or just run an application such as top. all of these should be easy to do in kubernetes.

the real question is why would you want to do this? your container should be providing a service, whose process will keep the container running in the background.
"
71888593,can i configure my eks cluster's inbound rules via cdk?,"i am wondering if it is possible to configure the “public access source allowlist” from cdk. i can see and manage this in the console under the networking tab, but can’t find anything in the cdk docs about setting the allowlist during deploy. i tried creating and assigning a security group (code sample below), but this didn't work. also the security group was created as an &quot;additional&quot; security group, rather than the &quot;cluster&quot; security group.
declare const vpc: ec2.vpc;
declare const adminrole: iam.role;

const securitygroup = new ec2.securitygroup(this, 'my-security-group', {
    vpc,
    allowalloutbound: true,
    description: 'created in cdk',
    securitygroupname: 'cluster-security-group'
});

securitygroup.addingressrule(
    ec2.peer.ipv4('&lt;vpn cidr block&gt;'),
    ec2.port.tcp(8888),
    'allow frontend access from the vpn'
);

const cluster = new eks.cluster(this, 'my-cluster', {
    vpc,
    clustername: 'cluster-cdk',
    version: eks.kubernetesversion.v1_21,
    mastersrole: adminrole,
    defaultcapacity: 0,
    securitygroup
});

update: i attempted the following, and it updated the cluster security group, but i'm still able to access the frontend when i'm not on the vpn:
cluster.connections.allowfrom(
  ec2.peer.ipv4('&lt;vpn cider block&gt;'),
  ec2.port.tcp(8888)
);

update 2: i tried this as well, and i can still access my application's frontend even when i'm not on the vpn. however i can now only use kubectl when i'm on the vpn, which is good! it's a step forward that i've at least improved the cluster's security in a useful manner.
const cluster = new eks.cluster(this, 'my-cluster', {
    vpc,
    clustername: 'cluster-cdk',
    version: eks.kubernetesversion.v1_21,
    mastersrole: adminrole,
    defaultcapacity: 0,
    endpointaccess: eks.endpointaccess.public_and_private.onlyfrom('&lt;vpn cider block&gt;')
});

",<amazon-web-services><kubernetes><amazon-eks><aws-cdk>,71925054,2,"in general eks has two relevant security groups:

the one used by nodes, which aws calls &quot;cluster security group&quot;. it's setup automatically by eks. you shouldn't need to mess with it unless you want (a) more restrictive rules the defaults (b) open your nodes to maintenance taks (e.g.: ssh access). this is what you are acessing via cluster.connections.

the ingress load balancer security group. this is an application load balancer created and managed by eks. in cdk, it can be created like so:


const cluster = new eks.cluster(this, 'helloeks', {
  version: eks.kubernetesversion.v1_22,
  albcontroller: {
    version: eks.albcontrollerversion.v2_4_1,
  },
});

this will will serve as a gateway for all internal services that need an ingress. you can access it via the cluster.albcontroller propriety and add rules to it like a regular application load balancer. i have no idea how eks deals with task communication when an ingress alb is not present.
relevant docs:

amazon eks security group considerations
alb controller on cdk docs
the alb propriety for eks cluster objects

"
75610695,kubernetes informer fails with unauthorized,"i'm trying to construct a kubernetes informer outside of the eks cluster that it's watching. i'm using aws-iam-authenticator plugin to provide the exec-based credentials to the eks cluster. for the plugin to work, i'm assuming an iam role and passing the aws iam credentials as environment variables.
the problem is that these credentials expire after an hour and cause the informer to fail with

e0301 23:34:22.167817     582 runtime.go:79] observed a panic: &amp;errors.statuserror{errstatus:v1.status{typemeta:v1.typemeta{kind:&quot;&quot;, apiversion:&quot;&quot;}, listmeta:v1.listmeta{selflink:&quot;&quot;, resourceversion:&quot;&quot;, continue:&quot;&quot;, remainingitemcount:(*int64)(nil)}, status:&quot;failure&quot;, message:&quot;the server has asked for the client to provide credentials (get pods)&quot;, reason:&quot;unauthorized&quot;, details:(*v1.statusdetails)(0xc0005b0300), code:401}} (the server has asked for the client to provide credentials (get pods))

is there a better way of getting clientconfig and aws-iam-authenticator to refresh the credentials?
here's a rough skeleton of my code:
credentialsprovider := aws.newcredentialscache(stscreds.newwebidentityroleprovider(...))
creds, err := credentialsprovider.retrieve(ctx)

config := clientcmdapi.newconfig()
// ...
config.authinfos[&quot;eks&quot;] = &amp;clientcmdapi.authinfo{
    exec: &amp;clientcmdapi.execconfig{
        command: &quot;aws-iam-authenticator&quot;,
        args: []string{
            &quot;token&quot;,
            &quot;-i&quot;,
            clustername,
        },
        // these env vars are static! :(
        env: []clientcmdapi.execenvvar{
            {
                name:  &quot;aws_access_key_id&quot;,
                value: creds.accesskeyid,
            },
            {
                name:  &quot;aws_secret_access_key&quot;,
                value: creds.secretaccesskey,
            },
            {
                name:  &quot;aws_session_token&quot;,
                value: creds.sessiontoken,
            },
        },
        apiversion:      &quot;client.authentication.k8s.io/v1beta1&quot;,
        interactivemode: clientcmdapi.neverexecinteractivemode,
    },
}

restconfig, err := config.clientconfig()
clientset, err = kubernetes.newforconfig(restconfig)

informerfactory := informers.newsharedinformerfactory(clientset, time.second*30)
podinformer := cw.informerfactory.core().v1().pods().informer()

here are a couple similar threads i found:

kubernetes client-go informers getting &quot;unauthorized&quot; error after 15 mins
https://github.com/kubernetes/client-go/issues/1189

",<kubernetes><amazon-eks><client-go><aws-iam-authenticator>,75621398,1,"my solution was to create write the credentials to a file and create a background thread to refresh that file. i can then pass tell aws-iam-authenticator to read the credentials from the file via the aws_shared_credentials_file environment variable.
this might also be possible using aws_web_identity_token_file to save some steps, but i didn't look further.
the updated code looks like this
func updatecredentials(ctx context.context) {
    creds, err := c.credentialsprovider.retrieve(ctx)
    s := fmt.sprintf(`[default]
aws_access_key_id=%s
aws_secret_access_key=%s
aws_session_token=%s`, creds.accesskeyid, creds.secretaccesskey, creds.sessiontoken)
    err = os.writefile(credentialsfile.name(), []byte(s), 0666)
    return nil
}

func updatecredentialsloop(ctx context.context) {
    for {
        err := updatecredentials(ctx)
        time.sleep(5*time.minute)
    }
}

credentialsprovider := aws.newcredentialscache(stscreds.newwebidentityroleprovider(...))

credentialsfile, err := os.createtemp(&quot;&quot;, &quot;credentials&quot;)
updatecredentials(ctx)
go updatecredentialsloop(ctx)

config := clientcmdapi.newconfig()
// ...
config.authinfos[&quot;eks&quot;] = &amp;clientcmdapi.authinfo{
    exec: &amp;clientcmdapi.execconfig{
        command: &quot;aws-iam-authenticator&quot;,
        args: []string{
            &quot;token&quot;,
            &quot;-i&quot;,
            clustername,
        },
        env: []clientcmdapi.execenvvar{
            {
                name:  &quot;aws_shared_credentials_file&quot;,
                value: credentialsfile.name(),
            },
        },
        apiversion:      &quot;client.authentication.k8s.io/v1beta1&quot;,
        interactivemode: clientcmdapi.neverexecinteractivemode,
    },
}

restconfig, err := config.clientconfig()
clientset, err = kubernetes.newforconfig(restconfig)

informerfactory := informers.newsharedinformerfactory(clientset, time.second*30)
podinformer := cw.informerfactory.core().v1().pods().informer()

"
64320978,"kubernetes apply all files inside a directory, ""kubectl apply --all""?","just wondering, let's say i have x kubernetes deployment.yaml, pod.yaml, persistedvolumecliam.yaml and service.yaml files inside a directory.
the tutorials would tell us to do the following:
kubectl apply -f frontend-service.yaml,redis-master-service.yaml,redis-slave-service.yaml,frontend-deployment.yaml,redis-master-deployment.yaml,redis-slave-deployment.yaml

is there a way just to do something like:
kubectl apply all

or
kubectl apply -f *

or some variation thereof to spin all of the kube stuffs within on directory?
",<kubernetes><kubectl>,64321019,7,"you can apply everything inside a directory with kubectl apply -f /path/to/dir. to include subdirectories use the paramter -r, like kubectl apply -r -f /path/to/dir
"
66246162,how to parse .env file (dotenv) with helm template?,"i'm migrating from docker to helm3. my docker deployment uses .env files to load environment variables see reference. during the migration i need to support both the old way and new way so i don't want change the .env format if i can avoid it.
here's my sample .env file:
key1=value1
key2=value2

then in my helm3 deployment.yaml i need:
kind: deployment
spec:
  template:
    spec:
      containers:
          env:
            - name: key1
              value: &quot;value1&quot;
            - name: key2
              value: &quot;value2&quot;

the .env file is the helm project root directory so i'm hoping i can do something like this based on this question but not sure how to proceed:
  {{- $files := .files }}
  #not sure how to select just one file?
  {{- range tuple &quot;.env&quot; }}
  
      #split file by newlines and =
      {{- range $line := splitlist &quot;\n&quot; $files.get . }}
        {{/* break the line into words */}}
        {{- $kv := splitlist &quot;=&quot; $line -}}
        {{- $k := first $kv -}}
        {{ $k }}: {{ last $kv | quote }}
      {{- end }}

  {{- end }}

",<docker><kubernetes><environment-variables><kubernetes-helm>,78504811,2,"related to the answer of @charlie, if the environment value contains = symbol, it will break. i fixed this issue with join function as follow:
{{ $file := .files.get &quot;.env&quot; | trimsuffix &quot;\n&quot; }}
{{- range $line := splitlist &quot;\n&quot; $file -}}
{{- $kv := splitlist &quot;=&quot; $line -}}
    {{ &quot;&quot; }}
    - name: {{ first $kv }}
      value: {{ join &quot;=&quot; (slice $kv 1) | quote }}
{{- end }}

"
50015081,kubectl delete/create secret forbidden (google cloud platform),"i was following the following tutorial on continuous integration using gitlab and kubernetes (in my case on google cloud): https://about.gitlab.com/2016/12/14/continuous-delivery-of-a-spring-boot-application-with-gitlab-ci-and-kubernetes/.

at some point in the tutorial you will have to first delete and then create a secret for the image registry of gitlab:

- kubectl delete secret registry.gitlab.com
- kubectl create secret docker-registry registry.gitlab.com --docker-server=https://registry.gitlab.com --docker-username=$registry_username --docker-password=$registry_passwd --docker-email=$email


things go wrong in this step, i get the following error:

error from server (forbidden): secrets ""registry.gitlab.com"" is forbidden: user ""client"" cannot delete secrets in the namespace ""default"": unknown user ""client""
error from server (forbidden): secrets is forbidden: user ""client"" cannot create secrets in the namespace ""default"": unknown user ""client""


i get the same exact error in the google cloud shell:



adding the following line does not really help, i still get the creation error (i am also 100% sure that the deletion also 'crashes' but the '2>/dev/null' just makes it move to the creation step):

kubectl delete secret registry.gitlab.com 2&gt;/dev/null || echo ""secret does not exist""


what am i doing wrong? thx in advance!
",<docker><kubernetes><google-cloud-platform><kubectl>,50015208,8,"run gcloud config unset container/use_client_certificate

after this logout and login. it should work. this happens when you disable legacy authorisation in the cluster settings, because the client certificate that you are using is a legacy authentication method
"
53499074,gitlab ci in gke private cluster can't connect to master,"so far we have been using gke public cluster for all our workloads. we have created a second, private cluster (still gke) with improved security and availability (old one is single zone, new one is regional cluster). we are using gitlab.com for our code, but using self-hosted gitlab ci runner in the clusters.

the runner is working fine on the public cluster, all workloads complete successfully. however on the private cluster, all kubectl commands of thr ci fail with unable to connect to the server: dial tcp &lt;ip&gt;:443: i/o timeout error. the ci configuration has not changed - same base image, still using gcloud sdk with a ci-specific service account to authenticate to the cluster.

both clusters have master authorized networks enabled and have only our office ips are set. master is accessible from a public ip. authentication is successful, client certificate &amp; basic auth are disabled on both. cloud nat is configured, nodes have access to the internet (can pull container images, gitlab ci can connect etc).

am i missing some vital configuration? what else should i be looking at?
",<kubernetes><gitlab><gitlab-ci><google-kubernetes-engine>,53501183,3,"i have found the solution to my problem, but i am not fully sure of the cause.

i used gcloud container clusters get-credentials [cluster_name], which gave the master's public endpoint. however that is inaccessible from within the cluster for some reason - so i assume it would require adding the public ip of the nat (which is not statically provided) to the authorized networks.

i added the --internal-ip flag, which gave the cluster's internal ip address. the ci is now able to connect to the master.

source: https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl#internal_ip

tl;dr - gcloud container clusters get-credentials --internal-ip [cluster_name] 
"
74115702,"how to convert deployment, configmap and service yaml files to helm package","i have an application with many services that are deployed in kubernetes. these services are represented by yaml files like configmap.yaml and deployment.yaml.
how can i convert these files to helm charts et deploy the application using:
helm install 
 

",<kubernetes><kubernetes-helm>,74124060,2,"if you run helm create to create a skeleton chart, that will create a basic file structure for you.  within that chart, the templates directory contains a set of templated yaml files.
if you're just getting started, it's enough to move aside the yaml files that helm create generates and copy your existing yaml into the templates directory.  helm install will install those exact files, similar to what kubectl apply would do, though note that the specific named resources need to not exist yet in the cluster.
helm create my-chart
cd my-chart
mkdir original-templates &amp;&amp; mv templates/*.yml original-templates
cp ~/application/k8s/*.yml templates
# helm template .
helm install --generate-name .

if you do look at the helm create template files, you'll notice that there are some conventions on how it chooses things like resource names, calling support functions in the _helpers.tpl file that allow installing the chart multiple times in parallel.  a good next step would be to update the metadata: blocks in the yaml files to follow these conventions.
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ include &quot;mychart.fullname&quot; . }}
  labels:
    {{- include &quot;mychart.labels&quot; . | nindent 4 }}
spec:
  ...

from there i'd suggest figuring out what specific things you need to have customized at install time, and replace those with template expressions and specific values.yaml settings.  i would not try to inject large parts of the kubernetes configuration through values, though the boundary can be a little blurry here.  (it makes sense to me to specify a service type, node port, and annotations through values, but not necessarily a long list of pod environment variables.)
"
55940828,what is the best way to setup proxy pass in an nginx ingress object for kubernetes,"currently i am trying to migrate a site that was living on an apache load balanced server to my k8s cluster. however the application was set up strangely with a proxypass and proxyreversepass like so:

proxypass /something http://example.com/something
proxypassreverse /something http://example.com/something


and i would like to mimic this in an nginx ingress

first i tried using the rewrite-target annotation however that does not keep the location header which is necessary to get the application running again. 

then i tried to get the proxy-redirect-to/from annotation in place inside a specific location block like so:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: gpg-app-ingress
  annotations:
    nginx.ingress.kubernetes.io/proxy-redirect-from: http://originalapp.com/something
    nginx.ingress.kubernetes.io/proxy-redirect-to: http://example.com/something
spec:
  rules:
  - host: example.com
    http:
      paths:
        - path: /something
          backend:
            servicename: example-com
            serviceport: 80


i would like to be able to instead use a custom proxy_pass variable but it doesn't seem like its possible.

what would be the best way to mimic this proxy pass?
",<nginx><kubernetes><proxy><kubernetes-ingress><nginx-ingress>,56148241,16,"firstly you can use custom configuration for your nginx ingress controller, documentation can be found here

also, if you just want to use nginx ingress controller as a reverse proxy, each ingress rule already creates proxy_pass directive to relevant upstream/backend service. 

and if paths are same with your rule and backend service, then you don't have to specify rewrite rule, only just path for backend service. but if paths
are different, then take consider using nginx.ingress.kubernetes.io/rewrite-target annotation, otherwise you will get 404 backend error

so to redirect request from which is coming to frontend http://example.com/something to backend example-com/something, your ingress rule should be similar to below

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: gpg-app-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
   #nginx.ingress.kubernetes.io/rewrite-target: /different-path
spec:
  rules:
  - host: example.com
    http:
      paths:
        - path: /something
          backend:
            servicename: example-com
            serviceport: 80


for more explanation about annotations, check nginx ingress annotations

also, consider checking logs of nginx-ingress-controller pod via if something wrong

kubectl logs nginx-ingress-controller-xxxxx


hope it helps!
"
26741451,"with google container engine, how to create a cluster with more than 3 nodes?","if i start a google container engine cluster like this:

gcloud container clusters --zone=$zone create $cluster_name


i get three worker nodes.  how can i create a cluster with more?
",<kubernetes><google-kubernetes-engine>,26741667,9,"it's possible to create a different number of worker nodes by using the --num-nodes option when you create the cluster, like this:

gcloud container clusters --zone=$zone create $cluster_name --num-nodes=5

"
61282507,kubectl version showing the wrong version number,"i have downloaded kubernetes latest version from kubernetes official site and referenced it in the path above the reference for docker but it is still showing the version installed with docker desktop.

i understand that docker comes with kubernetes installed out of the box but the docker version '1.15.5' doesn't work correctly with my minikube version which is 'v1.9.2' which is causing me problems.

any suggestions on how to fix this issues? should i remove the kubernetes binary from c:\program files\docker\docker\resources\bin i don't think that will be a good idea.

can someone help me tackle this issue, along with some explanation on how the versions work with each other? thanks
",<docker><kubernetes><kubectl><hyper-v><minikube>,61317795,1,"this is happening because windows always give you the first comment found in the path, both kubectl versions (docker and yours) are in the path but docker path in being referenced before your kubectl path. 

to solve this really depends on what you need. if you are not using your docker kubernetes you have two alternatives: 

1 - fix your path and make sure that your kubectl path is referenced before docker path.

2 - replace docker kubectl to yours.

3- make sure you restart your pc after doing these changes, as kubectl will automatically update the configuration to point to the newer kubectl version the next time you use the minikube start command with a correct --kubernetes-version:

if you are using both from time to time, i would suggest you to create a script that will change your path according to your needs. 

according to the documentation you must use a kubectl version that is within one minor version difference of your cluster. for example, a v1.2 client should work with v1.1, v1.2, and v1.3 master. using the latest version of kubectl helps avoid unforeseen issues.
"
56271232,"getting ""crashloopbackoff"" as status of deployed pod","how to debug why it's status is crashloopbackoff?

i am not using minikube , working on aws kubernetes instance.

i followed this tutorial.
https://github.com/mkjelland/spring-boot-postgres-on-k8s-sample

when i do 

  kubectl create -f specs/spring-boot-app.yml


and check status by 

  kubectl get pods 


it gives 

     spring-boot-postgres-sample-67f9cbc8c-qnkzg   0/1     crashloopbackoff   14         50m


below command 

 kubectl describe pods spring-boot-postgres-sample-67f9cbc8c-qnkzg


gives 

events:
  type     reason   age                    from                      message
  ----     ------   ----                   ----                      -------
  warning  backoff  3m18s (x350 over 78m)  kubelet, ip-172-31-11-87  back-off restarting failed container


command kubectl get pods --all-namespaces gives 

namespace     name                                           ready   status             restarts   age
default       constraintpod                                  1/1     running            1          88d
default       postgres-78f78bfbfc-72bgf                      1/1     running            0          109m
default       rcsise-krbxg                                   1/1     running            1          87d
default       spring-boot-postgres-sample-667f87cf4c-858rx   0/1     crashloopbackoff   4          110s
default       twocontainers                                  2/2     running            479        89d
kube-system   coredns-86c58d9df4-kr4zj                       1/1     running            1          89d
kube-system   coredns-86c58d9df4-qqq2p                       1/1     running            1          89d
kube-system   etcd-ip-172-31-6-149                           1/1     running            8          89d
kube-system   kube-apiserver-ip-172-31-6-149                 1/1     running            1          89d
kube-system   kube-controller-manager-ip-172-31-6-149        1/1     running            1          89d
kube-system   kube-flannel-ds-amd64-4h4x7                    1/1     running            1          89d
kube-system   kube-flannel-ds-amd64-fcvf2                    1/1     running            1          89d
kube-system   kube-proxy-5sgjb                               1/1     running            1          89d
kube-system   kube-proxy-hd7tr                               1/1     running            1          89d
kube-system   kube-scheduler-ip-172-31-6-149                 1/1     running            1          89d


command kubectl logs spring-boot-postgres-sample-667f87cf4c-858rx
doesn't print anything.
",<kubernetes><kubernetes-pod>,56278149,2,"first of all i fixed by postgres deployment, there was some error of ""pod has unbound persistentvolumeclaims"" , so i fixed that error by this post 
pod has unbound persistentvolumeclaims

so now my postgres deployment is running. 

kubectl logs spring-boot-postgres-sample-67f9cbc8c-qnkzg doesn't print anything, it means there is something wrong in config file.
kubectl describe pod spring-boot-postgres-sample-67f9cbc8c-qnkzg stating that container is terminated and reason is completed,
i fixed it by running container infinity time
by adding 

   # just sleep forever
command: [ ""sleep"" ]
args: [ ""infinity"" ]


so now my deployment is running.
but now i exposed my service by 

kubectl expose deployment spring-boot-postgres-sample --type=loadbalancer --port=8080


but can't able to get external-ip , so i did 

kubectl patch svc &lt;svc-name&gt; -n &lt;namespace&gt; -p '{""spec"": {""type"": ""loadbalancer"", ""externalips"":[""172.31.71.218""]}}'


so i get my external-ip as ""172.31.71.218""

but now the problem is curl http://172.31.71.218:8080/ getting timeout

anything i did wrong?

here is my deployment.yml

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: spring-boot-postgres-sample
  namespace: default
spec:
  replicas: 1
  template:
    metadata:
      name: spring-boot-postgres-sample
      labels:
        app: spring-boot-postgres-sample
    spec:
      containers:
      - name: spring-boot-postgres-sample
        command: [ ""/bin/bash"", ""-ce"", ""tail -f /dev/null"" ]
        env:
          - name: postgres_user
            valuefrom:
              configmapkeyref:
                name: postgres-config
                key: postgres_user
          - name: postgres_password
            valuefrom:
              configmapkeyref:
                name: postgres-config
                key: postgres_password
          - name: postgres_host
            valuefrom:
              configmapkeyref:
                name: hostname-config
                key: postgres_host
        image: &lt;mydockerhubaccount&gt;/spring-boot-postgres-on-k8s:v1


here is my postgres.yml

apiversion: v1
kind: configmap
metadata:
  name: postgres-config
  namespace: default
data:
  postgres_user: postgresuser
  postgres_password: password
---
apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: postgres
spec:
  template:
    metadata:
      labels:
        app: postgres
    spec:
      volumes:
        - name: postgres-storage
          persistentvolumeclaim:
            claimname: postgres-pv-claim
      containers:
        - image: postgres
          name: postgres
          env:
            - name: postgres_user
              valuefrom:
                configmapkeyref:
                  name: postgres-config
                  key: postgres_user
            - name: postgres_password
              valuefrom:
                configmapkeyref:
                  name: postgres-config
                  key: postgres_password
            - name: pgdata
              value: /var/lib/postgresql/data/pgdata
          ports:
            - containerport: 5432
              name: postgres
          volumemounts:
            - name: postgres-storage
              mountpath: /var/lib/postgresql/data
---
apiversion: v1
kind: service
metadata:
  name: postgres
spec:
  type: clusterip
  ports:
    - port: 5432
  selector:
    app: postgres


here how i got host-config map

kubectl create configmap hostname-config --from-literal=postgres_host=$(kubectl get svc postgres -o jsonpath=""{.spec.clusterip}"")

"
52890728,how to connect to google kubernetes engine with kubernetes python client,"i'm using kubernetes python client to manage my local kubernetes cluster:

from kubernetes import client, config


config = client.configuration()
config.host = ""http://local_master_node:8080""
client.configuration.set_default(config)
print(client.corev1api().v1.list_node())


everything works fine until i need to connect to a project on google cloud kubernetes engine using the key file provided by customer owning the project from google like:

{
    ""type"": ""..."",
    ""project_id"": ""..."",
    ""private_key_id"": ""..."",
    ""private_key"": ""..."",
    ""client_email"": ""..."",
    ""client_id"": ""..."",
    ""auth_uri"": ""https://accounts.google.com/o/oauth2/auth"",
    ""token_uri"": ""https://accounts.google.com/o/oauth2/token"",
    ""auth_provider_x509_cert_url"": ""https://www.googleapis.com/oauth2/v1/certs"",
    ""client_x509_cert_url"": ""https://www.googleapis.com/...""
}


i'm trying to load it (probably doing it in wrong way):

os.environ['google_application_credentials'] = os.path.abspath('credentials.json')
config.load_incluster_config()


but this code raises an exception  kubernetes.config.config_exception.configexception: service host/port is not set.

the questions are:


how to provide google credentials for kubernetes python client properly?
if i am on the right track then where can i find the host/port for using with google cloud?


some snippets will be appreciated. 
",<python><authentication><kubernetes><google-cloud-platform><google-kubernetes-engine>,52946983,9,"finally, i myself found the solution.

first, you need to get kubernetes configuration file. so, go to google cloud platform kubernetes engine panel. select cluster you want to connect and press the connect button. select run in cloud shell and after you have logged into the shell type suggested string like:

$ gcloud container clusters get-credentials ...


then you can find in ~/.kube folder the configuration file. save its content to a yaml-file which you should feed to kubernetes.config.load_kube_config function:

os.environ['google_application_credentials'] = os.path.abspath('credentials.json')
config.load_kube_config(os.path.abspath('config.yaml'))

"
50213721,installing jenkins-x on gke,"this may sound like a stupid question, but i am installing jenkins-x on a kubernetes cluster on gke.  when i install through cloud shell, the /usr/local/bin folder i am moving it to is refreshed every time the shell is restarted.

my question is two-fold:


am i correct in installing jenkins-x through cloud shell (and not on a particular node)?
how can i get it so the /jx folder is available when the cloud shell is restarted (or at least have the /jx folder on the path at all times)?

",<jenkins><kubernetes><google-kubernetes-engine>,50391245,2,"i am running jx from the cloud shell


in the cloud shell you are already logged in and you have a project configured.  to prevent jx to re-login to google cloud/project use the following arguments

jx create cluster gke  --skip-login=true --project-id projectid

download jx to ~/bin and update $path to include both ~/bin and ~/.jx/bin. put the following to ~/.profile

if [ -d ""$home/bin"" ] ; then
    path=""$home/bin:$path""
fi

path=""$home/.jx/bin:$path""


the .jx/bin is the place where jx downloads helm if needed.

"
52915110,unable to connect to the server: x509: certificate is valid for,"os: mac os 10.13.6  terminal

kubectl for remote access

when i execute the command with ""--insecure-skip-tls-verify"" it works fine.  

dev-env at balabimac in ~/kthw
$ kubectl --insecure-skip-tls-verify --context=kubernetes-me get pods
no resources found.
dev-env at balabimac in ~/kthw
$ kubectl --insecure-skip-tls-verify --context=kubernetes-me get nodes
name                        status     roles    age   version
balab29123.mylabserver.com   notready   &lt;none&gt;   4h    v1.10.2
balab29124.mylabserver.com   notready   &lt;none&gt;   4h    v1.10.2
dev-env at balabimac in ~/kthw
$ kubectl --insecure-skip-tls-verify --context=kubernetes-me version
client version: version.info{major:""1"", minor:""12"", gitversion:""v1.12.0"", gitcommit:""0ed33881dc4355495f623c6f22e7dd0b7632b7c0"", gittreestate:""clean"", builddate:""2018-09-28t15:20:58z"", goversion:""go1.11"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""10"", gitversion:""v1.10.2"", gitcommit:""81753b10df112992bf51bbc2c2f85208aad78335"", gittreestate:""clean"", builddate:""2018-04-27t09:10:24z"", goversion:""go1.9.3"", compiler:""gc"", platform:""linux/amd64""}


but i am unable to access using the below command, i am stuck.

dev-env at balabimac in ~/kthw
$ kubectl config use-context kubernetes-me
switched to context ""kubernetes-me"".
dev-env at balabimac in ~/kthw
$ kubectl get pods
unable to connect to the server: x509: certificate is valid for balab29121.mylabserver.com, balab29122.mylabserver.com, balab29126.mylabserver.com, 127.0.0.1.localhost, kubernetes.default, not localhost
dev-env at balabimac in ~/kthw
$ kubectl get nodes
unable to connect to the server: x509: certificate is valid for balab29121.mylabserver.com, balab29122.mylabserver.com, balab29126.mylabserver.com, 127.0.0.1.localhost, kubernetes.default, not localhost
dev-env at balabimac in ~/kthw

",<kubernetes><google-kubernetes-engine><kubernetes-health-check>,53074512,2,"it looks like when you generated the kubernetes api server certificate, you put 127.0.0.1.localhost instead of 127.0.0.1,localhost . just a small typo, but as a result the cert is not properly signed for localhost, which will lead to this error when you are trying to connect. re-generate the kube api server cert with the correct values. then copy the cert files to your control nodes and put the files in the correct place, replacing the old files.

dev-env at balabimac in ~/kthw 
$ kubectl get pods unable to connect to the server: x509: certificate is valid for balab29121.mylabserver.com, balab29122.mylabserver.com, balab29126.mylabserver.com, **127.0.0.1.localhost**, kubernetes.default, not localhost

"
66319182,"kubectl get pods' command fails on windows, works on wsl2","the kubernetes documentation includes an example command for listing container images by pod:

list container images by pod
the formatting can be controlled further by using the range operation to iterate over elements individually.
kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{&quot;\n&quot;}{.metadata.name}{&quot;:\t&quot;}{range .spec.containers[*]}{.image}{&quot;, &quot;}{end}{end}' |\
sort


when i run this command in my debian wsl2 instance, it correctly lists the containers for each pod i have running across all namespaces.
when i run the same command in the windows commandline, i get an error: error: a resource cannot be retrieved by name across all namespaces:
c:\workspace&gt;kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{&quot;\n&quot;}{.metadata.name}{&quot;:\t&quot;}{range .spec.containers[*]}{.image}{&quot;, &quot;}{end}{end}' | sort
error: a resource cannot be retrieved by name across all namespaces

is this a bug with kubectl, or is this command *nix only? is there an os-independent command for getting container images by pod across all namespaces?
(i'm running debian on wsl2, windows 10 enterprise. docker desktop using wsl2 integration, k8s with minikube.)
",<kubernetes><kubectl>,66320111,2,"from k8s offical doc:

on windows, you must double quote any jsonpath template that contains spaces (not single quote as shown above for bash). this in turn means that you must use a single quote or escaped double quote around any literals in the template. for example: kubectl get pods -o=jsonpath=&quot;{range .items[*]}{.metadata.name}{'\t'}{.status.starttime}{'\n'}{end}&quot;

i think this will solve your problem.
"
69979101,reference a secret's value when the key contains a (.) dot?,"my secret file looks like:
apiversion: v1
kind: secret
metadata:
  name: secret
type: opaque
stringdata:
  &quot;user.name&quot;:  &quot;user&quot;
  &quot;user.password&quot;:  &quot;password&quot;

and i am trying to get a value with the next code:
{{- $secret := lookup &quot;v1&quot; &quot;secret&quot; .release.namespace &quot;secret&quot; -}}
  {{- if $secret -}}
       {{- print $secret.data.user.password}}

the problem is &quot;user.password&quot;  key contains a dot and i haven't found how to fix it.
thanks for any help!
",<go><kubernetes><kubernetes-helm><go-templates>,69979272,5,"you can use the index function to access map values with dots in them like:
{{- print (index $secret.data &quot;user.password&quot;)}}

"
74599464,how to get the k8s ingress wildcard in the host and put it on the url path,"i use k8s to deploy my services.
i hope when i access the ingress host foo.example.com and the ingress forward it to server:8000/proxy/foo. the subdomain foo is dynamic and can be changed to any word. the expected result is as below:

foo.example.com -&gt; server:8000/proxy/foo
bar.example.com -&gt; server:8000/proxy/bar
......

i knew the ingress host could use wildcards and use ingress-nginx rewrite can rewrite the url path. i use the ingress-nginx controller. the ingress yaml file like as below:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /proxy/${wildcard}/$1 # could i use the host wildcard here?
name: nginx-forward
spec:
  rules:
  - host: *.example.com # i want to get the subdomain wildcard
    http:
      paths:
      - backend:
        service:
          name: service
        port:
          number: 8080
      path: /(.*)
      pathtype: prefix
  tls: # update this attribute
  - hosts:
    - *.example.com 
    secretname: my-secret

how could i use k8s ingress or other things to get what i want? thanks.
",<kubernetes><kubernetes-ingress>,74601424,2,"you can use server snippet to get the subdomain:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/server-snippet: |
      server_name     ~^(?&lt;subdomain&gt;\w+)\.example\.com$;
    nginx.ingress.kubernetes.io/rewrite-target: /proxy/$subdomain/$1 
name: nginx-forward
spec:
  rules:
  - http:
      paths:
      - backend:
        service:
          name: service
        port:
          number: 8080
      path: /(.*)
      pathtype: prefix

"
39667667,how to (re) use an existent static ip address when creating a tls ingress resource?,"i'm creating an (tls enabled) ingress resource using following configurations:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-app-apis
spec:
  tls:
  - secretname: tls-secret
  backend:
    servicename: my-web-service
    serviceport: 80


a new static ip address is provisioned everytime.
is it possible to reuse an existent one ?

(i'm using kubernetes running on gke)
",<google-compute-engine><kubernetes><google-kubernetes-engine>,39922899,4,"you can specify the ip address in an annotation on the ingress (it looks like you specify it by name rather than ip address). this is only picked up by the gce controller so don't expect it to work anywhere other than gce/gke.

https://github.com/kubernetes/contrib/blob/master/ingress/controllers/gce/controller/utils.go#l48

something like this should work:

apiversion: extensions/v1beta1
kind: ingress
metadata:
 name: myingress
 annotations:
   ""kubernetes.io/ingress.global-static-ip-name"": my-ip-name
spec:
  ...

"
52823308,what parameters should i pass for the schema-registry to run on non-master mode?,"i want to run the schema-registry in non-master-mode in kubernetes, i passed the environment variable master.eligibility=false, however, it's still electing the master.
please point me where else i should change the configuration! there are no errors in the environment value being wrong.
cmd:
helm install helm-test-0.1.0.tgz --set env.name.schema_registry_kafkastore_bootservers=&quot;plaintext://xx.xx.xx.xx:9092\,plaintext://xx.xx.xx.xx:9092\,plaintext://xx.xx.xx.xx:9092&quot; --set env.name.schema_registry_listeners=&quot;http://0.0.0.0:8083&quot; --set env.name.schema_registry_master_eligibility=false

details:
replicacount: 1

image:
  repository: confluentinc/cp-schema-registry
  tag: &quot;5.0.0&quot;
  pullpolicy: ifnotpresent
  env:
    name:
       schema_registry_kafkastore_bootstrap_servers: &quot;plaintext://xx.xxx.xx.xx:9092, plaintext://xx.xxx.xx.xx:9092, plaintext://xx.xxx.xx.xx:9092&quot;
       schema_registry_listeners: &quot;http://0.0.0.0:8883&quot;
       schema_registry_host_name: localhost
       schema_registry_master_eligibility: false


pod - schema-registry properties:
root@test-app-788455bb47-tjlhw:/# cat /etc/schema-registry/schema-registry.properties
master.eligibility=false
listeners=http://0.0.0.0:8883
host.name=xx.xx.xxx.xx
kafkastore.bootstrap.servers=plaintext://xx.xx.xx.xx:9092,plaintext://xx.xx.xx.xx:9092,plaintext://xx.xx.xx.xx:9092 


echo &quot;===&gt; launching ... &quot;
+ echo '===&gt; launching ... '
exec /etc/confluent/docker/launch
+ exec /etc/confluent/docker/launch
===&gt; launching ...
===&gt; launching schema-registry ...
[2018-10-15 18:52:45,993] info schemaregistryconfig values:
        resource.extension.class = []
        metric.reporters = []
        kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
        response.mediatype.default = application/vnd.schemaregistry.v1+json
        kafkastore.ssl.trustmanager.algorithm = pkix
        inter.instance.protocol = http
        authentication.realm =
        ssl.keystore.type = jks
        kafkastore.topic = _schemas
        metrics.jmx.prefix = kafka.schema.registry
        kafkastore.ssl.enabled.protocols = tlsv1.2,tlsv1.1,tlsv1
        kafkastore.topic.replication.factor = 3
        ssl.truststore.password = [hidden]
        kafkastore.timeout.ms = 500
        host.name = xx.xxx.xx.xx
        kafkastore.bootstrap.servers = [plaintext://xx.xxx.xx.xx:9092, plaintext://xx.xxx.xx.xx:9092, plaintext://xx.xxx.xx.xx:9092]
        schema.registry.zk.namespace = schema_registry
        kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
        kafkastore.sasl.kerberos.service.name =
        schema.registry.resource.extension.class = []
        ssl.endpoint.identification.algorithm =
        compression.enable = false
        kafkastore.ssl.truststore.type = jks
        avro.compatibility.level = backward
        kafkastore.ssl.protocol = tls
        kafkastore.ssl.provider =
        kafkastore.ssl.truststore.location =
        response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
        kafkastore.ssl.keystore.type = jks
        authentication.skip.paths = []
        ssl.truststore.type = jks
        kafkastore.ssl.truststore.password = [hidden]
        access.control.allow.origin =
        ssl.truststore.location =
        ssl.keystore.password = [hidden]
        port = 8081
        kafkastore.ssl.keystore.location =
        metrics.tag.map = {}
        master.eligibility = false

logs of the schema-registry pod:
(org.apache.kafka.clients.consumer.consumerconfig)
[2018-10-15 18:52:48,571] info kafka version : 2.0.0-cp1 (org.apache.kafka.common.utils.appinfoparser)
[2018-10-15 18:52:48,571] info kafka commitid : 4b1dd33f255ddd2f (org.apache.kafka.common.utils.appinfoparser)
[2018-10-15 18:52:48,599] info cluster id: v-mgqtptqnuwk_k9-wot1q (org.apache.kafka.clients.metadata)
[2018-10-15 18:52:48,602] info initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.kafkastorereaderthread)
[2018-10-15 18:52:48,605] info [kafka-store-reader-thread-_schemas]: starting (io.confluent.kafka.schemaregistry.storage.kafkastorereaderthread)
[2018-10-15 18:52:48,715] info [consumer clientid=kafkastore-reader-_schemas, groupid=schema-registry-10.100.4.189-8083] resetting offset for partition _schemas-0 to offset 0. (org.apache.kafka.clients.consumer.internals.fetcher)
[2018-10-15 18:52:48,721] info cluster id: v-mgqtptqnuwk_k9-wot1q (org.apache.kafka.clients.metadata)
[2018-10-15 18:52:48,775] info wait to catch up until the offset of the last message at 228 (io.confluent.kafka.schemaregistry.storage.kafkastore)
[2018-10-15 18:52:49,831] info joining schema registry with kafka-based coordination (io.confluent.kafka.schemaregistry.storage.kafkaschemaregistry)
[2018-10-15 18:52:49,852] info kafka version : 2.0.0-cp1 (org.apache.kafka.common.utils.appinfoparser)
[2018-10-15 18:52:49,852] info kafka commitid : 4b1dd33f255ddd2f (org.apache.kafka.common.utils.appinfoparser)
[2018-10-15 18:52:49,909] info cluster id: v-mgqtptqnuwk_k9-wot1q (org.apache.kafka.clients.metadata)
[2018-10-15 18:52:49,915] info [schema registry clientid=sr-1, groupid=schema-registry] discovered group coordinator ip-10-150-4-5.ec2.internal:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.abstractcoordinator)
[2018-10-15 18:52:49,919] info [schema registry clientid=sr-1, groupid=schema-registry] (re-)joining group (org.apache.kafka.clients.consumer.internals.abstractcoordinator)
[2018-10-15 18:52:52,975] info [schema registry clientid=sr-1, groupid=schema-registry] successfully joined group with generation 92 (org.apache.kafka.clients.consumer.internals.abstractcoordinator)
[2018-10-15 18:52:52,980] info finished rebalance with master election result: assignment{version=1, error=0, master='sr-1-abcd4cf2-8a02-4105-8361-9aa82107acd8', masteridentity=version=1,host=ip-xx-xxx-xx-xx.ec2.internal,port=8083,scheme=http,mastereligibility=true} (io.confluent.kafka.schemaregistry.masterelector.kafka.kafkagroupmasterelector)
[2018-10-15 18:52:53,088] info adding listener: http://0.0.0.0:8083 (io.confluent.rest.application)
[2018-10-15 18:52:53,347] info jetty-9.4.11.v20180605; built: 2018-06-05t18:24:03.829z; git: d5fc0523cfa96bfebfbda19606cad384d772f04c; jvm 1.8.0_172-b01 (org.eclipse.jetty.server.server)
[2018-10-15 18:52:53,428] info defaultsessionidmanager workername=node0 (org.eclipse.jetty.server.session)
[2018-10-15 18:52:53,429] info no sessionscavenger set, using defaults (org.eclipse.jetty.server.session)
[2018-10-15 18:52:53,432] info node0 scavenging every 660000ms (org.eclipse.jetty.server.session)
oct 15, 2018 6:52:54 pm org.glassfish.jersey.internal.inject.providers checkproviderruntime
warning: a provider io.confluent.kafka.schemaregistry.rest.resources.subjectsresource registered in server runtime does not implement any provider interfaces applicable in the server runtime. due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.subjectsresource will be ignored.
oct 15, 2018 6:52:54 pm org.glassfish.jersey.internal.inject.providers checkproviderruntime
warning: a provider io.confluent.kafka.schemaregistry.rest.resources.configresource registered in server runtime does not implement any provider interfaces applicable in the server runtime. due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.configresource will be ignored.
oct 15, 2018 6:52:54 pm org.glassfish.jersey.internal.inject.providers checkproviderruntime
warning: a provider io.confluent.kafka.schemaregistry.rest.resources.schemasresource registered in server runtime does not implement any provider interfaces applicable in the server runtime. due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.schemasresource will be ignored.
oct 15, 2018 6:52:54 pm org.glassfish.jersey.internal.inject.providers checkproviderruntime
warning: a provider io.confluent.kafka.schemaregistry.rest.resources.subjectversionsresource registered in server runtime does not implement any provider interfaces applicable in the server runtime. due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.subjectversionsresource will be ignored.
oct 15, 2018 6:52:54 pm org.glassfish.jersey.internal.inject.providers checkproviderruntime
warning: a provider io.confluent.kafka.schemaregistry.rest.resources.compatibilityresource registered in server runtime does not implement any provider interfaces applicable in the server runtime. due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.compatibilityresource will be ignored.
[2018-10-15 18:52:54,364] info hv000001: hibernate validator 5.1.3.final (org.hibernate.validator.internal.util.version)
[2018-10-15 18:52:54,587] info started o.e.j.s.servletcontexthandler@764faa6{/,null,available} (org.eclipse.jetty.server.handler.contexthandler)
[2018-10-15 18:52:54,619] info started o.e.j.s.servletcontexthandler@14a50707{/ws,null,available} (org.eclipse.jetty.server.handler.contexthandler)
[2018-10-15 18:52:54,642] info started networktrafficserverconnector@62656be4{http/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.abstractconnector)
[2018-10-15 18:52:54,644] info started @9700ms (org.eclipse.jetty.server.server)
[2018-10-15 18:52:54,644] info server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.schemaregistrymain)

",<kubernetes><apache-kafka><kubernetes-helm><confluent-schema-registry>,52824333,2,"i checked and your configs look good. i believe, it is, in fact, starting as a follower and the logs are basically displaying who the master is in this case:
assignment{version=1, error=0, master='sr-1-abcd4cf2-8a02-4105-8361-9aa82107acd8', masteridentity=version=1,host=ip-xx-xxx-xx-xx.ec2.internal,port=8083,scheme=http,mastereligibility=true}
"
51067786,kubernetes failed to discover supported resources: getsockopt: connection refused,"i am going through the kubernetes tutorial at udacity. when i run the the nginx image using the following command 

kubectl run nginx --image=nginx:1.10.0


it given me the error 


  error: failed to discover supported resources: get http://localhost:8080/apis/extensions/v1beta1: dial tcp 127.0.0.1:8080: getsockopt: connection refused


if i try to get pods using the following command

kubectl get pods


it says


  the connection to the server localhost:8080 was refused - did you specify the right host or port?


the nginx server is running, i can tell because i can get the appropriate output by running curl http://127.0.0.1

i am not able to figure out what the issue is, and there are not a lot of resources on the internet for this problem. can anyone please tell me how do i resolve it?
",<docker><kubernetes><google-kubernetes-engine>,51068093,4,"check your kubectl config file (~/.kube/config)

for testing purposes, you can use the admin one:

kubectl --kubeconfig /etc/kubernetes/admin.conf get po


or (again, for testing)

sudo cp /etc/kubernetes/admin.conf $home/
sudo chown $(id -u):$(id -g) $home/admin.conf
export kubeconfig=$home/admin.conf


you can see more suggestions in kubernetes/kubernetes issue 23726

as commented below, that requires kubernetes to be installed, for the node to be able to join a cluster:

sudo kubeadm join --token token master_ip:6443

"
54698875,gcloud kubernetes cluster with 1 insufficient cpu error,"i created a kubernetes cluster on google cloud using:

gcloud container clusters create my-app-cluster --num-nodes=1


then i deployed my 3 apps (backend, frontend and a scraper) and created a load balancer. i used the following configuration file:

apiversion: apps/v1
kind: deployment
metadata:
    name: my-app-deployment
    labels:
        app: my-app
spec:
    replicas: 1
    selector:
        matchlabels:
            app: my-app
    template:
        metadata:
            labels:
                app: my-app
        spec:
            containers:
              - name: my-app-server
                image: gcr.io/my-app/server
                ports:
                  - containerport: 8009
                envfrom:
                  - secretref:
                        name: my-app-production-secrets
              - name: my-app-scraper
                image: gcr.io/my-app/scraper
                ports:
                  - containerport: 8109
                envfrom:
                  - secretref:
                        name: my-app-production-secrets
              - name: my-app-frontend
                image: gcr.io/my-app/frontend
                ports:
                  - containerport: 80
                envfrom:
                  - secretref:
                        name: my-app-production-secrets

---

apiversion: v1
kind: service
metadata:
    name: my-app-lb-service
spec:
    type: loadbalancer
    selector:
        app: my-app
    ports:
      - name: my-app-server-port
        protocol: tcp
        port: 8009
        targetport: 8009
      - name: my-app-scraper-port
        protocol: tcp
        port: 8109
        targetport: 8109
      - name: my-app-frontend-port
        protocol: tcp
        port: 80
        targetport: 80


when typing kubectl get pods i get:

name                                   ready     status    restarts   age
my-app-deployment-6b49c9b5c4-5zxw2   0/3       pending   0          12h


when investigation i google cloud i see ""unschedulable"" state with ""insufficient cpu"" error on pod:



when going to nodes section under my cluster in the clusters page, i see 681 mcpu requested and 940 mcpu allocated:


what is wrong? why my pod doesn't start?
",<kubernetes><google-cloud-platform><gcloud><kubectl><google-kubernetes-engine>,54699582,8,"every container has a default cpu request (in gke i’ve noticed it’s 0.1 cpu or 100m). assuming these defaults you have three containers in that pod so you’re requesting another 0.3 cpu.

the node has 0.68 cpu (680m) requested by other workloads and a total limit (allocatable) on that node of 0.94 cpu (940m).

if you want to see what workloads are reserving that 0.68 cpu, you need to inspect the pods on the node. in the page on gke where you see the resource allocations and limits per node, if you click the node it will take you to a page that provides this information.
in my case i can see 2 pods of kube-dns taking 0.26 cpu each, amongst others. these are system pods that are needed to operate the cluster correctly. what you see will also depend on what add-on services you have selected, for example: http load balancing (ingress), kubernetes dashboard and so on.

your pod would take cpu to 0.98 cpu for the node which is more than the 0.94 limit, which is why your pod cannot start.

note that the scheduling is based on the amount of cpu requested for each workload, not how much it actually uses, or the limit.

your options:


turn off any add-on service which is taking cpu resource that you don't need.
add more cpu resource to your cluster. to do that you will either need to change your node pool to use vms with more cpu, or increase the number of nodes in your existing pool. you can do this in gke console or via the gcloud command line.
make explicit requests in your containers for less cpu that will override the defaults.


apiversion: apps/v1
kind: deployment
...
        spec:
            containers:
              - name: my-app-server
                image: gcr.io/my-app/server
                ...
                resources:
                  requests:
                     cpu: ""50m""
              - name: my-app-scraper
                image: gcr.io/my-app/scraper
                ...
                resources:
                  requests:
                     cpu: ""50m""
              - name: my-app-frontend
                image: gcr.io/my-app/frontend
                ...
                resources:
                  requests:
                     cpu: ""50m""

"
57460374,namespace deployment issue in kubernetes helm chart,"i am now testing the deployment into different namespace using kubernetes. here i am using kubernetes helm chart for that. in my chart, i have deployment.yaml and service.yaml.

when i am defining the ""namespace"" parameter with helm command helm install --upgrade, it is not working. when i a read about that i found the statement that - ""helm 2 is not overwritten by the --namespace parameter"".

i tried the following command:

helm upgrade --install kubedeploy --namespace=test pipeline/spacestudychart 


nb here my service is deploying with default namespace.

screenshot of describe pod:



here my ""helm version"" command output is like follows:

docker@mildevdcr01:~$ helm version
client: &amp;version.version{semver:""v2.14.3"", 
gitcommit:""0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085"", gittreestate:""clean""}
server: &amp;version.version{semver:""v2.14.3"", 
gitcommit:""0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085"", gittreestate:""clean""}


because of this reason, i tried to addthis command in deployment.yaml, under metadata.namespace like following,

apiversion: apps/v1
kind: deployment
metadata:
  name: {{ include ""spacestudychart.fullname"" . }}
  namespace: test


i created test and prod, 2 namespaces. but here also it's not working. when i adding like this, i am not getting my service up. i am not able to accessible. and in jenkins console there is no error. when i defined in helm install --upgrade command it was deploying with default namespace. but here not deploying also.

after this, i removed the namespace from deployment.yaml and added metadata.namespace like the same. there also i am not able to access deployed service. but jenkins console output still showing success.

why namespace is not working with my helm deployment? what changes i need to do here for deploying test/prod instead of this default namespace. 
",<kubernetes><kubernetes-helm>,57460414,4,"remove namespace: test from all of your chart files and helm install --namespace=namespace2 ... should work.
"
67872452,kibana not accessible with ingress path url after kubernetes deployment,"i am unable to access the kibana server ui through ingress path url i have deployed the kibana pod along with elasticsearch on kubernetes cluster. while access the ui it is stating as &quot;503 service unavailable&quot; and it is re-directing path as https://myserver.com/spaces/enter. both the elasticsearch and kibana pods are running. and i am able to curl my elasticsearch pod through my ingress path url. can someone help with the issue.
kibana yaml files:
deployment.yaml
---
  apiversion: &quot;apps/v1&quot;
  kind: &quot;deployment&quot;
  metadata: 
    name: &quot;kibana-development&quot;
    namespace: &quot;development&quot;
  spec: 
    selector: 
      matchlabels: 
        app: &quot;kibana-development&quot;
    replicas: 1
    strategy: 
      type: &quot;rollingupdate&quot;
      rollingupdate: 
        maxsurge: 1
        maxunavailable: 1
    minreadyseconds: 5
    template: 
      metadata: 
        labels: 
          app: &quot;kibana-development&quot;
      spec: 
        containers: 
          - 
            name: &quot;kibana-development&quot;
            image: &quot;docker.elastic.co/kibana/kibana:7.10.2&quot;
            imagepullpolicy: &quot;always&quot;
            
            env:
             - name: &quot;elasticsearch_hosts&quot;
               value: &quot;https://my-server.com/elasticsearch&quot;
            
            ports: 
              - 
                containerport: 5601
                protocol: tcp     
        imagepullsecrets: 
          - 
            name: &quot;kibana&quot;

service.yaml
---
  apiversion: &quot;v1&quot;
  kind: &quot;service&quot;
  metadata: 
    name: &quot;kibana-development&quot;
    namespace: &quot;development&quot;
    labels: 
      app: &quot;kibana-development&quot;
  spec: 
    ports: 
      - 
        port: 56976
        targetport: 5601
    selector: 
      app: &quot;kibana-development&quot;

ingress.yaml
---
  apiversion: &quot;networking.k8s.io/v1beta1&quot;
  kind: &quot;ingress&quot;
  metadata: 
    name: &quot;kibana-development-ingress&quot;
    namespace: &quot;development&quot;
    annotations: 
      nginx.ingress.kubernetes.io/rewrite-target: &quot;/$1&quot;
  spec: 
    rules: 
      - 
        host: &quot;my-server.com&quot;
        http: 
          paths: 
            - 
              backend: 
                servicename: &quot;kibana-development&quot;
                serviceport: 56976
              path: &quot;/kibana/(.*)&quot;


i am able to access kibana through cliuster-ip:port, but not with ingress path url. is there any annotations that i am missing? or the version 7.10.2 for elasticsearch and kibana not stable. i checked my endpoint, it is showing my cluster-ip
",<elasticsearch><kubernetes><kibana><kubernetes-ingress>,67888123,2,"issue resolved now, needed to add the below two env variables in deployment.yaml file.
- 
  name: &quot;server_basepath&quot;
  value: &quot;/kibana-development&quot;
                
-
  name: &quot;server_rewritebasepath&quot;
  value: &quot;false&quot;


don't forget the &quot;/&quot; in server_basepath value
"
71806609,ingress no address,"i have little k8s cluster in my machine and i try to make something for learn but i stack right now.
i have 2 app, one of mysql and another one wordpress and they are working good. when i give a loadbalancer type for wordpress, it's taking a ip and i can see in my browser.
so i want to create a ingress and call by hostname but ingress not take a loadbalancer ip..
am i doing wrong anythin?
this is my ingress configuration
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: wp-ingress
  kubernetes.io/ingress.class: nginx
  labels:
    name: wp-ingress
spec:
  rules:
  - host: wordpress.pandora.local
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: wp-svc
            port: 
              number: 80
  - host: phpmyadmin.pandora.local
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: phpmyadmin-svc
            port: 
              number: 80

and problem
# kg ingress
name         class    hosts                                              address   ports   age
wp-ingress   &lt;none&gt;   wordpress.pandora.local,phpmyadmin.pandora.local             80      38m

i'm using a metallb for loadbalancer and i know it's work becasue of wordpress, but if you want to see
kg svc -a
namespace          name                                 type           cluster-ip       external-ip      port(s)                      age
calico-apiserver   calico-api                           clusterip      10.108.149.243   &lt;none&gt;           443/tcp                      45h
calico-system      calico-kube-controllers-metrics      clusterip      10.100.211.40    &lt;none&gt;           9094/tcp                     45h
calico-system      calico-typha                         clusterip      10.107.217.253   &lt;none&gt;           5473/tcp                     45h
default            kubernetes                           clusterip      10.96.0.1        &lt;none&gt;           443/tcp                      45h
default            mysql-svc                            clusterip      10.103.110.242   &lt;none&gt;           3306/tcp                     3h1m
default            phpmyadmin-svc                       clusterip      10.105.195.144   &lt;none&gt;           80/tcp                       156m
default            wp-svc                               clusterip      10.100.96.37     &lt;none&gt;           80/tcp                       126m
ingress-nginx      ingress-nginx-controller             loadbalancer   10.99.196.206    192.168.188.20   80:30986/tcp,443:32709/tcp   49m
ingress-nginx      ingress-nginx-controller-admission   clusterip      10.99.212.249    &lt;none&gt;           443/tcp                      49m
kube-system        kube-dns                             clusterip      10.96.0.10       &lt;none&gt;           53/udp,53/tcp,9153/tcp       45h

how can i troubleshoot the situation
",<kubernetes><kubernetes-ingress>,71814726,5,"i solved. thank for help :)
the problem was about to ingress class.
kind: ingress
metadata:
  name: wp-ingress
spec:
  rules:
  - host: wordpress.pandora.local
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: wp-svc
            port:
              number: 80
  - host: phpmyadmin.pandora.local
    http:
      paths:
      - pathtype: prefix
        path: &quot;/&quot;
        backend:
          service:
            name: phpmyadmin-svc
            port:
              number: 80
  ingressclassname: nginx

i added the last line ingressclassname: nginx defination and it's work!
kg ingress
name         class   hosts                                              address         ports   age
wp-ingress   nginx   wordpress.pandora.local,phpmyadmin.pandora.local   192.168.88.20   80      5h19m

"
66829947,terraform eks setup - namespaces is forbidden: user cannot list resource,"i have been following a guide on how to setup aws eks using terraform. https://learn.hashicorp.com/tutorials/terraform/eks
i am on the section where i need to authenticate the dashboard. https://learn.hashicorp.com/tutorials/terraform/eks#authenticate-the-dashboard

i have created the cluster roll binding

$ kubectl apply -f https://raw.githubusercontent.com/hashicorp/learn-terraform-provision-eks-cluster/master/kubernetes-dashboard-admin.rbac.yaml


i have generated the token

kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep service-controller-token | awk '{print $1}')


i have logged into the kubernetes dashboard using token. kubectl proxy

however after im logged in and i try to click on any of the panels to see the resources, i get a set of errors that are similar to the following.

namespaces is forbidden: user
&quot;system:serviceaccount:kube-system:service-controller&quot; cannot list
resource &quot;namespaces&quot; in api group &quot;&quot; at the cluster scope
cronjobs.batch is forbidden: user
&quot;system:serviceaccount:kube-system:service-controller&quot; cannot list
resource &quot;cronjobs&quot; in api group &quot;batch&quot; in the namespace &quot;default&quot;

the messages suggest to me the user im logged in as via the token does not have the permissions to view these resources. although i am able to view them using kubectl cli tool.
kubectl describe clusterrole kubernetes-dashboard
name:         kubernetes-dashboard
labels:       k8s-app=kubernetes-dashboard
annotations:  &lt;none&gt;
policyrule:
  resources             non-resource urls  resource names  verbs
  ---------             -----------------  --------------  -----
  nodes.metrics.k8s.io  []                 []              [get list watch]
  pods.metrics.k8s.io   []                 []              [get list watch]

",<kubernetes><terraform><amazon-eks>,66830596,8,"the following will log you in as an admin-user, which seems to be the behavior you're looking for.
$ admin_user_token_name=$(kubectl -n kube-system get secret | grep admin-user-token | cut -d' ' -f1)
$ echo $admin_user_token_name

admin-user-token-k4s7r
# the suffix is auto-generated

$ admin_user_token_value=$(kubectl -n kube-system get secret &quot;$admin_user_token_name&quot; -o jsonpath='{.data.token}' | base64 --decode)
$ echo &quot;$admin_user_token_value&quot;

eyjhbgcioij ...
.....................-tg
# copy this token and use it on the kubernetes dashboard login page

the service account that was used in the tutorial is service-controller, which seems to have a very few permissions
$ kubectl -n kube-system describe clusterrole system:controller:service-controller
name:         system:controller:service-controller
labels:       kubernetes.io/bootstrapping=rbac-defaults
annotations:  rbac.authorization.kubernetes.io/autoupdate: true
policyrule:
  resources             non-resource urls  resource names  verbs
  ---------             -----------------  --------------  -----
  events                []                 []              [create patch update]
  events.events.k8s.io  []                 []              [create patch update]
  services              []                 []              [get list watch]
  nodes                 []                 []              [list watch]
  services/status       []                 []              [patch update]

let me know if you have any issues.
"
56470386,unable to determine the type of a kubernetes service that was installed on a cluster,"i am trying to set up tls for a messagesight service that has been installed on ibm cloud private(icp) 

icp and messagesight have already been installed and i was trying to see how the messagesight has been exposed as a service (is that a nodeport, loadbalancer or externalname)

$kubectl get services 
name                              type        cluster-ip     external-ip     port(s)                       age
messagesight-messagesight-svc     clusterip   10.0.241.72    168.xx.xx.xxx   9089/tcp,1883/tcp,16102/tcp   9d
messagesight-messagesightui-svc   clusterip   10.0.139.199   168.xx.xx.xxx   9087/tcp                      9d


the type states it is a clusterip however it has an external ip. i always thought an external ip is going to empty if the service type is clusterip. if it were a loadbalancer i would expect to see the external ip. 

describing the service does not provide any additional information

kubectl describe svc messagesight-messagesight-svc 
name:              messagesight-messagesight-svc
labels:            app=messagesight
                   chart=messagesight
                   heritage=tiller
                   release=messagesight
annotations:       &lt;none&gt;
selector:          app=messagesight,release=messagesight
type:              clusterip
ip:                10.0.241.72
external ips:      168.xx.xx.xxx
port:              adminport  9089/tcp
targetport:        9089/tcp
endpoints:         10.1.66.1:9089
port:              messaging-1883  1883/tcp
targetport:        1883/tcp
endpoints:         10.1.66.1:1883
port:              messaging-16102  16102/tcp
targetport:        16102/tcp
endpoints:         10.1.66.1:16102
session affinity:  none
events:            &lt;none&gt;


i am able to access the service via the external-ip and ports and am puzzled as to how it is working.

i installed a jenkins setup to make observations and the output looks good and makes sense to me

$kubectl get services 
name                       type       cluster-ip     external-ip   port(s)                          age
jenkins-ibm-jenki   nodeport   10.0.241.156   &lt;none&gt;        8080:31058/tcp,50000:31155/tcp   1d


i can see the type is nodeport and it doesn't have a corresponding externalip.

the description of the service also give me clear insights that this service is of type nodeport

$kubectl describe svc jenkins-ibm-jenki 
name:                     jenkins-ibm-jenki
labels:                   app=jenkins-ibm-jenki
                          chart=ibm-jenkins-dev-1.0.2
                          component=jenkins-jenkins-master
                          heritage=tiller
                          release=jenkins
annotations:              helm.sh/created=1559696400
selector:                 app=jenkins-ibm-jenki,component=jenkins-jenkins-master
type:                     nodeport
ip:                       10.0.241.156
port:                     http  8080/tcp
targetport:               8080/tcp
nodeport:                 http  31058/tcp
endpoints:                10.1.66.89:8080
port:                     slavelistener  50000/tcp
targetport:               50000/tcp
nodeport:                 slavelistener  31155/tcp
endpoints:                10.1.66.89:50000
session affinity:         none
external traffic policy:  cluster
events:                   &lt;none&gt;

",<kubernetes><ibm-cloud><kubernetes-helm><ibm-cloud-private>,56474117,4,"as stated in documentation:

in the service spec, externalips can be specified along with any of the servicetypes
"
64954420,cross namespace communication in kubernetes,"is there any way to setup cross communication with different namespace, say pods of namespace-a to communicate pods of namespace-b with each other in gke cluster except for setting network policies?
",<network-programming><kubernetes><google-cloud-platform><google-kubernetes-engine>,64955747,8,"networking within a kubernetes cluster can be done in different ways, but the recommended and most common way is to use dns names. pods get their own dns names, but it is recommended that you access another app in the cluster via the dns name for the service.
dns names are hierarchical, starting with the service name, and then the namespace name.

to access another app in the same namespace, use &lt;other-app-service-name&gt;, e.g. http://&lt;other-app-service-name&gt;.

to send a request to an app in a different namespace, also use the namepspace part of the domain name, &lt;another-app-service-name&gt;.&lt;other-namespace-name&gt;, e.g. http://&lt;another-app-service-name&gt;.&lt;other-namespace-name&gt;


"
73032148,kubernetes: error: unexpected args: [create],"follow guide at https://operatorhub.io/operator/postgresql-operator-dev4devs-com (press button install), on windows 10 pro x64 . error
microsoft windows [version 10.0.19044.1826]
(c) microsoft corporation. all rights reserved.

c:\users\administrator&gt;curl -sl https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.21.2/install.sh | bash -s v0.21.2
customresourcedefinition.apiextensions.k8s.io/catalogsources.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/clusterserviceversions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/installplans.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/olmconfigs.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operatorconditions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operatorgroups.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operators.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/subscriptions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/catalogsources.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/clusterserviceversions.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/installplans.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/olmconfigs.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operatorconditions.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operatorgroups.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operators.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/subscriptions.operators.coreos.com condition met
namespace/olm created
namespace/operators created
serviceaccount/olm-operator-serviceaccount created
clusterrole.rbac.authorization.k8s.io/system:controller:operator-lifecycle-manager created
clusterrolebinding.rbac.authorization.k8s.io/olm-operator-binding-olm created
olmconfig.operators.coreos.com/cluster created
deployment.apps/olm-operator created
deployment.apps/catalog-operator created
clusterrole.rbac.authorization.k8s.io/aggregate-olm-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-olm-view created
operatorgroup.operators.coreos.com/global-operators created
operatorgroup.operators.coreos.com/olm-operators created
clusterserviceversion.operators.coreos.com/packageserver created
catalogsource.operators.coreos.com/operatorhubio-catalog created
waiting for deployment &quot;olm-operator&quot; rollout to finish: 0 of 1 updated replicas are available...
deployment &quot;olm-operator&quot; successfully rolled out
waiting for deployment &quot;catalog-operator&quot; rollout to finish: 0 of 1 updated replicas are available...
deployment &quot;catalog-operator&quot; successfully rolled out
package server phase: installing
package server phase: succeeded
deployment &quot;packageserver&quot; successfully rolled out

c:\users\administrator&gt;kubectl create -f https://operatorhub.io/install/postgresql-operator-dev4devs-com.yamlkubectl create -f https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml
error: unexpected args: [create]
see 'kubectl create -h' for help and examples

c:\users\administrator&gt;

error: unexpected args: [create]

how to fix it?
",<kubernetes><kubectl><docker-for-windows><docker-desktop>,73032236,1,"kubectl create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yamlkubectl 
create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml

duplicate create -f,
so you need use only create -f as:
kubectl create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml

"
64965827,"unable to attach aws ebs volume, error ""instance not found""","info:

kubernetes server version: 1.14
aws cloud provider
ebs volume, storageclass

details:
i have installed statefulset in our kubernetes cluster, however, it stuck it &quot;containercreating&quot; status. upon checking the logs, the error is &quot;attachvolume.attach failed for volume pvc-xxxxxx: error finding instance ip-xxxxx : &quot;instance not found&quot;
it was succesfully installed around 17 days ago, but re-installing for an update caused the pod to stuck in containercreating.
manual attaching volume to the instance works. but doing it via storage class is not working and stuck in containercreating status.
storageclass:
apiversion: storage.k8s.io/v1
kind: storageclass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: &quot;true&quot;
  name: ssd-default
allowvolumeexpansion: true
parameters:
  encrypted: &quot;true&quot;
  type: gp2
provisioner: kubernetes.io/aws-ebs
reclaimpolicy: delete
volumebindingmode: immediate

pvc yaml:
apiversion: v1
kind: persistentvolumeclaim
metadata:
  annotations:
    pv.kubernetes.io/bind-completed: &quot;yes&quot;
    pv.kubernetes.io/bound-by-controller: &quot;yes&quot;
    volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/aws-ebs
  finalizers:
  - kubernetes.io/pvc-protection
  labels:
    app.kubernetes.io/instance: thanos-store
    app.kubernetes.io/name: thanos-store
  name: data-thanos-store-0
  namespace: thanos
spec:
  accessmodes:
  - readwriteonce
  resources:
    requests:
      storage: 3gi
  storageclassname: ssd-default
  volumemode: filesystem
  volumename: pvc-xxxxxx
status:
  accessmodes:
  - readwriteonce
  capacity:
    storage: 3gi
  phase: bound

pv yaml:
apiversion: v1
kind: persistentvolume
metadata:
  annotations:
    kubernetes.io/createdby: aws-ebs-dynamic-provisioner
    pv.kubernetes.io/bound-by-controller: &quot;yes&quot;
    pv.kubernetes.io/provisioned-by: kubernetes.io/aws-ebs
  finalizers:
  - kubernetes.io/pv-protection
  labels:
    failure-domain.beta.kubernetes.io/region: ap-xxx
    failure-domain.beta.kubernetes.io/zone: ap-xxx
  name: pvc-xxxx
spec:
  accessmodes:
  - readwriteonce
  awselasticblockstore:
    fstype: ext4
    volumeid: aws://xxxxx
  capacity:
    storage: 3gi
  claimref:
    apiversion: v1
    kind: persistentvolumeclaim
    name: data-athena-thanos-store-0
    namespace: thanos
  nodeaffinity:
    required:
      nodeselectorterms:
      - matchexpressions:
        - key: failure-domain.beta.kubernetes.io/region
          operator: in
          values:
          - ap-xxx
        - key: failure-domain.beta.kubernetes.io/zone
          operator: in
          values:
          - ap-xxx
  persistentvolumereclaimpolicy: delete
  storageclassname: ssd-default
  volumemode: filesystem
status:
  phase: bound

describe pvc:
name:          data-athena-thanos-store-0
namespace:     athena-thanos
storageclass:  ssd-encrypted
status:        bound
volume:        pvc-xxxx
labels:        app.kubernetes.io/instance=athena-thanos-store
               app.kubernetes.io/name=athena-thanos-store
annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/aws-ebs
finalizers:    [kubernetes.io/pvc-protection]
capacity:      3gi
access modes:  rwo
volumemode:    filesystem
mounted by:    athena-thanos-store-0

",<kubernetes><amazon-ec2><kubernetes-pod><amazon-ebs>,65088254,2,"the failedattachvolume error occurs when an ebs volume can’t be detached from an instance and thus cannot be attached to another. the ebs volume has to be in the available state to be attached. failedattachvolume is usually a symptom of an underlying failure to unmount and detach the volume.
notice that while describing the pvc the storageclass name is ssd-encrypted which is a mismatch with the config you showed earlier where the kind: storageclass name is ssd-default. that's why you can mount the volume manually but not via the storageclass. you can drop and recreate the storageclass with a proper data.
also, i recommend going through this article and using volumebindingmode: waitforfirstconsumer instead of volumebindingmode: immediate. this setting instructs the volume provisioner to not create a volume immediately, and instead, wait for a pod using an associated pvc to run through scheduling.
"
55052565,retrieve kubernetes secrets mounted as volumes,"hi i am playing around with kubernetes secrets.
my deployment file is :

---
apiversion: v1
kind: secret
metadata:
  name: my-secrets
  labels:
    app: my-app
data:
  username: dxnlcm5hbwu=
  password: cgfzc3dvcmq=


i am able to create secrets and i am mounting them in my deployments as below:

---
apiversion: v1
kind: service
metadata:
  name: my-service
spec:
  selector:
    app: my-service
  ports:
  - protocol: tcp
    port: 80
    targetport: 8080
  type: nodeport

---

apiversion: apps/v1
kind: deployment
metadata:
  name: spring-service
  labels:
    app: spring-service
spec:
  replicas: 1
  selector:
    matchlabels:
      app: spring-service
  template:
    metadata:
      labels:
        app: spring-service
    spec:
      containers:
      - name: spring-service
        image: my-image:tag
        imagepullpolicy: always
        ports:
        - containerport: 8080
        volumemounts:
        - name: my-secret-vol
          mountpath: ""/app/secrets/my-secret""
          readonly: true            
      volumes:
      - name: my-secret-vol
        secret:
          secretname: my-secrets


my question is how can i access username and password i created in secret in spring-boot app?

i have tried loading in with ${my-secrets.username} and ${username}, but it fails to find values.

i also tried adding secrets as enviroment variables as below in deployment.yml:

env:
- name: username
  valuefrom:
    secretkeyref:
      name: my-secrets
      key: username
- name: password
  valuefrom:
    secretkeyref:
      name: my-secrets
      key: password


in this case, values are loaded from secrets and when i change values of secrets in minikube dashboard, it does not reflect the changes.

please help me to understand how this works.

i am using minikube and docker as containers
",<spring-boot><kubernetes><kubernetes-secrets><mounted-volumes>,55103692,2,"you don't inject the secret into properties.yml. instead, you use the content of the secret as properties.yml. the process is look like the following:


create a properties.yml with the sensitive data (e.g. password)
base64 encode this file (e.g. base64 properties.yml).
take the base64 encoded value and put that in the secret under the key properties.yaml.


you should end up with a secret in the following format:

apiversion: v1
kind: secret
metadata:
  name: my-secrets
  labels:
    app: my-app
data:
  properties.yml: dxnlcm5hbwu=


now when you mount this secret on your pod, kubernetes will decrypt the secret and put the value under the relevant path and you can just mount it. 

the pattern is to have 2 configuration files - one with non-sensitive configurations that is stored with the code, and the second (which includes sensitive configurations) stored as a secret. i don't know if that possible to load multiple config files using spring boot.

and one final comment - this process is cumbersome and error-prone. each change to the configuration file requires decoding the original secret and repeating this manual process. also, it's very hard to understand what changed - all you see is the entire content has changed. for that reason, we build kamus. it let you encrypt only the sensitive value instead of the entire file. let me know if that could be relevant for you :)
"
53338042,are you trying to mount a directory onto a file (or vice-versa) with kuberneters/configmap?,"i followed this post kubernetes configmap - only one file to pass a config file to a deployment, but got an error. why?

the config file config-prom-prometheus.yml:

scrape_configs:
- job_name: job-leo-prometheus
  kubernetes_sd_configs:
  - role: endpoints


the .yaml file prom-prometheus.yaml:

apiversion: apps/v1
kind: deployment
metadata:
  name: prom-prometheus-deployment
spec:
  selector:
    matchlabels:
      app: prom-prometheus
  replicas: 1
  template:
    metadata:
      labels:
        app: prom-prometheus
    spec:
      containers:
      - name: prom-prometheus
        image: 127.0.0.1:30400/prom/prometheus
        ports:
        - name: port9090
          containerport: 9090
        volumemounts:
        - name: volume-prometheus
          mountpath: /etc/prometheus/prometheus.yml
          subpath: prometheus.yml
      volumes:
      - name: volume-prometheus
        configmap:
          name: config-prom

---
apiversion: v1
kind: service
metadata:
  name: prom-prometheus
spec:
  type: nodeport
  ports:
  - name: port9090
    protocol: tcp
    port: 9090
    targetport: 9090
    nodeport: 30090
  selector:
    app: prom-prometheus


commands:

kubectl create configmap config-prom --from-file=config-prom-prometheus.yml
kubectl -f prom-prometheus.yaml apply


results:

events:
  type     reason                 age               from               message
  ----     ------                 ----              ----               -------
  normal   scheduled              17s               default-scheduler  successfully assigned prom-prometheus-deployment-66887dcdbf-bfqd4 to minikube
  normal   successfulmountvolume  17s               kubelet, minikube  mountvolume.setup succeeded for volume ""default-token-ml6w5""
  normal   successfulmountvolume  17s               kubelet, minikube  mountvolume.setup succeeded for volume ""volume-prometheus""
  warning  failed                 9s                kubelet, minikube  error: failed to start container ""prom-prometheus"": error response from daemon: oci runtime create failed: container_linux.go:348: starting container process caused ""process_linux.go:402: container init caused \""rootfs_linux.go:58: mounting \\\""/var/lib/kubelet/pods/ec99da92-e994-11e8-a578-08002742f2a3/volume-subpaths/volume-prometheus/prom-prometheus/0\\\"" to rootfs \\\""/var/lib/docker/overlay2/12c7da1c07c55fe2ec5dff61e5c457fa8aeaa32d47232c28a1d7e127c4f81bf0/merged\\\"" at \\\""/var/lib/docker/overlay2/12c7da1c07c55fe2ec5dff61e5c457fa8aeaa32d47232c28a1d7e127c4f81bf0/merged/etc/prometheus/prometheus.yml\\\"" caused \\\""not a directory\\\""\"""": unknown: are you trying to mount a directory onto a file (or vice-versa)? check if the specified host path exists and is the expected type
  normal   pulling                7s (x2 over 13s)  kubelet, minikube  pulling image ""127.0.0.1:30400/prom/prometheus""
  normal   pulled                 7s (x2 over 13s)  kubelet, minikube  successfully pulled image ""127.0.0.1:30400/prom/prometheus""
  normal   created                6s (x2 over 10s)  kubelet, minikube  created container
  warning  failed                 4s                kubelet, minikube  error: failed to start container ""prom-prometheus"": error response from daemon: oci runtime create failed: container_linux.go:348: starting container process caused ""process_linux.go:402: container init caused \""rootfs_linux.go:58: mounting \\\""/var/lib/kubelet/pods/ec99da92-e994-11e8-a578-08002742f2a3/volume-subpaths/volume-prometheus/prom-prometheus/0\\\"" to rootfs \\\""/var/lib/docker/overlay2/7b07728ae4439e4d479386eab6b042948e2cb586c54171941f24d03352a7c8b4/merged\\\"" at \\\""/var/lib/docker/overlay2/7b07728ae4439e4d479386eab6b042948e2cb586c54171941f24d03352a7c8b4/merged/etc/prometheus/prometheus.yml\\\"" caused \\\""not a directory\\\""\"""": unknown: are you trying to mount a directory onto a file (or vice-versa)? check if the specified host path exists and is the expected type

",<docker><kubernetes><prometheus><kubectl><minikube>,53346471,12,"this is not well documented but as per my experience name of configmap yaml (config-prom-prometheus.yml in your case) should be the same as mountpath and subpath in deployment.

if you use subpath: prometheus.yml - rename config-prom-prometheus.yml to prometheus.yml and try again.
"
55115001,how to ssh into a traefik pod?,"i am using gke. i've launched the following traefik deployment through kubectl:

https://github.com/containous/traefik/blob/master/examples/k8s/traefik-deployment.yaml

the pod runs on the kube-system namespace.
i'm not able to ssh into the pod. 

kubectl get po -n kube-system
traefik-ingress-controller-5bf599f65d-fl9gx   1/1     running   0    30m

kubectl exec -it traefik-ingress-controller-5bf599f65d-fl9gx -n kube-system -- '\bin\bash'
rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused ""exec: \""\\\\bin\\\\bash\"": executable file not found in $path""
command terminated with exit code 126

am i missing something? the same thing for '-- sh' too.
",<kubernetes><google-kubernetes-engine><traefik>,55218230,1,"so, apparently the default traefik image is an amd64 version. i had to use the alpine version to ssh into it using:
 kubectl exec -it _podname_ -- sh
"
56711894,does k8 update environment variables when secrets change?,"while running kubernetes clusters, i've noticed that when a secret's value is changed pods that use it as an environment variable are not rebuilt and my applications don't receive a sigterm event.

while i know it's technically possible to update the environment of a running process using something like gdb, this is a horrible thing to do and i assume k8s doesn't do this.

is there a signal that is sent to an effected process when this situation occurs, or some other way to handle this?
",<docker><kubernetes><signals><kubernetes-secrets>,56712306,4,"no, nor does any such thing happen on configmap mounts, env-var injection, or any other situation; signals are sent to your process only as a side-effect of pod termination

there are innumerable solutions to do rolling update on configmap or secret change but you have to configure what you would want your cluster to do and under what circumstances, because there is no way that a one-size-fits-all solution would work in all the ways that kubernetes is used in the world
"
74570337,how to forward k8s ingress domain to backend server with uri?,"i want to use k8s ingress to forward the domain to some service with uri. the ingress yaml just like as below:
- host: foo.example
  http:
    paths:
    - backend:
        path: /
        pathtype: prefix
        service:
          name: servicea
          port:
            number: 8999
          path: /foo/bar # don't have this attribute, but i want something like this
      

i found the k8s documents say the path attribute in paths can do this:

foo.example/foo -&gt; servicea:8999
foo.example/bar -&gt; serviceb:9888

but i want to do this: foo.example -&gt; servicea:8999/foo/bar. the same thing in nginx config is:
server {
    server_name foo.example;
    location / {
      proxy_pass http://service:8999/foo/bar;
    }
}

how could i do in the k8s ingress? thanks.
",<kubernetes><kubernetes-ingress>,74575038,2,"nginx ingress controller supports rewrites and code snippets. i think what you want can be done by annotations. from the example here https://kubernetes.github.io/ingress-nginx/examples/rewrite/ your code should look like:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /foo/bar/$1
  name: &lt;ingress-name&gt;
  namespace: &lt;namespace&gt;
spec:
  ingressclassname: nginx
  rules:
  - host: fool.example
    http:
      paths:
      - path: /(.*)
        pathtype: prefix
        backend:
          service:
            name: servicea
            port: 
              number: 8999

you can add even more complex behavior (like your nginx config) with server snippets:
https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/annotations.md#server-snippet
"
65709110,"kubernetes: what is the significance of ""storage"" field in a block persistent volume?","scenario
i have a persistentvolume with volumemodeas block. it is defined as:
apiversion: v1
kind: persistentvolume
metadata:
  name: block-vol
spec:
  accessmodes:
  - readwriteonce
  capacity:
    storage: 1gi
  local:
    path: /dev/sdb # this path on the host specified below is used as a device mount
  nodeaffinity:
    required:
      nodeselectorterms:
      - matchexpressions:
        - key: kubernetes.io/hostname
          operator: in
          values:
          - &lt;my-host&gt;
  persistentvolumereclaimpolicy: retain
  storageclassname: block-storage
  volumemode: block

when i mount this on a statefulset with a volumeclaimtemplate, i specify it's storage field as 1gi. however, when exec'd in to the deployed pod, i see that the block size more than 1gi (it is the actual size of that device on physical machine)
statefulset yaml:

apiversion: apps/v1
kind: statefulset
metadata:
  name: nginx
spec:
  selector:
    matchlabels:
      app: nginx
  servicename: &quot;nginx&quot;
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      terminationgraceperiodseconds: 10
      containers:
      - name: nginx
        image: k8s.gcr.io/nginx-slim:0.8
        ports:
        - containerport: 80
          name: web
        volumedevices:
        - name: rawdev0
          devicepath: /dev/kdb0
  volumeclaimtemplates:
  - metadata:
      name: rawdev0
    spec:
      accessmodes: [ &quot;readwriteonce&quot; ]
      storageclassname: block-storage
      volumemode: block
      resources:
        requests:
          storage: 1gi

i have used blockdev to find the size of block in bytes:
root@nginx-0:/# ls -lhrt /dev/kdb0 
brw-rw----. 1 root disk 8, 16 jan 13 19:49 /dev/kdb0

root@nginx-0:/# blockdev --getsize64 /dev/kdb0 
536870912000 #size of block in bytes


question
what does the storage field signify in this case?
",<kubernetes><persistent-storage><persistent-volumes><kubernetes-statefulset>,65709310,2,"kubernetes can't do much about the storage size for local volumes. the admin that created the persistentvolume must set a proper size, for granular sizing he/she should probably create its own partition instead of mapping the local volume to a directory.
the storage size in the persistentvolumeclaim is a request so that the app at least get a volume of that size.
"
61569848,set container port based on environment property,"i am setting port value in an environment property while generating pod yaml.

master $ kubectl run nginx --image=nginx --restart=never --env=my_port=8080 --dry-run -o yaml  &gt; pod.yaml


i am trying to use the environment property my_port in the ports section of my pod yaml.

spec:
     containers:
     - env:
       - name: my_port
         value: ""8080""
       image: nginx
       name: nginx
       ports:
       - containerport: $(my_port)


when i try to create the pod i am getting following error message.

error: error validating ""pod.yaml"": error validating data: validationerror(pod.spec.containers[0].ports[0].containerport): invalid type for io.k8s.api.core.v1.containerport.containerport: got ""string"", expected ""integer""; if you choose to ignore theseerrors, turn validation off with --validate=false


i tried referencing like ${my_port} , my_port etc.. but all the time same error as above.

how i can use an environment variable value in an integer field.
",<kubernetes><kubectl>,61572896,6,"you can't use an environment variable there.  in the containerport api object the containerport field is specified as an integer.  variable substitution is only support in a couple of places, and where it does it is called out; see for example args and command in the higher-level container api object.

there's no reason to make this configurable.  in a kubernetes environment the pod will have its own ip address, so there's no risk of conflict; if you want to use a different port number to connect, you can set up a service where e.g. port 80 on the service forwards to port 8080 in the pod.  (in plain docker, you can do a similar thing with a docker run -p 80:8080 option: you can always pick the external port even if the port number inside the container is fixed.)  i'd delete the environment variable setting.
"
54949016,how can i update all ingress rules comments using kubectl?,"good morning,

i have a k8s cluster where multiple ingress services share a pre generated self managed certificate in gcp. 

my problem is that when the certificate expires, i need to update the yaml file with the name of the new cert and apply the modified yaml file for each of the ingress to update the certs. we do it, updating the environment variable and redeploying the application. i was thinking in a better way to do it that will not require to redeploy it, i was planning to use kubectl patch to do this, anyone has already have to done something similar?

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    ingress.gcp.kubernetes.io/pre-shared-cert: cert-abc
    ingress.kubernetes.io/forwarding-rule: fwd-abc
    ingress.kubernetes.io/https-forwarding-rule: https-fwd-abc
    ingress.kubernetes.io/https-target-proxy: tgt-https-abc
    ingress.kubernetes.io/ssl-cert: cert-abc
    ingress.kubernetes.io/static-ip: ip-abc
    ingress.kubernetes.io/target-proxy: tgt-http-abc
    ingress.kubernetes.io/url-map: lb-abc
    kubernetes.io/ingress.global-static-ip-name: sta-ip-abc
  creationtimestamp: 2019-01-29t22:38:10z
  generation: 2
  name: abc-ingress
  namespace: abc  
spec:
  backend:
    servicename: abc
    serviceport: 80


thanks in advance for your help.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,54962670,1,"we have similar challenges. kubectl apply works fine here as hernan garcia already pointed out.

a patch can do the same trick.

our choice in fact way using helm which is quite easy to use and which makes it quite easy to update selectively values. furthermore you have the option to rollback if something goes wrong, which is nice for automated deployments.
"
57020776,how to start a mysql container in kubernetes with sample data?,"i need to start a mysql container in kubernetes with a database and a schema and sample data.

i tried to use the parameter ""command"" in the kubernetes yaml, but at the time of execution, the db is still not started.

        - image: mysql:5.7.24
          name: database
          command:
            [
              '/usr/bin/mysql -u root -e ""create database if not exists mydbname""',
            ]
          env:
            - name: mysql_allow_empty_password
              value: ""1""

",<mysql><kubernetes><google-kubernetes-engine><dump>,57299434,4,"solved adding 

      volumemounts:
        - name: initdb
          mountpath: /docker-entrypoint-initdb.d

...
  volumes:
    - name: initdb
      configmap:
        name: initdb-config

...
---
apiversion: v1
kind: configmap
metadata:
  name: initdb-config
data:
  initdb.sql: |
      mysqlquery

"
59284489,failed to setup kubeconfig when starting minikube,"i have installed kubectl and minikube on my windows environment, but when running minikube start it creates the vm on vitualbox but i got this error when it trying to prepare kubernetes on docker.

c:\users\asusstrix&gt;minikube start

* minikube v1.6.0 on microsoft windows 10 home 10.0.18362 build 18362
* selecting 'virtualbox' driver from user configuration (alternates: [])
* creating virtualbox vm (cpus=2, memory=2000mb, disk=20000mb) ...
* preparing kubernetes v1.17.0 on docker '19.03.5' ...
*
x failed to setup kubeconfig: writing kubeconfig: error writing file c:\users\asusstrix/.kube/config: error acquiring lock for c:\users\asusstrix/.kube/config: timeout acquiring mutex
*
* sorry that minikube crashed. if this was unexpected, we would love to hear from you:
  - https://github.com/kubernetes/minikube/issues/new/choose

",<docker><kubernetes><kubectl><minikube>,59286085,1,"according to the official documentation:


  to confirm successful installation of both a hypervisor and minikube,
  you can run the following command to start up a local kubernetes
  cluster: 
  
  minikube start --vm-driver=&lt;driver_name&gt;
  
  for setting the --vm-driver with minikube start, enter the name of the
  hypervisor you installed in lowercase letters where  is
  mentioned below. a full list of --vm-driver values is available in
  specifying the vm driver
  documentation.


so in your case it would be: minikube start --vm-driver=&lt;virtualbox&gt;

if you want ot make sure your previous steps were correct you can go through the whole tutorial.

please let me know if that helped. 

edit:

there is a github thread showing the same issue.

basically you still should use minikube start --vm-driver=&lt;driver_name&gt; but it will not work with v1.6.0 yet. consider downgrading to v1.5.2 instead. 
"
59228240,permanently replacing api server certificates,"i have microk8s cluster, and expose the api server at my domain. 
the server.crt and server.key in /var/snap/microk8s/1079/certs need to be replaced with the ones that include my domain.
otherwise, as expected, i get the error: 

unable to connect to the server: x509: certificate is valid for kubernetes, kubernetes.default, kubernetes.default.svc, kubernetes.default.svc.cluster, kubernetes.default.svc.cluster.local, not mydonaim.com

with the help of cert-manager i have produced certificates and replaced them, my system works well. 

problem: every time server is restarted, server.crt and server.key are generated again in 
/var/snap/microk8s/1079/certs. my custom certs are deleted, making api server unreachable remotely. 
how can i stop the system from doing that all the time? 

workaround?
should i place my certificates elsewhere and edit config files like /var/snap/microk8s/1079/args/kube-controller-manager with the path to those certificates? are those config files auto-replaced as well? 

cluster information:


kubernetes version: 1.16.3 
cloud being used: bare metal, single-node
cluster installation method: ubuntu server with snaps 
host os: ubuntu 18.04.3 lts

",<ssl><kubernetes><kubernetes-apiserver><microk8s>,59241936,4,"it looks like there is an existing issue that describes copying and modifying the /var/snap/microk8s/current/certs/csr.conf.template to include any extra ip or dns entries for the generated certificates
"
49096672,jenkins pipeline no signature of method: java.util.collections$unmodifiablemap.$(),"i'm using the kubernetes jenkins plugin in order to create jenkins slaves on demand. the slaves job is to deploy and provision my apps to the kubernetes cluster.

i created a pipeline project and wrote a very simple jenkinsfile:

podtemplate(label: 'jenkins-pipeline', containers: [
containertemplate(name: 'jnlp', image: 'lachlanevenson/jnlp-slave:3.10-1-alpine', args: '${computer.jnlpmac} ${computer.name}', workingdir: '/home/jenkins', resourcerequestcpu: '200m', resourcelimitcpu: '300m', resourcerequestmemory: '256mi', resourcelimitmemory: '512mi'),
containertemplate(name: 'helm', image: 'lachlanevenson/k8s-helm:v2.6.0', command: 'cat', ttyenabled: true),
containertemplate(name: 'kubectl', image: 'lachlanevenson/k8s-kubectl:v1.4.8', command: 'cat', ttyenabled: true),
containertemplate(name: 'curl', image: 'appropriate/curl:latest', command: 'cat', ttyenabled: true)
],
volumes:[
    hostpathvolume(mountpath: '/var/run/docker.sock', hostpath: 
'/var/run/docker.sock'),
]){

node ('jenkins-pipeline') {

def pwd = pwd()
def chart_dir = ""${pwd}/chart""

checkout([$class: 'subversionscm', additionalcredentials: [], excludedcommitmessages: '', excludedregions: '', excludedrevprop: '', excludedusers: '', filterchangelog: false, ignoredirpropchanges: false, includedregions: '', locations: [[credentialsid: '4041436e-e9dc-4060-95d5-b28be47b1a14', depthoption: 'infinity', ignoreexternalsoption: true, local: '.', remote: 'https://svn.project.com/repo/trunk/rnd/dev/server/src/my-app']], workspaceupdater: [$class: 'checkoutupdater']])

stage ('deploy canary to k8s') {
  container('helm') {
    def version = params.${version}
    def environment = params.${environment}
    // deploy using helm chart

    sh ""helm upgrade --install ${version} ${chart_dir} --set imagetag=${version},replicas=1,environment=${environment} --namespace=dev""  

      }
    }
  }
}


the jenkins slave spins up on kubernetes but the job fails with this stack trace:

[pipeline] stage
[pipeline] { (deploy canary to k8s)
[pipeline] container
[pipeline] {
[pipeline] }
[pipeline] // container
[pipeline] }
[pipeline] // stage
[pipeline] }
[pipeline] // node
[pipeline] }
[pipeline] // podtemplate
[pipeline] end of pipeline
hudson.remoting.proxyexception: groovy.lang.missingmethodexception: no signature of method: java.util.collections$unmodifiablemap.$() is applicable for argument types: (org.jenkinsci.plugins.workflow.cps.cpsclosure2) values: [org.jenkinsci.plugins.workflow.cps.cpsclosure2@7d7d26fa]
possible solutions: is(java.lang.object), any(), get(java.lang.object), any(groovy.lang.closure), max(groovy.lang.closure), min(groovy.lang.closure)
    at org.codehaus.groovy.runtime.scriptbytecodeadapter.unwrap(scriptbytecodeadapter.java:58)
    at org.codehaus.groovy.runtime.callsite.pojometaclasssite.call(pojometaclasssite.java:49)
    at org.codehaus.groovy.runtime.callsite.callsitearray.defaultcall(callsitearray.java:48)
    at org.codehaus.groovy.runtime.callsite.abstractcallsite.call(abstractcallsite.java:113)
    at com.cloudbees.groovy.cps.sandbox.defaultinvoker.methodcall(defaultinvoker.java:18)
    at workflowscript.run(workflowscript:20)
    at ___cps.transform___(native method)
    at com.cloudbees.groovy.cps.impl.continuationgroup.methodcall(continuationgroup.java:57)
    at com.cloudbees.groovy.cps.impl.functioncallblock$continuationimpl.dispatchorarg(functioncallblock.java:109)
    at com.cloudbees.groovy.cps.impl.functioncallblock$continuationimpl.fixarg(functioncallblock.java:82)
    at sun.reflect.generatedmethodaccessor512.invoke(unknown source)
    at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)
    at java.lang.reflect.method.invoke(method.java:498)
    at com.cloudbees.groovy.cps.impl.continuationptr$continuationimpl.receive(continuationptr.java:72)
    at com.cloudbees.groovy.cps.impl.closureblock.eval(closureblock.java:46)
    at com.cloudbees.groovy.cps.next.step(next.java:74)
    at com.cloudbees.groovy.cps.continuable.run0(continuable.java:154)
    at org.jenkinsci.plugins.workflow.cps.cpsthread.runnextchunk(cpsthread.java:165)
    at org.jenkinsci.plugins.workflow.cps.cpsthreadgroup.run(cpsthreadgroup.java:328)
    at org.jenkinsci.plugins.workflow.cps.cpsthreadgroup.access$100(cpsthreadgroup.java:80)
    at org.jenkinsci.plugins.workflow.cps.cpsthreadgroup$2.call(cpsthreadgroup.java:240)
    at org.jenkinsci.plugins.workflow.cps.cpsthreadgroup$2.call(cpsthreadgroup.java:228)
    at org.jenkinsci.plugins.workflow.cps.cpsvmexecutorservice$2.call(cpsvmexecutorservice.java:64)
    at java.util.concurrent.futuretask.run(futuretask.java:266)
    at hudson.remoting.singlelaneexecutorservice$1.run(singlelaneexecutorservice.java:112)
    at jenkins.util.contextresettingexecutorservice$1.run(contextresettingexecutorservice.java:28)
    at java.util.concurrent.executors$runnableadapter.call(executors.java:511)
    at java.util.concurrent.futuretask.run(futuretask.java:266)
    at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142)
    at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617)
    at java.lang.thread.run(thread.java:748)
finished: failure


i understand that the error comes from a type mismatch but i'm having a hard time understanding in which part of the jenkinsfile and what i should do about it.

can anyone please help me?
",<jenkins><groovy><kubernetes><jnlp><kubernetes-helm>,49097002,1,"this

def version = params.${version}
def environment = params.${environment}


should be this

def version = params.""${version}""
def environment = params.""${environment}""

"
53041041,how to access multiple services deployed (spring boot app) in google kubernetes?,"i created 2 simple spring boot application and deployed in google kubernetes using a docker container by referring this link :
deploy spring boot in kubernetes

now when i run kubectl get services i can see 2 services(spring boot applications) listed! 

i understand that using expose i can reserve a static ip for the services! but what i need is ** i need to access two services using single ip** (similar to routing) so that end-user need only be known about one ip address for the multiservices! how could i achieve that? i am very new to this! please help.. 
",<spring-boot><kubernetes><google-kubernetes-engine>,53090012,1,"you can use gce ingress resource so that both services are used as backends. 

as mentioned in patrick's comment above, convert both services to type: nodeport instead of lb. verify that a node port was allocated. 

kubectl get service web

and then create ingress with 2 host paths. 

the following documentation will help you get started: 
"
49812830,"helm upgrade with same chart version, but different docker image tag","i have a question about a helm upgrade. i'm working on a chart foo-1.0.0 which deploys a pod with a docker image bar:4.5.1.

i have a release ""myrelease"" based on this chart foo in version 1.0.0 (with a bar:4.5.1 running inside).

now, i make a fix on bar, rebuild the image bar:4.5.2, change the image in the chart but i did not bump its version. it is still foo-1.0.0

i launch:

$ helm upgrade myrelease repo/foo --version 1.0.0


my problem is that after the upgrade, my pod is still running the bar:4.5.1 instead the 4.5.2

is the a ""cache"" in tiller? it seems that tiller did not download foo-1.0.0 again. is there a way to force it to download?
",<kubernetes><kubernetes-helm>,49820299,47,"you need to change the tag version in the image section of  values.yaml:
image:
  repository: bar
  tag: 4.5.2
  pullpolicy: always

and then run the following command:
helm upgrade myrelease repo/foo 

or just run the following:
helm upgrade myrelease repo/foo --set=image.tag=1.2.2

and set the applicable image version.
"
69095627,cronjob created as job in k8s 1.19.11,"i have what seems like an api issue that results in not being to be able to create a job from a cron job.
i have a cronjob helm file using the api like so:
apiversion: batch/v1beta1
kind: cronjob

deploying that with helm works just fine.
then after it is deployed i attempt to create a job using that cronjob like so:
 kubectl create job $(helm-release-name) --from=cronjob/connector-config

this used to create the job based on the chart above. now however, since upgrading to 1.19.11 i instead get this error:
##[error]error: unknown object type *v1beta1.cronjob
commandoutput
##[error]the process 
'/opt/hostedtoolcache/kubectl/1.22.1/x64/kubectl' failed with exit code 1

if i change the api in the helm chart to this:
apiversion: batch/v1
kind: cronjob

then the helm chart fails to deploy.
upgrade failed: unable to recognize &quot;&quot;: no matches for kind &quot;cronjob&quot; in version 
&quot;batch/v1&quot;

suggestions?
thanks!
",<kubernetes><kubernetes-helm>,69097277,3,"cronjobs is generally available (ga) in google kubernetes engine (gke) version 1.21 and later.
the version you should use apiversion: batch/v1
https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/

cronjobs was promoted to general availability in kubernetes v1.21. if
you are using an older version of kubernetes, please refer to the
documentation for the version of kubernetes that you are using, so
that you see accurate information. older kubernetes versions do not
support the batch/v1 cronjob api.

you can check the support kubernetes api versions using
kubectl api-resources or kubectl api-versions

you can also try
kubectl explain &lt;resource type&gt;

kubectl explain cronjob

"
57685866,is it possible to expose the contents of application.properties as key/value pairs in env inside the container?,"i have defined application properties files in a config dir. config dir is on the below structure.

config
  application.properties
  application-test.properties
  application-dev.properties
  application-prod.properties


i have defined configmap as below 

{{ range $path, $bytes := .files.glob ""config/*"" }}
  {{ base $path }}: '{{- $.files.get $path | nindent 2 | upper | replace ""."" ""_"" }}'
  {{- end }}


we are consuming the configmap via environment variables in a running container using the envfrom property. (this in my deployment yaml file)

spec:
   containers:
   - envfrom:
     - configmapref:
         name: nginx-configmap


post running helm install, i see that configmap is generated.

kubectl describe cm sample-configmap
data
====
----
 server_port = 8080 server_name = localhost server_greeting = greeting-service 
----


in configmap,  the contents are not generated as single string instead of key/value pair.

even, inside the container, the values are not stored as key/value pair. they are stored as string.

kubectl exec -it &lt;pod&gt; sh
/data # env | grep application.properties
application.properties= server_port = 8080 server_name = localhost server_greeting = greeting-service sample_groupa_param1 = value1base sample_groupa_param2 = value2base sample_higherparam = valuehigherbase
/data # echo $application.properties
.properties
/data # echo $server_port



i have also tried 

data:
  {{- (.files.glob ""config/*"").asconfig | nindent 2 | upper | replace ""."" ""_"" }}


observe the same issue. 

is it possible to expose the contents of application.properties as key/value pairs in env inside the container?
",<kubernetes><kubernetes-helm><configmap>,57688840,1,"the issue is the way you are reading your files and configmap configuration.
assuming your file from config folder looks like this (please note that integers should be included in as quoted strings):

config.ini

server_port = ""8080"" 
server_name = localhost 
server_greeting = greeting-service 
sample_groupa_param1 = value1base 
sample_groupa_param2 = value2base 
sample_higherparam = valuehigherbase


configmap.yaml

apiversion: v1
kind: configmap
metadata:
  name: special-config
data:
{{ range $path, $bytes := .files.glob ""config/*"" }}
  {{- $.files.get $path | indent 2 | upper | replace ""."" ""_"" | replace "" = "" "": "" }}
{{- end }}


pod.yaml

apiversion: v1
kind: pod
metadata:
  name: test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ ""/bin/sh"", ""-c"", ""env"" ]
      envfrom:
      - configmapref:
          name: special-config


output:

$ kubectl logs test-pod
kubernetes_port=tcp://10.96.0.1:443
kubernetes_service_port=443
sample_groupa_param1=value1base
sample_groupa_param2=value2base
hostname=test-pod
...
pwd=/
kubernetes_service_host=10.96.0.1
server_greeting=greeting-service
server_port=8080
server_name=localhost


see configure all key-value pairs in a configmap as container environment variables
"
66750257,"return persistent volume (pv) capacity in integer instead of gi, mi, ki, g, m, k etc","i would like to calculate the total number of bytes allocated by the persistent volumes (pvs) in a cluster. using the following:
$ kubectl get pv -a -o json

i can get a json list of all the cluster's pvs and for each pv in the items[] list one can read the spec.capacity.storage key to access the necessary information.
see example below:
{
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;kind&quot;: &quot;persistentvolume&quot;,
  &quot;spec&quot;: {
    &quot;accessmodes&quot;: [
      &quot;readwriteonce&quot;
    ],
    &quot;capacity&quot;: {
      &quot;storage&quot;: &quot;500gi&quot;
    },
    &quot;claimref&quot;: {
      &quot;apiversion&quot;: &quot;v1&quot;,
      &quot;kind&quot;: &quot;persistentvolumeclaim&quot;,
      &quot;name&quot;: &quot;s3-storage-minio&quot;,
      &quot;namespace&quot;: &quot;default&quot;,
      &quot;resourceversion&quot;: &quot;515932&quot;,
    },
    &quot;persistentvolumereclaimpolicy&quot;: &quot;delete&quot;,
    &quot;volumemode&quot;: &quot;filesystem&quot;,
  },
  &quot;status&quot;: {
    &quot;phase&quot;: &quot;bound&quot;
  }
},

however, the returned values can be represented in different suffix (storage as a plain integer or as a fixed-point number using one of these suffixes: e, p, t, g, m, k. or similarly, power-of-two equivalents: ei, pi, ti, gi, mi, ki).
is there a neat way to request the capacity in integer format (or any other format but consistent among all the pvs) using the kubectl?
otherwise, transforming different suffix to a common one in bash looks like not very straightforward.
thanks in advance for your help.
",<kubernetes><kubernetes-pvc>,66783417,4,"i haven't found a way to transform a value in .spec.capacity.storage using purely kubectl.

i've managed to create a code with python and it's kubernetes library to extract the data and calculate the size of all used pv's. please treat this code as an example and not production ready:
from kubernetes import client, config
import re 

config.load_kube_config() # use .kube/config
v1 = client.corev1api()

multiplier_dict = {&quot;k&quot;: 1000, &quot;ki&quot;: 1024, &quot;m&quot;: 1000000, &quot;mi&quot;: 1048576 , &quot;g&quot;: 1000000000, &quot;gi&quot;: 1073741824} # and so on ... 
size = 0 

# for i in v1.list_persistent_volume_claim_for_all_namespaces(watch=false).items: # pvc

for i in v1.list_persistent_volume(watch=false).items: # pv

    x = i.spec.capacity[&quot;storage&quot;] # pv
    # x = i.spec.resources.requests[&quot;storage&quot;] # pvc
    y = re.findall(r'[a-za-z]+|\d+', x)
    print(y)

    # try used if no suffix (like mi) is used
    try: 
        if y[1] in multiplier_dict: 
            size += multiplier_dict.get(y[1]) * int(y[0])
    except indexerror:
            size += int(y[0])
    
print(&quot;the size in bytes of all pv's is: &quot; + str(size))

having as an example a cluster that has following pv's:

$ kubectl get pv

name                                       capacity   access modes   reclaim policy   status   claim               storageclass   reason   age
pvc-6b5236ec-547f-4f96-8448-e3dbe01c9039   500mi      rwo            delete           bound    default/pvc-four    hostpath                4m13s
pvc-86d178bc-1673-44e0-9a89-2efb14a1d22c   512m       rwo            delete           bound    default/pvc-three   hostpath                4m15s
pvc-89b64f93-6bf4-4987-bdda-0356d19d6f59   1g         rwo            delete           bound    default/pvc-one     hostpath                4m15s
pvc-a3455e77-0db0-4cab-99c9-c72721a65632   10ki       rwo            delete           bound    default/pvc-six     hostpath                4m14s
pvc-b47f92ef-f627-4391-943f-efa4241d0811   10k        rwo            delete           bound    default/pvc-five    hostpath                4m13s
pvc-c3e13d78-9047-4899-99e7-0b2667ce4698   1gi        rwo            delete           bound    default/pvc-two     hostpath                4m15s
pvc-c57fe2b0-013a-412b-bca9-05050990766a   10         rwo            delete           bound    default/pvc-seven   hostpath                113s

the code would produce the output of:
['500', 'mi']
['512', 'm']
['1', 'g']
['10', 'ki']
['10', 'k']
['1', 'gi']
['10']
the size in bytes of all pv's is: 3110050074


adding to the whole answer remember that there could be differences on the request of a pvc and the actual pv size. please refer to the storage documentation of your choosing on that regard.

pvc.yaml:

apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: pvc
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 100m

part of the $ kubectl get pvc -o yaml output:
  spec:
    accessmodes:
    - readwriteonce
    resources:
      requests:
        storage: 100m # &lt;-- request
    &lt;-- redacted --&gt; 
  status:
    accessmodes:
    - readwriteonce
    capacity:
      storage: 1gi # &lt;-- size of pv
    phase: bound


additional resources:

kubernetes.io: docs: concepts: storage: persistent volumes
wikipedia.org: byte: multiple byte units

"
66881237,how can i tell what causes a helm chart deployment to fail?,"if a helm deployment's status is failed, what can i do to determine what made it fail?
",<kubernetes><kubernetes-helm><rancher>,70174972,17,"helm history &lt;release_name&gt;
shows the kubernetes errors for the attempted deployment of that release.
"
60111764,azure aks - pod keep crashloopbackoff status,"i am trying to deploy application from my personal docker registry into azure aks pods.
i have python application that only logs some output:

import time
import logging

logger = logging.getlogger('main')
logger.setlevel(logging.info)

handler = logging.streamhandler(sys.stdout)
handler.setlevel(logging.debug)
formatter = logging.formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setformatter(formatter)
logger.addhandler(handler)

def main():
    logger.info('this is test')
    time.sleep(5)


while true:
    try:
        main()
    except exception:
        logger.critical('something critical.', exc_info=1)

    logger.info('sleep for 5 seconds')
    time.sleep(5)


and this is my dockerfile:

from python:3.7-alpine

run apk update &amp;&amp; apk upgrade

arg app_dir=/app
run mkdir -p ${app_dir}
workdir ${app_dir}

copy requirements.txt .

run \
 apk add --no-cache --virtual .build-deps gcc python3-dev musl-dev linux-headers &amp;&amp; \
 python3 -m pip install -r requirements.txt --no-cache-dir &amp;&amp; \
 apk --purge del .build-deps

copy app .

entrypoint [ ""python"", ""-u"", ""run.py"" ]


i am able to run the container on my local computer, here some logs:

docker logs -tf my-container
2020-02-07t10:26:57.939062754z 2020-02-07 10:26:57,938 - main - info - this is test
2020-02-07t10:27:02.944500969z 2020-02-07 10:27:02,943 - main - info - sleep for 5 seconds
2020-02-07t10:27:07.948643749z 2020-02-07 10:27:07,948 - main - info - this is test
2020-02-07t10:27:12.953683767z 2020-02-07 10:27:12,953 - main - info - sleep for 5 seconds
2020-02-07t10:27:17.955954057z 2020-02-07 10:27:17,955 - main - info - this is test
2020-02-07t10:27:22.960453835z 2020-02-07 10:27:22,959 - main - info - sleep for 5 seconds
2020-02-07t10:27:27.964402790z 2020-02-07 10:27:27,963 - main - info - this is test
2020-02-07t10:27:32.968647112z 2020-02-07 10:27:32,967 - main - info - sleep for 5 seconds


i am trying to deploy pod with this yaml file with kubectl apply -f onepod.yaml:

apiversion: v1
kind: pod
metadata:
  name: my-container
  labels:
    platform: xxx
    event: yyy
    protocol: zzz
spec:
    imagepullsecrets:
    - name: myregistry
    containers:
    - name: my-container
      image: mypersonalregistry/my-container:test


the pod is created but keep crashloopbackoff status without any output logs via kubectl logs command. i tried kubectl describe pod but in events are nothing usefull:

name:         my-container
namespace:    default
priority:     0
node:         aks-agentpool-56095163-vmss000000/10.240.0.4
start time:   fri, 07 feb 2020 11:41:48 +0100
labels:       event=yyy
              platform=xxx
              protocol=zzz
annotations:  kubectl.kubernetes.io/last-applied-configuration:
                {""apiversion"":""v1"",""kind"":""pod"",""metadata"":{""annotations"":{},""labels"":{""event"":""yyy"",""platform"":""xxx"",""protocol"":""zzz""},""name"":""my-container...
status:       running
ip:           10.244.1.33
ips:          &lt;none&gt;
containers:
  my-container:
    container id:   docker://c497674f86deadca2ef874f8a94361e26c770314e9cff1729bf20b5943d1a700
    image:          mypersonalregistry/my-container:test
    image id:       docker-pullable://mypersonalregistry/my-container@sha256:c4208f42fea9a99dcb3b5ad8b53bac5e39bc54b8d89a577f85fec1a94535bc39
    port:           &lt;none&gt;
    host port:      &lt;none&gt;
    state:          waiting
      reason:       crashloopbackoff
    last state:     terminated
      reason:       completed
      exit code:    0
      started:      fri, 07 feb 2020 12:28:10 +0100
      finished:     fri, 07 feb 2020 12:28:10 +0100
    ready:          false
    restart count:  14
    environment:    &lt;none&gt;
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lv75n (ro)
conditions:
  type              status
  initialized       true 
  ready             false 
  containersready   false 
  podscheduled      true 
volumes:
  default-token-lv75n:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-lv75n
    optional:    false
qos class:       besteffort
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type     reason     age                    from                                        message
  ----     ------     ----                   ----                                        -------
  normal   scheduled  49m                    default-scheduler                           successfully assigned default/my-container to aks-agentpool-56095163-vmss000000
  normal   pulled     48m (x5 over 49m)      kubelet, aks-agentpool-56095163-vmss000000  container image ""mypersonalregistry/my-container:test"" already present on machine
  normal   created    48m (x5 over 49m)      kubelet, aks-agentpool-56095163-vmss000000  created container my-container
  normal   started    48m (x5 over 49m)      kubelet, aks-agentpool-56095163-vmss000000  started container my-container
  warning  backoff    4m55s (x210 over 49m)  kubelet, aks-agentpool-56095163-vmss000000  back-off restarting failed container


how can i find out, why does it work on my computer but not in kubernetes cluster?
",<kubernetes><kubectl><azure-aks><kubernetes-pod>,60137624,3,"so the porblem was with pulling latest version of my image. more here:


  the default pull policy is ifnotpresent which causes the kubelet to skip pulling an image if it already exists.


so it still run the first version of my-container with tag test and never download new one even when it is in my registry.

solution is add this line to yaml file:

imagepullpolicy: always

"
63766999,unset/remove default value in helm values.yaml,"i have a downloaded file through helm inspect called sftp.yaml
i have a parameter in that sftp.yaml file:-
sftp:
    allowedmacs: &quot;hmac-sha2-512&quot;
    allowedciphers: aes256-ctr

now if i install the corresponding helm chart after commenting out the entire line of &quot;allowedmacs&quot; from custom values files i.e. &quot;sftp.yaml&quot;, then k8s takes the delta of sftp.yaml and the actual values.yaml and then use values.yaml's &quot;allowedmacs&quot;.
however what i want is if &quot;allowedmacs&quot; line is commented in &quot;sftp.yaml&quot; custom values file, then it should not set the env variable at all, or sets it as null.
presently my deployment file's env section looks like
  - name: macs
    value: {{ default &quot;&quot; .values.sftp.allowedmacs | quote }}

",<kubernetes><kubernetes-helm>,63791176,42,"you need to either override (with new value) or unset the value, if you only comment out the section you are not doing any of the above and the default value is going to be used.
basically you are looking to unset a default value. as per banzaicloud example this can be done like so:
helm install stable/chart-name --set sftp.allowedmacs=null

you can also use override value file in a similar way:
sftp:
    allowedmacs: null
    allowedciphers: aes256-ctr

this is available in helm since version 2.6. if you like in-depth information you can review the issue and the subsequent pr that introduced the feature.
"
60744761,adding firewall rule for gke nodes,"so i'm trying to achieve the following: 
- via terraform deploy rancher 2 on gce
- create k8s cluster
- add firewall rules so the nodes are able to talk back to the racher master vm.

i was able to add a firewall rule with the external ips of the nodes to access the rancher master, but instead of adding the ips i should be able to use a tag. google kubernetes engine create a compute engine instance group

 gke-c-wlvrt-default-0-5c42eb4e-grp


when i add in the firewall rules:

target tag: rancher-master
source tag: gke-c-wlvrt-default-0-5c42eb4e-grp


nothing works.

when i change it to: 

target tag: rancher-master
source ip: 35.xx.xx.xx, 35.xx.xx.xx.xx, 35.xx.x.xxx.x


it works. 

so to i get the tags for the kubernetes nodes working on the firewall rule ? 
",<kubernetes><google-cloud-platform><google-kubernetes-engine><rancher><terraform-provider-gcp>,60754218,3,"you don't use the correct tag. for knowing it, go to compute engine page and click on the detail on a vm. you can see this:



the instance group name is not the same as the network tag name. use the network tag instead of the instance group name.

you can also see these values when you go to the instance group page, and you go to the instance template detail.

update

because you can't (or i don't know how to do) know the network tag applied to the vm, you can use a special trick on gcp.

start to update your node pool definition with a service account

resource ""google_service_account"" ""sa-node"" {
  account_id = ""sa-node""
  display_name = ""sa-node""
}

resource ""google_container_node_pool"" ""primary_preemptible_nodes"" {
  name       = ""my-node-pool""
  location   = ""us-central1""
  cluster    = google_container_cluster.primary.name
  node_count = 1

  node_config {
    preemptible  = true
    machine_type = ""n1-standard-1""
    service_account = google_service_account.sa-node.email
....



then define a firewall rule by using the service account as source, instead of the network tag

resource ""google_compute_firewall"" ""default"" {
  name    = ""test-firewall""
  network = google_compute_network.default.name

  allow {
    protocol = ""tcp""
    ports    = [""80"", ""8080"", ""1000-2000""]
  }

  source_service_accounts = [google_service_account.sa-node.email]
}


sadly, you can't mix target tag and source service account, but you can use a target service account. thus, do the same thing on rancher. use a specific service account for your rancher deployment and that should work.

hope this help!
"
56008728,istio 1.1.4 helm setup --set global.defaultnodeselector sample,"regarding the current installation options for istio 1.1.4 it should be possible to define a default node selector which gets added to all istio deployments

the documentation does not show a dedicated sample how the selector has to be defined, only {} as value.

currently i was not able to find a working format to pass the values to the helm charts by using --set, e.g:

 --set global.defaultnodeselector=""{cloud.google.com/gke-nodepool:istio-pool}""


i tried several variations, with and without escapes, json map, ... but currently everything results into the same helm error message:

2019/05/06 15:58:10 warning: merging destination map for chart 'istio'. cannot overwrite table item 'defaultnodeselector', with non table value: map[]

istio version 1.1.4

helm 2.13.1


the expectation would be to have a more detailed documentation, giving some samples on istio side.
",<kubernetes><kubernetes-helm><istio>,56025402,2,"when specifying overrides with --set, multiple key/value pairs are deeply merged based on keys. it means in your case, that only last item will be present in the generated template. the same will happen even if you override with -f (yaml file) option. 
here is an example of -f option usage with custom_values.yaml, with distinguished keys: 

#custom_values.yaml

global:
  defaultnodeselector:
    cloud.google.com/bird: stork
    cloud.google.com/bee: wallace



  helm template . -x charts/pilot/templates/deployment.yaml -f
  custom_values.yaml


snippet of rendered istio`s pilot deployment.yaml manifest file:

 volumes:
      - name: config-volume
        configmap:
          name: istio
      - name: istio-certs
        secret:
          secretname: istio.istio-pilot-service-account
          optional: true
      affinity:      
        nodeaffinity:
          requiredduringschedulingignoredduringexecution:
            nodeselectorterms:
            - matchexpressions:
              - key: beta.kubernetes.io/arch
                operator: in
                values:
                - amd64
                - ppc64le
                - s390x
              - key: cloud.google.com/bee
                operator: in
                values:
                - wallace
              - key: cloud.google.com/bird
                operator: in
                values:
                - stork
          preferredduringschedulingignoredduringexecution:
          - weight: 2
            preference:
              matchexpressions:
              - key: beta.kubernetes.io/arch
                operator: in
                values:
                - amd64


the same can be achieved with --set:

--set global.defaultnodeselector.""cloud\.google\.com/bird""=stork,global.defaultnodeselector.""cloud\.google\.com/bee""=wallace

"
72060758,helm 2.x - use subchart as template,"depending on a subchart via requirements.yaml results in the template being rendered. i'm aware that i can use aliases to have more than one copy of a subchart, but is there a way to prevent the subchart to be rendered by default and instead included as a template, along the lines of:
{{- $root := . }}

{{- range $i, $service := .values.services }}
---
{{ $k8sdeployment := (include &quot;my_subchart_name&quot; (dict &quot;top&quot; $root &quot;deployment&quot; $service)) | fromyaml }}
{{ include &quot;deployment&quot;  (dict &quot;top&quot; $root &quot;deployment&quot; $k8sdeployment) }}
---
{{ $k8sservice := (include &quot;my_subchart_name2&quot; $service) | fromyaml }}
{{ include &quot;service&quot; (dict &quot;top&quot; $root &quot;service&quot; $k8sservice) }}
{{- end -}}

",<kubernetes><yaml><google-kubernetes-engine><kubernetes-helm>,72067544,1,"no, there's no way to do this.  helm dependencies (both in helm 2 and helm 3) work only as things that are installed in the cluster under the same helm release name.  without using something like a post-renderer to manipulate the produced yaml, there's no way to include only part of a dependency chart or to re-include its kubernetes objects with different parameters.
one could imagine the subchart being specifically designed to be used this way.  the subchart would have to provide the templates you're trying to call, and its templates/*.yaml file would call those templates with standard values inside an if block, and then your parent chart could depend on the subchart with a value that disabled its normal output.  most charts aren't built this way, though.
"
48850255,kubernetes fission setup fails,"i am trying to install fission on a kubernetes cluster. when i ran: 

helm install --namespace fission https://github.com/fission/fission/releases/download/0.4.1/fission-all-0.4.1.tgz


i gave some errors:

e0218 09:14:41.578967    3357 portforward.go:331] an error occurred forwarding 36281 -&gt; 44134: error forwarding port 44134 to pod b29ecdfb514ada5583e99e416d3fc07e25d5bcf71206b450a1f4f972a9d2502b, uid : exit status 1: 2018/02/18 09:14:41 socat[26057] e connect(5, af=2 127.0.0.1:44134, 16): connection refused
error: transport is closing


how can i fix these errors and install fission?

my cluster os is debian 9 and kubernetes version is:

kubeadm version: &amp;version.info{major:""1"", minor:""9"", gitversion:""v1.9.3"", gitcommit:"""", gittreestate:""clean"", builddate:""2018-02-07t11:55:20z"", goversion:""go1.9.2"", compiler:""gc"", platform:""linux/amd64""}


update:

i solved the previous error and i could install fission. but i have a new error. when i ran fission env create --name nodejs --image fission/node-env:0.4.1

i gave this error:

failed to create environment: post 
http://178.162.203.65:31313/v2/environments: dial tcp 178.162.203.65:31313: 
getsockopt: connection refused

",<kubernetes><kubernetes-helm><kubernetes-fission>,48900857,2,"finally i own found the answer of the question. when i was installing the kubernetes. exactly after ran kubeadm init i must ran :

mkdir -p $home/.kube
sudo cp -i /etc/kubernetes/admin.conf $home/.kube/config
sudo chown $(id -u):$(id -g) $home/.kube/config


neither root nor none-root must ran the above command.(i don't know why)
"
59903851,gce loadbalancer not being created despite ingress resource creation,"i am installing the official jenkins helm chart on gke.

i am enabling ingress therefore the corresponding template should be applied and the resource created.

according to the official gke documentation:


  when you create the ingress, the gke ingress controller creates and configures an http(s) load balancer according to the information in the ingress and the associated services. also, the load balancer is given a stable ip address that you can associate with a domain name.


however, this does not happen in my case; the ingress does not get an external ip associated with it:

▶ k get ingress --all-namespaces
namespace   name                hosts   address   ports   age
jenkins     jenkins-inception   *                 80      82s


here is the actual ingress resource:

▶ k get ingress --all-namespaces -o yaml
apiversion: v1
items:
- apiversion: extensions/v1beta1
  kind: ingress
  metadata:
    annotations:
      kubernetes.io/ingress.class: nginx
    creationtimestamp: ""2020-01-24t21:20:49z""
    generation: 1
    labels:
      app.kubernetes.io/component: jenkins-master
      app.kubernetes.io/instance: jenkins-inception
      app.kubernetes.io/managed-by: tiller
      app.kubernetes.io/name: jenkins
      helm.sh/chart: jenkins-1.9.16
    name: jenkins-inception
    namespace: jenkins
    resourceversion: ""15741661""
    selflink: /apis/extensions/v1beta1/namespaces/jenkins/ingresses/jenkins-inception
    uid: 6461793e-3eef-11ea-a0a5-42010a790807
  spec:
    rules:
    - http:
        paths:
        - backend:
            servicename: jenkins-inception
            serviceport: 8080
          path: /jenkins
  status:
    loadbalancer: {}
kind: list
metadata:
  resourceversion: """"
  selflink: """"


why is that?

have tried both nginx and gce in kubernetes.io/ingress.class annotation values.

edit_1: it seems that the http load balancing add on is enabled.



the weirdest part however is the following:

▶ k describe ingress jenkins-inception -n jenkins
error from server (notfound): the server could not find the requested resource

~                                                                                                                                         
▶ k get ingress jenkins-inception -n jenkins
name                hosts   address   ports   age
jenkins-inception   *                 80      11h



edit_2:

client version: version.info{major:""1"", minor:""15"", gitversion:""v1.15.0"", gitcommit:""e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529"", gittreestate:""clean"", builddate:""2019-06-19t16:40:16z"", goversion:""go1.12.5"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""13+"", gitversion:""v1.13.11-gke.14"", gitcommit:""56d89863d1033f9668ddd6e1c1aea81cd846ef88"", gittreestate:""clean"", builddate:""2019-11-07t19:12:22z"", goversion:""go1.12.11b4"", compiler:""gc"", platform:""linux/amd64""}



edit_3: after addressing the kubectl compatibility issue, it turns out no events are generated by the ingress

▶ k describe ingress jenkins-inception -n jenkins
name:             jenkins-inception
namespace:        jenkins
address:
default backend:  default-http-backend:80 (10.8.32.33:8080)
rules:
  host  path  backends
  ----  ----  --------
  *
        /jenkins   jenkins-inception:8080 (10.8.33.87:8080)
annotations:
  kubernetes.io/ingress.class:  nginx
events:                         &lt;none&gt;


is there a command line to list enabled add-ons on a cluster?

edit_4: about the add ons..

▶ gcloud container clusters describe inception-cluster --zone us-east4-b | grep -i add -a 6
addonsconfig:
  horizontalpodautoscaling: {}
  httploadbalancing: {}
  kubernetesdashboard:
    disabled: true
  networkpolicyconfig:
    disabled: true


edit_5: after enabling the actual gce ingress with the correct annotation as pointed out in comments by @arghya sadhu, i see the following error in the ingress description


  warning  translate  2s (x11 over 7s)  loadbalancer-controller  error while evaluating the ingress spec: service ""jenkins/jenkins-inception"" is type ""clusterip"", expected ""nodeport"" or ""loadbalancer""


however this contradicts with the following recommendation from the official jenkins helm charts:

  # for minikube, set this to nodeport, elsewhere use loadbalancer
  # use clusterip if your setup includes ingress controller


edit_6: the ingress managed to get a public ip:

  spec:
    rules:
    - http:
        paths:
        - backend:
            servicename: jenkins-inception
            serviceport: 8080
          path: /jenkins
  status:
    loadbalancer:
      ingress:
      - ip: 12.234.543.111


however i am unable to access the following paths:

https://12.234.543.111/jenkins
http://12.234.543.111/jenkins
https://12.234.543.111
http://12.234.543.111


edit_7: the yaml of the jenkins-inception service

▶ k get svc jenkins-inception -o yaml
apiversion: v1
kind: service
metadata:
  creationtimestamp: ""2020-01-25t12:40:14z""
  labels:
    app.kubernetes.io/component: jenkins-master
    app.kubernetes.io/instance: jenkins-inception
    app.kubernetes.io/managed-by: tiller
    app.kubernetes.io/name: jenkins
    helm.sh/chart: jenkins-1.9.16
  name: jenkins-inception
  namespace: jenkins
  resourceversion: ""16000964""
  selflink: /api/v1/namespaces/jenkins/services/jenkins-inception
  uid: d5bfd760-3f6f-11ea-a0a5-42010a790807
spec:
  clusterip: 10.8.59.184
  externaltrafficpolicy: cluster
  ports:
  - name: http
    nodeport: 30361
    port: 8080
    protocol: tcp
    targetport: 8080
  selector:
    app.kubernetes.io/component: jenkins-master
    app.kubernetes.io/instance: jenkins-inception
  sessionaffinity: none
  type: nodeport
status:
  loadbalancer: {}

",<kubernetes><google-cloud-platform><google-kubernetes-engine>,59905954,1,"run describe on the ingress. if you see create/add events, you have an ingress controller running in the cluster, otherwise, you probably have the httploadbalancing(gke ingress controller) add-on disabled on your gke cluster

edit1:

you have version incompatibility between kubernetes server and kubectl. you can check both client and server version by running below command. check this issue for details.

kubectl version


edit2:

you either should not have the annotation kubernetes.io/ingress.class or if you have it needs be gce kubernetes.io/ingress.class:  gce

edit3:

as per the google cloud doc the service type for jenkins-inception service needs to be of type nodeport 
"
49417575,"error: found in requirements.yaml, but missing in charts/ directory: dependency-chart","i'm getting the following error

error: found in requirements.yaml, but missing in charts/ directory: dependency-chart


when i try to install a chart. the chart has a dependency on dependency-chart. 

requirements.yaml:

dependencies:
- name: dependency-chart
  repository: ""@some-repo""
  version: 0.1.0


commands performed:

rm -rf charts
helm dep up
helm upgrade --install chart-to-install . --debug


output:

hang tight while we grab the latest from your chart repositories...
...successfully got an update from the ""some-repo"" chart repository
update complete. ⎈happy helming!⎈
saving 1 charts
downloading dependency-chart from repo gs://some-repo
deleting outdated charts

[debug] created tunnel using local port: '65477'
[debug] server: ""127.0.0.1:65477""
error: found in requirements.yaml, but missing in charts/ directory: dependency-chart


charts/ directory contains dependency-chart-0.1.0.tgz

i have many other charts which depends on dependency-chart and they work just fine. helm lint does not help:

==&gt; linting .
[error] chart.yaml: directory name (helm) and chart name (dependency-chart) must be the same
[info] chart.yaml: icon is recommended
[warning] templates/: directory not found

error: 1 chart(s) linted, 1 chart(s) failed


the error is reported by the linter in other charts where the helm install command works, so it's not really helping me.

i've tried to point to the local chart in the requirements.yaml instead of from the aliased repository, same result.

i've run out of things to try to debug the issue as well, any suggestion?
",<kubernetes><kubernetes-helm>,49428255,15,"i've started debugging the helm project locally and i stumbled upon this:

// if a .helmignore file matches, skip this file.
if rules.ignore(n, fi) {
    return nil
}


this reminded me that, for some reason, i've added charts/ to the .helmignore file. and that is the reason why it was not seeing the downloaded dependencies :(
"
56871198,creating multiple namespaces from the kubernetes command line interface,"i want to create multiple namespaces from the kubernetes cli (kubectl) without any yaml manifests:
kubectl create namespace app1,app2,app3

can this be done?
",<kubernetes><kubectl>,56871751,3,"kubectl expects exactly one namespace:

➜  / kubectl create ns
error: exactly one name is required, got 0


depending on your shell you could pack it into a loop. here's an example for bash and zsh:

➜  / foreach ns (ns1 ns2 ns3); kubectl create ns $ns; end

"
70493325,helm chart always not going into the if condition,"yaml file and in that below values are defined including one specific value called &quot;environment&quot;
image:
 repository: my_repo_url
 tag: my_tag
 pullpolicy: ifnotpresent

releasename: cron_script
schedule: &quot;0 10 * * *&quot;
namespace: deploy_cron
rav_admin_password: asdf
environment: testing
testing_forwarder_ip: 10.2.71.21
prod_us_forwarder_ip: 10.2.71.15

now in my helm chart based on this environment value i need to assign a value to new variable and for that i have written code like below, but always it is not entering into the if else block itself
{{- $fwip := .values.prod_us_forwarder_ip }}
  {{- if contains .values.environment  &quot;testing&quot; }}
    {{- $fwip := .values.testing_forwarder_ip }}
{{- end }}
---
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: &quot;{{ .values.releasename }}&quot;
  namespace: &quot;{{ .values.namespace }}&quot;
  labels:
  ....................................
  ....................................
  ....................................
  spec:
      restartpolicy: never
      containers:
      - name: &quot;{{ .values.releasename }}&quot;
        image: &quot;{{ .values.image.repository }}:{{ .values.image.tag }}&quot;
        imagepullpolicy: ifnotpresent
        args:
          - python3
          - test.py
          - --data
          - 100
          - {{ $fwip }}

in the above code always i get $fwip value as 10.2.71.21 what ever environment value is either testing or production for both i am getting same value
and if i don't declare the variable $fwip before the if else statement then it says $fwip variable is not defined error, so i am not sure why exactly if else statement is not getting used at all, how to debug further ?
",<kubernetes><kubernetes-helm>,70494290,1,"this is a syntax problem of variables and local variables.
the fwip in if should use = instead of :=
{{- $fwip := .values.prod_us_forwarder_ip }}
{{- if contains .values.environment  &quot;testing&quot; }}
  {{- $fwip = .values.testing_forwarder_ip }}
{{- end }}


i translated it into go code to make it easier for you to understand.
(in the go language, := means definition and assignment, = means assignment)
// := 
env := &quot;testing&quot;
test := &quot;10.2.71.21&quot;
prod := &quot;10.2.71.15&quot;

fwip := prod
if strings.contains(env,&quot;testing&quot;){
    fwip := test
    fmt.println(fwip) // 10.2.71.21
}
fmt.println(fwip) // 10.2.71.15

// =
env := &quot;testing&quot;
test := &quot;10.2.71.21&quot;
prod := &quot;10.2.71.15&quot;

fwip := prod
if strings.contains(env,&quot;testing&quot;){
    fwip = test
    fmt.println(fwip) // 10.2.71.21
}
fmt.println(fwip) // 10.2.71.21

"
69363190,kubernetes python api get instances of crd,"i'm currently using the python apis for kubernetes and i have to:

retrieve the instance of a custom resource name fadepl.

edit the value of that instance.


in the terminal, i would simply list all fadepls with kubectl get fadepl and then edit the right one using kubectl edit fadepl &lt;fadepl_name&gt;. i checked the k8s apis for python but i can't find what i need. is it something i can do with the apis?
thank you in advance!
",<kubernetes><kubernetes-apiserver><kubernetes-custom-resources><kubernetes-python-client>,69376195,4,"you're right. using get_namespaced_custom_object you can retrieve the instance. this method returns a namespace scoped custom object. by default it uses a synchronous http request.
since the output of that method returns an object, you can simply replace it using replace_cluster_custom_object.
here you can find implementation examples.
see also whole list of api reference for python.
"
77490368,aks error when trying to install a private marketplace app,"i have created an app that is in a private store on azure.  i am trying to install the app from the marketplace when i get the following error:
error: [ innererror: [helm installation failed : unable to build the kubernetes resources in the extension based on the cluster : innererror [unable to build kubernetes objects from release manifest: error validating &quot;&quot;: error validating data: failed to check crd: failed to list crds: customresourcedefinitions.apiextensions.k8s.io is forbidden: user &quot;system:serviceaccount:kube-system:ext-installer-ssdeploy1&quot; cannot list resource &quot;customresourcedefinitions&quot; in api group &quot;apiextensions.k8s.io&quot; at the cluster scope]]] occurred while doing the operation : [patch] on the config, for general troubleshooting visit: https://aka.ms/k8s-extensions-tsg

here are the role and role binding yamls i tried but that did not work.  i am new to k8s so there are things i do not understand about it.
role.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  namespace: default
  name: default
rules:
- apigroups: [&quot;apiextensions.k8s.io&quot;] 
  resources: [&quot;customresourcedefinitions&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]

role-binding.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: ext-installer-ssdeploy1
  namespace: default
subjects:
- kind: serviceaccount
  name: default
  namespace: default
roleref:
  kind: role 
  name: ext-installer-ssdeploy1
  apigroup: rbac.authorization.k8s.io

any help is greatly appreciated.
",<kubernetes><kubernetes-helm><azure-aks>,77543822,1,"your error indicates that the service account ext-installer-ssdeploy1 does not have necessary permissions to list custom resource definitions in the apiextensions.k8s.io api group. to fix this issue, you need to grant the necessary rbac permissions to the service account. also modify the name attribute in your role.yaml
apiversion: rbac.authorization.k8s.io/v1
kind: role
metadata:
  namespace: default
  name: ext-installer-ssdeploy1
rules:
- apigroups: [&quot;apiextensions.k8s.io&quot;] 
  resources: [&quot;customresourcedefinitions&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;]


kubectl apply -f role.yaml

after granting the necessary permissions, attempt to install the helm chart again, it should work.
reference doc-
official k8s role example
"
47655363,adjusting kubernetes configurations depending on environment,"i want to describe my services in kubernetes template files. is it possible to parameterise values like number or replicas, so that i can set this at deploy time.

the goal here is to be able to run my services locally in minikube (where i'll only need one replica) and have them be as close to those running in staging/live as possible.

i'd like to be able to change the number of replicas, use locally mounted volumes and make other minor changes, without having to write a seperate template files that would inevitably diverge from each other.
",<kubernetes><kubectl><minikube>,54331943,12,"helm
helm is becoming the standard for templatizing kubernetes deployments. a helm chart is a directory consisting of yaml files with golang variable placeholders
---
kind: deployment
metadata:
  name: foo
spec:
  replicas: {{ .values.replicacount }}

you define the default value of a 'value' in the 'values.yaml' file
replicacount: 1

you can optionally overwrite the value using the --set command line
helm install foo --set replicacount=42

helm can also point to an external answer file
helm install foo -f ./dev.yaml
helm install foo -f ./prod.yaml

dev.yaml
---
replicacount: 1

prod.yaml
---
replicacount: 42

another advantage of helm over simpler solutions like envbsubst is that helm supports plugins. one powerful plugin is the helm-secrets plugin that lets you encrypt sensitive data using pgp keys. https://github.com/futuresimple/helm-secrets
if using helm + helm-secrets your setup may look like the following where your code is in one repo and your data is in another.
git repo with helm charts
stable
  |__mysql
     |__values.yaml
     |__charts
  |__apache
     |__values.yaml
     |__charts
incubator
  |__mysql
     |__values.yaml
     |__charts
  |__apache
     |__values.yaml
     |__charts


then in another git repo that contains the environment specific data
values
|__ mysql
    |__dev
       |__values.yaml
       |__secrets.yaml
    |__prod
       |__values.yaml
       |__secrets.yaml


you then have a wrapper script that references the values and the secrets files
helm secrets upgrade foo --install -f ./values/foo/$environment/values.yaml -f ./values/foo/$environment/secrets.yaml


envsubst
as mentioned in other answers, envsubst is a very powerful yet simple way to make your own templates. an example from kiminehart
apiversion: extensions/v1beta1
kind: deployment
# ...
    architecture: ${goos}

goos=amd64 envsubst &lt; mytemplate.tmpl &gt; mydeployment.yaml

apiversion: extensions/v1beta1
kind: deployment
# ...
    architecture: amd64


kubectl
there is a feature request to allow kubectl to do some of the same features of helm and allow for variable substitution. there is a background document that strongly suggest that the feature will never be added, and instead is up to external tools like helm and envsubst to manage templating.

(edit)
kustomize
kustomize is a new project developed by google that is very similar to helm. basically you have 2 folders base and overlays. you then run kustomize build someapp/overlays/production and it will generate the yaml for that environment.
   someapp/
   ├── base/
   │   ├── kustomization.yaml
   │   ├── deployment.yaml
   │   ├── configmap.yaml
   │   └── service.yaml
   └── overlays/
      ├── production/
      │   └── kustomization.yaml
      │   ├── replica_count.yaml
      └── staging/
          ├── kustomization.yaml
          └── cpu_count.yaml

it is simpler and has less overhead than helm, but does not have plugins for managing secrets. you could combine kustomize with sops or  envsubst to manage secrets.
https://kubernetes.io/blog/2018/05/29/introducing-kustomize-template-free-configuration-customization-for-kubernetes/
"
66288565,"duplicated env variable names in pod definition, what is the precedence rule to determine the final value?","using kubernetes 1.19.3, i initialize env variable values using 3 different ways:

env field with explicit key/value in the pod definition
envfrom using configmapref and secretref

when a key name is duplicated, as shown in the example below, duplik1 and duplik2 are defined multiple times with different values.
what is the precedence rule that kubernetes uses to assign the final value to the variable?
# create some test key/value configs and key/value secrets
kubectl create configmap myconfigmap --from-literal=duplik1=myconfig1 --from-literal=cmkey1=cmval1 --from-literal=duplik2=fromconfigmap -n mydebugns

kubectl create secret generic mysecret --from-literal=secretkey1=secval1 --from-literal=secretkey2=secval2 --from-literal=duplik2=fromsecret -n mydebugns

# create a test pod
cat &lt;&lt;eof | kubectl apply -n mydebugns -f -
apiversion: v1
kind: pod
metadata:
  name: pod1
spec:
  containers:
    - name: container1
      image: busybox
      command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot; ]
      env:
      - name: duplik1
        value: &quot;key/value defined in field env&quot;
      envfrom:
      - configmapref:
          name: myconfigmap
      - secretref:
          name: mysecret          
  restartpolicy: never
eof

show environement variables values. the result is deterministic. deleting resources + recreate always end up with the same result.
kubectl logs pod/pod1 -n mydebugns

cmkey1=cmval1
duplik1=key/value defined in field env
duplik2=fromsecret
secretkey1=secval1
secretkey2=secval2

cleanup test resources
kubectl delete pod/pod1 -n mydebugns
kubectl delete cm/myconfigmap  -n mydebugns
kubectl delete secret/mysecret -n mydebugns

",<kubernetes><kubernetes-pod><configmap>,66288704,11,"from kubernetes docs:

envvar: list of environment variables to set in the container.
cannot be updated.


envfrom: list of sources to populate environment variables in the
container. the keys defined within a source must be a c_identifier.
all invalid keys will be reported as an event when the container is
starting. when a key exists in multiple sources, the value associated
with the last source will take precedence. values defined by an env
with a duplicate key will take precedence. cannot be updated.

the above link clearly states the env will take precedence over envfrom and cannot be updated.
also, when a referenced key is present in multiple resources, the value associated with the last source will override all previous values.
based on the above, the result you are seeing is expected behavior:

duplik1 is added as env field and thus cannot be updated
duplik2 is added as envfrom and so the one from the secret takes precedence as it is defined at the last

"
70693529,kubernetes delete jobs by name,"i'm on a windows machine in a powershell prompt.
i don't have the linux commands like grep, awk.
i have a couple of jobs that i want to delete

i'm not finding the correct syntax for  deleting them such as
kubectl delete job mailmigrationjob-id699*

or
kubectl delete job where name like mailmigrationjob-id699

",<powershell><kubernetes><kubectl>,70694041,2,"try:
$pattern=&quot;mailmigrationjob-id699&quot;; &amp; kubectl get job | % {&quot;$_&quot; -split &quot; &quot;} | select-string -pattern $pattern | %{ &amp; kubectl delete job $_ }

taken from: delete all kubernetes pods by regex pattern with powershell
"
65960875,delete kubernetes pvc ebs volumes in batch,"i have more than 4000 pvc in my kubernetes aws eks cluster.

from those 4000+ pvc i have to delete almost 3999 pvcs

now instead of using command:
kubetcl delete pvc pvc-data-name

and delete every pvc separately which can take me sooo long.. i want to find a way to delete them in batches or all together.
",<kubernetes><amazon-eks><kubernetes-pvc>,65961365,3,"you can try this one.
kubectl delete pvc --field-selector metadata.name!=&lt;name-dont-want-to-delete-1&gt;, metadata.name!=&lt;name-dont-want-to-delete-2&gt;, metadata.name!=&lt;name-dont-want-to-delete-3&gt;

or,
also you can do this with go-client. to do this with go client see the document ref
i have added a label in every pvc that i don't want to delete.
  labels:
    test: test-1


import (
   &quot;context&quot;
   &quot;fmt&quot;
   metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;

   &quot;k8s.io/client-go/kubernetes&quot;
   &quot;k8s.io/client-go/util/homedir&quot;
   &quot;kmodules.xyz/client-go/tools/clientcmd&quot;
   &quot;log&quot;
   &quot;path/filepath&quot;
)

func testfunc() ( error) {
   masterurl := &quot;&quot;

   kubeconfigpath := filepath.join(homedir.homedir(), &quot;.kube&quot;, &quot;config&quot;)



   config, err := clientcmd.buildconfigfromflags(masterurl, kubeconfigpath)
   if err != nil {
       log.fatalf(&quot;could not get kubernetes config: %s&quot;, err)
   }

   kc := kubernetes.newforconfigordie(config)
   labelselector := &amp;metav1.labelselector{
       matchexpressions: []metav1.labelselectorrequirement{
           {
               &quot;test&quot;,
               metav1.labelselectoropnotin,
               []string{
                   &quot;test-0&quot;,
                   &quot;test-1&quot;,
               },
           },
       },
   }
   err = kc.corev1().persistentvolumeclaims(&quot;default&quot;).deletecollection(context.todo(), metav1.deleteoptions{}, metav1.listoptions{
       labelselector: metav1.formatlabelselector(labelselector),
   })
   fmt.println(err)
   
   return  nil
}



"
69881586,how can i disable a service been monitor on the prometheus-operator stack,"we have deployed the prometheus-operator stack on aws eks
by default it monitors all services deployed.
is it possible to configure the prometheus-operator stack to by default monitor all services with the exceptions of services &quot;foo&quot; and &quot;bar&quot;
",<kubernetes><prometheus><kubernetes-helm><prometheus-operator>,69883331,2,"you can use service monitor resource to limit what to be monitored:
take a look at documentation
you can remove services from monitoring by excluding them from selector or namespace selector in servicemonitor specification.
as an example:
apiversion: monitoring.coreos.com/v1
kind: servicemonitor
metadata:
  name: k8s-apps-http
  labels:
    k8s-apps: http
spec:
  joblabel: k8s-app
  selector:
    matchexpressions:
    - {key: foo, operator: notin} &lt;---
    - {key: bar, operator: notin} &lt;---
  namespaceselector:
    matchnames:
    - kube-system
    - monitoring
  endpoints:
  - port: http-metrics
    interval: 15s

"
61639038,kubernetes management of traffic between pod replicas of different applications in one cluster,"i have a keycloak and client application on one kubernetes node. i have 3 pods for keycloak and client can i manage traffic in kubernetes so that the query from the client replica to the keycloak always returns to the same replica from which it comes? for now, traffic is being redirected 

client replica -&gt; keyclok -&gt; random client replica.


i want to get effect:

client replica x -&gt; keycloak -&gt; client replica x.


thank you in advance for all the answers
",<kubernetes><keycloak><kubernetes-pod>,61639401,2,"this feature is called sticky sessions, can be configured in nginx ingress controller following these annotations:

https://kubernetes.github.io/ingress-nginx/examples/affinity/cookie/

if you have everything deployed in aws and you are using an alb ingress controller, you can achieve this with stickiness annotation.

my working in production example:

alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=6000

"
67808747,manage environments with github and google kubernetes engine,"i have a github repo with 2 branches on it, develop and main. the first is the &quot;test&quot; environment and the other is the &quot;production&quot; environment. i am working with google kubernetes engine and i have automated deployment from the push on github to the deploy on gke. so our workflow is :

pull develop
write code and test locally
when everything is fine locally, push on develop (it will automatically deploy on gke workload app_name_develop)
qa tests on app_name_develop
if qa tests passed, we create a pull request to put develop into main
automatically deploy on gke workload app_name_production (from the main branch)

the deployment of the container is defined in dockerfile and the kubernetes deployment is defined in kubernetes/app.yaml. those two files are tracked with git inside the repo.
the problem here is when we create a pull request to put develop into main, it also take the two files app.yaml and dockerfile from develop to main. we end up with the settings from develop in main, and it messes the whole thing.
i can't define environment variables in those files because it could end up in the wrong branch.
my question is : how can i exclude those files from the pull request ? or is there any way to manage multiple environments without having to manually modify the files after each pull request ?
i don't know if it can hlphere is my dockerfile :
from python:3.8

run apt-get update &amp;&amp; apt-get install -y --no-install-recommends

run python -m pip install --upgrade pip

workdir /app/

copy requirements.txt .
run python -m pip install -r requirements.txt

copy . .

expose 8080
cmd [&quot;gunicorn&quot;, &quot;-b&quot;, &quot;:8080&quot;, &quot;main:app&quot;]

and here is my yaml file to deploy on gke (actually i took the one advised by gke when creating automated deployment) :
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: app_name-api
  name: app_name-api
  namespace: default
spec:
  replicas: 1
  selector:
    matchlabels:
      app: app_name-api
  strategy:
    rollingupdate:
      maxsurge: 25%
      maxunavailable: 25%
    type: rollingupdate
  template:
    metadata:
      labels:
        app: app_name-api
    spec:
      containers:
        - image: gcr.io/path_to_image/github.com/company_name/app_name
          imagepullpolicy: ifnotpresent
          name: app_name-1
---
apiversion: autoscaling/v2beta1
kind: horizontalpodautoscaler
metadata:
  labels:
    app: app_name-api
  name: app_name-api-pod-autoscaler
  namespace: default
spec:
  maxreplicas: 3
  metrics:
    - resource:
        name: cpu
        targetaverageutilization: 80
      type: resource
  minreplicas: 1
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: app_name-api

thanks a lot for any help you could provide !
",<git><docker><kubernetes><google-cloud-platform><google-kubernetes-engine>,67837669,2,"you can't ignore some files from a pull request selectively. but there are 2 simple workarounds for this :
first -
create a new branch from ‘develop’
replace the non-required files from 'main'
create pull request from this new branch
second -
create a new branch from 'main'
put changes of required files from 'develop'
create pull request from this new branch
any of these methods will work. which will be easier depends on how many files are to be included / excluded.
example :
considering main as target and dev as source
root 
|-- src 
| -- app.py 
|-- .gitignore 
|-- settings.py 
|-- requirements.txt

let's say, i would want to ignore the settings.py file from being merged
first move to the target branch (the branch to which you want to merge the changes)
git checkout main

then you can use the git checkout command to selective pick the files you want to merge
git checkout dev src/

this will only merge the files changed inside src/ folder
note: you can also do it selectively for each file. 

then push to remote repository
git push origin main

bear in mind that this solution is useful only if the files to be excluded are small.
note: &quot;there are tools that are built to solve this problem like  skaffold and kustomize, but they might take a bit of time and restructuring of your repository before everything works. so, in the meantime, this is a simple solution which requires manual work but can do while you study and decide which of the more advanced instrumentation is suitable .&quot;
"
44312745,"kubernetes rbac unable to upgrade connection: forbidden (user=system:anonymous, verb=create, resource=nodes, subresource=proxy)","i'm running kubernetes 1.6.2 with rbac enabled. i've created a user kube-admin that has the following cluster role binding
kind: clusterrolebinding
apiversion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: k8s-admin
subjects:
- kind: user
  name: kube-admin
  apigroup: rbac.authorization.k8s.io
roleref:
  kind: clusterrole
  name: cluster-admin
  apigroup: rbac.authorization.k8s.io

when i attempt to kubectl exec into a running pod i get the following error.
kubectl -n kube-system exec -it kubernetes-dashboard-2396447444-1t9jk -- /bin/bash
error: unable to upgrade connection: forbidden (user=system:anonymous, verb=create, resource=nodes, subresource=proxy)

my guess is i'm missing a clusterrolebinding ref, which role am i missing?
",<kubernetes><kubectl>,44313979,12,"the connection between kubectl and the api is fine, and is being authorized correctly.

to satisfy an exec request, the apiserver contacts the kubelet running the pod, and that connection is what is being forbidden.

your kubelet is configured to authenticate/authorize requests, and the apiserver is not providing authentication information recognized by the kubelet.

the way the apiserver authenticates to the kubelet is with a client certificate and key, configured with the --kubelet-client-certificate=... --kubelet-client-key=... flags provided to the api server.

see https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#overview for more information. 
"
66160603,helm - documentation specification for very unusual and not regular kubernetes yaml format,"on microsoft docs i found that i should define this helm yaml file for creating kubernetes ingress controller:
controller:
  service:
    loadbalancerip: 10.240.0.42
    annotations:
      service.beta.kubernetes.io/azure-load-balancer-internal: &quot;true&quot;

so you can easily notice it does not have usual kubernetes apiversion and kind specification.
and after, on the same link that i need to execute the helm command to create ingress:
helm install nginx-ingress ingress-nginx/ingress-nginx \
    -f internal-ingress.yaml \
..............

as you see - suggested helm file is not very usual, but i would like to stick to those official microsoft instructions!
again, it does not have specification for creating ingress controller using the regular apiversion and kind notation like on many links and examples that can be found on the internet.
https://github.com/helm/charts/blob/master/stable/nginx-ingress/templates/controller-service.yaml
https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/
can i set custom ports for a kubernetes ingress to listen on besides 80 / 443?
so i really feel very very confused!!! can you please help me on this - i need to set it's port but i really could not find specification documentation and examples for this one yaml microsoft example which actually works!!!
controller:
  service:
    loadbalancerip: 10.240.0.42
    annotations:
      service.beta.kubernetes.io/azure-load-balancer-internal: &quot;true&quot;

where and how i can find correct syntax how i can &quot;translate&quot; regular &quot;apiversion&quot; and &quot;kind&quot; specification into this?
why they are making confusion in this way with this different format???
please help! thanks
",<kubernetes><kubernetes-helm><azure-aks><nginx-ingress>,66162097,4,"the -f does not set a &quot;manifest&quot; as stated in the microsoft docs. as per helm install --help:

-f, --values strings               specify values in a yaml file
or a url (can specify multiple)

the default values file contains the values to be passed into the chart.
user-supplied values with -f are merged with the default value files to generate the final manifest. the precedence order is:


the values.yaml file in the chart
if this is a subchart, the values.yaml file of a parent chart
a values file if passed into helm install or helm upgrade with the -f flag (helm install -f myvals.yaml ./mychart)
individual parameters passed with --set (such as helm install --set foo=bar ./mychart)



the list above is in order of specificity: values.yaml is the default, which can be overridden by a parent chart's values.yaml, which can in turn be overridden by a user-supplied values file, which can in turn be overridden by --set parameters.

what are you doing is overriding the controller value on top of the default values file. you can find the original/default values for the ingress-nginx chart here.
"
67533815,inheritance of multiline helm chart template,"i want to set resources to pods with helm chart with template of resource section from subchart. because it should be several different reource templates in subchart.
i have values.yaml , main-values.yaml and templates/deployment.yaml
the command to update helm chart is
helm upgrade -i mynamespace ./kubernetes/mynamespace --namespace mynamespace --create-namespace -f kubernetes/mynamespace/main-values.yaml --reset-values

files are cuted to show just an example:
main-values.yaml :
namespace: mynamespace
baseurl: myurl.com
custombranch: dev

components:

  postgresql:
    nodeport: 5432

  elasticsearch:
    nodeport: 9200

resources_minimum:
  requests:
    memory: &quot;100m&quot;
    cpu: &quot;100m&quot;
  limits:
     memory: &quot;300m&quot;
     cpu: &quot;200m&quot;


values.yaml
namespace: 
baseurl: 
custombranch: 

components:
  service:
    name: service
    image: docker-registry.service.{{ .values.custombranch }}
    imagepullpolicy: always
    resources: &quot;{{ .values.resources_minimum }}&quot;
    tag: latest
    port: 8080
    accesstype: clusterip
cut

and deployment.yaml is
cut
      containers:
        - name: {{ $val.name }}
          securitycontext:
            {{- toyaml $.values.securitycontext | nindent 12 }}
          image: &quot;{{ tpl $val.image $ }}:{{ $val.tag | default &quot;latest&quot; }}&quot;
          imagepullpolicy: {{ $val.imagepullpolicy }}
          resources: &quot;{{ tpl $val.resources $ }}&quot;
cut

and the deployment section of resources does not work at all. however image section with intermediate template {{ .values.custombranch }} works and nodeport template works fine in services.yaml
spec:
  type: {{ $val.accesstype }}
  ports:
    - port: {{ $val.port }}
      name: mainport
      targetport: {{ $val.port }}
      protocol: tcp
      {{ if and $val.nodeport  }}
      nodeport:  {{ $val.nodeport }}

i've tried $val, toyaml, tpl , and plain $.values options in resources section of deployment.yaml and got several errors like:

error converting yaml to json: yaml: invalid map key: map[interface {}]interface {}{&quot;.values.resources_minimum&quot;:interface {}(nil)}

or

error converting yaml to json: yaml: line 29: could not find expected ':'

and other error like so.
is it impossible to push yaml values of multiline resources_minimum through values.yaml to deployment.yaml?
which syntax should i use?
what documentation can you advice me to read?
",<kubernetes><yaml><kubernetes-helm>,67771259,1,"ok. fellows helped me with elegant solution.
values.yaml :
resource_pool:
  minimum:
    limits:
      memory: &quot;200m&quot;
      cpu: &quot;200m&quot;
    requests:
      memory: &quot;100m&quot;
      cpu: &quot;100m&quot;
...
components:
  service:
    name: service
    image: docker.image
    imagepullpolicy: always
    tag: latest
    resources_local: minimum


and deployment.yaml :
          {{- range $keyresources, $valresources := $.values.resource_pool }}
            {{- if eq $val.resources_local $keyresources }}
              {{ $valresources | toyaml | nindent 12}}
            {{- end }}
          {{- end }}

any sugestion what to read to get familiar with all helm trics?
"
62089243,helm subcharts names and url variables configuratiion,"requirement: deploy multiple releases of chart a to single k8s namespace

i have a complex problem with subcharts name configuration. relations between my charts are:

a
|- b
   |- c
      |- d - postgres
      |- e - graphql-engine
|- f - postgres
|- g - graphql-engine



a depends on b, f, g
b depends on c
c depends on d, e


and the chart of type graphql-engine can requires zero or n variables based on application which for it is (if you know this app it should be backend url, action url, trigger url etc.). in instance e the variables should points to aplication c and in instance g they should points to a.

i made helm chart for graphql-engine with this part in deployment`s container section:

          env:
{{- range $k, $v := .values.environmentvariables }}
            - name: {{ quote $k }}
              value: {{ quote ""$v"" }}
{{- end }}


to have a right names of subcharts i am doing this in a`s variables.yaml file:

b:
  c:
    nameoverride: a-b-c
    d:
      nameoverride: a-b-c-d
    e:
      nameoverride: a-b-c-e
f:
  nameoverride: a-f
g:
  nameoverride: a-g


default chart`s _helpers.tpl file prefixs nameoverride variable with .release.name variable.
it is not nice and optimal but i did not find a way to made this process to be dynamically created. is here someone who knows better way to do this naming? that is my first question.

to simplify my problem. i need to put variable list like this:


var1=""http://{{ .release.name }}-a-b-c:8080/graphql""
var2=""http://{{ .release.name }}-a-b-c:8080/actions""


into e chart from a chart. but i did not find a way to let go templating expand .release.name variable. i made this in a variables.yaml:

b:
  c:
    nameoverride: a-b-c
    d:
      nameoverride: a-b-c-d
    e:
      nameoverride: a-b-c-e
      extravariables:
        var1: ""http://{{ .release.name }}-a-b-c:8080/graphql""
        var2: ""http://{{ .release.name }}-a-b-c:8080/actions""
f:
  nameoverride: a-f
g:
  nameoverride: a-g
  extravariables:
    var1: ""http://{{ .release.name }}-a:8080/graphql""


but i did not find a way how to use tpl helm function in range part with dollar variable input. or another possibility to accomplish this. i tried just include some ""template"" which i can made in a chart but it had bad vars context and is used in every graphql-engine chart instance and it is not right in this.

the real a application have more levels of dependencies but it is not important to this problem. is this wrong way to do that? how are you creating names of k8s objects and how are you setting url variables for you applications?

thank you!
",<kubernetes><deployment><kubernetes-helm>,62130192,1,"and answer to question about looping over list with tpl function calling is this. you just have to change context of tpl.

{{- range $k, $v := .values.environmentvariables }}
            - name: {{ quote $k }}
              value: {{ tpl $v $ }}
{{- end }}

"
60838726,correct way to create a k8s secret?,"i am not sure if i'm interpreting the output from my container correctly, but i am seeing the following output from sequelize in the logs:

nates-macbook-pro:k8s natereed$ docker logs 1a3e6141d050
...
(node:36) unhandledpromiserejectionwarning: sequelizeconnectionerror: password authentication failed for user 
""postgres
""


it appears there is an extra newline character in the username, which should be ""postgres"". the database is configured with the environment variable $postgress_username (yes, i know it is mispelled, it is from another author).

src/config/config.ts:    ""username"": process.env.postgress_username


i shelled into the running container and checked that the environment variables are correctly set:

root@backend-feed-75c4f97d6-9tp2f:/usr/src/app# echo $postgress_username
postgres
root@backend-feed-75c4f97d6-9tp2f:/usr/src/app# echo $postgress_password
...
root@backend-feed-75c4f97d6-9tp2f:/usr/src/app# echo $postgress_db      
mydb

...


to create the secret and then apply, i ran:

echo ""postgres"" | openssl base64
(edit env-secret.yaml)
kubectl apply -f env-secret.yaml 


the contents of the secret:

apiversion: v1
kind: secret
metadata:
  name: env-secret
type: opaque
data:
  postgress_username: cg9zdgdyzxmk
  postgress_password: ...


is this not the correct way to create the k8s secret?
",<kubernetes><sequelize.js><kubernetes-secrets>,60838793,3,"echo ""postgres"" includes a newline at the end of the string which is also included in the encoded secret. instead, use:

echo -n ""postgres"" | openssl base64


the -n flag suppresses the newline.
"
65450662,does apply works according to the rolling update policy?,"i know about several ways to perform rolling update of deployment. but do either kubectl apply -f deployment.yaml or kubectl apply -k ... update deployment according to the rolling update policy of a new version of deployment or an old one?
",<kubernetes><kubectl>,65451702,2,"yes it will, with one note :

note: a deployment's rollout is triggered if and only if the
deployment's pod template (that is, .spec.template) is changed, for
example if the labels or container images of the template are updated.
other updates, such as scaling the deployment, do not trigger a
rollout.

reference : https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment
for example, you can see the events section of a deployment update after updating the nginx image and running kubectl apply -f nginx-deploy.yml :
...
newreplicaset:   nginx-deployment-559d658b74 (3/3 replicas created)
events:
  type    reason             age   from                   message
  ----    ------             ----  ----                   -------
  normal  scalingreplicaset  112s  deployment-controller  scaled up replica set nginx-deployment-66b6c48dd5 to 3
  normal  scalingreplicaset  44s   deployment-controller  scaled up replica set nginx-deployment-559d658b74 to 1
  normal  scalingreplicaset  20s   deployment-controller  scaled down replica set nginx-deployment-66b6c48dd5 to 2
  normal  scalingreplicaset  20s   deployment-controller  scaled up replica set nginx-deployment-559d658b74 to 2
  normal  scalingreplicaset  19s   deployment-controller  scaled down replica set nginx-deployment-66b6c48dd5 to 1
  normal  scalingreplicaset  19s   deployment-controller  scaled up replica set nginx-deployment-559d658b74 to 3
  normal  scalingreplicaset  18s   deployment-controller  scaled down replica set nginx-deployment-66b6c48dd5 to 0
$ kubectl get deploy
name               ready   up-to-date   available   age
nginx-deployment   3/3     3            3           114s

"
63273727,"error ""no route matched with those values"" with the kong ingress controller","attempting to connect to a jupyter lab container (ultimately other applications as well) running on a cloud managed kubernetes service using kong as the ingress controller. receiving &quot;no route matched with those values&quot; on the http response to kong's public ip and the ingress-controller logs indicate:
service kong/rjup2 does not have any active endpoints
no configuration change, skipping sync to kong

deployment config:
apiversion: apps/v1
kind: deployment
metadata:
  name: rjup2
  namespace: kong
spec:
  selector:
    matchlabels:
      run: rjup2
  replicas: 1
  template:
    metadata:
      labels:
        run: rjup2
    spec:
      restartpolicy: always
      containers:
        - name: rjup2
          image: jupyter/minimal-notebook
          imagepullpolicy: always
          ports:
            - containerport: 8888
              protocol: tcp

service config:
apiversion: v1
kind: service
metadata:  
  name: rjup2
  namespace: kong
spec:
  selector:    
    app: rjup2
  type: clusterip
  ports:  
  - name: http
    port: 80
    targetport: 8888
    protocol: tcp

ingress resource config:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: rjup2
  namespace: kong
spec:
  tls:
  - hosts:
      - &lt;aks api server address&gt;
  rules:
  - host: &lt;aks api server address&gt;
    http:
      paths:
      - path: /
        backend:
          servicename: rjup2
          serviceport: 80

the api server address is properly populated in the deployed yaml. i have tried different namespaces before consolidating them under kong's default namespace and also tried making the service ports 8888 in addition to the containers target port.
thanks for any assistance in debugging this.
",<kubernetes><kubernetes-ingress><kong><kubernetes-networking><kong-ingress>,63282380,2,"your rjup2 service doesn't have a valid selector. note that the pods you are trying to expose are labelled with run: rjup2 label and your service has app: rjup2 selector.
btw. you get very clear error message that indicates where the problem could be:
service kong/rjup2 does not have any active endpoints

if your rjup2 service in kong namespace doesn't have any active endpoints, it means it doesn't expose your pods properly which may indicate a possible mismatch in your configuration.
you can check it by running:
kubectl get ep -n kong

normally you should see the matching endpoints object. in your case you won't see it as your service cannot expose any pods untill it has a valid selector.
if you fix your service definition, everything should work just fine:
apiversion: v1
kind: service
metadata:  
  name: rjup2
  namespace: kong
spec:
  selector:    
    run: rjup2
  type: clusterip
  ports:  
  - name: http
    port: 80
    targetport: 8888
    protocol: tcp

"
60316148,ingress controller nodeport not reachable from outside,"i have a cluster of 3 vm on which i install kubernetes and deployed some pods and services that i would like to be accessible from outside (my local pc for exemple)

i followed this tutorial https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal to install my ingress controller.
i have created a service of type nodeport.
i have created a ingress that looks like this:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: test-ingress
  annotations:
      kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: my.service.com
    http:
      paths:
      - path: /
        backend:
          servicename: myservice
          serviceport: 9090


kubectl get svc myservice gives me:

name        type       cluster-ip        external-ip   port(s)          age
myservice   nodeport   xxx.xxx.xxx.xxx   &lt;none&gt;        9090:31220/tcp   47m


kubectl get ingress test-ingress gives me

name            hosts            address          ports   age
test-ingress    my.service.com   xx.xxx.xxx.xxx   80      49m


on my local computer i have added to /etc/hosts i have mapped the ip address of the ingress to the name my.service.com
when i try to ping my.service.com or directly the ip i go request timeout 100% packet loss.
i tried to reach my service visual interface with the web browser and it does not work either.

how can i investigate further why i can't access to my service from outside the cluster ?
",<kubernetes><kubernetes-ingress>,60317191,4,"there is probably an issue with your firewall. check the firewall rules if they are blocking access from outside to that port.

also you should access the service from the nodeport of the service you created while deploying the ingress controller.

also edit your ingress and add the tls and hosts property with a self signed certificate for my.service.com

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: test-ingress
  annotations:
      ingress.kubernetes.io/rewrite-target: /
      kubernetes.io/ingress.class: nginx
spec:
  tls:
  - hosts:
    - my.service.com
    secretname: tls-secret-for my service
  rules:
  - host: my.service.com
    http:
      paths:
      - path: /
        backend:
          servicename: myservice
          serviceport: 9090

"
74588493,"error when trying to create a deployment using yaml: deployment in version ""v1"" cannot be handled as a deployment","i am new to k8s and trying to create a deployment using the below yaml file.
apiversion: apps/v1
kind: deployment
metadata:
  name: building-apps-deploy
  labels:
    app: kubeacademy
spec:
  replicas: 2
  selector:
    matchlabels:
      app: kubeacademy
  template:
    metadata:
      labels:
        app: kubeacademy
    spec:
      containers:
        - name: building-apps-containers
          image: 'lander2k2/building-apps:0.1'


i had the file validated by 3 online validator websites and all is coming back ok but when i run the command - kubectl apply -f deployment_yam27112022.yml, it is throwing the below error:

error from server (badrequest): error when creating &quot;deployment_yam27112022.yml&quot;: deployment in version &quot;v1&quot; cannot be handled as a deployment: strict decoding error: unknown field &quot;spec.selector.matchlabels&quot;*

i understand that the spec.selector.matchlables has some issue but cannot pinpoint the same.
request the community help to resolve this situation and let me know if there are any online resources for validating the yaml files or generating ones which are recommended?
additional info:
the pod was created successfully using below yaml file:
apiversion: v1              
kind: pod
metadata:
    name: building-apps-pod
    labels:
        app: kubeacademy
spec:
    containers:
    - name: building-apps-container
      image: lander2k2/building-apps:0.1

command used for pod creation: kubectl apply -f createpod22112022.yml
and the cluster was created using the command kind create cluster --name demo271122
to conclude my question: was trying to create a deployment post creation of cluster and pod. the deployment command is failing again and again.
i have also gone through the questions with same / similar error messages on stack overflow but have not been able to resolve the issue - some suggestions to earlier question was to format the yaml file properly but have already tried the same using notepad++ and online yaml validator websites.
",<kubernetes><deployment><kubectl>,74588670,3,"your error message says:
unknown field &quot;spec.selector.matchlabels&quot;

in your deployment, we can see the following:
selector:
  matchlabels:
    app: kubeacademy

you meant to do this instead:
selector:
  matchlabels:
    app: kubeacademy

"
61682474,multiple port names required when only using one port,"i have one port specified as below.

my-app-service.yaml

apiversion: v1
kind: service
metadata:
  labels:
    app: my-app
  name: my-app-service
  namespace: default
spec:
  externaltrafficpolicy: cluster
  ports:
    - port: 80
      name: my-port
      protocol: tcp
      targetport: 8000
  selector:
    app: my-app
  sessionaffinity: none
  type: nodeport



cloudbuild.yaml summary:

steps:
  - name: gcr.io/cloud-builders/gcloud
  - name: gcr.io/cloud-builders/docker
  - name: gcr.io/cloud-builders/gke-deploy


for some reason i get an error asking for a name param on port1, when port1 doesn't even exist. see below.

output:

step #3: applying deployment.
step #3: getting access to cluster ""my-cluster"" in ""my-zone"".
step #3: configuration files to be used: [{kind: deployment, name: my-app} {kind: horizontalpodautoscaler, name: my-app-hpa} {kind: service, name: my-app-service}]
step #3: applying configuration files to cluster.
step #3: warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
step #3: the service ""my-app-service"" is invalid: 
step #3: * spec.ports[1].name: required value


kubernetes version: 1.15.9-gke.24

anyone know what i'm missing?
",<kubernetes><google-kubernetes-engine><kubernetes-service>,61726998,9,"recreating the yaml worked:

kubectl delete -f service.yaml
kubectl apply -f service.yaml

"
64505183,how to access minikube (installed on a remote vm) from my local machine?,"i have a centos 7 vm, which has minikube running with --vm-driver=none. on the vm itself, i can run kubectl commands to interact with the minikube cluster.
as i am new to k8s, i am not sure how to generate all the necessary values to put in the ~/.kube/config file. my end goal is to interact with minikube cluster like my other aws eks clusters by using kubectl on my local machine.
",<kubernetes><kubectl><minikube><kubeconfig>,64505184,4,"to understand what you need in your local machine's ~/.kube/config file, checkout the ~/.kube/config file on the remote vm itself.
you'll find that you need to add these 3 items in your local machine's ~/.kube/config file:

a cluster under clusters
a context under contexts
a user under users

to add these 3 items, first you need to copy these 3 files from remote vm to your local machine:

ca.crt (usually found at ~/.minikube/profiles/minikube/ca.crt)
client.crt (usually found at ~/.minikube/profiles/minikube/client.crt)
client.key (usually found at ~/.minikube/profiles/minikube/client.key)

now, you need to base64 encode these 3 files. for example, if you're on macos, you can use this command:
base64 -i &lt;input_file&gt; -o &lt;output_file&gt;

now you're ready to update your local machine's ~/.kube/config file.

add this cluster under clusters:

- cluster:
    certificate-authority-data: &lt;base64 of ca.crt file&gt;
    server: &lt;same ip as remote vm's kubeconfig file, since you've used vm-driver=none&gt;
  name: minikube


add this context under contexts (same values as remote vm)

- context:
    cluster: minikube
    user: minikube
  name: minikube


add this user under users

- name: minikube
  user:
    client-certificate-data: &lt;base64 of client.crt file&gt;
    client-key-data: &lt;base64 of client.key file&gt;

"
37464518,how to format the output of kubectl describe to json,"kubectl get command has this flag -o to format the output.

is there a similar way to format the output of the kubectl describe command?

for example:

kubectl describe -o=""jsonpath={...}"" pods my-rc


would print a json format for the list of pods in my-rc replication controller. but -o is not accepted for the describe command.
",<kubernetes><output-formatting><kubectl>,37468186,77,"kubectl describe doesn't support -o or equivalent. it's meant to be human-readable rather than script-friendly. you can achieve what you described with kubectl get pods -l &lt;selector_of_your_rc&gt; -o &lt;output_format&gt;, for example:

$ kubectl get pods -l app=guestbook,tier=frontend -o name
pod/frontend-a4kjz
pod/frontend-am1ua
pod/frontend-yz2dq

"
75758115,"persistentvolumeclaim is stuck 'waiting for a volume to be created, either by external provisioner ""ebs.csi.aws.com""' on new aws eks cluster","we have a eks setup provisioned where we use a cloud native buildpacks based tekton pipeline our pipelineruns are stuck and pending forever without getting a pod resource. we created a persistentvolumeclaim like this:
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: buildpacks-source-pvc
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 500mi

having a look into the events of this pvc after creation there are the following events indicating something is wrong with our eks setup:
the command kubectl describe pvc buildpacks-source-pvc gives the following event messages:
name:          buildpacks-source-pvc
namespace:     default
storageclass:  gp2
status:        pending
volume:
labels:        &lt;none&gt;
annotations:   volume.beta.kubernetes.io/storage-provisioner: ebs.csi.aws.com
               volume.kubernetes.io/selected-node: ip-999-99-99-99.eu-central-1.compute.internal
               volume.kubernetes.io/storage-provisioner: ebs.csi.aws.com
finalizers:    [kubernetes.io/pvc-protection]
capacity:
access modes:
volumemode:    filesystem
used by:       affinity-assistant-0b3d266b91-0
               affinity-assistant-53a7c08baf-0
               affinity-assistant-a375f28de3-0
               affinity-assistant-e8cb1a6e15-0
               buildpacks-test-pipeline-run-9rz4l-fetch-repository-pod
events:
  type    reason                age                     from                         message
  ----    ------                ----                    ----                         -------
  normal  externalprovisioning  3m43s (x561 over 143m)  persistentvolume-controller  waiting for a volume to be created, either by external provisioner &quot;ebs.csi.aws.com&quot; or manually created by system administrator

what is this ebs csi thing and how do we get our cluster working as before?
",<amazon-web-services><kubernetes><amazon-eks><persistent-volumes><amazon-ebs>,75758116,80,"from eks 1.23 on a container storage interface (csi) driver is needed in order to get your persisentvolumeclaims served by a persistentvolume as you are used to from earlier eks versions.
the docs tell us, what needs to be configured:
solution: configure amazon ebs csi driver for working persistentvolumes in eks
in essence we need to enable the aws ebs csi driver as an eks addon. but beforehand we need to enable the iam oidc provider and create the iam role for the ebs csi driver. the easiest way to do both is to use eksctl (other ways like using plain aws cli or the aws gui are described in the docs).
1.) install eksctl
we assume here that the aws cli is installed and configured - and you have access to your eks cluster. to use eksctl we need to install it first. on a mac use brew like:
brew tap weaveworks/tap
brew install weaveworks/tap/eksctl

or on linux use:
curl --silent --location &quot;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz&quot; | tar xz -c /tmp
sudo mv /tmp/eksctl /usr/local/bin

2.) enable iam oidc provider
a prerequisite for the ebs csi driver to work is to have an existing aws identity and access management (iam) openid connect (oidc) provider for your cluster. this iam oidc provider can be enabled with the following command:
eksctl utils associate-iam-oidc-provider --region=eu-central-1 --cluster=yourclusternamehere --approve

3.) create amazon ebs csi driver iam role
now having eksctl in place, create the iam role:
eksctl create iamserviceaccount \
  --region eu-central-1 \
  --name ebs-csi-controller-sa \
  --namespace kube-system \
  --cluster yourclusternamehere \
  --attach-policy-arn arn:aws:iam::aws:policy/service-role/amazonebscsidriverpolicy \
  --approve \
  --role-only \
  --role-name amazoneks_ebs_csi_driverrole

as you can see aws maintains a managed policy for us we can simply use (aws maintains a managed policy, available at arn arn:aws:iam::aws:policy/service-role/amazonebscsidriverpolicy). only if you use encrypted ebs drives you need to additionally add configuration to the policy.
the command...

...deploys an aws cloudformation stack that creates an iam role,
attaches the iam policy to it, and annotates the existing
ebs-csi-controller-sa service account with the amazon resource name
(arn) of the iam role.

4.) add the amazon ebs csi add-on
now we can finally add the ebs csi add-on. therefor we also need the aws account id which we can obtain by running aws sts get-caller-identity --query account --output text (see quick way to get aws account number from the aws cli tools?). now the eksctl create addon command looks like this:
eksctl create addon --name aws-ebs-csi-driver --cluster yourclusternamehere --service-account-role-arn arn:aws:iam::$(aws sts get-caller-identity --query account --output text):role/amazoneks_ebs_csi_driverrole --force

now your persistentvolumeclaim should get the status bound while a ebs volume got created for you - and the tekton pipeline should run again.
"
68960083,bitnami redis on kubernetes authentication failure with existing secret,"i'm trying to install redis on kubernetes environment with bitnami redis helm chart. i want to use a defined password rather than randomly generated one. but i'm getting error below when i want to connect to redis master or replicas with redis-cli.
i have no name!@redis-client:/$ redis-cli -h redis-master -a $redis_password 
warning: using a password with '-a' or '-u' option on the command line interface may not be safe.
warning: auth failed

i created a kubernetes secret like this.
---
apiversion: v1
kind: secret
metadata:
  name: redis-secret
  namespace: redis
type: opaque
data:
  redis-password: ywrtaw4xmjm0cg==

and in values.yaml file i updated auth spec like below.
auth:
  enabled: true
  sentinel: false
  existingsecret: &quot;redis-secret&quot;
  existingsecretpasswordkey: &quot;redis-password&quot;
  usepasswordfiles: false

if i don't define existingsecret field and use randomly generated password then i can connect without an issue. i also tried auth admin1234 after warning: auth failed error but it didn't work either.
",<kubernetes><redis><kubernetes-helm><bitnami>,69029976,3,"the issue was about how i encoded password with echo command. there was a newline character at the end of my password. i tried with printf command rather than echo and it created a different result.
printf admin1234 | base64

"
67518407,superset on kubernetes with helm not using custom values file,"i'm trying to install apache superset on a kubernetes cluster (aws eks) using helm and following the official procedure described here.
bash-3.2$ helm repo add superset https://apache.github.io/superset
&quot;superset&quot; has been added to your repositories

bash-3.2$ helm search repo superset
name                chart version   app version description                                       
superset/superset   0.1.2           1.0         apache superset is a modern, enterprise-ready b...

since i want to use rds and elasticache for database and cache respectively, instead of the bundled postgresql and redis, i need to override several values in the default values.yaml so i  made a copy of the default values
bash-3.2$ helm show values superset/superset &gt; custom-values.yaml

edited several sections such as
postgresql:
  ##
  ## use the postgresql chart dependency.
  ## set to false if bringing your own postgresql.
  enabled: false

[...]

  ##
  ## if you are bringing your own postgresql, you should set postgreshost and
  ## also probably service.port, postgresqlusername, postgresqlpassword, and postgresqldatabase
  postgreshost: myproject.cluster-xxxxxxxxx.us-east-2.rds.amazonaws.com

and others, and installed my release with
bash-3.2$ helm upgrade --install --values custom-values.yaml superset superset/superset

as described in the guide.
the first three pods are created:
bash-3.2$ kubectl get pods
name                               ready   status     restarts   age
superset-7d96fc8787-vr6c6          0/1     init:0/1   0          3m4s
superset-init-db-xqmd9             0/1     init:0/1   0          3m3s
superset-worker-7fff4f497b-cnqs5   0/1     init:0/1   0          3m4s

but then nothing happens. logging in into the init-container of the superset-init pod i discovered that the process waiting for the database to become available is stuck because it is using the default environment variables instead of those i provided in the custom-values.yaml file:
bash-3.2$ kubectl exec -it --container wait-for-postgres superset-init-db-xqmd9 -- sh
/ # 
/ # env
redis_port=6379
kubernetes_port=tcp://172.20.0.1:443
kubernetes_service_port=443
hostname=superset-init-db-xqmd9
db_port=5432
superset_port=tcp://172.20.72.4:8088
superset_service_port=8088
superset_port_8088_tcp_addr=172.20.72.4
shlvl=1
home=/root
db_name=superset
superset_port_8088_tcp_port=8088
superset_port_8088_tcp_proto=tcp
superset_port_8088_tcp=tcp://172.20.72.4:8088
term=xterm
kubernetes_port_443_tcp_addr=172.20.0.1
path=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
kubernetes_port_443_tcp_port=443
kubernetes_port_443_tcp_proto=tcp
db_pass=superset
superset_service_port_http=8088
kubernetes_service_port_https=443
kubernetes_port_443_tcp=tcp://172.20.0.1:443
redis_host=superset-redis-headless
kubernetes_service_host=172.20.0.1
pwd=/
db_host=superset-postgresql
superset_service_host=172.20.72.4
db_user=superset

edit:
some of the custom values in the custom-values.yaml file are actually used to override the defaults. e.g:
service:
  type: loadbalancer

instead of
service:
  type: clusterip

and also postgresql and redis pods are not created when i set them as enabled: false but for some reason other custom values are not applied or passed to the secret storing env variables for the pods.
what am i doing wrong?
",<kubernetes><kubernetes-helm><apache-superset>,67518998,4,"according to the values.yaml of superset,
i do see if you are bringing your own postgres instance, from the above question as i've understood, you have to change the values of these
supersetnode:
  connections:
    # change incase bringing your own redis and then also make `redis.enabled`:false
    redis_host: '{{ template &quot;superset.fullname&quot; . }}-redis-headless'
    redis_port: &quot;6379&quot;
    # you need to change below configuration incase bringing own pg instance and as you made `postgresql.enabled`:false that's correct incase bringing own pg instance
    db_host: &lt;your rds pg host&gt;
    db_port: &quot;5432&quot;
    db_user: &lt;your db user&gt;
    db_pass: &lt;your db pass&gt;
    db_name: &lt;your db name | postgres&gt;

"
56348813,how to get programmatically the current gke project id from one of its clusters?,"i'd like to get the current gke project id from within one of its clusters via the java client or the gcloud api itself.


i'm running java containers in a gke cluster of a specific google cloud project
i initialize the clustermanagerclient with the appropriate clustermanagersettings


-> is it possible to fetch this specific project id with this client?

(i'm expecting that there would be a global context within each gke cluster where we could know the current project we're running on).

thank you
",<kubernetes><google-cloud-platform><google-kubernetes-engine><google-api-java-client><google-container-builder>,56350074,9,"as john hanley mentioned in his comment above, you can use the instance metadata on the node in your cluster to determine the project that the node is a part of. the easiest way to see it is to use curl from a shell (either on the node or in a container).

if you want the project name, it can be seen at:

curl ""http://metadata.google.internal/computemetadata/v1/project/project-id"" -h ""metadata-flavor: google""


and if you want the project number, it can be seen at:

curl ""http://metadata.google.internal/computemetadata/v1/project/numeric-project-id"" -h ""metadata-flavor: google""


this isn't part of the container api surface, so the clustermanagerclient isn't the right api client to use. you need to create a client to fetch the instance metadata, which i would expect might be part of the compute client libraries, or you can just make a local http request if you add the right headers (as shown above) since you don't need any special client authentication / authorization to access the local metadata. 
"
55510783,can't access eks api server endpoint within vpc when private access is enabled,"i have set up eks cluser with ""private access"" enabled and set up one instance in the same vpc to communicate with eks. the issue is if i enable to the ""public access"", i can access the api endpoint. but if i disable the public access and enable the private access, i can't access api endpoints.

when private access is enabled:

kubectl get svc
unable to connect to the server: dial tcp: lookup randomstring.region.eks.amazonaws.com on 127.0.0.53:53: no such host


when public access is enabled:

kubectl get svc
name         type        cluster-ip   external-ip   port(s)   age
kubernetes   clusterip   172.20.0.1   &lt;none&gt;        443/tcp   57m

",<amazon-web-services><kubernetes><amazon-vpc><amazon-eks>,55511883,9,"i had to enable enablednshostnames and enablednssupport for my vpc.

when enabling the private access of a cluster, eks creates a private hosted zone and associates with the same vpc. it is managed by aws itself and you can't view it in your aws account. so, this private hosted zone to work properly, your vpc must have enablednshostnames and enablednssupport set to true.

note: wait for a while for changes to be reflected(about 5 minutes).
"
67170734,"where does kubernetes store cached images for use of ""ifnotpresent""-cachepolicy and how to delete the cache?","i have a cluster to manage which has pods running with image-cachepolicy set to &quot;ifnotpresent&quot;.
containers:
  - name: test-app
    image: myimages/test-app
    imagepullpolicy: &quot;ifnotpresent&quot;

i am already familiar with the difference between ifnotpresent and always.
in our case, if the pod gets respawned, k8s will due to &quot;ifnotpresent&quot; load the image from some cache instead of fetching the image from docker-hub.
what we want to achieve is to find this place where kubectl is caching the image and delete the cache in order to make k8s re-fetching the image on the next time, when the pod gets restarted.
we don't want to apply a new policy with imagepullpolicy set to always because this would already fetch the latest version of the pod, which we don't want yet. instead, it shall only fetch new newest image on the next restart of the pod.
is there any way to do this? where to find this caching-location?
",<docker><kubernetes><kubectl>,67170860,3,"if you imagined kubernetes was running docker, it'd do the equivalent of:

look at docker images.
if the image isn't already there, docker pull it.
docker run the resulting image.

(imagepullpolicy: always skips the first step and always pulls the image; never skips the pull, and will fail if the image isn't already there.)
each node will have its own copy of the images; where exactly depends on the specific container runtime in use.  each node in turn knows how to garbage collect images not currently in use, though old images will generally stick around until the local disk fills up (or until a tool like the cluster autoscaler deletes the node).
a general assumption in kubernetes is that a given registry.example.com/name/image:tag string uniquely identifies an image.  your ci/cd system should cooperate with this, and assign a distinct tag to each image build (maybe based on the commit id or a date stamp).  if you do this, you shouldn't need to adjust imagepullpolicy: from its default or try to manually remove images from nodes.
"
55454477,"desired gke pod not found , google cloud composer","i am using google cloud composer ,and created composer environment.composer environment is ready(has green tick), now i am trying to set variables used in dag python code using google cloud shell.

command to set variables:

     gcloud composer environments run test-environment \
       --location us-central1 variables -- \
       --set gcp_project xxx-gcp


exact error message:

  error: (gcloud.composer.environments.run) desired gke pod not found. if the environment was recently started, please wait and retry.


i tried following things as part of investigation, but got same error each time.
i have created a new environment using ui and not google shell commands.
i checked pods in kubernetes engine and all are green , did not see any issue.
i verified composer api, billing kubernetes, all required api's are enabled.

i have 'editor' role assigned.

added screenshot i saw first time some failures





error with exit code 1
google troubleshooting guide describe: if the exit code is 1, the container crashed because the application crashed.
",<kubernetes><google-cloud-platform><airflow><google-kubernetes-engine><google-cloud-composer>,55468977,6,"this is a side effect of composer version 1.6.0 if you are using a google-cloud-sdk that is too old, because it now launches pods in namespaces other than default. the error you see is a result of looking for kubernetes pods in the default namespace and failing to find them.

to fix this, run gcloud components update. if you cannot yet update, a workaround to execute airflow commands is to manually ssh to a pod yourself and run airflow. to start, obtain gke cluster credentials:

$ gcloud container clusters get-credentials $composer_gke_cluster_name


once you have the credentials, you should find which namespace the pods are running in (which you can also find using cloud console):

$ kubectl get namespaces
name                                    status   age
composer-1-6-0-airflow-1-9-0-6f89fdb7   active   17h
default                                 active   17h
kube-public                             active   17h
kube-system                             active   17h


you can then ssh into any scheduler/worker pod, and run commands:

$ kubectl exec \
    --namespace=$namespace \
    -it airflow-worker-569bc59df5-x6jhl airflow list_dags -r


you can also open a shell if you prefer:

$ kubectl exec \
    --namespace=$namespace \
    -it airflow-worker-569bc59df5-x6jhl bash

airflow@airflow-worker-569bc59df5-x6jhl:~$ airflow list_dags -r


the failed airflow-database-init-job jobs are unrelated and will not cause problems in your composer environment.
"
63655419,kubernetes client go couldn't find module,"i'm trying to connect to my local kubernetes cluster hosted on minikube, here's the code for the same, now when i do go run minikube.go, it gives me an error saying:
../../../pkg/mod/k8s.io/client-go@v11.0.0+incompatible/kubernetes/scheme/register.go:26:2: module k8s.io/api@latest found (v0.19.0), but does not contain package k8s.io/api/auditregistration/v1alpha1`.

now, i tried to manually install the package using go get then i found out that this package does not exist.
how can i make it work and fix this?.
my go.mod file in case anyone wants to see that.
",<go><kubernetes><go-modules><kubernetes-go-client><go-packages>,63655793,23,"always specify matching versions of all three k8s.io/... components in your go.mod file
require (
    ...
    k8s.io/api v0.19.0
    k8s.io/apimachinery v0.19.0
    k8s.io/client-go v0.19.0
    ...
)

"
68209297,how to deploy .net core web and worker projects to kubernetes in single deployment?,"i am relatively new to docker and kubernetes technologies. my requirement is to deploy one web and one worker (.net background service) project in a single deployment.
this is how my deployment.yml file looks like :
apiversion : apps/v1
kind: deployment
metadata:
  name: worker
spec:
  progressdeadlineseconds: 3600
  replicas: 1
  selector:
    matchlabels:
      app: worker
  template:
    metadata:
      labels:
        app: worker
    spec:
      containers:
        - name: worker
          image: xxxxx.azurecr.io/worker:#{build.buildid}#
          #image: xxxxx.azurecr.io/web
          imagepullpolicy: always
          #ports:
          #- containerport: 80

apiversion : apps/v1
kind: deployment
metadata:
  name: web
spec:
  progressdeadlineseconds: 3600
  replicas: 1
  selector:
    matchlabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
        - name: web
          image: xxxxx.azurecr.io/web:#{build.buildid}#
          #image: xxxxx.azurecr.io/web
          imagepullpolicy: always
          ports:
          - containerport: 80

this is how my service.yml file looks like :
apiversion: v1
kind: service
metadata:
    name: worker
spec:
    type: loadbalancer
    ports:
    - port: 80 
    selector:
        app: worker
---
apiversion: v1
kind: service
metadata:
    name: web
spec:
    type: loadbalancer
    ports:
    - port: 80 
    selector:
        app: web

what i have found is if i keep both in service.yml file then its only deploying one in kubernetes and if i comment one and execute one by one then its deploying to kubernetes.
is there any rule that we can’t have both in single file? any reason why it’s not working together however working individually?
one more ask is there any way we can look into worker service pod something like taking remote of that and see what exactly going on there....even if it’s a console application then anyway to read what’s its printing on console after deployment.?
",<azure><docker><kubernetes><azure-aks><kubernetes-pod>,68343941,1,"this issue was resolved in the comments section and i decided to provide a community wiki answer just for better visibility to other community members.
it is possible to group multiple kubernetes resources in the same file, but it is important to separate them using three dashes (“---”).
it's also worth mentioning that resources will be created in the order they appear in the file.
for more information, see the organizing resource configurations documentation.

i've created an example to demonstrate how we can create a simple app-1 application (deployment + service) using a single manifest file:
$ cat app-1.yml
apiversion: v1
kind: service
metadata:
  labels:
    app: app-1
  name: app-1
spec:
  ports:
  - port: 80
    protocol: tcp
    targetport: 80
  selector:
    app: app-1
---
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: app-1
  name: app-1
spec:
  replicas: 1
  selector:
    matchlabels:
      app: app-1
  template:
    metadata:
      labels:
        app: app-1
    spec:
      containers:
      - image: nginx
        name: nginx

note: resources are created in the order they appear in the file:
$ kubectl apply -f app-1.yml
service/app-1 created
deployment.apps/app-1 created

$ kubectl get deploy,svc
name                    ready   up-to-date   
deployment.apps/app-1   1/1     1            

name                 type        cluster-ip    external-ip   port(s)   
service/app-1        clusterip   10.8.14.179   &lt;none&gt;        80/tcp  

"
73207945,can't access k8s cluster in linode lke,"i am trying to connect the lke cluster on linode with my terminal. steps i've taken:

created the cluster in linode
downloaded the generated cluster's .config file
set kubeconfig context from the .config file

i can see that i'm connected to the cluster from the terminal:
$ kubectl config get-contexts
current   name           cluster    authinfo         namespace
*         lke67746-ctx   lke67746   lke67746-admin   default

i can see the running pods through the linode's web portal:

but when i try to list the pods through the terminal - i see no pods
$ kubectl get pods
no resources found in default namespace.

thank you in advance for the help!
",<kubernetes><kubectl><kubernetes-pod><linode>,73208406,1,"you see no pods because your command only check on the default namespace.
to check the other pods, it's either you already know your_namespace, and you can kubectl get pods -n your_namespace or you can check all pods by this command:
kubectl get pods -a

if you want to get an idea about your namespaces kubectl get namespaces
"
53550367,gitlab-runner on a kubernetes cluster error while creating mount source path '/usr/share/ca-certificates/mozilla',"i'm trying to get gitlab-runner ""run"" on a kubernetes cluster, after following the official doc -> https://docs.gitlab.com/runner/install/kubernetes.html (using kubernetes executor) i'm getting an error once i deploy:


  error: failed to start container ""gitlab-runner"": error response from
  daemon: error while creating mount source path
  '/usr/share/ca-certificates/mozilla': mkdir
  /usr/share/ca-certificates/mozilla: read-only file system


i'm using the examples in that web and can't figure out why isn't allowing to create that dir (as i understand the default user is root)

here my config-map.yaml:

apiversion: v1
kind: configmap
metadata:
  name: gitlab-runner
  namespace: gitlab
data:
  config.toml: |
    concurrent = 1
    [[runners]]
      name = ""kubernetes runner""
      url = ""url""
      token = ""token""
      executor = ""kubernetes""
      [runners.kubernetes]
        namespace = ""gitlab""


and this is the deployment.yaml

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: gitlab-runner
  namespace: gitlab
spec:
  replicas: 1
  selector:
    matchlabels:
      name: gitlab-runner
  template:
    metadata:
      labels:
        name: gitlab-runner
    spec:
      containers:
        - args:
            - run
          image: gitlab/gitlab-runner:alpine-v11.5.0
          imagepullpolicy: always
          name: gitlab-runner
          volumemounts:
            - mountpath: /etc/gitlab-runner
              name: config
            - mountpath: /etc/ssl/certs
              name: cacerts
              readonly: true
      restartpolicy: always
      volumes:
        - configmap:
            name: gitlab-runner
          name: config
        - hostpath:
            path: /usr/share/ca-certificates/mozilla
          name: cacerts


here is the complete list of events initializing the pod:

events:
  type     reason                 age                from                                                          message
  ----     ------                 ----               ----                                                          -------
  normal   scheduled              29s                default-scheduler                                             successfully assigned gitlab-runner-5b689c7cbc-hw6r5 to gke-my-project-dev-default-pool-0d32b263-6skk
  normal   successfulmountvolume  29s                kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  mountvolume.setup succeeded for volume ""cacerts""
  normal   successfulmountvolume  29s                kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  mountvolume.setup succeeded for volume ""config""
  normal   successfulmountvolume  29s                kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  mountvolume.setup succeeded for volume ""default-token-6hr2h""
  normal   pulling                23s (x2 over 28s)  kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  pulling image ""gitlab/gitlab-runner:alpine-v11.5.0""
  normal   pulled                 19s (x2 over 24s)  kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  successfully pulled image ""gitlab/gitlab-runner:alpine-v11.5.0""
  normal   created                19s (x2 over 24s)  kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  created container
  warning  failed                 19s (x2 over 24s)  kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  error: failed to start container ""gitlab-runner"": error response from daemon: error while creating mount source path '/usr/share/ca-certificates/mozilla': mkdir /usr/share/ca-certificates/mozilla: read-only file system
  warning  backoff                14s                kubelet, gke-my-project-dev-default-pool-0d32b263-6skk  back-off restarting failed container


any clue will be appreciated

thanks
",<kubernetes><gitlab-ci-runner><google-kubernetes-engine>,53575784,1,"finally, i got it working here what i use to register and run the gitlab-runner on gke

configmap:

apiversion: v1
kind: configmap
metadata:
  name: gitlab-runner-cm
  namespace: gitlab
data:
  config.toml: |
    concurrent = 4
    check_interval = 30
  entrypoint: |
    #!/bin/bash

    set -xe
    cp /scripts/config.toml /etc/gitlab-runner/

    # register the runner
    /entrypoint register --non-interactive \
      --url $gitlab_url \
      --tag-list ""kubernetes, my_project"" \
      --kubernetes-image ""alpine:latest"" \
      --kubernetes-namespace ""gitlab"" \
      --executor kubernetes \
      --config ""/etc/gitlab-runner/config.toml"" \
      --locked=false \
      --run-untagged=true \
      --description ""my project - kubernetes runner"" \
      --kubernetes-privileged

    # start the runner
    /entrypoint run --user=gitlab-runner \
      --working-directory=/home/gitlab-runner \
      --config ""/etc/gitlab-runner/config.toml""


deployment:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: gitlab-runner
  namespace: gitlab
spec:
  replicas: 1
  selector:
    matchlabels:
      app: gitlab-runner
  template:
    metadata:
      labels:
        app: gitlab-runner
    spec:
      containers:
        - name: gitlab-runner
          image: gitlab/gitlab-runner:latest
          command: [""/bin/bash"", ""/scripts/entrypoint""]
          env:
            - name: gitlab_url
              value: ""url""
            - name: registration_token
              value: ""token""
            - name: kubernetes_namespace
              value: gitlab
            - name: google_application_credentials
              value: /var/secrets/google/key.json
          imagepullpolicy: always
          volumemounts:
            - name: config
              mountpath: /scripts
            - name: google-cloud-key
              mountpath: /var/secrets/google
      restartpolicy: always
      volumes:
        - name: config
          configmap:
            name: gitlab-runner-cm
        - name: google-cloud-key
          secret:
            secretname: gitlab-runner-sa


and autoscaling:

apiversion: autoscaling/v2beta1
kind: horizontalpodautoscaler
metadata:
  name: gitlab-runner-hpa
  namespace: gitlab
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: gitlab-runner
  minreplicas: 1
  maxreplicas: 3
  metrics:
    - type: resource
      resource:
        name: cpu
        targetaverageutilization: 50


i hope this helps someone trying to run a gitlab runner in a kubernetes cluster on google kubernetes engine
"
66399589,run helm in jenkins pipeline,"i have added helm as podtemplate in value.yaml file
 podtemplates: 
    helm: |
      - name: helm
        label: jenkins-helm
        serviceaccount: jenkins
        containers:
          - name: helm
            image: lachlanevenson/k8s-helm:v3.1.1
            command: &quot;/bin/sh -c&quot;
            args: &quot;cat&quot;
            ttyenabled: true
            privileged: true
            resourcerequestcpu: &quot;400m&quot;
            resourcerequestmemory: &quot;512mi&quot;
            resourcelimitcpu: &quot;1&quot;
            resourcelimitmemory: &quot;1024mi&quot;

so i want to run helm in pipeline as
     steps {
            container('helm') {
                sh &quot;helm upgrade --install --force  ./helm&quot;
            }
        }

but i got error
       /home/jenkins/workspace/coverwhale@tmp/durable-4d1fbfd5/script.sh: 1: /home/jenkins/workspace/coverwhale@tmp/durable-4d1fbfd5/script.sh: helm: not found

version of helm and kubernetes:
helm version:
$ helm version
version.buildinfo{version:&quot;v3.5.2&quot;, gitcommit:&quot;167aac70832d3a384f65f9745335e9fb40169dc2&quot;, gittreestate:&quot;dirty&quot;, goversion:&quot;go1.15.7&quot;}


kubernetes version:
$ kubectl version
client version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.2&quot;, gitcommit:&quot;faecb196815e248d3ecfb03c680a4507229c2a56&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-01-13t13:28:09z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}
server version: version.info{major:&quot;1&quot;, minor:&quot;20&quot;, gitversion:&quot;v1.20.2&quot;, gitcommit:&quot;faecb196815e248d3ecfb03c680a4507229c2a56&quot;, gittreestate:&quot;clean&quot;, builddate:&quot;2021-01-13t13:20:00z&quot;, goversion:&quot;go1.15.5&quot;, compiler:&quot;gc&quot;, platform:&quot;linux/amd64&quot;}


which version of the chart:
what happened:
/home/jenkins/workspace/coverwhale@tmp/durable-4d1fbfd5/script.sh: 1: /home/jenkins/workspace/coverwhale@tmp/durable-4d1fbfd5/script.sh: helm: not found
what you expected to happen:
run helm chart

pipeline code
pipeline {

agent any

stages {

         stage('initialize docker'){
             steps {
                  script {
                       def docker = tool 'whaledocker'
                       echo &quot;${docker}&quot;
                       echo &quot;${env.path}&quot;
                       env.path = &quot;${docker}/bin:${env.path}&quot;
                       echo &quot;${env.path}&quot;
                  }
             }
        }
    
        stage('checkout source') {

             steps {
                 git url:'https://github.com/alialrabi/laravel-example.git', branch: 'uat', credentialsid: 'github'
             }
        }

        stage(&quot;build image&quot;) {
      
            steps {
                 script {
                   myapp = docker.build(&quot;alialrabi/coverwhale:${env.build_id}&quot;)
                 }
            }
        }
    
 
        stage(&quot;run test&quot;) {
      
            steps {
                 script {
                      docker.image(&quot;alialrabi/coverwhale:${env.build_id}&quot;).inside {
                     //   sh 'composer install'  
                      //  sh 'php artisan test'
                      }
                 }
            }
        }
    

        stage(&quot;push image&quot;) {
        
             steps {
                
                 script {
                     docker.withregistry('https://registry.hub.docker.com', 'dockerhub') {
                          myapp.push(&quot;latest&quot;)
                          myapp.push(&quot;${env.build_id}&quot;)
                     }
                 }
             }
        }

        stage('deploy uat') {
            
 
            steps {
                 script {
                echo &quot;done uat&quot;
                  sh &quot;helm upgrade --install --force&quot;
             }
            }
        }
 }
}

",<jenkins><kubernetes><jenkins-pipeline><kubernetes-helm>,66473045,2,"i have solved it by add containertemplate to agent.
  stage('deploy dev') {
            
         agent {
           kubernetes {
                 containertemplate {
                   name 'helm'
                   image 'lachlanevenson/k8s-helm:v3.1.1'
                   ttyenabled true
                   command 'cat'
              }
            }
         }
            
            steps {
               container('helm') { 
                 sh &quot;helm upgrade full-cover ./helm&quot;
               }    
             }
        } 

"
63975324,include system username in helm charts in helm version 2.14.1,"i am using helm version 2.14.1. i have created helm charts for an application that will be deployed by users to test their code on kubernetes cluster. i want to add labels for username values, so i can retrieve deployments by users (deployments by user labels). is there a way to include system username in helm charts just like we do in java with system.getproperty(&quot;user.name&quot;). my helm template is like this:
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ include &quot;common.fullname&quot; . }}--{{ release.name }}
  labels:
    application: {{ include &quot;common.name&quot; . }}
    branch: &quot;{{ release.name }}&quot;
    username: &quot;{{ system.user.name }}&quot;   # need to fetch the logged in user from system here
spec:
...

is there a standard way to achieve this or is there anyway i can allow users to input there usernames from command line while using helm install or helm template commands?
edit:
although, the --set works for me in setting the values for my chart, i also need to set the same value in the dependencies. something like this:
values.yaml
username: &quot;&quot; 

dependency1:
 username: {{ .values.username }} 

dependency2:
 username: {{ .values.username }}

...


of course the above implementation doesn't work. i need to reference the set value in the dependencies as well
",<kubernetes><kubernetes-helm>,64230493,1,"i have resolved this. thanks for help @michaelalbers and @wytrzymaływiktor. so the solution is as below.
helm template path/to/chart --set global.username=username

and then in all the templates refer to this value as {{ .values.global.username }}. this works for any dependency chart as well.
"
75890673,helm kube-prometheus-stack stuck in pending-install,"problem: for some reason, helm release of kube-prometheus-stack is stuck in pending-install status. what is the correct to install a helm release for this using helm cli?
details:
due to docker registry k8s.gcr.io getting frozen, i had to update the docker image registry to registry.k8s.io for kube-state-metrics by updating the values.yaml as follows:
kube-state-metrics:
  prometheusscrape: true
  image:
    repository: registry.k8s.io/kube-state-metrics/kube-state-metrics
    tag: v1.9.8
    pullpolicy: always
  namespaceoverride: &quot;&quot;
  rbac:
    create: true
  podsecuritypolicy:
    enabled: true

after that, when i tried update the helm release for kube-prometheus-stack using same version of 14.9.0, it failed with status failed for helm release. upon retrying, it deleted the previous helm release and created a new one. all the components by the new one created successfully but the helm release got stuck in the pending-install status.
i waited for almost 30 minutes but no success. i also tried deleting helm release, rollbacking helm release, deleting helm release secret but got no success.
what could be the issue? how can i solve it?
",<amazon-web-services><kubernetes><kubernetes-helm><kube-prometheus-stack><kube-state-metrics>,75890674,2,"solution: after some investigation, i found that there was a job named kube-prometheus-stack-admission-patch which was failing with backofflimitexceeded error. it was some kind of an initializing job. deleting the job (not pod) fixed the issue and the helm release changed its status to deployed.
error log in kube-prometheus-stack-admission-patch job:
w0331 10:58:03.079451       1 client_config.go:608] neither --kubeconfig nor --master was specified.  using the inclusterconfig.  this might not work.
{&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;patching webhook configurations 'kube-prometheus-stack-admission' mutating=true, validating=true, failurepolicy=fail&quot;,&quot;source&quot;:&quot;k8s/k8s.go:39&quot;,&quot;time&quot;:&quot;2023-03-31t10:58:03z&quot;}
{&quot;err&quot;:&quot;the server could not find the requested resource&quot;,&quot;level&quot;:&quot;fatal&quot;,&quot;msg&quot;:&quot;failed getting validating webhook&quot;,&quot;source&quot;:&quot;k8s/k8s.go:48&quot;,&quot;time&quot;:&quot;2023-03-31t10:58:03z&quot;}

"
72379080,configure volumes in airflow gkestartpodoperator operator,"i have a google cloud composer environment. in my dag i want to create a pod in gke. when i come to deploy a simple app based on a docker container that doesn't need any volume configuration or secrets, everything works fine, for example:
kubernetes_max = gkestartpodoperator(
    # the id specified for the task.
    task_id=&quot;python-simple-app&quot;,
    # name of task you want to run, used to generate pod id.
    name=&quot;python-demo-app&quot;,
    project_id=project_id,
    location=cluster_region,
    cluster_name=cluster_name,
    # entrypoint of the container, if not specified the docker container's
    # entrypoint is used. the cmds parameter is templated.
    cmds=[&quot;python&quot;, &quot;app.py&quot;],
    namespace=&quot;production&quot;,
    image=&quot;gcr.io/path/to/lab-python-job:latest&quot;,
)

but when i have an application that need to access to my gke cluster volumes, i need to configure volumes in my pod. the issue is the documentation is not clear regarding this. the only example that i ever foud is this:
volume = k8s.v1volume(
    name='test-volume',
    persistent_volume_claim=k8s.v1persistentvolumeclaimvolumesource(claim_name='test-volume'),
)

while the volumes in the my manifest file (i use it to deploy my app from local) looks like this:
volumes:
  - name: volume-prod
    secret:
      secretname: volume-prod
      items:
        - key: config
          path: config.json
        - key: another_config
          path: another_config.conf
        - key: random-ca
          path: random-ca.pem

so when i compare how both volumes looks like in the console (when i manually deploy the manifest file that successfully run, and when i deploy the pod using clod composer that fails):

the successful run - manifest file:
volume-prod
name: volume-prod
type: secret
source volume identifier: volume-prod

the failed run - composer gkestartpodoperator:
volume-prod
name: volume-prod
type: emptydir
source volume identifier: node's default medium


how i can configure my pod from cloud composer in a way it can read the volume of my cluster?
",<python><kubernetes><airflow><google-kubernetes-engine><google-cloud-composer>,72379538,3,"the kubernetespodoperator/gkestartoperator is just a wrapper around the python kubernetes sdk - i agree that it isn't well documented in the airflow/cloud composer documentation but the python sdk for kubernetes itself is well documented.
start here with the kubernetes python sdk documentation: https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/v1podspec.md
you'll notice that the arguments the kubernetespodoperator/gkestartoperator take match this spec. if you dig into the source code of the operators you'll see that the operator is nothing more than a builder that creates a kubernetes.client.models.v1pod object and uses the api to deploy the pod.
the operator takes a volumes parameter which should be of type list[v1volume], where the documentation for v1volume is here.
so in your case you would need to provide:
from kubernetes.client import models as k8s

kubernetes_max = gkestartpodoperator(
    # the id specified for the task.
    task_id=&quot;python-simple-app&quot;,
    # name of task you want to run, used to generate pod id.
    name=&quot;python-demo-app&quot;,
    project_id=project_id,
    location=cluster_region,
    cluster_name=cluster_name,
    # entrypoint of the container, if not specified the docker container's
    # entrypoint is used. the cmds parameter is templated.
    cmds=[&quot;python&quot;, &quot;app.py&quot;],
    namespace=&quot;production&quot;,
    image=&quot;gcr.io/path/to/lab-python-job:latest&quot;,
    volumes=[
        k8s.v1volume(
            name=&quot;volume-prod&quot;,
            secret=k8s.v1secretvolumesource(
                secret_name=&quot;volume-prod&quot;,
                items=[
                    k8s.v1keytopath(key=&quot;config&quot;, path=&quot;config.json&quot;),
                    k8s.v1keytopath(key=&quot;another_config&quot;, path=&quot;another_config.conf&quot;),
                    k8s.v1keytopath(key=&quot;random-ca&quot;, path=&quot;random-ca.pem&quot;),
                ],
            )
        )
    ]
)

alternatively, you can provide your manifest to the pod_template_file argument in gkestartpodoperator - this will need to be available to the workers inside airflow.
there are 3 ways to create pods in airflow using this operator:

use the arguments of the operator to specify what you need and have the operator build the v1pod for you.
provide a manifest by passing in pod_template_file argument.
use the kubernetes sdk to create a v1pod object yourself and pass this to the full_pod_spec argument.

"
77094922,"""kubectl --template"". how can i understand it?","i can't catch up what is the difference between
kubectl.....-o jsonpath='{...}' and kubectl....--template='{{...}}'
are they both just for retrieving data?
i know well about the jsonpath flag.
but couldn't understand the template flag. is there a difference?
i think https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands here are some descriptions. but i can't understand it. could you please explain more about it?
",<kubernetes><kubectl><flags>,77095341,2,"1. kubectl ... -o jsonpath='{...}'

this option allows you to extract specific data from the json
representation of kubernetes resources.
you provide a jsonpath expression enclosed in single quotes ('...') after the -o jsonpath= flag.
jsonpath is a query language for json data that lets you
specify a path to navigate through the json structure and extract
specific values.
it is primarily used for filtering and extracting
data, making it more suitable for cases where you need fine-grained
control over what data to retrieve.

example:
kubectl get pod my-pod -o jsonpath='{.status.phase}'

this command retrieves the phase field from the json representation of the my-pod resource.
2. kubectl ... --template='{{...}}'

this option allows you to use go templates to format the output of kubectl.
you provide a go template enclosed in double curly braces ({{...}}) after the --template= flag.

go templates are a more powerful and flexible way to format output. they allow you to manipulate and format data in various ways, including conditional statements and loops.

it's not limited to extracting data but can also perform transformations on the data and create custom output formats.


example:
kubectl get pod my-pod --template='{{.metadata.name}} is in {{.status.phase}} phase'

this command formats the output to display the pod's name and phase in a custom format.
in summary, both jsonpath and template options in kubectl are used for retrieving data from kubernetes resources, but they serve different purposes:

jsonpath is focused on extracting specific data using a jsonpath expression, which is useful for simple data extraction.

template is more versatile and allows you to format and manipulate the output using go templates, making it suitable for complex formatting and transformations.


the choice between the two depends on your specific use case and whether you need simple data extraction or more advanced formatting and processing of the output.
"
66191218,no data recover from incluster config with kubernetes/go-client,"i made a demo with kubernetes/go-client where i tried to list pods from my cluster.
    config, err := rest.inclusterconfig()

    if err != nil {
        panic(err.error())
    }

    clientset, err := kubernetes.newforconfig(config)
    if err != nil {
        panic(err.error())
    }

    pods, err := clientset.corev1().pods(&quot;&quot;).list(context.todo(), metav1.listoptions{})

    fmt.fprint(w, &quot;there are d pods in the cluster\n&quot;, len(pods.items))

i created serviceaccount token to assign to the pod where this code is running in.
but when code is executed pods.items has no pods.
i deployed this pod inside minikube. when i launch some kubectl command for listing pods, this way i can get resources so it is no t permissions problems.
i wonder what is happening and how i can fix it.

repository https://github.com/srpepperoni/inframanager.git
image is pushed into: https://hub.docker.com/r/jaimeyh/inframanager
the endpoint i have problems with is this one :
mux.handlefunc(&quot;/getpods&quot;, getpodsfromnamespace)

",<go><kubernetes><kubernetes-pod><kubernetes-go-client>,66200591,2,"you need to check if the err on the last line is non-nil.
pods, err := clientset.corev1().pods(&quot;&quot;).list(context.todo(), metav1.listoptions{})


ok, there is the problem. pods is forbidden: user &quot;system:serviceaccount:mis-pruebas:sa-prueba-go&quot; cannot list resource &quot;pods&quot; in api group &quot;&quot; at the cluster scope

as the error message indicates, the serviceaccount does not have permission to list pods at cluster scope. you need to create role and bind it to the serviceaccount.
the article using rbac authorization even has a role example for how to create such a role.
"
62493616,when does status.lastscheduletime change?,"i'm working on a kubernetes cronjob that relies on knowing when the last successfull run happened in order to correctly notify users about new events since said run. that said, i need to know if i can rely on status.lastscheduletime to be my &quot;last successful run&quot; timestamp.
when does it change? does it depend on exit codes? is it even a good idea to use it for that purpose?
",<kubernetes><kubernetes-cronjob>,62494176,2,"no, you can't rely on that as an indicator of a successful run. that value changes whenever your cronjob runs. it doesn't mean that it's your last successful run and it doesn't change depending on exit codes.
a cronjob essentially runs a job with a name that is &lt;cronjob name&gt;-&lt;unix epoch&gt;. the epoch is in unix/linux what you would get from the date +%s command, for example, also that epoch is a timestamp that is slightly later than the timestamp of the lastscheduletime (it's when the job resource gets created)
to find out if your last cron job ran successfully you can do something like the following.
you can get the last job run/started name including its epoch with something like this:
$ kubectl get jobs | tail -1 | awk '{print $1}'

then after that, you could check whether that job is successful with something like:
$ kubectl get job &lt;job-name&gt; -o=jsonpath='{.status.succeeded}'

should return a 1.
"
68049761,aws eks - get available kubernetes versions,"i am looking for a programmatic way to get available kubernetes versions in aws eks. something similar to the following azure cli command:
az aks get-versions --location eastus --output table

",<amazon-web-services><kubernetes><amazon-eks>,71448603,5,"as mentioned earlier, there is no api that explicitly returns the list of available kubernetes versions available in aws eks.
however, there is a somewhat hacky way to get this by describing all add-on versions available and getting the k8s versions they are compatible with.
i guess it would be a fair assumption that all available k8s versions in eks would be compatible with some add-on or the other. in which case, the below cli command will return the list of available kubernetes versions present in eks which can be used.
aws eks describe-addon-versions | jq -r &quot;.addons[] | .addonversions[] | .compatibilities[] | .clusterversion&quot; | sort | uniq

the command gets all add-ons for eks and each add-ones compatible version and then uses jq utility to get the unique kubernetes versions.
"
69974376,helm global & subchart - call values,"i've created a helm chart with sub-charts.
the global helm chart contains values.yaml and values-int.yaml files. as well as all the sub-charts.
this is the structure:
- global-helm-chart:
  - values.yaml
  - values-int.yaml
  - sub-charts:
    - chart-1:
      - values.yaml
      - value-int.yaml
      - templates:
        - configmap.yaml
    - chart-2:
      - values.yaml
      - value-int.yaml
      - templates:
        - configmap.yaml

this is the configmap.yaml under chart-1 (chart-2 is the same):
{{- $root := .values -}}
{{ if eq .values.global.env &quot;int&quot; }}
apiversion: v1
kind: configmap
metadata:
  name: &quot;{{ .chart.name }}-configuration&quot;
data:
  json: {{ $root.tickets | tojson | quote }}
{{ end }}

this is the values-int.yaml under chart-1:
tickets:
  dynamicevents:
    topics:
    - topic_name: &quot;ai-recommendations-pending-for-review&quot;
      events:
      - name: &quot;pendingforreview&quot;
        parameters:
          subject: &quot;$.insighttypeid&quot;
          group_uid: &quot;customer_care&quot;

helm template . from the global chart will print out two configmaps, where their values are taken from values.yaml and values-int.yml of the global chart and not as expected which is from chart-1 and chart-2.
i expect helm template from the global-helm-chart to show the json:  in configmap with the values of values-int.yaml under chart-1.
thanks in advance..
",<kubernetes><kubernetes-helm>,69982448,2,"helm, on its own, doesn't have a notion of per-environment values files the way you're describing it.  if you run
helm template . -f values-int.yaml

that reads ./values-int.yaml in the current directory, but doesn't look for that file in any other place; in particular it does not try to look for the same-named values file in sub charts.
instead, you need to fold all of the settings together into a single values-int.yaml file wherever you're running the deployment from (it does not need to be in the chart directory per se).  that single file includes settings for all of the sub-charts under top-level keys with the charts' names.
so, with a filesystem layout of:
global-helm-chart/
+-- chart.yaml
+-- values.yaml
+-- values-int.yaml
|
\-- charts/
  +-- chart1/
  | +-- chart.yaml
  | +-- values.yaml
  | \-- templates/
  |   \-- configmap.yaml
  |
  \-- chart2/ 
    +-- chart.yaml
    +-- values.yaml
    \-- templates/
      \-- configmap.yaml

the top-level values-int.yaml would contain:
# helm values for the integration environment.  these override
# settings in values.yaml in this chart and its subcharts.

global:
  env: int

chart1:
  tickets:
    dynamicevents: { ... }

chart2: { ... }

"
72489600,specify service account name with namespace for kubernetes pod,"i am trying to use workflow identity for my kubernetes cluster. i have created the service account on a new namespace. my issue is that i am not able to specify the name space when i am trying to add the service account name on the pod deployment yml.
following is my pod spect file:
apiversion: apps/v1
kind: deployment
metadata:
  name: test-scheduler
spec:
  replicas: 1
  selector:
    matchlabels:
      app: test-scheduler
  template:
    metadata:
      labels:
        app: test-scheduler
    spec:
      serviceaccountname: test-na/test-k8-sa
      nodeselector:
        iam.gke.io/gke-metadata-server-enabled: &quot;true&quot;
      containers:
        - name: test-scheduler
          image: gcr.io/project_id/image:tag
          ports:
            - name: scheduler-port
              containerport: 8002
              protocol: tcp
          env:
            - name: namespace
              value: test-scheduler
            - name: container_name
              value: test-scheduler
---
apiversion: v1
kind: service
metadata:
  name: test-scheduler
spec:
  selector:
    app: test-scheduler
  ports:
    - port: 8002
      protocol: tcp
      targetport: scheduler-port 


when i deploy this code using github actions i get this error:
the deployment &quot;test-scheduler&quot; is invalid: spec.template.spec.serviceaccountname: invalid value: &quot;test-na/test-k8-sa&quot;: a lowercase rfc 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.',

when i remove the namespace in a file like this:
serviceaccountname: test-k8-sa

it searches for the service account on default name space and fails.
my question here is what is the right way to specify the custom namespace with the service account in kubernetes?
i can start using the default but i am inclined to keep the namespace. i saw some reference to service account file but i don't really understand how to use them.
by the way, i am using this guide https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity#gcloud_3
",<kubernetes><google-cloud-platform><google-kubernetes-engine><kubernetes-pod>,72491396,5,"...i have created the service account on a new namespace. my issue is that i am not able to specify the name space when i am trying to add the service account name on the pod deployment yml.
to assign the created service account to your deployment, you can create the deployment in the same namespace as the service account:
apiversion: apps/v1
kind: deployment
metadata:
  name: test-scheduler
  namespace: test-na  # &lt;-- add this line with the namespace where the service account resides
spec:
  ...
  template:
    ...
    spec:
      serviceaccountname: test-k8-sa
      ...

"
63539337,how kubectl command retrieves the manifest from remote server,"when we run kubectl apply -k github.com/minio/direct-csi command, how kubectl downloads and apply the deployment manifest?
how can we download this file to local using curl or wget command?
thanks
sr
",<kubernetes><kubectl>,63539518,1,"you can see all the http request that kubectl does by using a verbose log level.
e.g.
kubectl get po --v=7

output
$ kubectl get po --v=7
i0822 20:08:27.940422   36846 loader.go:375] config loaded from file:  /users/jonas/.kube/config
i0822 20:08:27.958708   36846 round_trippers.go:420] get https://clusteraddress.com/api/v1/namespaces/default/pods?limit=500
i0822 20:08:27.958736   36846 round_trippers.go:427] request headers:
i0822 20:08:27.958742   36846 round_trippers.go:431]     accept: application/json;as=table;v=v1beta1;g=meta.k8s.io, application/json
i0822 20:08:27.958747   36846 round_trippers.go:431]     user-agent: kubectl/v1.17.5 (darwin/amd64) kubernetes/e0fccaf
i0822 20:08:28.624188   36846 round_trippers.go:446] response status: 200 ok in 665 milliseconds
name                  ready   status    restarts   age
nx-67b4f5946c-2z58x   1/1     running   0          21h



how can we download this file to local using curl or wget command?

you can do the same with e.g. curl, everyting in kubernetes is a rest api and you need proper authentication from your .kube/config or some else valid authentication.

what is download from github.com/minio/direct-cs ?

instead of applying with kustomize (apply -k) you can just build the kustomize without applying with this command:
kubectl kustomize github.com/minio/direct-csi

and you should see all manifests (derived from kustomization.yaml) in the remote location in a large manifest.
"
61211267,how to filter finished jobs in kubernetes,"i'm trying to filter jobs that are complete using golang kubernetes client-go lib by their status.

i've checked other answers explaining how to get the jobs using kubectl, like this:

kubectl get job -o=jsonpath='{.items[?(@.status.succeeded==1)].metadata.name}'


but i don't know how to ""turn"" that jsonpath output into a filter or list options

if i were searching for pods by their status phase and a label i would do something like this:

listoptions := metav1.listoptions{
    labelselector: ""app.kubernetes.io/name=my-custom-job"",
    fieldselector: ""status.phase=running"",
}
result, err := clientset.corev1().pods(""default"").list(listoptions) 


but if i am going to implement the jsonpath {.items[?(@.status.succeeded==1)].metadata.name}

this is going to iterate through all jobs and check if the succeeded key under status is equal to one. for all jobs.

is there a way to look for those jobs more ""memory friendly"" or a way to use jsonpaths like that in listoptions?
",<go><kubernetes><kubectl><client-go>,61217473,4,"yes, you can filter out, on the server-side, only finished jobs.

listoptions := metav1.listoptions{
    fieldselector: ""status.successful=1"",
}
result, err := clientset.batchv1().jobs("""").list(listoptions) 


status.successful field from the job's spec is being directly mapped to status.succeeded field from metav1.listoptions.fieldselector. more info about that.

that being said, the list of available options to filter on the server-side is highly restricted. you can not filter using arbitrary fields from the spec (e.g. status.active or spec.parallelism). github issue on that.
"
49027234,k8s gce1.8.7 - pods is forbidden - unknown user system:serviceaccount:default:default,"i have a mongo database in the gce . (config see below)

when i deploy it to a 1.7.12-gke.1  everything works fine. which means the sidecar resolves the pods and links then

now when i deploy the same konfiguration to 1.8.7-gke.1 resultes in missing permissions to list pods see below.

i don't get the point what has changed . i assume i need to assign specific permissions to the user account is that right ?

what am i missing?

error log

message: 'pods is forbidden: user ""system:serviceaccount:default:default"" cannot list pods at the cluster scope: unknown user ""system:serviceaccount:default:default""',

mongo-sidecar | feb 28, 2018, 11:04:19 am | status: 'failure',
mongo-sidecar | feb 28, 2018, 11:04:19 am | metadata: {},
mongo-sidecar | feb 28, 2018, 11:04:19 am | apiversion: 'v1',
mongo-sidecar | feb 28, 2018, 11:04:19 am | { kind: 'status',
mongo-sidecar | feb 28, 2018, 11:04:19 am | message:
mongo-sidecar | feb 28, 2018, 11:04:19 am | error in workloop { [error: [object object]]
mongo-sidecar | feb 28, 2018, 11:04:14 am | statuscode: 403 }
mongo-sidecar | feb 28, 2018, 11:04:14 am | code: 403 },
mongo-sidecar | feb 28, 2018, 11:04:14 am | details: { kind: 'pods' },
mongo-sidecar | feb 28, 2018, 11:04:14 am | reason: 'forbidden',


config:

---
kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-ssd
---
apiversion: v1
kind: service
metadata:
  name: mongo
  labels:
    name: mongo
spec:
  ports:
  - port: 27017
    targetport: 27017
  clusterip: none
  selector:
    role: mongo
---
apiversion: apps/v1beta1
kind: statefulset
metadata:
  name: mongo
spec:
  servicename: ""mongo""
  replicas: 3
  template:
    metadata:
      labels:
        role: mongo
        environment: test
    spec:
      terminationgraceperiodseconds: 10
      containers:
        - name: mongo
          image: mongo:3.4.9
          command:
            - mongod
            - ""--replset""
            - rs0
            - ""--smallfiles""
            - ""--noprealloc""
          ports:
            - containerport: 27017
          volumemounts:
            - name: mongo-persistent-storage
              mountpath: /data/db
        - name: mongo-sidecar
          image: cvallance/mongo-k8s-sidecar
          env:
            - name: mongo_sidecar_pod_labels
              value: ""role=mongo,environment=test""
  volumeclaimtemplates:
  - metadata:
      name: mongo-persistent-storage
      annotations:
        volume.beta.kubernetes.io/storage-class: ""fast""
    spec:
      accessmodes: [ ""readwriteonce"" ]
      resources:
        requests:

          storage: 5gi

",<kubernetes><google-kubernetes-engine><kubernetes-security><kubernetes-mongodb-sidecar>,49202261,12,"according to original solution: https://github.com/cvallance/mongo-k8s-sidecar/issues/75

you have to create role binding which will grant the default service account view permissions:

apiversion: rbac.authorization.k8s.io/v1beta1
kind: clusterrolebinding
metadata:
  name: default-view
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: clusterrole
  name: view
subjects:
  - kind: serviceaccount
    name: default
    namespace: default

"
62147527,how to delete label on kubernetes namespace,"i labeled a kubernetes namespace like so:

kubectl label namespace kube-system name=kube-system


how do i get rid of this label?
",<kubernetes><kubectl>,62147640,23,"use below command to remove the label

 kubectl label namespace kube-system name-

"
59662585,pods in eks: can't resolve dns (but can ping ip),"i have 2 eks clusters, in 2 different aws accounts and with, i might assume, different firewalls (which i don't have access to). the first one (dev) is all right, however, with the same configuration, uat cluster pods is struggling to resolve dns. the nodes can resolve and seems to be all right.

1) ping 8.8.8.8 works

--- 8.8.8.8 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3003ms


2) i can ping the ip of google (and others), but not the actual dns names.

our configuration:


configured with terraform.
the worker nodes and control plane sg are the same than the dev ones. i believe those are fine.
added 53 tcp and 53 udp on inbound + outbound nacl (just to be sure 53 was really open...). added 53 tcp and 53 udp outbound from worker nodes.
we are using ami-059c6874350e63ca9 with 1.14 kubernetes version.


i am unsure if the problem is a firewall somewhere, coredns, my configuration that needs to be updated or an ""stupid mistake"". any help would be appreciated.
",<kubernetes><amazon-eks><coredns>,59788764,3,"after days of debugging, here is what was the problem : 
i had allowed all traffic between the nodes but that all traffic is tcp, not udp.

it was basically a one line in aws: 
in worker nodes sg, add an inbound rule from/to worker nodes port 53 protocol dns (udp).

if you use terraform, it should look like that:

resource ""aws_security_group_rule"" ""eks-node-ingress-cluster-dns"" {
  description = ""allow pods dns""
  from_port                = 53
  protocol                 = 17
  security_group_id        = ""${aws_security_group.sg-eks-workernodes.id}""
  source_security_group_id = ""${aws_security_group.sg-eks-workernodes.id}""  
  to_port                  = 53
  type                     = ""ingress""
}

"
64647258,how nginx ingress controller back-end protocol annotation works in path based routing?,"i'm currently playing with nginx ingress controller in my k8s cluster. i was trying to make end-to-end encryption work and i was able to make the connection secure all the way to the pod.
in order to achieve https all the way till pod, i had to use annotation
nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;

sample ingress:
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: foo-api-ingress
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;
spec:
  tls:
  - hosts:
    - foo.example.com
    secretname: foo-cert
  rules:
  - host: foo.example.com
    http:
      paths:
      - path: /path1
        backend:
          servicename: foo-api-path1-service
          serviceport: 443
      - path: /path2
        backend:
          servicename: foo-api-path2-service
          serviceport: 443

i'm confused in terms of how exactly this happens because when we encrypt the connection path also get encrypted then how nginx does path-based routing? does it decrypt the connection at ingress and re-encrypt it? also, does performance get affected by using this method?
",<ssl><nginx><kubernetes><kubernetes-ingress><nginx-ingress>,64662822,14,"tl;dr

does it decrypt the connection at ingress and re-encrypt it?

in short, yes. please see the explanation below.

explanation
the path that a request is travelling to get to a pod can be seen as:


kubernetes.io: docs: concepts: services networking: ingress

assuming that we have an ingress controller (nginx-ingress) in place of an ingress you can have several ways to connect your client with a pod (simplified):

unencrypted:

client -- (http) --&gt; ingress controller -- (http) --&gt; service ----&gt; pod





encrypted at the ingress controller (with nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;)

client -- (http) --&gt; ingress controller -- (https) --&gt; service ----&gt; pod





encrypted and decrypted at the ingress controller where tls termination happens:

client -- (https) --&gt; ingress controller (tls termination) -- (http) --&gt; service ----&gt; pod




your setup:

encrypted and decrypted at the ingress controller where tls termination happens and encrypted once again when connecting with a https backend by nginx.ingress.kubernetes.io/backend-protocol: &quot;https&quot;:

client -- (https) --&gt; ingress controller (tls termination) -- (https) --&gt; service ----&gt; pod





encrypted and decrypted at the pod where ingress controller is configured with ssl passthrough:

client -- (https) --&gt; ingress controller -- (https) --&gt; service ----&gt; pod




disclaimer!
this is only a simplified explanation. for more reference you can look at this comment:

there is a missing detail here, the ssl passthrough traffic never reaches nginx in the ingress controller. there is a go listener for tls connections that just pipes the traffic to the service defined in the ingress.

github.com: kubernetes: ingress nginx: issues: 5618





for more reference you can look on the similar question (with an answer):

stackoverflow.com: answer: how to configure ingress to direct traffic to an https backend using https

you can also check this article with example setup similar to yours:

code.oursky.com: how to enable tls https between your kubernetes ingress and back end deployments


additional resources:

github.com: kubernetes: ingress nginx: is it possible to have secure backend connections from the nginx controller?
github.com: kubernetes: ingress nginx: nginx configuration: annotations: backend certificate authentication

"
61180560,how to integrate openldap to keycloak correctly?,"installed openldap by helm

helm install openldap stable/openldap


check data in the initialized server

kubectl port-forward $openldap_pod_name 3890:389
ldapsearch -x -h ldap://localhost:3890 -b dc=example,dc=org -d ""cn=admin,dc=example,dc=org"" -w $ldap_admin_password

# extended ldif
#
# ldapv3
# base &lt;dc=example,dc=org&gt; with scope subtree
# filter: (objectclass=*)
# requesting: all
#

# example.org
dn: dc=example,dc=org
objectclass: top
objectclass: dcobject
objectclass: organization
o: example inc.
dc: example

# admin, example.org
dn: cn=admin,dc=example,dc=org
objectclass: simplesecurityobject
objectclass: organizationalrole
cn: admin
description: ldap administrator
userpassword:: [hidden]

# search result
search: 2
result: 0 success

# numresponses: 3
# numentries: 2


install keycloak

helm install keycloak codecentric/keycloak
kubectl port-forward $keycloak_pod_name 8080


bind it to keycloak in the user federation -> add user storage provider -> ldap as below.



why can't connect to ldap server? i login to the ldap pod to see the log but didn't find where is it.
",<kubernetes><ldap><keycloak><kubernetes-helm><openldap>,63367555,2,"the &quot;connection url&quot; should most probably be ldap://openldap.default:389 (and if openldap was deployed in a different namespace, replace default with that).
"
52121422,how to automatically stop rolling update when crashloopbackoff?,"i use google kubernetes engine and i intentionally put an error in the code. i was hoping the rolling update will stop when it discovers the status is crashloopbackoff, but it wasn't.

in this page, they say.. 


  the deployment controller will stop the bad rollout automatically, and
  will stop scaling up the new replicaset. this depends on the
  rollingupdate parameters (maxunavailable specifically) that you have
  specified.


but it's not happening, is it only if the status imagepullbackoff?

below is my configuration.

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: volume-service
  labels:
    group: volume
    tier: service
spec:
  replicas: 4
  strategy:
    type: rollingupdate
    rollingupdate:
      maxunavailable: 2
      maxsurge: 2
  template:
    metadata:
      labels:
        group: volume
        tier: service
    spec:
      containers:
      - name: volume-service
        image: gcr.io/example/volume-service:latest


p.s. i already read liveness/readiness probes, but i don't think it can stop a rolling update? or is it?
",<kubernetes><google-kubernetes-engine>,52122467,3,"turns out i just need to set minreadyseconds and it stops the rolling update when the new replicaset has status crashloopbackoff or something like exited with status code 1. so now the old replicaset still available and not updated.

here is the new config.

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: volume-service
  labels:
    group: volume
    tier: service
spec:
  replicas: 4
  minreadyseconds: 60
  strategy:
    type: rollingupdate
    rollingupdate:
      maxunavailable: 2
      maxsurge: 2
  template:
    metadata:
      labels:
        group: volume
        tier: service
    spec:
      containers:
      - name: volume-service
        image: gcr.io/example/volume-service:latest


thank you for averyone help!
"
48151388,kubernetes python client: authentication issue,"we are using the kubernetes python client (4.0.0) in combination with google's kubernetes engine (master + nodepools run k8s 1.8.4) to periodically schedule workloads on kubernetes. the simplified version of the script we use to creates the pod, attach to the the logs and report the end status of the pod looks as follows:

config.load_kube_config(persist_config=false)
v1 = client.corev1api()
v1.create_namespaced_pod(body=pod_specs_dict, namespace=args.namespace)
logging_response = v1.read_namespaced_pod_log(
    name=pod_name,
    namespace=args.namespace,
    follow=true,
    _preload_content=false
)
for line in logging_response:
    line = line.rstrip()
    logging.info(line)
status_response = v1.read_namespaced_pod_status(pod_name, namespace=args.namespace)
print(""pod ended in status: {}"".format(status_response.status.phase))


everything works pretty fine, however we are experiencing some authentication issues. authentication happens through the default gcp auth-provider, for which i obtained the initial access token by running a kubectl container cluster get-credentials manually on the scheduler. at some random timeframes, some api calls result in a 401 response from the api server. my guess is that this happens whenever the access token is expired, and the script tries to obtain a new access token. however it happens that multiple scripts are running concurrently on the scheduler, resulting in obtaining a new api key multiple times of which only one is still valid. i tried out multiple ways to fix the issue (use persist_config=true, retry 401's after reloading the config,...) without any success. as i am not completely aware how the gcp authentication and the kubernetes python client config work (and docs for both are rather scarce), i am a bit left in the dark. 

should we use another authentication method instead of the gcp auth-provider? is this a bug in the kubernetes python client? should we use multiple config files?
",<kubernetes><google-kubernetes-engine><kubernetes-python-client>,48377444,29,"in the end we have solved this by using bearer token authentication, instead of relying on the default gcloud authentication method.

here are the steps that i did to achieve this.

first create a service account in the desired namespace, by creating a file with the following content.

apiversion: v1
kind: serviceaccount
metadata:
  name: &lt;name_of_service_account&gt;


then use this file to create the service account

kubectl create -f &lt;path_to_file&gt; --namespace=&lt;namespace_name&gt;


each service account has a bearer token linked to it, which can be used for authentication. this bearer token is automatically mounted as a secret into the namespace. to find out what this token is, first find the name of the secret (is of the form &lt;service_account_name&gt;-token-&lt;random_string&gt;) and then use that name to get to content.

# to search for out service account's token name
kubectl get secrets --namespace=&lt;namespace_name&gt;

# to find the token name
kubectl describe secret/&lt;secret_name&gt;


after this you should find out the ip address of the api server, and the cluster ca certificate of the kubernetes cluster. this can be done by going to the kubernetes engine detail page on google cloud console. copy the content of the certificate into a local file.

you can now use the bearer token to authenticate via the kubernetes python client, as follows:

from kubernetes import client

configuration = client.configuration()
configuration.api_key[""authorization""] = '&lt;bearer_token&gt;'
configuration.api_key_prefix['authorization'] = 'bearer'
configuration.host = 'https://&lt;ip_of_api_server&gt;'
configuration.ssl_ca_cert = '&lt;path_to_cluster_ca_certificate&gt;'

v1 = client.corev1api(client.apiclient(configuration))

"
49962582,trouble accessing nginx deployment externally,"i can curl an exposed nginx deployment:

apiversion: apps/v1
kind: deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  selector:
    matchlabels:
      app: nginx
      tr: frnt
  template:
    metadata:
      labels:
        app: nginx
        tr: frnt
    spec:
      containers:
        - image: nginx
          name: nginx
          ports:
            - containerport: 80
      restartpolicy: always 

----

apiversion: v1
kind: service
metadata:
  name: web-dep-nodeport-service
spec:
  selector:
    tr: frnt
  ports:
    - nodeport: 30000
      port: 80
  type: nodeport     


on a node, with success:

user@gke-cluster-1-default-pool-xxxx ~ $ curl -lvso /dev/null http://localhost:30000
* rebuilt url to: http://localhost:30000/
*   trying 127.0.0.1...
* tcp_nodelay set
* connected to localhost (127.0.0.1) port 30000 (#0)
&gt; get / http/1.1
&gt; host: localhost:30000
&gt; user-agent: curl/7.58.0
&gt; accept: */*
&gt; 
&lt; http/1.1 200 ok
&lt; server: nginx/1.9.15
&lt; date: sun, 22 apr 2018 04:40:24 gmt
&lt; content-type: text/html
&lt; content-length: 612
&lt; last-modified: tue, 19 apr 2016 17:27:46 gmt
&lt; connection: keep-alive
&lt; etag: ""xxxxx""
&lt; accept-ranges: bytes
&lt; 
{ [612 bytes data]
* connection #0 to host localhost left intact


but when trying the same command on an external machine, using the node external_ip (from gcloud compute instances list), i get:

$ curl -lvso /dev/null  http://x.x.x.x:30000 &amp;&gt; result.txt &amp;
$ cat result.txt 
* rebuilt url to: http://x.x.x.x:30000/
*   trying x.x.x.x...
* connect to x.x.x.x port 30000 failed: connection timed out
* failed to connect to x.x.x.x port 30000: connection timed out
* closing connection 0


i can ping the external_ip with success:

ping -c 2 x.x.x.x
ping x.x.x.x (x.x.x.x) 56(84) bytes of data.
64 bytes from x.x.x.x: icmp_seq=1 ttl=56 time=32.4 ms
64 bytes from x.x.x.x: icmp_seq=2 ttl=56 time=33.7 ms

--- x.x.x.x ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 32.456/33.099/33.742/0.643 ms


what can i do here to expose the nodeport externally?
",<deployment><kubernetes><google-compute-engine><google-kubernetes-engine><google-cloud-networking>,49962772,1,"this was solved by creating a firewall rule:

gcloud compute firewall-rules create nginx-rule --allow tcp:30000
"
78590323,helm mount a set of confimaps or secrets dynamically,"i have a use case for a helm deployment to mount a set of configmaps (it can be also secrets) which are present in the system already.
the configmaps follow a pattern *-version. as the name suggests, this contains version details of each application we have in the namespace. with this new deployment mounting all these configmaps, i can run a prometheus exporter in there to scrape this information and send it to prometheus.
i'm not sure if helm can do this dynamically with a given pattern and loop somehow to form all the configmap mount to different files in the pod.
optionally, i can define this configmap names in the values.yaml and also loop through it, but it would be bit difficult to maintain and to update values when there is new deployment added.
",<loops><kubernetes><kubernetes-helm><configmap><kubernetes-secrets>,78591373,3,"in principle you can use the helm lookup function for this.  it might look something like
{{- $lookups := lookup &quot;v1&quot; &quot;configmap&quot; .release.namespace &quot;&quot; }}
volumes:
{{- range $lookups.items }}
{{- if hassuffix &quot;-version&quot; .metadata.name }}
  - name: {{ .metadata.name }}
    configmap:
      name: {{ .metadata.name }}
{{- end }}
{{- end }}
containers:
  - ...
    volumemounts:
{{- range $lookups.items }}
{{- if hassuffix &quot;-version&quot; .metadata.name }}
      - name: {{ .metadata.name }}
        mountpath: /tmp/{{ .metadata.name }}
        subpath: version
{{- end }}
{{- end }}

note that this will not automatically update itself; you will need to helm upgrade the chart whenever the set of resources in the cluster changes.  its behavior also depends heavily on what's in the cluster, which can make this hard to test.  but this is the only way to do this using only helm.
"
75770929,the connection to the server localhost:8080 was refused in kubectl,"i installed kubectl and k3d after following these official documentations (k3d and kubectl).
i created a cluster with the following command:
k3d cluster create mycluster

then i ran this command:
kubectl cluster-info

which gave me this error message:
the connection to the server localhost:8080 was refused - did you specify the right host or port?
after searching i found that the file /etc/kubernetes wasn't created (which means no admin.conf file was created), and the folder ~/.kube also doesn't exist.
ps: see this answer to understand
here are the versions of k3d and kubectl
$ k3d version
k3d version v5.4.9
k3s version v1.25.7-k3s1 (default)

$ kubectl version --short
client version: v1.25.2
kustomize version: v4.5.7

",<kubernetes><kubectl><k3d>,75774223,1,"check kubeadm was properly installed or not?. the command kubeadm version helps you to know the running status of kubeadm.
note : if you can see the kubeadm version number, your kubeadm was installed properly.
and also run kubeadm init to initialize the control plane on your machine and create the necessary configuration files. see kubernetes community forum issue for more information.

you may haven’t set the kubeconfig environment variable and the
.kube/config file is not exported to the user $home directory.

see nijo luca’s blog on k21 academy  for more information, which may help to resolve your issue.
"
71506066,helm3 using lookup function to load a variable,"i am currently attempting to use the lookup function via helm 3.1 to load a variable during installation.
{{ $ingress := (lookup &quot;v1&quot; &quot;ingress&quot; &quot;mynamespace&quot; &quot;ingressname&quot;).status.loadbalancer.ingress[0].hostname }}

of course, this returns, &quot;bad character [.&quot; if i remove it, it returns &quot;nil pointer evaluating interface {}.loadbalancer&quot;.
is what i am attempting to do even possible?
thanks
",<kubernetes><kubernetes-helm>,71506472,3,"you are attempting to use &quot;normal&quot; array indexing syntax, but helm charts use &quot;golang templates&quot; and thus array indexing is done via the index function
{{ $ingress := (index (lookup &quot;v1&quot; &quot;ingress&quot; &quot;mynamespace&quot; &quot;ingressname&quot;).status.loadbalancer.ingress 0).hostname }}


after further thought, i can easily imagine that nil pointer error happening during helm template runs, since lookup returns map[] when running offline
in that case, you'd want to use the index function for every path navigation:
{{ $ingress := (index (index (index (index (index (lookup &quot;v1&quot; &quot;ingress&quot; &quot;mynamespace&quot; &quot;ingressname&quot;) &quot;status&quot;) &quot;loadbalancer&quot;)  &quot;ingress&quot;) 0) &quot;hostname&quot;) }}

or, assert the lookup is in &quot;offline&quot; mode and work around it:
      {{ $ingress := &quot;fake.example.com&quot; }}
      {{ $maybelookup := (lookup &quot;v1&quot; &quot;ingress&quot; &quot;mynamespace&quot; &quot;ingressname&quot;) }}
      {{ if $maybelookup }}
      {{   $ingress = (index $maybelookup.status.loadbalancer.ingress 0).hostname }}
      {{ end }}

"
45964882,kubernetes - persistentvolumeclaim failed,"i have a gke based kubernetes setup and a pod that requires a storage volume. i attempt to use the config below:

kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: my-scratch-space
spec:
  accessmodes:
  - readwriteonce
resources:
  requests:
    storage: 2000gi
storageclassname: standard


this pvc is not provisioned. i get the below error:

failed to provision volume with storageclass ""standard"": googleapi: error 503: the zone 'projects/p01/zones/europe-west2-b' does not have enough resources available to fulfill the request.  try a different zone, or try again later.


looking at gke quotas page, i don't see any issues. deleting other pvcs also is not solving the issue. can anyone help? thanks.
",<kubernetes><google-kubernetes-engine>,45967044,1,"there is no configuration problem at your side - there are actually not enough resources in the europe-west2-b zone to create a 2t persistent disk. either try for a smaller volume or use a different zone.

there is an example for gce in the docs. create a new storageclass specifying say the europe-west1-b zone (which is actually cheaper than europe-west2-b) like this:

kind: storageclass
apiversion: storage.k8s.io/v1
metadata:
  name: gce-pd-europe-west1-b
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard
  zones: europe-west1-b


and modify your pvc:

kind: persistentvolumeclaim
apiversion: v1
metadata:
  name: my-scratch-space
spec:
  accessmodes:
  - readwriteonce
resources:
  requests:
    storage: 2000gi
storageclassname: gce-pd-europe-west1-b

"
66098797,kubernetes vpa for cronjob,"i need to run vpa for cronjob. i refer to this doc.
i think i followed it properly but it doesn't work for me.

using gke, 1.17
vpa version is vpa-release-0.8
i created cronjob and vpa with this file.

apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: &quot;*/1 * * * *&quot;
  jobtemplate:
    spec:
      template:
        metadata:
          labels:
            app: hello
        spec:          
          containers:
          - name: hello
            image: busybox
            imagepullpolicy: ifnotpresent
            args:
            - /bin/sh
            - -c
            - date; echo hello from the kubernetes cluster
          restartpolicy: onfailure
---
apiversion: autoscaling.k8s.io/v1
kind: verticalpodautoscaler
metadata:
  name: my-vpa
spec:
  targetref:
    apiversion: &quot;batch/v1beta1&quot;
    kind: cronjob
    name: hello
  updatepolicy:
    updatemode: &quot;auto&quot;

when i type this command:
kubectl describe vpa

i got this result:
name:         my-vpa
namespace:    default
labels:       &lt;none&gt;
annotations:  &lt;none&gt;
api version:  autoscaling.k8s.io/v1
kind:         verticalpodautoscaler
metadata:
  creation timestamp:  2021-02-08t07:38:23z
  generation:          2
  resource version:    3762
  self link:           /apis/autoscaling.k8s.io/v1/namespaces/default/verticalpodautoscalers/my-vpa
  uid:                 07803254-c549-4568-a062-144c570a8d41
spec:
  target ref:
    api version:  batch/v1beta1
    kind:         cronjob
    name:         hello
  update policy:
    update mode:  auto
status:
  conditions:
    last transition time:  2021-02-08t07:39:14z
    status:                false
    type:                  recommendationprovided
  recommendation:
events:  &lt;none&gt;

",<kubernetes><autoscaling><kubernetes-cronjob>,67650394,1,"
@mario oh!! so there was not enough time to get metrics to recommend
resource.... – 변상현 feb 10 at 2:36

yes, exactly. if the only task of your cronjob is to echo hello from the kubernetes cluster and exit you won't get any recommendations from vpa as this is not a resource-intensive task.
however if you modify your command so that it generates an artificial load in your cronjob-managed pods:
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: hello
spec:
  schedule: &quot;*/1 * * * *&quot;
  jobtemplate:
    spec:
      template:
        metadata:
          labels:
            app: hello
        spec:
          containers:
          - name: hello
            image: busybox
            imagepullpolicy: ifnotpresent
            args:
            - /bin/sh
            - -c
            - date; dd if=/dev/urandom | gzip -9 &gt;&gt; /dev/null
          restartpolicy: onfailure

after a few minutes you'll get the expected result:
$ kubectl describe vpa my-vpa
name:         my-vpa
namespace:    default
labels:       &lt;none&gt;
annotations:  &lt;none&gt;
api version:  autoscaling.k8s.io/v1
kind:         verticalpodautoscaler
metadata:
  creation timestamp:  2021-05-22t13:02:27z
  generation:          8

...

    manager:         vpa-recommender
    operation:       update
    time:            2021-05-22t13:29:40z
  resource version:  5534471
  self link:         /apis/autoscaling.k8s.io/v1/namespaces/default/verticalpodautoscalers/my-vpa
  uid:               e37abd79-296d-4f72-8bd5-f2409457e9ff
spec:
  target ref:
    api version:  batch/v1beta1
    kind:         cronjob
    name:         hello
  update policy:
    update mode:  auto
status:
  conditions:
    last transition time:  2021-05-22t13:39:40z
    status:                false
    type:                  lowconfidence
    last transition time:  2021-05-22t13:29:40z
    status:                true
    type:                  recommendationprovided
  recommendation:
    container recommendations:
      container name:  hello
      lower bound:
        cpu:     1185m
        memory:  2097152
      target:
        cpu:     1375m
        memory:  2097152
      uncapped target:
        cpu:     1375m
        memory:  2097152
      upper bound:
        cpu:     96655m
        memory:  115343360
events:          &lt;none&gt;

❗important: just don't leave it running for too long as you might be quite surprised with your bill 😉
"
37923927,google container engine stdout logs not showing up,"my stdout logs are not showing up in google logs viewer, or when using kubectl logs &lt;pod&gt;. the cluster has cloud logging enabled and fluentd containers are running on each node.

example python code:

logger = logging.getlogger()
logger.setlevel(logging.info)
handler = logging.streamhandler(sys.stdout)
handler.setlevel(logging.info)
logger.addhandler(handler)
logger.info(""test log"")


the ""counter-pod"" example from their docs does work on my cluster, so the fluentd containers are picking up stdout and sending it to logs viewer.

any suggestions for things i should try? thanks in advance.
",<python><docker><kubernetes><google-kubernetes-engine><google-cloud-logging>,37956227,6,"the logs are definitely going to stdout, they just aren't showing up when running kubectl logs &lt;pod_name&gt;. nor are they showing up in google logs viewer.

this is because logs sent to stdout will only be captured if they're coming from the process that's the entry point of the docker container. things that are done in the shell or via a cron job don't show up.

in my case i had a cron job that was invoking a script. by running the script as the container's entry point, the logs showed up fine.
"
54311129,"k8s, rabbitmq, and peer discovery","we are trying to run an instance of the rabbitmq chart with helm from the helm/charts/stable/rabbit project. i had it running perfect but then i had to restart k8s for some maintenance. now we are completely unable to launch the rabbitmq chart in any way shape or form. i am not even trying to run the chart with any variables, i.e. just the default values. 

here is all i am doing:

helm install stable/rabbitmq


i have confirmed i can simply run the default right on my local k8s which i'm running with docker for desktop. when we run the rabbit chart on our shared k8s the exact same way as on desktop and what we did before the restart, the following error is thrown:

failed to get nodes from k8s - 503


i have also posted an issue on the helm charts repo as well. click here to see the issue on github. 

we are suspecting the dns but are unable to confirm anything yet. what is very frustrating is after the restart every single other chart we installed restarted perfectly except rabbit which now will not start at all. 

anyone know what i could do to get rabbits peer discovery to work? anyone seen issue like this after restarting k8s? 
",<kubernetes><rabbitmq><kubernetes-helm>,54366745,2,"so i actually got rabbit to run. turns out my issue was the k8s peer discovery could not connect over the default port 443 and i had to use the external port 6443 because kubernetes.default.svc.cluster.local resolved to the public port and could not find the internal, so yeah our config is messed up too. 

it took me a while to realize the variable below was not overriding when i overrode it with  helm install . -f server-values.yaml.  

rabbitmq:
  configuration: |-
    ## clustering
    cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s
    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
    cluster_formation.k8s.port = 6443
    cluster_formation.node_cleanup.interval = 10
    cluster_formation.node_cleanup.only_log_warning = true
    cluster_partition_handling = autoheal
    # queue master locator
    queue_master_locator=min-masters
    # enable guest user
    loopback_users.guest = false


i had to add cluster_formation.k8s.port = 6443 to the main values.yaml file instead of my own. once the port was changed specifically in the values.yaml, rabbit started right up. 
"
61140985,aws eks - create cluster minimum iam permissions (accessdenied),"does anyone know what should be the minimum iam permissions that would allow a user creating an eks cluster?

i'm assuming a role to just create a cluster with terraform and that role has got the following statements in its policy defined (nothing more than that):

        {
            ""sid"": ""allowekscreate"",
            ""effect"": ""allow"",
            ""action"": [
                ""eks:list*"",
                ""eks:describe*"",
                ""eks:createcluster"",
                ""ec2:describe*""
            ],
            ""resource"": ""*""
        },
        {
            ""sid"": ""alloweksall"",
            ""effect"": ""allow"",
            ""action"": ""eks:*"",
            ""resource"": ""arn:aws:eks:eu-west-1:xxxxxxxxxx:cluster/my-cluster""
        }


in cloudtrail i'am only seeing:

aws access key: xxxxxxxx
aws region: eu-west-1
error code: accessdenied
event id: xxxxxxxx
event name: createcluster
event source: eks.amazonaws.com


successful events:


sts:getcalleridentity
ec2:describeaccountattributes


no other event is present in cloudtrail that would be unsuccessful.
",<amazon-web-services><kubernetes><amazon-eks>,61141900,1,"found it!

the missing permission was iam:passrole on the cluster iam role resource.

for some reason cloudtrail does not reveal that information :(

p.s.
i think i made my question very clear so am wondering why someone would give me -1.
"
60426580,how to use inclusterconfig of kubernetes in go,"i am using kubernetes-client. here, i am trying to load my config file using the filepath. i want to create the client using inclusterconfig without having to load a kubeconfig file. how do i go about doing this?
var kube_config_path = &quot;/home/saivamsi/.kube/config&quot;    
var config, conferr = clientcmd.buildconfigfromflags(&quot;&quot;, kube_config_path)
var clientset, cler = kubernetes.newforconfig(config)

",<go><kubernetes><kubernetes-go-client>,60427214,4,"here is an example

package main

import (
    ""context""
    ""fmt""
    ""time""

    ""k8s.io/apimachinery/pkg/api/errors""
    metav1 ""k8s.io/apimachinery/pkg/apis/meta/v1""
    ""k8s.io/client-go/kubernetes""
    ""k8s.io/client-go/rest""
    //
    // uncomment to load all auth plugins
    // _ ""k8s.io/client-go/plugin/pkg/client/auth""
    //
    // or uncomment to load specific auth plugins
    // _ ""k8s.io/client-go/plugin/pkg/client/auth/azure""
    // _ ""k8s.io/client-go/plugin/pkg/client/auth/gcp""
    // _ ""k8s.io/client-go/plugin/pkg/client/auth/oidc""
    // _ ""k8s.io/client-go/plugin/pkg/client/auth/openstack""
)

func main() {
    // creates the in-cluster config
    config, err := rest.inclusterconfig()
    if err != nil {
        panic(err.error())
    }
    // creates the clientset
    clientset, err := kubernetes.newforconfig(config)
    if err != nil {
        panic(err.error())
    }
    for {
        // get pods in all the namespaces by omitting namespace
        // or specify namespace to get pods in particular namespace
        pods, err := clientset.corev1().pods("""").list(context.todo(), metav1.listoptions{})
        if err != nil {
            panic(err.error())
        }
        fmt.printf(""there are %d pods in the cluster\n"", len(pods.items))

        // examples for error handling:
        // - use helper functions e.g. errors.isnotfound()
        // - and/or cast to statuserror and use its properties like e.g. errstatus.message
        _, err = clientset.corev1().pods(""default"").get(context.todo(), ""example-xxxxx"", metav1.getoptions{})
        if errors.isnotfound(err) {
            fmt.printf(""pod example-xxxxx not found in default namespace\n"")
        } else if statuserror, isstatus := err.(*errors.statuserror); isstatus {
            fmt.printf(""error getting pod %v\n"", statuserror.errstatus.message)
        } else if err != nil {
            panic(err.error())
        } else {
            fmt.printf(""found example-xxxxx pod in default namespace\n"")
        }

        time.sleep(10 * time.second)
    }
}

"
74257073,kubectl logs displays only 'api server listening at: [::]:40000' when remote debugging with dlv is enabled - how do i get my logs back?,"i currently have a go app that uses a lot fmt.printf. whenever that app would run in a pod i was able to get the logs back by doing
kubectl logs podname
however i also needed to integrate remote debugging. i need to use dlv to allow my ide(goland) to remotely connect to the pod. it connects to the pod at port 40000.
also when the pods image runs it exposes port 40000 i.e the docker file has this in it 40000
i also have a service that looks like this in my minikube
apiversion: v1
kind: service
metadata:
  name: mydebug
spec:
  type: clusterip
  selector:
    app: fooapp
  ports:
  - protocol: tcp
    port: 40000
    targetport: 40000
    name: delve

now when i do kubectl logs podname i only get this back
api server listening at: [::]:40000
2022-10-30t21:18:57z warning layer=rpc listening for remote connections (connections are not authenticated nor encrypted)

is there anyway to get my logs back ? ho
",<docker><go><kubernetes><kubectl><delve>,74343678,1,"you can use the --continue exec flag, to continue the debugged process on the start, which then will lead to continued logs.
so start delve e.g. with:
dlv --listen=:2345 --headless exec your/app --continue

without the --continue flag, delve will wait for remote connections and halt your application. with the --continue flag, the application instead will start already.
from dlv help exec:
...
usage:
  dlv exec &lt;path/to/binary&gt; [flags]

flags:
      --continue     continue the debugged process on start.
...

"
43119983,kubernetes - how to know which minions are hosting pods,"i have a 6 minion cluster and would like to know how many of these minions are actually hosting pods at any given time. is there a specific command for that ? right now im using a very generic command.

kubectl get po | grep running &gt; running.txt
for i in `cat running.txt `; do kubectl describe po $i; done | grep ""started container with docker


""

any direct command to fetch the info i want ? 
",<kubernetes><kubectl><kubernetes-health-check>,43120622,1,"just add -o wide:

kubectl get pod -o wide

"
70244509,kubernetes: does extending the status subresource require a new api version?,"i intend to add additional error message fields to a custom resource status. the fields are marked as
errmsg string `json:&quot;errmsg,omitempty&quot;`

does adding these fields require a new api version, or is is safe to just change the managing operator to fill these fields with values?
",<kubernetes><kubernetes-custom-resources>,70277578,2,"according to this

additional fields may be added in the future.

if your controller is only ever writing to status then you don't need to bump the crd version.
it also depends what sort of validation you have on the crd - like if the structural schema is validating the status.
here are conventions for multiple api versions (although there isn't much on status)
"
54686604,nginx ingress controller failed to run,"i'm trying to deploy nginx-ingress controller in my own server without load balancer and cloud provider. i did the following steps:

apiversion: v1
kind: namespace
metadata:
  name: ingress-nginx


then, i created a cluster role named nginx-ingress for the serviceaccount.
my nginx-controller-service.yaml:

kind: service
apiversion: v1
metadata:
  name: ingress-nginx
  namespace: ingress-nginx
  labels:
    app: ingress-nginx
spec:
  externaltrafficpolicy: local
  type: nodeport
  selector:
    app: ingress-nginx
  ports:
  - name: http
    port: 80
    targetport: http
  - name: https
    port: 443
    targetport: https
  externalips:
    - my-external-node-ip


and nginx-ingress-controller.yaml:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
spec:
  replicas: 1
  selector:
    matchlabels:
      app: ingress-nginx
  template:
    metadata:
      labels:
        app: ingress-nginx
      annotations:
        prometheus.io/port: '10254'
        prometheus.io/scrape: 'true'
    spec:
      serviceaccountname: nginx-ingress
      containers:
        - name: nginx-ingress-controller
          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.9.0-beta.17
          args:
            - /nginx-ingress-controller
            - --default-backend-service=$(pod_namespace)/default-http-backend
          env:
            - name: pod_name
              valuefrom:
                fieldref:
                  fieldpath: metadata.name
            - name: pod_namespace
              valuefrom:
                fieldref:
                  fieldpath: metadata.namespace
          ports:
          - name: http
            containerport: 80
          - name: https
            containerport: 443
          livenessprobe:
            failurethreshold: 3
            httpget:
              path: /healthz
              port: 10254
              scheme: http
            initialdelayseconds: 10
            periodseconds: 10
            successthreshold: 1
            timeoutseconds: 1
          readinessprobe:
            failurethreshold: 3
            httpget:
              path: /healthz
              port: 10254
              scheme: http
            periodseconds: 10
            successthreshold: 1
            timeoutseconds: 1


but, when i get the deployment status, it shows me:

namespace       name                                       ready   up-to-date   available   age
ingress-nginx   deployment.apps/default-http-backend       1/1     1            1           17m
ingress-nginx   deployment.apps/nginx-ingress-controller   0/1     0            0           17m


the controller is not available/not running.

what's going wrong here, how to get logs of that failed deployment?
",<docker><kubernetes><kubernetes-ingress><nginx-ingress>,54708078,1,"the issue was caused due to missing service account. 

58m warning failedcreate replicaset error creating: pods ""nginx-ingress-controller-5b7f66f95f-"" is forbidden: error looking up service account ingress-nginx/nginx-ingress: serviceaccount ""nginx-ingress"" not found


with the following command you can create the sa

kubectl create serviceaccount my-service-account

for further detail  k8s-service-account
"
77528050,unable to connect to the server gke/gcp x509: certificate has expired or is not yet valid,"i can't connect to gke cluster. i have everything necessary for kubectl authentication.
$ gke-gcloud-auth-plugin version
{
    &quot;kind&quot;: &quot;execcredential&quot;,
    &quot;apiversion&quot;: &quot;client.authentication.k8s.io/v1beta1&quot;,
    &quot;spec&quot;: {
        &quot;interactive&quot;: false
    },
    &quot;status&quot;: {
        &quot;expirationtimestamp&quot;: &quot;2023-11-21t18:46:36z&quot;,

$ gcloud container clusters get-credentials $name

$ kubectl get nodes   
                                                                                                    
e1121 21:07:03.903867  109630 memcache.go:265] couldn't get current server api group list: get &quot;https://35.230.71.198/api?timeout=32s&quot;: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:03+03:00 is before 2023-11-22t06:42:11z
e1121 21:07:04.348742  109630 memcache.go:265] couldn't get current server api group list: get &quot;https://35.230.71.198/api?timeout=32s&quot;: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:04+03:00 is before 2023-11-22t06:42:11z
e1121 21:07:04.765932  109630 memcache.go:265] couldn't get current server api group list: get &quot;https://35.230.71.198/api?timeout=32s&quot;: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:04+03:00 is before 2023-11-22t06:42:11z
e1121 21:07:05.214094  109630 memcache.go:265] couldn't get current server api group list: get &quot;https://35.230.71.198/api?timeout=32s&quot;: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:05+03:00 is before 2023-11-22t06:42:11z
e1121 21:07:05.648717  109630 memcache.go:265] couldn't get current server api group list: get &quot;https://35.230.71.198/api?timeout=32s&quot;: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:05+03:00 is before 2023-11-22t06:42:11z
unable to connect to the server: tls: failed to verify certificate: x509: certificate has expired or is not yet valid: current time 2023-11-21t21:07:05+03:00 is before 2023-11-22t06:42:11z

",<kubernetes><google-kubernetes-engine>,77528128,1,"i found that wsl did not have the same system time as windows, not sure why, but running hwclock -s fixed this
"
61616203,nginx ingress controller - failed calling webhook,"i set up a k8s cluster using kubeadm (v1.18) on an ubuntu virtual machine.
now i need to add an ingress controller. i decided for nginx (but i'm open for other solutions). i installed it according to the docs, section &quot;bare-metal&quot;:
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-0.31.1/deploy/static/provider/baremetal/deploy.yaml

the installation seems fine to me:
kubectl get all -n ingress-nginx

name                                            ready   status      restarts   age
pod/ingress-nginx-admission-create-b8smg        0/1     completed   0          8m21s
pod/ingress-nginx-admission-patch-6nbjb         0/1     completed   1          8m21s
pod/ingress-nginx-controller-78f6c57f64-m89n8   1/1     running     0          8m31s

name                                         type        cluster-ip       external-ip   port(s)                      age
service/ingress-nginx-controller             nodeport    10.107.152.204   &lt;none&gt;        80:32367/tcp,443:31480/tcp   8m31s
service/ingress-nginx-controller-admission   clusterip   10.110.191.169   &lt;none&gt;        443/tcp                      8m31s

name                                       ready   up-to-date   available   age
deployment.apps/ingress-nginx-controller   1/1     1            1           8m31s

name                                                  desired   current   ready   age
replicaset.apps/ingress-nginx-controller-78f6c57f64   1         1         1       8m31s

name                                       completions   duration   age
job.batch/ingress-nginx-admission-create   1/1           2s         8m31s
job.batch/ingress-nginx-admission-patch    1/1           3s         8m31s

however, when trying to apply a custom ingress, i get the following error:
error from server (internalerror): error when creating &quot;yaml/xxx/xxx-ingress.yaml&quot;: internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: post https://ingress-nginx-controller-admission.ingress-nginx.svc:443/extensions/v1beta1/ingresses?timeout=30s: temporary redirect

any idea what could be wrong?
i suspected dns, but other nodeport services are working as expected and dns works within the cluster.
the only thing i can see is that i don't have a default-http-backend which is mentioned in the docs here. however, this seems normal in my case, according to this thread.
last but not least, i tried as well the installation with manifests (after removing ingress-nginx namespace from previous installation) and the installation via helm chart. it has the same result.
i'm pretty much a beginner on k8s and this is my playground-cluster. so i'm open to alternative solutions as well, as long as i don't need to set up the whole cluster from scratch.
update:
with &quot;applying custom ingress&quot;, i mean:
kubectl apply -f &lt;myingress.yaml&gt;
content of myingress.yaml
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - path: /someroute/fittingmyneeds
        pathtype: prefix
        backend:
          servicename: some-service
          serviceport: 5000

",<kubernetes><kubernetes-ingress><nginx-ingress><kubeadm>,69289313,6,"i am not sure if this helps this late, but might it be, that your cluster was behind proxy? because in that case you have to have no_proxy configured correctly. specifically, it has to include .svc,.cluster.local otherwise validation webhook requests such as https://ingress-nginx-controller-admission.ingress-nginx.svc:443/extensions/v1beta1/ingresses?timeout=30s will be routed via proxy server (note that .svc in the url).
i had exactly this issue and adding .svc into no_proxy variable helped. you can try this out quickly by modifying /etc/kubernetes/manifests/kube-apiserver.yaml file which will in turn automatically recreate your kubernetes api server pod.
this is not the case just for ingress validation, but also for other things that might refer url in your cluster ending with .svc or .namespace.svc.cluster.local (i.e. see this bug)
"
74120333,kubernetes clusterrole api resource to read log,"i made a service account that bound to clusterrole.
here is the clusterrole
apiversion: rbac.authorization.k8s.io/v1
kind: clusterrole
metadata:
  name: devops-tools-role
  namespace: devops-tools
rules:
  - apigroups:
        - &quot;&quot;
        - apps
        - autoscaling
        - batch
        - extensions
        - policy
        - rbac.authorization.k8s.io
        - networking.k8s.io
    resources:
      - pods
      - componentstatuses
      - configmaps
      - daemonsets
      - deployments
      - events
      - endpoints
      - horizontalpodautoscalers
      - ingress
      - ingresses
      - jobs
      - limitranges
      - namespaces
      - nodes
      - pods
      - persistentvolumes
      - persistentvolumeclaims
      - resourcequotas
      - replicasets
      - replicationcontrollers
      - serviceaccounts
      - services
    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]


i try to read logs from a pod
kubectl -n dfg02 logs postgres-69c7bb5cf7-dstzt

, and got :
error from server (forbidden): pods &quot;postgres-69c7bb5cf7-dstzt&quot; is forbidden: user &quot;system:serviceaccount:devops-tools:bino&quot; cannot get resource &quot;pods/log&quot; in api group &quot;&quot; in the namespace &quot;dfg02&quot;


so i switch to 'admin' account anda try to find which resource to add to the cluster role
 ✘ bino@corobalap  ~/gitjece  kubectl config use-context k0s-cluster          
switched to context &quot;k0s-cluster&quot;.
 bino@corobalap  ~/gitjece  kubectl api-resources |grep log

and got nothing.
my question is how to add 'logs read rights' to a clusterrole.
sincerely
-bino-
",<kubernetes><kubectl>,74121966,4,"logs are a sub-resource of pods and by just specifying pods in the resource sections isn't enough.
so simply add the following to your yaml then it should work.
resources:
  - pods
  - pods/log

ps: you've specified pods twice in your resources section, not that it does anything but just wanted to point it out.
"
63819126,expose kube-apiserver with additional ip address,"i setup a k8s cluster using kubeadm init on a bare metal cluster.
i noticed the kube-apiserver is exposing its interface on a private ip:
# kubectl get pods kube-apiserver-cluster1 -n kube-system -o wide
name                                        ready   status    restarts   age     ip           node                         nominated node   readiness gates
kube-apiserver-cluster1                     1/1     running   0          6d22h   10.11.1.99   cluster1   &lt;none&gt;           &lt;none&gt;

here's the kube config inside the cluster:
# kubectl config view
apiversion: v1
clusters:
- cluster:
    certificate-authority-data: data+omitted
    server: https://10.11.1.99:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: redacted
    client-key-data: redacted

this is fine for using kubectl locally on the cluster, but i want to add an additional interface to expose the kube-apiserver using the public ip address.  ultimately i'm trying to configure kubectl from a laptop to remotely access the cluster.
how can i expose the kube-apiserver on an external ip address?
",<kubernetes><kubectl><kubeadm><kubernetes-apiserver><kube-apiserver>,63830147,3,"execute following command:
$ kubeadm init --pod-network-cidr=&lt;ip-range&gt; --apiserver-advertise-address=0.0.0.0 --apiserver-cert-extra-sans=&lt;private_ip&gt;[,&lt;public_ip&gt;,...]

don't forget to replace the private ip for the public ip in your .kube/config if you use kubectl from remote.
you can also forward the private ip of the master node to the public ip of the master node on the worker node. run this command on worker node before running kubeadm join:
$ sudo iptables -t nat -a output -d &lt;private ip of master node&gt; -j dnat --to-destination &lt;public ip of master node&gt;.
but keep in mind that you'll also have to forward worker private ips the same way on the master node to make everything work correctly (if they suffer from the same issue of being covered by cloud provider nat).
see more: apiserver-ip,  kube-apiserver.
"
65936076,python pod can't connect to mongodb when using ingress,"it can connect fine whenever i try to access it via the worker node's address, but not when i try access via the ingress gateway. i get the following error:
pymongo.errors.serverselectiontimeouterror
pymongo.errors.serverselectiontimeouterror: mongo:27017: timed out, timeout: 30s, topology description: &lt;topologydescription id: 60119598e7c0e0d52f58c52c, topology_type: single, servers: [&lt;serverdescription ('mongo', 27017) server_type: unknown, rtt: none, error=networktimeout('mongo:27017: timed out',)&gt;]&gt;

this is how i connect to mongodb via python which works fine when not accessing over the ingress url.
mongo = mongoclient(&quot;mongodb://mongo:27017/user_data&quot;)

this is my ingress.yaml file
apiversion: networking.k8s.io/v1beta1
kind: ingress
metadata:
  name: weasel-ingress
spec:
  rules:
  - host: {host-address}
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          servicename: weasel
          serviceport: 5000
      - path: /
        pathtype: prefix
        backend:
          servicename: mongo
          serviceport: 27017

any idea's on how to get it to connect via ingress? i guess i need to add mongo to the ingress?
both services are already exposed via external ip's.
kubectl get svc
name         type           cluster-ip       external-ip      port(s)           age
kubernetes   clusterip      172.21.0.1       &lt;none&gt;           443/tcp           19h
mongo        loadbalancer   172.21.218.91    {exposed-ip}   27017:31308/tcp   17h
weasel       loadbalancer   172.21.152.134   {exposed-ip}   5000:32246/tcp    17h

ingress logs:
kubectl describe ingress weasel-ingress
name:             weasel-ingress
namespace:        default
address:          
default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)
rules:
  host                                                                                  path  backends
  ----                                                                                  ----  --------
  {host-address}  
                                                                                        /   weasel:5000 (172.30.27.69:5000)
                                                                                        /   mongo:27017 (&lt;none&gt;)
annotations:                                                                            &lt;none&gt;
events:
  type    reason  age   from                      message
  ----    ------  ----  ----                      -------
  normal  create  27s   nginx-ingress-controller  ingress default/weasel-ingress
  normal  create  27s   nginx-ingress-controller  ingress default/weasel-ingress
  normal  create  27s   nginx-ingress-controller  ingress default/weasel-ingress

",<python><mongodb><kubernetes><kubernetes-ingress>,65936787,1,"it was a problem with my deployment.yaml. it needed to be changed to the following:
apiversion: v1
kind: service
metadata:
  name: mongo
  labels:
    app: mongo
spec:
  type: loadbalancer
  ports:
  - port: 27017
    name: http
  selector:
    app: mongo
---
apiversion: apps/v1
kind: deployment
metadata:
  name: mongo
spec:
  replicas: 1
  selector:
    matchlabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
        version: v1
    spec:
      containers:
        - name: mongo
          image: mongo:latest
          ports:
          - containerport: 27017

"
69427309,"is ""service"" type kubernetes object a pod container?","service abstract pod ip address from consumers, load balances between pods, relies on labels to associate a service with a pod, holds virtual ip provided by node's kube-proxy, non-ephemeral
given below services:
$ kubectl -n mynamespace get services | more
name         type          cluster-ip        external-ip   port(s)                                          age
my-app1     nodeport   192.168.112.249   &lt;none&gt;            80:32082/tcp,2121:30581/tcp   50d
my-app2    nodeport   192.168.113.154   &lt;none&gt;             80:30704/tcp,2121:30822/tcp   50d
my-app3    nodeport   192.168.114.232   &lt;none&gt;            80:32541/tcp,2121:32733/tcp   5d2h
my-app4    nodeport   192.168.115.182    &lt;none&gt;             80:30231/tcp,2121:30992/tcp   5d2h


is &quot;service&quot; type kubernetes object launched as a separate pod container in data plane?
",<kubernetes><kubernetes-pod>,69427711,2,"
is &quot;service&quot; type kubernetes object launched as a separate pod container in data plane?

nope, a service is an abstract resource in kubernetes.
from the service documentation:

an abstract way to expose an application running on a set of pods as a network service.
with kubernetes you don't need to modify your application to use an unfamiliar service discovery mechanism. kubernetes gives pods their own ip addresses and a single dns name for a set of pods, and can load-balance across them.

"
73862248,how do i grant permission to my kubernetes cluster to pull images from gcr.io?,"in kubernetes container repository i have my permission set to private:

when i create a pod on my cluster i get the the pod status ending in imagepullbackoff and when i describe the pod i see:
failed to pull image &quot;gcr.io/redacted&quot;: rpc error: code = unknown desc = error response from daemon: pull access denied for gcr.io/redacted, repository does not exist or may require 'docker login': denied: permission denied for &quot;v11&quot; from request &quot;/v2/redacted/manifests/v11&quot;.

i am certainly logged in.
docker login
authenticating with existing credentials...
login succeeded

now if i enable public access (top image) on my container repository things work fine and the pod deploys correctly. but i don't want my repository to be public. what is the correct way to keep my container repository private and still be able to deploy. i'm pretty sure this used to work a couple weeks ago unless i messed up something with my service account although i don't know how to find out which service account is being used for these permissions.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,73872050,1,"if your gke version is &gt; 1.15, and the container registry is in the same project, and gke uses the default compute engine service account (sa) it should work out of the box.
if you are running the registry in another project, or using a different service account, you should give to the sa the right permissions (e.g., roles/artifactregistry.reader)
a step by step tutorial, with all the different cases, it is present in the official documentation: https://cloud.google.com/artifact-registry/docs/access-control#gcp
"
71409884,dockershim deprecation in kubernetes - dind on containerd,"currently we are using dind(we are not mounting docker.sock from host) on kuberenetes to build container images and also to run containers inside container for running unit tests. with dockershim deprecation in kubernetes, i am trying to analyze whether dind will still work on kubernetes without dockershim and with containerd runtime.
i tried running dind pod on gcp and aws eks with containerd container runtime with kubernetes 1.21 release. it worked without any issue in privileged mode. but i am confused how it can even work as dind is docker in docker and not docker in containerd. i did some research, but still cannot figure out how this works and whether it will work with kubernetes 1.24 release. can someone help?
i used below spec for testing on kubernetes with containerd runtime
apiversion: v1
kind: pod
metadata:
  creationtimestamp: null
  labels:
    run: dind
  name: dind
spec:
  containers:
  - image: docker:20.10.12-dind
    name: dind
    ports:
    - containerport: 2375
    securitycontext:
     privileged: true
    env:
    - name: docker_tls_certdir
      value: ''
  - name: client
    image: ubuntu:latest
    command:
    - sleep
    - infinity
    env:
    - name: docker_host
      value: tcp://localhost:2375

aws userguide regarding dockershim deprecation
",<docker><kubernetes><containers><amazon-eks>,73652556,1,"despite the name docker-in-docker it's actually docker-in-any-compatible-cri-runtime. this clause confirms it (source https://kubernetes.io/blog/2020/12/02/dockershim-faq/#will-my-existing-docker-images-still-work):

yes, the images produced from docker build will work with all cri implementations. all your existing images will still work exactly the same.

so if you aren't using /var/run/docker.sock you're good.
"
47516355,multi-broker kafka on kubernetes how to set kafka_advertised_host_name,"my current kafka deployment file with 3 kafka brokers looks like this:

apiversion: apps/v1beta1
kind: statefulset
metadata:
  name: kafka
spec:
  selector:
    matchlabels:
      app: kafka
  servicename: kafka-headless
  replicas: 3
  updatestrategy:
    type: rollingupdate
  podmanagementpolicy: parallel
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka-instance
        image: wurstmeister/kafka
        ports:
        - containerport: 9092
        env:
        - name: kafka_advertised_port
          value: ""9092""
        - name: kafka_advertised_host_name
          valuefrom:
              fieldref:
                fieldpath: metadata.name
        - name: kafka_zookeeper_connect
          value: ""zookeeper-0.zookeeper-headless.default.svc.cluster.local:2181,\
                  zookeeper-1.zookeeper-headless.default.svc.cluster.local:2181,\
                  zookeeper-2.zookeeper-headless.default.svc.cluster.local:2181""
        - name: broker_id_command
          value: ""hostname | awk -f '-' '{print $2}'""
        - name: kafka_create_topics
          value: hello:2:1
        volumemounts:
        - name: data
          mountpath: /var/lib/kafka/data
  volumeclaimtemplates:
  - metadata:
      name: data
    spec:
      accessmodes: [ ""readwriteonce"" ]
      resources:
        requests:
          storage: 50gi


this creates 3 kafka brokers as a stateful set and connects to the zookeeper cluster using the kubedns service with fqdn (fully qualified domain names) such as: 

zookeeper-0.zookeeper-headless.default.svc.cluster.local:2181


broker ids are generated based on the pod name:

- name: broker_id_command
          value: ""hostname | awk -f '-' '{print $2}'""


result:

kafka-0 = 0
kafka-1 = 1
kafka-2 = 2


however, in order to use the kubedns names for the kafka brokers:

kafka-0.kafka-headless.default.svc.cluster.local:9092
kafka-1.kafka-headless.default.svc.cluster.local:9092
kafka-2.kafka-headless.default.svc.cluster.local:9092


i need to be able to set the kafka_advertised_host_name variable to the above fqdn values based on the name of the pod.

currently i have the variable set to the name of the pod:

- name: kafka_advertised_host_name
   valuefrom:
      fieldref:
        fieldpath: metadata.name


result:

kafka_advertised_host_name=kafka-0
kafka_advertised_host_name=kafka-1
kafka_advertised_host_name=kafka-2


but somehow i would need to append the rest of the dns name.

is there a way i could set the dns value directly? 

something like that:

- name: kafka_advertised_host_name
       valuefrom:
          fieldref:
            fieldpath: kubedns.name

",<dns><kubernetes><yaml><kubectl><kube-dns>,47521828,5,"i managed to solve the problem with a command field inside the pod definition:

    command:
    - sh
    - -c
    - ""export kafka_advertised_host_name=$(hostname).kafka-headless.default.svc.cluster.local &amp;&amp;
       start-kafka.sh""


this runs a shell command which exports the advertised hostname environment variable based on the hostname value.
"
67745689,kubernetes lifecycle commands not running,"i have been trying to get prestop to run a script before the pod terminates (to prolong the termination until the current job has finished), but command doesn't seem to be executing the commands. i've temporarily added an echo command, which i would expect to see in kubectl logs for the pod, i can't see this either.
this is part of the (otherwise working) deployment spec:
      containers:
        - name: file-blast-app
          image:  my_image:stuff
          imagepullpolicy: always
          lifecycle:
            prestop:
              exec:
                command: [&quot;echo&quot;,&quot;pre stop!&quot;]

does anyone know why this would not be working and if i'm correct to expect the logs from hook in kubectl logs for the pod?
",<kubernetes><kubernetes-pod>,67745771,2,"you forgot to mention the shell through which you want this command to be executed.
try using the following in your yaml.
  containers:
    - name: file-blast-app
      image:  my_image:stuff
      imagepullpolicy: always
      lifecycle:
        prestop:
          exec:
            command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;echo pre stop!&quot;]

also, one thing to note is that a prestop hook only gets executed when a pod is terminated, and not when it is completed. you can read more on this here.
you can also refer to the k8s official documentation for lifecycle hooks here.
"
58613628,how do i list all pods that were not created by a controller,"i need to get a list of all pods that were not created by a controller so i can decide how to handle them before doing a drain on a node. 

otherwise i get the message: 

error: cannot delete pods not managed by replicationcontroller, replicaset, job, daemonset or statefulset (use --force to override) while running the drain.


i can find the information by running kubectl describe &lt;pod&gt; and looking to see if the controlled by: is missing but i want to programmatically search all pods on the node and since kubectl describe is not designed for that. i need to find an alternative method.
",<kubernetes><kubectl>,58613732,7,"you can relly on the ownerreferences api object to find this:


  $ kubectl explain pod.metadata.ownerreferences
  
  kind:     pod
  
  version: v1
  
  resource: ownerreferences &lt;[]object>
  
  description:
       list of objects depended by this object. if all objects in the list have
       been deleted, this object will be garbage collected. if this object is
       managed by a controller, then an entry in this list will point to this
       controller, with the controller field set to true. there cannot be more
       than one managing controller.


bare pods (i.e., pods without controllers/owners) will not contain the ownerreferences field, so you can use the --custom-columns to find out which pods are controlled or not:

$ kubectl get pods --all-namespaces -o custom-columns=name:.metadata.name,controller:.metadata.ownerreferences[].kind,namespace:.metadata.namespace
name                               controller   namespace
nginx-85ff79dd56-tvpts             replicaset   default
static-pod1                        &lt;none&gt;       default
static-pod2                        &lt;none&gt;       default
coredns-5644d7b6d9-6hg82           replicaset   kube-system
coredns-5644d7b6d9-wtph7           replicaset   kube-system
etcd-minikube                      &lt;none&gt;       kube-system
kube-addon-manager-minikube        &lt;none&gt;       kube-system
kube-apiserver-minikube            &lt;none&gt;       kube-system
kube-controller-manager-minikube   &lt;none&gt;       kube-system
kube-proxy-fff5c                   daemonset    kube-system
kube-scheduler-minikube            &lt;none&gt;       kube-system
storage-provisioner                &lt;none&gt;       kube-system
tiller-deploy-55c9c4b4df-hgzwm     replicaset   kube-system




if you want only the pod names that are not owned by a controller manager, you can process the output of kubectl get -o json with jq (very useful for post script processing):

$ kubectl get pods --all-namespaces -o json | jq -r '.items | map(select(.metadata.ownerreferences == null ) | .metadata.name) | .[]'
static-pod1
static-pod1
etcd-minikube
kube-addon-manager-minikube
kube-apiserver-minikube
kube-controller-manager-minikube
kube-scheduler-minikube
storage-provisioner

"
61963659,how can i add service annotation in istio operator patch,"i am installing istio 1.6.0 using istioctl with below config file:

--
apiversion: install.istio.io/v1alpha1
kind: istiooperator
spec:
  profile: default
  components:
    egressgateways:
      - name: istio-egressgateway
        enabled: true
    ingressgateways:
      - name: istio-ingressgateway
        enabled: true
        k8s:
          overlays:
          - kind: service
            name: istio-ingressgateway
            patches:
            - path: spec.loadbalancerip
              value: x.x.x.x
            - path: spec.externaltrafficpolicy
              value: local
            - path: metadata.annotations.[service.beta.kubernetes.io/azure-load-balancer-resource-group]
              value: az-rg-group


this part giving me an error:

- path: metadata.annotations.[service.beta.kubernetes.io/azure-load-balancer-resource-group]
  value: az-rg-group



  error: failed to apply manifests: errors occurred during operation


path is not correct for annotation. how can i provide a path of annotation with valid syntax?

following this sample code: https://github.com/istio/istio/blob/master/operator/samples/pilot-advanced-override.yaml
",<kubernetes><kubectl><istio>,61968467,3,"there is a new field for service annotations. the issue was raised here https://github.com/istio/istio/issues/20078
please refer the following example
ingressgateway_k8s_settings.yaml
apiversion: install.istio.io/v1alpha1
kind: istiooperator
spec:
  components:
    pilot:
      enabled: false
    ingressgateways:
    - namespace: istio-system
      name: istio-ingressgateway
      enabled: true
      k8s:
        service:
          externaltrafficpolicy: local
        serviceannotations:
          manifest-generate: &quot;testserviceannotation&quot;
        securitycontext:
          sysctls:
          - name: &quot;net.ipv4.ip_local_port_range&quot;
            value: &quot;80 65535&quot;

"
49241418,gke node pool custom machine type cli,"is it possible to use gcloud container cluster create to create a node pool for gke using custom machine types (https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type)?

instead of n1-standard-1/etc, i would like to create an instance with 4 vcpu and 8 gb memory (for example).

i know this is possible in the ui, but i want to wrap this gcloud command in a script.
",<kubernetes><google-cloud-platform><gcloud><google-kubernetes-engine>,49247182,8,"seems like you are trying to use custom machine types rather than standard machine types and want to use gcloud command for it like gcloud container cluster create.

this is actually supported by a beta gcloud command and you can create a cluster with custom machines by specifying the machine type as below


  --machine-type “custom-{cpus}-{mib-ram}”


for the example you have provided 4 vcpu and 8 gb memory, the command would be something like

gcloud beta container --project [project name] clusters create [cluster name] --zone [zone name] --username [username] --cluster-version ""1.8.7-gke.1"" --machine-type ""custom-4-8192"" ......

hope this helps.
"
58692713,extra secrets created when helm is used,"i created a helm chart which has secrets.yaml as:

apiversion: v1
kind: secret
type: opaque
metadata: 
 name: appdbpassword
stringdata:
  password: password@1


my pod is:

apiversion: v1
kind: pod
metadata:
  name: expense-pod-sample-1
spec:
  containers:
    - name: expense-container-sample-1
      image: exm:1
      command: [ ""/bin/sh"", ""-c"", ""--"" ]
      args: [ ""while true; do sleep 30; done;"" ]
      envfrom:
      - secretref:
              name: appdbpassword


whenever i run the kubectl get secrets command, i get the following secrets:

name                                     type                 data    age
appdbpassword                            opaque               1      41m
sh.helm.release.v1.myhelm-1572515128.v1  helm.sh/release.v1   1      41m


why am i getting that extra secret? am i missing something here?
",<kubernetes><kubernetes-helm><kubernetes-secrets>,58693790,24,"helm v2 used configmaps by default to store release information. the configmaps were created in the same namespace of the tiller (generally kube-system).
in helm v3 the tiller was removed, and the information about each release version had to go somewhere:

in helm 3, release information about a particular release is now
stored in the same namespace as the release itself.

furthermore, helm v3 uses secrets as default storage driver instead of configmaps (i.e., it's expected that you see these helm secrets for each namespace that has a release version on it).
"
59470624,does kubernetes kubectl run with image creates deployment yaml file,"i am trying to use minikube and docker to understand the concepts of kubernetes architecture.

i created a spring boot application with dockerfile, created tag and pushed to dockerhub.

in order to deploy the image in k8s cluster, i issued the below command,

# deployed the image
$ kubectl run &lt;deployment-name&gt; --image=&lt;username/imagename&gt;:&lt;version&gt; --port=&lt;port the app runs&gt;

# exposed the port as nodeport
$ kubectl expose deployment &lt;deployment-name&gt; --type=nodeport


everything worked and i am able to see the 1 pods running kubectl get pods

the docker image i pushed to dockerhub didn't had any deployment yaml file.

below command produced an yaml output

does kubectl command creates deployment yaml file out of the box?

 $ kubectl get deployments --output yaml 


apiversion: v1
items:
- apiversion: apps/v1
  kind: deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: ""1""
    creationtimestamp: ""2019-12-24t14:59:14z""
    generation: 1
    labels:
      run: hello-service
    name: hello-service
    namespace: default
    resourceversion: ""76195""
    selflink: /apis/apps/v1/namespaces/default/deployments/hello-service
    uid: 90950172-1c0b-4b9f-a339-b47569366f4e
  spec:
    progressdeadlineseconds: 600
    replicas: 1
    revisionhistorylimit: 10
    selector:
      matchlabels:
        run: hello-service
    strategy:
      rollingupdate:
        maxsurge: 25%
        maxunavailable: 25%
      type: rollingupdate
    template:
      metadata:
        creationtimestamp: null
        labels:
          run: hello-service
      spec:
        containers:
        - image: thirumurthi/hello-service:0.0.1
          imagepullpolicy: ifnotpresent
          name: hello-service
          ports:
          - containerport: 8800
            protocol: tcp
          resources: {}
          terminationmessagepath: /dev/termination-log
          terminationmessagepolicy: file
        dnspolicy: clusterfirst
        restartpolicy: always
        schedulername: default-scheduler
        securitycontext: {}
        terminationgraceperiodseconds: 30
  status:
    availablereplicas: 1
    conditions:
    - lasttransitiontime: ""2019-12-24t14:59:19z""
      lastupdatetime: ""2019-12-24t14:59:19z""
      message: deployment has minimum availability.
      reason: minimumreplicasavailable
      status: ""true""
      type: available
    - lasttransitiontime: ""2019-12-24t14:59:14z""
      lastupdatetime: ""2019-12-24t14:59:19z""
      message: replicaset ""hello-service-75d67cc857"" has successfully progressed.
      reason: newreplicasetavailable
      status: ""true""
      type: progressing
    observedgeneration: 1
    readyreplicas: 1
    replicas: 1
    updatedreplicas: 1
kind: list
metadata:
  resourceversion: """"
  selflink: """"

",<docker><kubernetes><kubectl>,59471803,2,"i think the easiest way to understand whats going on under the hood when you create kubernetes resources using imperative commands (versus declarative approach by writing and applying yaml definition files) is to run a simple example with 2 additional flags:

--dry-run


and

--output yaml


names of these flags are rather self-explanatory so i think there is no further need for comment explaining what they do. you can simply try out the below examples and you'll see the effect:

kubectl run nginx-example --image=nginx:latest --port=80 --dry-run --output yaml


as you can see it produces the appropriate yaml manifest without applying it and creating actual deployment:

apiversion: apps/v1beta1
kind: deployment
metadata:
  creationtimestamp: null
  labels:
    run: nginx-example
  name: nginx-example
spec:
  replicas: 1
  selector:
    matchlabels:
      run: nginx-example
  strategy: {}
  template:
    metadata:
      creationtimestamp: null
      labels:
        run: nginx-example
    spec:
      containers:
      - image: nginx:latest
        name: nginx-example
        ports:
        - containerport: 80
        resources: {}
status: {}


same with expose command:

kubectl expose deployment nginx-example --type=nodeport --dry-run --output yaml


produces the following output:

apiversion: v1
kind: service
metadata:
  creationtimestamp: null
  labels:
    run: nginx-example
  name: nginx-example
spec:
  ports:
  - port: 80
    protocol: tcp
    targetport: 80
  selector:
    run: nginx-example
  type: nodeport
status:
  loadbalancer: {}


and now the coolest part. you can use simple output redirection:

kubectl run nginx-example --image=nginx:latest --port=80 --dry-run --output yaml &gt; nginx-example-deployment.yaml

kubectl expose deployment nginx-example --type=nodeport --dry-run --output yaml &gt; nginx-example-nodeport-service.yaml


to save generated deployment and nodeport service definitions so you can further modify them if needed and apply using either kubectl apply -f filename.yaml or kubectl create -f filename.yaml.

btw. kubectl run and kubectl expose are generator-based commands and as you may have noticed when creating your deployment (as you probably got the message: kubectl run --generator=deployment/apps.v1beta1 is deprecated and will be removed in a future version. use kubectl create instead.) they use --generator flag. if you don't specify it explicitly it gets the default value which for kubectl run is --generator=deployment/apps.v1beta1 so by default it creates a deployment. but you can modify it by providing --generator=run-pod/v1 nginx-example and instead of deployment it will create a single pod. when we go back to our previous example it may look like this:

kubectl run --generator=run-pod/v1 nginx-example --image=nginx:latest --port=80 --dry-run --output yaml


i hope this answered your question and clarified a bit the mechanism of creating kubernetes resources using imperative commands.
"
75407718,connection refused when trying to load keycloak on the browser after deployed it on kubernetes successfully,"i just follow the keycloak documentation for kubernetes.
https://www.keycloak.org/getting-started/getting-started-kube

but after deployed it like exactly how they are saying in the documentation.
when i try to load the keyclaok page, i'm getting this,

if you can give me a solution or explain why this is happening, really appreciate it!
my ingress config (keycloak-ingress.yaml) is,
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: keycloak
spec:
  tls:
    - hosts:
      - keycloak.192.168.49.2.nip.io
  rules:
  - host: keycloak.192.168.49.2.nip.io
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: keycloak
            port:
              number: 8080

",<kubernetes><keycloak><kubectl>,75407849,1,"make sure you have updated the ingress file with the proper ip of minikube.
also check with http instead https &amp; keycloak_hostname value
try below yaml :
apiversion: v1
kind: service
metadata:
  name: keycloak
  labels:
    app: keycloak
spec:
  ports:
  - name: http
    port: 8080
    targetport: 8080
  selector:
    app: keycloak
  type: loadbalancer
---
apiversion: apps/v1
kind: deployment
metadata:
  name: keycloak
  labels:
    app: keycloak
spec:
  replicas: 1
  selector:
    matchlabels:
      app: keycloak
  template:
    metadata:
      labels:
        app: keycloak
    spec:
      containers:
      - name: keycloak
        image: quay.io/keycloak/keycloak:20.0.3
        args: [&quot;start-dev&quot;]
        env:
        - name: keycloak_admin
          value: &quot;admin&quot;
        - name: keycloak_admin_password
          value: &quot;admin&quot;
        - name: kc_proxy
          value: &quot;edge&quot;
        ports:
        - name: http
          containerport: 8080
        readinessprobe:
          httpget:
            path: /realms/master
            port: 8080

it will creat the lb service for you so you will be able to access it without ingress config. run kubectl get svc -n &lt;namespace-name&gt; and check external ip and try opening that in browser.
extra :
you can refer to this yaml if the default one is not working. i am using postgres &amp; dpeloying the keycloak with that.
github repo path : https://github.com/harsh4870/keycloack-postgres-kubernetes-deployment
ref : https://faun.pub/keycloak-kubernetes-deployment-409d6ccd8a39
"
52594976,data is empty when accessing config file in k8s configmap with helm,"i am trying to use a configmap in my deployment with helm charts. now seems like files can be accessed with helm according to the docs here: https://github.com/helm/helm/blob/master/docs/chart_template_guide/accessing_files.md

this is my deployment:

kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: ""{{ template ""service.fullname"" . }}""
  labels:        
    chart: ""{{ .chart.name }}-{{ .chart.version }}""
spec:
  replicas: {{ .values.replicacount }}
  template:
    metadata:
      labels:
        app: ""{{ template ""service.fullname"" . }}""
    spec:
      containers:
      - name: ""{{ .chart.name }}""
        image: ""{{ .values.registryhost }}/{{ .values.usernamespace }}/{{ .values.projectname }}/{{ .values.servicename }}:{{.chart.version}}""
        volumemounts:
        - name: {{ .values.configmapname}}configmap-volume
          mountpath: /app/config
        ports:
        - containerport: 80
          name: http            
        livenessprobe:
          httpget:
            path: /health
            port: http
          initialdelayseconds: 10
          timeoutseconds: 5
        readinessprobe:
          httpget:
            path: /health
            port: http
          initialdelayseconds: 10
          timeoutseconds: 5            
      volumes:
        - name: {{ .values.configmapname}}configmap-volume
          configmap:            
            name: ""{{ .values.configmapname}}-configmap""


my configmap is accessing a config file. here's the configmap:

apiversion: v1
kind: configmap
metadata:
  name: ""{{ .values.configmapname}}-configmap""
  labels:
    app: ""{{ .values.configmapname}}""
data:
  {{ .files.get ""files/{{ .values.configmapname}}-config.json"" | indent 2}}


the charts directory looks like this:

files/
--runtime-config.json
templates/
--configmap.yaml
--deployment.yaml
--ingress.yaml
--service.yaml
chart.value
vaues.yaml


and this is how my runtime-confi.json file looks like:

{
    ""gamemodeconfiguration"": {
        ""command"": ""xx"",
        ""modeid"": 10,
        ""sessionid"": 11            
    }
}


the problem is, when i install my chart (even with a dry-run mode), the data for my configmap is empty. it doesn't add the data from the config file into my configmap declaration. this is how it looks like when i do a dry-run:

---
apiversion: v1
kind: configmap
metadata:
  name: ""runtime-configmap""
  labels:
    app: ""runtime""
data:
---

kind: deployment
apiversion: extensions/v1beta1
metadata:
  name: ""whimsical-otter-runtime-service""
  labels:        
    chart: ""runtime-service-unknown/version""
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: ""whimsical-otter-runtime-service""
    spec:
      containers:
      - name: ""runtime-service""
        image: ""gcr.io/xxx-dev/xxx/runtime_service:unknown/version""
        volumemounts:
        - name: runtimeconfigmap-volume
          mountpath: /app/config
        ports:
        - containerport: 80
          name: http
        resources:
          limits:
            cpu: 100m
            memory: 100mi
          requests:
            cpu: 100m
            memory: 100mi

        livenessprobe:
          httpget:
            path: /health
            port: http
          initialdelayseconds: 10
          timeoutseconds: 5
        readinessprobe:
          httpget:
            path: /health
            port: http
          initialdelayseconds: 10
          timeoutseconds: 5

      volumes:
        - name: runtimeconfigmap-volume
          configmap:            
            name: ""runtime-configmap""
---


what am i doing wrong that i don't get data?
",<kubernetes><kubernetes-helm><configmap>,52595455,5,"the replacement of the variable within the string does not work: 

{{ .files.get ""files/{{ .values.configmapname}}-config.json"" | indent 2}}


but you can gerenate a string using the printf function like this: 

{{ .files.get (printf ""files/%s-config.json"" .values.configmapname) | indent 2 }}

"
67119864,why can't copy a file from pod to my local,"i know this question asked before and i checked them but still fails.
pod name : postgresl-7c8b9-qs67z
file in the pod : /home/backup/db
so i want to try to copy &quot;db&quot; file to my local and i tried to commands below, but all of them giving the same error.
 kubectl cp default/postgresl-7c8b9-qs67z:/home/backup/db c:\users\myuser\desktop\mydb1.dmp

 kubectl cp default/postgresl-7c8b9-qs67z:/home/backup/ c:\users\myuser\desktop\

 kubectl cp postgresl-7c8b9-qs67z:/home/backup/db c:\users\myuser\desktop\mydb1.dmp

and the error is :
error: one of src or dest must be a local file specification

how can i do that? thanks!
",<azure><kubernetes><kubectl>,67120196,24,"currently there seems to be a bug in kubectl where c: is treaten as the pod name.
just use a relative path for your local file. e.g:
kubectl cp default/postgresl-7c8b9-qs67z:/home/backup/db ./desktop/mydb1.dmp

additional hint:
if you receive a tar: removing leading '/' from member names, check if the file was downloaded anyhow.
"
75098753,"gitlab ci/cd pipeline passed, but no changes were applied to the server","i am testing automation by applying gitlab ci/cd to a gke cluster. the app is successfully deployed, but the source code changes are not applied (eg renaming the html title).
i have confirmed that the code has been changed in the gitlab repository master branch. no other branch.
ci/cd simply goes through the process below.

push code to master branch
builds the nextjs code
builds the docker image and pushes it to gcr
pulls the docker image and deploys it in.

the content of the menifest file is as follows.
.gitlab-ci.yml
stages:
  - build-push
  - deploy

image: docker:19.03.12
variables:
  gcp_project_id: project_id..
  gke_cluster_name: cicd-micro-cluster
  gke_cluster_zone: asia-northeast1-b
  docker_host: tcp://docker:2375/
  docker_tls_certdir: &quot;&quot;
  registry_hostname: gcr.io/${gcp_project_id}
  docker_image_name: ${ci_project_name}
  docker_image_tag: latest
services:
  - docker:19.03.12-dind

build-push:
 stage: build-push
 before_script:
   - docker info
   - echo &quot;$gke_access_key&quot; &gt; key.json
   - docker login -u _json_key --password-stdin https://gcr.io &lt; key.json
 script:
   - docker build --tag $registry_hostname/$docker_image_name:$docker_image_tag .
   - docker push $registry_hostname/$docker_image_name:$docker_image_tag

deploy:
  stage: deploy
  image: google/cloud-sdk
  script:
    - export use_gke_gcloud_auth_plugin=true
    - echo &quot;$gke_access_key&quot; &gt; key.json
    - gcloud auth activate-service-account --key-file=key.json
    - gcloud config set project $gcp_project_id
    - gcloud config set container/cluster $gke_cluster_name
    - gcloud config set compute/zone $gke_cluster_zone
    - gcloud container clusters get-credentials $gke_cluster_name --zone $gke_cluster_zone --project $gcp_project_id
    - kubectl apply -f deployment.yaml
    - gcloud container images list-tags gcr.io/$gcp_project_id/${ci_project_name} --filter='-tags:*' --format=&quot;get(digest)&quot; --limit=10 &gt; tags &amp;&amp; while read p; do gcloud container images delete &quot;gcr.io/$gcp_project_id/${ci_project_name}@$p&quot; --quiet; done &lt; tags

dockerfile
# install dependencies only when needed
from node:16-alpine as deps
# check https://github.com/nodejs/docker-node/tree/b4117f9333da4138b03a546ec926ef50a31506c3#nodealpine to understand why libc6-compat might be needed.
run apk add --no-cache libc6-compat
workdir /app

# install dependencies based on the preferred package manager
copy package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./
run \
  if [ -f yarn.lock ]; then yarn --frozen-lockfile; \
  elif [ -f package-lock.json ]; then npm ci; \
  elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm &amp;&amp; pnpm i --frozen-lockfile; \
  else echo &quot;lockfile not found.&quot; &amp;&amp; exit 1; \
  fi


# rebuild the source code only when needed
from node:16-alpine as builder
workdir /app
copy --from=deps /app/node_modules ./node_modules
copy . .

# next.js collects completely anonymous telemetry data about general usage.
# learn more here: https://nextjs.org/telemetry
# uncomment the following line in case you want to disable telemetry during the build.
# env next_telemetry_disabled 1

run yarn build

# if using npm comment out above and use below instead
# run npm run build

# production image, copy all the files and run next
from node:16-alpine as runner
workdir /app

env node_env production
# uncomment the following line in case you want to disable telemetry during runtime.
# env next_telemetry_disabled 1

run addgroup --system --gid 1001 nodejs
run adduser --system --uid 1001 nextjs

copy --from=builder /app/public ./public

# automatically leverage output traces to reduce image size
# https://nextjs.org/docs/advanced-features/output-file-tracing
copy --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
copy --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

user nextjs

expose 3000

env port 3000

cmd [&quot;node&quot;, &quot;server.js&quot;]

deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: frontweb-lesson-prod
  labels:
    app: frontweb-lesson
spec:
  selector:
    matchlabels:
      app: frontweb-lesson
  template:
    metadata:
      labels:
        app: frontweb-lesson
    spec:
      containers:
      - name: frontweb-lesson-prod-app
        image: gcr.io/project_id../repository_name..:latest
        ports:
        - containerport: 3000
        resources:
          requests:
            cpu: 200m
---
apiversion: v1
kind: service
metadata:
  name: frontweb-lesson-prod-svc
  labels:
    app: frontweb-lesson
spec:
  selector:
    app: frontweb-lesson
  ports:
  - name: http
    port: 80
    protocol: tcp
    targetport: 3000
  type: loadbalancer
  loadbalancerip: &quot;external_ip..&quot;

is there something i'm missing?
",<kubernetes><gitlab><gitlab-ci><google-kubernetes-engine><cicd>,75100846,1,"by default,imagepullpolicy will be always but there could be chances if there is no change in the deployment file when applying it might not update the deployment. as you are using the same label each time latest.
as there different between kubectl apply and kubectl patch command
what you can do is add minor label change or annotation change in deployment and check image will get updated with kubectl apply command too otherwise it will be mostly unchange response of kubectl apply
ref : imagepullpolicy

you should avoid using the :latest tag when deploying containers in
production as it is harder to track which version of the image is
running and more difficult to roll back properly.

"
55650540,how to search by arbitrary fields using field selector with kubectl?,"in this doc supported fields are not listed and i cannot find them properly. with some trial and experiments i noticed the following: 

this works nicely and finds some pods:

kubectl get pods --field-selector=spec.restartpolicy=never


but this produces error:

kubectl get pods --field-selector=spec.serviceaccount=default

no resources found.
error from server (badrequest): unable to find {"""" ""v1"" ""pods""} that match label selector """", field selector ""spec.serviceaccount=default"": field label not supported: spec.serviceaccount


so how is this decided? i know i can find with jsonpath but it is client-side filtering afaik. 
",<linux><shell><docker><kubernetes><kubectl>,55651869,5,"you can select the serviceaccount using following query:

kubectl get pods --field-selector=spec.serviceaccountname=""default""


the --field-selector currently selects only equality based values and in that too it has very limited support to select the pod based on fields. the following fields are supported by --field-selector:

metadata.name
metadata.namespace
spec.nodename
spec.restartpolicy
spec.schedulername
spec.serviceaccountname
status.phase
status.podip
status.nominatednodename


as you already know, you need to rely on the jsonpath to select any other field other than above fields.

you can visit following link to find out more:


  https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/core/v1/conversion.go#l160-l167]1

"
59274519,kubernetes health check look for string,"i have a container that has a ping endpoint (returns pong) and i want to probe the ping endpoint and see if i get a pong back. if it was just to check 200 , i could have added a liveliness check in my pod like this ->

livenessprobe:
  initialdelayseconds: 2
  periodseconds: 5
  httpget:
    path: /ping
    port: 9876 


how do i modify this to check  to see if i get a pong response back? 
",<kubernetes><amazon-eks>,59274772,8,"as the http probe only checks the status code of the response, you need to use the exec probe to run a command on the container. something like this, which requires curl being installed on the container:

livenessprobe:
  initialdelayseconds: 2
  periodseconds: 5
  exec:
    command:
    - sh
    - -c
    - curl -s http://localhost:9876/ping | grep pong

"
65952021,how does pvc on kubernetes work with mysql?,"i am an computer enginering student. in my freetime i am working an a k8s project.
i was wondering how pvc works, i understand the basic concept. but here is my question.
so this is the code for a basic wordpress with mysql application.
i was wondering if i want to make multiple instaces of this application, do i need to change the mountpath? or is the mountpath the location within the container.
apiversion: v1
kind: service
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  ports:
    - port: 3306
  selector:
    app: wordpress
    tier: mysql
  clusterip: none
---
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: mysql-pv-claim
  labels:
    app: wordpress
spec:
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 20gi
---
apiversion: apps/v1
kind: deployment
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  selector:
    matchlabels:
      app: wordpress
      tier: mysql
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
        - name: mysql_root_password
          valuefrom:
            secretkeyref:
              name: mysql-pass
              key: password
        ports:
        - containerport: 3306
          name: mysql
        volumemounts:
        - name: mysql-persistent-storage
          mountpath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentvolumeclaim:
          claimname: mysql-pv-claim

",<mysql><kubernetes><kubernetes-pvc>,65952518,3,"if you really want to run different instance you would really love to create different data directory for them. it's never good idea to use deployment in this scenario. it's better if you use statefulset to manage database. statefulset will automatically generate different pvc for different pods.  you can check that with kubectl get pvc. here, in statefulset volumeclaimtemplates is the template for pvc.
pvc name will be like that &lt;pvc_template_name&gt;-&lt;statefulset_name&gt;-&lt;podnumber&gt;.
eg: mysql-pv-claim-wordpress-mysql-0

apiversion: v1
kind: service
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  ports:
    - port: 3306
  selector:
    app: wordpress
    tier: mysql
  clusterip: none

---
apiversion: apps/v1
kind: statefulset
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  servicename: wordpress-mysql
  replicas: 1
  selector:
    matchlabels:
      app: wordpress
      tier: mysql

  template:
    metadata:
      labels:
        app: wordpress
        tier: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
        - name: mysql_root_password
          valuefrom:
            secretkeyref:
              name: mysql-pass
              key: password
        ports:
        - containerport: 3306
          name: mysql
        volumemounts:
        - name: mysql-pv-claim
          mountpath: /var/lib/mysql
  volumeclaimtemplates:
  - metadata:
      name: mysql-pv-claim
    spec:
      accessmodes: [ &quot;readwriteonce&quot; ]
      storageclassname: standard
      resources:
        requests:
          storage: 20gi

"
56700699,how to write a custom ingressgateway in istio?,"i'm new to istio, i have a simple test yaml file which is a little long. what i want to do is to write a custom ingressgateway service for my gateway. and after testing, the incorrect part is the definition of ingressgateway which is at the top. the entire yaml is below:

apiversion: v1
kind: service
metadata:
  name: batman-ingressgateway
  labels:
    app: batman-ingressgateway
spec:
  type: loadbalancer
  selector:
    app: batman-ingressgateway
  ports:
  - port: 80
    targetport: 80
    nodeport: 31389
    name: http
---
apiversion: networking.istio.io/v1alpha3
kind: gateway
metadata:
  name: batman-gateway
spec:
  selector:
    app: batman-ingressgateway
      #istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - ""*""
---
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: batman
spec:
  hosts:
  - ""*""
  gateways:
  - batman-gateway
  http:
    - match:
      route:
      - destination:
          host: batman
          port:
            number: 8000
          subset: v1
        weight: 80
      - destination:
          host: batman
          port:
            number: 8000
          subset: v2
        weight: 20
---
apiversion: networking.istio.io/v1alpha3
kind: destinationrule
metadata:
  name: batman-destination
spec:
  host: batman
  subsets:
  - name: v1
    labels:
      version: v1
      run: batman
  - name: v2
    labels:
      version: v2
      run: batman


i want to access my app from browser with the address like: http://my_host_ip:31389/article. the problem now is the ingressgateway doesn't route traffic to my gateway. is there any one can help me? 
thanks.
",<kubernetes><kubernetes-ingress><istio>,56821177,2,"documentation on istio gateway routing is here  https://istio.io/docs/tasks/traffic-management/ingress/ingress-control/.
if you look at gateway spec they have
selector:
    istio: ingressgateway # use istio default gateway implementation

while you have
selector:
    app: batman-ingressgateway
      #istio: ingressgateway

for virtualservice definition you can look here https://istio.io/docs/reference/config/networking/v1alpha3/virtual-service/
you can try with routing requests to /article to your service
apiversion: networking.istio.io/v1alpha3
kind: virtualservice
metadata:
  name: article-route
spec:
  hosts:
  - *
  http:
  - match:
    - uri:
        prefix: &quot;/article&quot;
    route:
    - destination:
        host: &lt;name of your service&gt;

"
33293265,execute command into kubernetes pod as other user,"docker allows execution of commands as other user with docker exec -u, when user something in used in dockerfile.
it is helpful to enter into superuser mode to debug issues, when you are running you cmd as system user in dockerfile.

how to execute commands on kubernetes as other user?

my kubectl version output is

client version: version.info{major:""1"", minor:""0"", gitversion:""v1.0.6"", gitcommit:""388061f00f0d9e4d641f9ed4971c775e1654579d"", gittreestate:""clean""}
server version: version.info{major:""1"", minor:""0"", gitversion:""v1.0.6"", gitcommit:""388061f00f0d9e4d641f9ed4971c775e1654579d"", gittreestate:""clean""}

",<kubernetes><google-kubernetes-engine>,33298062,7,"you can check the spec schema to see what you can add in a pod or replication controller or whatever: https://cloud.google.com/container-engine/docs/spec-schema

you have runasuser for what you want:

apiversion: v1
kind: pod
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerport: 80
    securitycontext:
      runasuser: 41

"
56170284,unable to run a lifecycle command from config.yaml while deploying jupyterhub,"i want to run a command as soon as a pod is created and starts running. i am deploying jupyterhub but the config that i am using is:

proxy:
  secrettoken: ""yada yada""
singleuser:
  image:
    # get the latest image tag at:
    # https://hub.docker.com/r/jupyter/datascience-notebook/tags/
    # inspect the dockerfile at:
    # https://github.com/jupyter/docker-stacks/tree/master/datascience-notebook/dockerfile
    name: jupyter/datascience-notebook
    # name: ${image}
    tag: 177037d09156
    # tag: latest
  lifecycle:
    poststart:
      exec:
        command: [""/bin/sh"", ""-c"", ""echo hello from the poststart handler &gt; /usr/share/message""]


when the pod is up and running, i am not able to see the file /usr/share/message and hence, i deduce that the exec command is not running.

what is the right way to make this command work?
",<docker><kubernetes><jupyter-notebook><jupyter><kubernetes-helm>,56172120,2,"the correct key for lifecycle stanza is lifecylehooks.

following blob is with the correct values. 

proxy:
  secrettoken: ""yada yada""
singleuser:
  image:
    # get the latest image tag at:
    # https://hub.docker.com/r/jupyter/datascience-notebook/tags/
    # inspect the dockerfile at:
    # https://github.com/jupyter/docker-stacks/tree/master/datascience-notebook/dockerfile
    name: jupyter/datascience-notebook
    # name: ${image}
    tag: 177037d09156
    # tag: latest
  lifecyclehooks:
    poststart:
      exec:
        command: [""/bin/sh"", ""-c"", ""echo hello from the poststart handler &gt; /usr/share/message""]

"
64331201,what's the correct way of creating a configmap from a file using a yaml syntax?,"i can create a configmap without issues with kubectl create configmap settings --from-file settings.yaml, but i don't want to manually create it but as part of a helm install.
so, i created a template file:
apiversion: v1
kind: configmap
metadata:
  name: {{ .values.settingsconfigmap }}
data:
  settings.yaml: |-
{{ .files.get &quot;settings.yaml&quot; | indent 4}}

but whenever i run helm install i get an error saying that

invalid type for io.k8s.api.core.v1.configmap.data: got &quot;map&quot;,
expected &quot;string&quot;

so, what can i do to create this configmap with helm loading the content from a yaml file?
update
it turns out the error mentioned above is related to some issues with the indentation. by removing the indent 4, i managed to get a step further, but now it's failing because all my settings are detected as unknown fields, for example:

unknown field &quot;customers&quot; in io.k8s.api.core.v1.configmap, validationerror(configmap): unknown field &quot;deploy_name&quot; in io.k8s.api.core.v1.configmap, validationerror(configmap): unknown field &quot;system&quot; in io.k8s.api.core.v1.configmap

deploy_name, system and customers are the top level keys of my settings.yaml file.
",<kubernetes><kubernetes-helm>,64333554,2,"i found the answer.
the error mentioned in the update is the outcome of removing indent 4. by removing that, the yaml used by helm is screwed up, hence that's why it doesn't understand those fields.
so, why did it fail when i had the indent 4? the reason is the missing white space before the }. with {{ .files.get &quot;settings.yaml&quot; | indent 4 }}, everything is good.
"
51613842,wildcard ssl certificate with subdomain redirect in kubernetes,"i've configured my kubernetes to use one wildcard ssl certificate to all my apps using cert-manager and letsencrypt, now the problem is that i can't configure subdomain redirects cause ingress is kinda ""stiff"". here's how i'm trying to achieve this:

apiversion: extensions/v1beta1
kind: ingress
metadata:
name: my-wildcard-ingress
  namespace: mynamespace
  annotations:
    kubernetes.io/ingress.class: nginx
    certmanager.k8s.io/cluster-issuer: letsencrypt-prod
    certmanager.k8s.io/acme-challenge-type: dns01
    certmanager.k8s.io/acme-dns01-provider: azuredns
    ingress.kubernetes.io/force-ssl-redirect: ""true""
    ingress.kubernetes.io/ssl-redirect: ""true""
spec:
  rules:
  - host: ""domain.com""
    http:
      paths:
      - path: /
        backend:
          servicename: some-service
          serviceport: 3000          
  - host: somesub.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: some-other-service
          serviceport: 80
  - host: othersub.domain.com
    http:
      paths:
      - path: /
        backend:
          servicename: one-more-service
          serviceport: 8080          
  - host: ""*.domain.com""
    http:
      paths:
      - path: /
        backend:
          servicename: default-service-to-all-other-non-mapped-subdomains
          serviceport: 8000          

  tls:
  - secretname: domain-com-tls
    hosts:         
     - ""*.domain.com.br""


the problem is that ingress ignores the declared subdomain redirects just because they're not listed in the ""tls:hosts"" section. and if i do put them there, it tries to issue the ssl certificate using the wildcard and the other subdomains as well in the same cert, which causes the issuer to refuse the order, saying the obvious: ""subdomain.domain.com and *.domain.com are redundant""

is there any other way that i can declare those redirects and force them to use my ssl wildcard certificate?
",<kubernetes><lets-encrypt><wildcard-subdomain><kubernetes-ingress><cert-manager>,52116111,11,"well, for anyone who's having this kind of trouble, i've managed to solve it (not the best solution, but it's a start). for this, i'll be using cert-manager and letsencrypt.

first, i've created a clusterissuer to issue for my certs with letsencrypt:

apiversion: certmanager.k8s.io/v1alpha1
kind: clusterissuer
metadata:      
  name: letsencrypt-prod-dns
spec:
  acme:
    dns01:
      providers:
      - azuredns:
          clientid: my_azure_client_id
          clientsecretsecretref:
            key: client-secret
            name: azure-secret
          hostedzonename: mydomain.com
          resourcegroupname: my_azure_resource_group_name
          subscriptionid: my_azure_subscription_id
          tenantid: my_azure_tenant_id
        name: azuredns
    email: somemail@mydomain.com
    privatekeysecretref:
      key: """"
      name: letsencrypt-prod-dns
    server: https://acme-v02.api.letsencrypt.org/directory


then i've created a fallback ingress to all my subdomains (this one will be the cert generator):

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    certmanager.k8s.io/acme-challenge-type: dns01
    certmanager.k8s.io/acme-dns01-provider: azuredns
    certmanager.k8s.io/cluster-issuer: letsencrypt-prod-dns
    ingress.kubernetes.io/force-ssl-redirect: ""true""
    ingress.kubernetes.io/ssl-redirect: ""true""    
    kubernetes.io/ingress.class: nginx    
  name: wildcard-ingress
  namespace: some-namespace  
spec:
  rules:
  - host: '*.mydomain.com'
    http:
      paths:
      - backend:
          servicename: some-default-service
          serviceport: 80
        path: /      
  tls:
  - hosts:
    - '*.mydomain.com'
    - mydomain.com
    secretname: wildcard-mydomain-com-tls


notice that i've declared at the tls section the wildcard and the absolute paths, so the cert will be valid for the urls without subdomains too.

at this point, any requests to your domain, will be redirected to ""some-default-service"" with ssl(cert-manager will issue for a new cert as soon as you create the fallback ingress. this can take a while once cert-manager dns01 issuer is not mature yet), great!!! 

but, what if you need to redirect some specific subdomain to another service? no problem (since they're running on the same namespace), all you have to do is to create a new ingress to your subdomain, pointing it to your existing wildcard-mydomain-com-tls cert secret:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    ingress.kubernetes.io/force-ssl-redirect: ""false""
    ingress.kubernetes.io/ssl-redirect: ""true""
    kubernetes.io/ingress.class: nginx
  name: somesubdomain-ingress
  namespace: some-namespace
spec:
  rules:
  - host: somesubdomain.mydomain.com
    http:
      paths:
      - backend:
          servicename: some-other-service
          serviceport: 8080
        path: /        
  tls:
  - hosts:
    - somesubdomain.mydomain.com
    secretname: wildcard-mydomain-com-tls


easy peasy lemon squeezy!!! now your somesubdomain.mydomain.com overrides your fallback rule and sends the user to another app. the only thing you should notice here is that the secret is valid only for ""some-namespace"" namespace, if you need to use this cert in another namespace, you could:


copy the secret from namespace ""some-namespace"" to ""other-namespace"". if you do this, remember that cert-manager will not renew this cert automatically for ""other-namespace"", so, you'd have to copy the secret again, every time your cert expires.
recreate the fallback ingress to every namespace you have, so you'd have a new cert for each of them. this approach is more ingress verbose, but, it's fully automatic.


i guess that's it. hope someone out there can benefit from this info.

cheers
"
58760572,"kubernetes service account created with terraform causes 'doc is missing path: ""/spec/volumes/0""' error for replica set","i'm trying to create a kubernetes deployment with an associated serviceaccount, which is linked to an aws iam role. this yaml produces the desired result and the associated deployment (included at the bottom) spins up correctly:

apiversion: v1
kind: serviceaccount
metadata:
  name: service-account
  namespace: example
  annotations:
    eks.amazonaws.com/role-arn: role_arn


however, i would like to instead use the terraform kubernetes provider to create the serviceaccount:

resource ""kubernetes_service_account"" ""this"" {
  metadata {
    name = ""service-account2""
    namespace = ""example""
    annotations = {
      ""eks.amazonaws.com/role-arn"" = ""role_arn""
    }
  }
}


unfortunately, when i create the serviceaccount this way, the replicaset for my deployment fails with the error:

error creating: internal error occurred: internal error occurred: jsonpatch add operation does not apply: doc is missing path: ""/spec/volumes/0""


i have confirmed that it does not matter whether the deployment is created via terraform or kubectl; it will not work with the terraform-created service-account2, but works fine with the kubectl-created service-account. switching a deployment back and forth between service-account and service-account2 correspondingly makes it work or not work as you might expect.

i have also determined that the eks.amazonaws.com/role-arn is related; creating/assigning serviceaccounts that do not try to link back to an iam role work regardless of whether they were created via terraform or kubectl.

using kubectl to describe the deployment, replicaset, serviceaccount, and associated secret, i don't see any obvious differences, though i will admit i'm not entirely sure what i might be looking for.

here is a simple deployment yaml that exhibits the problem:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: example
  namespace: example
spec:
  strategy:
    type: recreate
  template:
    metadata:
      labels:
        app: example
    spec:
      serviceaccountname: service-account # or ""service-account2""
      containers:
      - name: nginx
        image: nginx:1.7.8

",<amazon-web-services><kubernetes><terraform><amazon-eks>,58806366,11,"adding automountserviceaccounttoken: true to the pod spec in your deployment should fix this error.  this is usually enabled by default on service accounts, but terraform defaults it to off.  see this issue on the mutating web hook that adds the required environment variables to your pods: https://github.com/aws/amazon-eks-pod-identity-webhook/issues/17
"
68462055,curl doesn't save the cookie inside a k8s cronjob,"i want to create a cronjob that interacts with my api.
first, i need to send a request to authentificate, then send a get request
here is the yaml of my cronjob:
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: verification-pointage
  namespace: isi-incubator
spec:
  schedule: &quot;*/1 * * * *&quot;
  jobtemplate:
    spec:
      template:
        spec:
          containers:
            - name: verification-pointage
              image: curlimages/curl:7.77.0
              imagepullpolicy: ifnotpresent
              command: [&quot;/bin/sh&quot;,&quot;-c&quot;]
              args: [&quot;curl -c session -h \&quot;content-type:application/json\&quot; -d '{\&quot;username\&quot;:\&quot;johndoe\&quot;,\&quot;password\&quot;:\&quot;johndoe123\&quot;}' http://odoo-api/authentication  &amp;&amp; curl -b session http://odoo-api/timesheets/verification&quot;]
          restartpolicy: onfailure

when i do the two curl commands in local, i have no problem, but when the commands are executed in the cronjob, the session doesn't seem to have been created. so the second command cannot use the cookie stored in the session file.
",<curl><kubernetes><kubernetes-cronjob>,68463032,1,"ok, so i change the path to the cookie file from session to tmp/session and it works
"
55852194,nginx-ingress controller for azure kubernetes service 502 bad gateway,"i'm having trouble getting an nginx-ingress controller to work on an azure kubernetes service; it's currently returning 502 bad gateway each time i try to hit some web apis exposed as services.
because i must use an existing certificate, i followed https://learn.microsoft.com/en-us/azure/aks/ingress-own-tls to set up the controller and have followed https://www.markbrilman.nl/2011/08/howto-convert-a-pfx-to-a-seperate-key-crt-file/ to generate a cert and key from a pfx (how the certificate was exported from an azure key vault). i created the secret ""aks-ingress-tls"" using the certificate including the intermediate and root ceritficates and the decrypted key file.
i have a yaml file to create a deployment, a service to expose it, and an ingress to route to it. applying this yaml i can access the services via their ip addresses in http, but using https to the ingress controller's external_ip always gives the 502 error.
my yaml file (redacted):

---
apiversion: apps/v1
kind: deployment
metadata:
  name: my-api
spec:
  strategy:
    type: recreate
  selector:
    matchlabels:
      app: my-api
  replicas: 3
  template:
    metadata:
      labels:
        app: my-api
    spec:
      containers:
      - name: my-api
        image: [redacted]/my-api:1.0
        ports:
        - containerport: 443
        - containerport: 80
      imagepullsecrets: 
      - name: data-creds
---
apiversion: v1
kind: service
metadata:
  name: my-service
  labels:
    app: my-service
spec:
  ports:
  - name: https
    port: 443
    targetport: 443
    protocol: tcp
  - name: http
    port: 80
    targetport: 80
    protocol: tcp
  selector:
    app: my-api
  type: loadbalancer
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: api-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/backend-protocol: ""https""
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
spec:
  tls:
  - hosts: 
    - [redacted].co.uk
    secretname: aks-ingress-tls
  rules:
  - host: [redacted].co.uk
    http:
      paths:
      - path: /
        backend:
          servicename: my-service
          serviceport: 443


i added a record to my hosts file (i'm on windows so can't use curl's --resolve) to map [redacted].co.uk to the ingress controller's external_ip so i can try accessing it. that's when i get the errors.
a curl -v https://[redacted].co.uk gives this: 

verbose: get https://[redacted].co.uk/ with 0-byte payload
curl : the request was aborted: could not create ssl/tls secure channel.
at line:1 char:1
+ curl -v https://[redacted].co.uk
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + categoryinfo          : invalidoperation: (system.net.httpwebrequest:httpwebrequest) [invoke-webrequest], webexception
    + fullyqualifiederrorid : webcmdletwebresponseexception,microsoft.powershell.commands.invokewebrequestcommand


looking at logs for one of the ingress controller's pods:

10.244.1.1 - [10.244.1.1] - - [25/apr/2019:13:39:20 +0000] ""get / http/2.0"" 502 559 ""-"" ""mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/73.0.3683.103 safari/537.36"" 10 0.001 [default-sub360-auth-service-443] 10.244.1.254:443, 10.244.1.3:443, 10.244.1.4:443 0, 0, 0 0.000, 0.000, 0.000 502, 502, 502 e44e21c8a2f61f5137c9afdfc64c6584
2019/04/25 13:39:20 [error] 1622#1622: *1127096 connect() failed (111: connection refused) while connecting to upstream, client: 10.244.1.1, server: [redacted].co.uk, request: ""get /favicon.ico http/2.0"", upstream: ""https://10.244.1.254:443/favicon.ico"", host: ""[redacted].co.uk"", referrer: ""https://[redacted].co.uk/""
2019/04/25 13:39:20 [error] 1622#1622: *1127096 connect() failed (111: connection refused) while connecting to upstream, client: 10.244.1.1, server: [redacted].co.uk, request: ""get /favicon.ico http/2.0"", upstream: ""https://10.244.1.3:443/favicon.ico"", host: ""[redacted].co.uk"", referrer: ""https://[redacted].co.uk/""
2019/04/25 13:39:20 [error] 1622#1622: *1127096 connect() failed (111: connection refused) while connecting to upstream, client: 10.244.1.1, server: [redacted].co.uk, request: ""get /favicon.ico http/2.0"", upstream: ""https://10.244.1.4:443/favicon.ico"", host: ""[redacted].co.uk"", referrer: ""https://[redacted].co.uk/""
10.244.1.1 - [10.244.1.1] - - [25/apr/2019:13:39:20 +0000] ""get /favicon.ico http/2.0"" 502 559 ""https://[redacted].co.uk/"" ""mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/73.0.3683.103 safari/537.36"" 26 0.000 [default-sub360-auth-service-443] 10.244.1.254:443, 10.244.1.3:443, 10.244.1.4:443 0, 0, 0 0.000, 0.000, 0.004 502, 502, 502 63b6ed4414bf32694de3d136f7f277aa


can anyone point me to what i need to look at or do to get this working now?
",<azure><nginx><kubernetes><kubernetes-ingress><nginx-ingress>,55864309,2,"for your issue, the ingress uses the https protocol with the port 443, so you do not need to expose the port 443 for your container. just expose the port that which your application listens to. 

for you, it means you just expose the port 80 for your container and the service. you also need to remove the annotation nginx.ingress.kubernetes.io/backend-protocol: ""https"" and change the serviceport value into 80.

note: add the dns name into the certificate is also important.
"
52834030,do i have to do service to a get shell from localhost?,"i want to use ssh from localhost to pod. is there any way to connect using ssh [pod_ip] without using kubectl exec -it [pod] /bin/bash? 

the results are as shown in error: ssh: connect to host [ip] port 22: connection refused.
",<ssh><kubernetes><devops><kubernetes-pod>,52837441,1,"i think you can achieve this goal by installing openssh-server on the targeted pod

for example:

establish ssh connection to the pod:

$ kubectl exec -it &lt;pod_name&gt; -- /bin/bash
$ apt-get update
$ apt-get install -y openssh-server


ensure that sshd service is up and running:

$ service ssh status


start it if necessary:

$ service ssh start


edit the /etc/ssh/sshd_config file if you want to change some specific settings, and restart the ssh service.

check the connection via ssh from your local machine using pod ip address.

update:

i use the following pod configuration in order to establish ssh connection to the centos 7 container:

apiversion: v1
kind: pod
metadata:
  name: centos
spec:
  containers:
  - name: centos
    image: centos:latest
    command: [ ""/bin/bash"", ""-c"", ""yum install openssh-server -y &amp;&amp; /usr/bin/ssh-keygen -a &amp;&amp; /usr/sbin/sshd -p 
22 -f /etc/ssh/sshd_config &amp;&amp; tail -f /dev/null"" ]
    securitycontext:
      privileged: true

"
69679735,preserve sourceip address in kubernetes and distribute the load,"in a multiple node cluster we want to expose a service handling udp traffic. there are two requirements:

we want the service to be backed up by multiple pods (possibly running on different nodes) in order to scale horizontally.
the service needs the udp source ip address of the client (i.e., should use dnat instead of snat)

is that possible?
we currently use a nodeport service with externaltrafficpolicy: local. this forces dnat but only the pod running on the requested node is receiving the traffic.
there doesn't seem to be a way to spread the load over multiple pods on multiple mnodes.
i already looked at this kubernetes tutorial and also this article here.
",<kubernetes><network-programming><kubernetes-ingress>,69774420,5,"the problem
i feel like there is a need for some explanation before facing the actual issue(s) in order to understand why things do not work as expected:
usually what happens when using nodeport is that you expose a port on every node in your cluster. when making a call to node1:port the traffic will then (same as with a clusterip type) be forwarded to one pod that matches the selector, regardless of that pod being on node1 or another node.
now comes the tricky part.
when using externaltrafficpolicy: local, packages that arrive on a node that does not have a pod on it will be dropped.
perhaps the following illustration explains the behavior in a more understandable way.
nodeport with default externaltrafficpolicy: cluster:
package --&gt; node1 --&gt; forwards to random pod on any node (node1 or node2 or ... nodex)

nodeport with externaltrafficpolicy: local:
package --&gt; node1 --&gt; forwards to pod on node1 (if pod exists on node1)

package --&gt; node1 --&gt; drops package (if there is no pod on node1)

so in essence to be able to properly distribute the load when using externaltrafficpolicy: local two main issues need to be addressed:

there has to be a pod running on every node in order for packages not to be dropped
the client has to send packages to multiple nodes in order for the load to be distributed


the solution
the first issue can be resolved rather easily by using a daemonset. it will ensure that one instance of the pod runs on every node in the cluster.
alternatively one could also use a simple deployment, manage the replicas manually and ensure proper distribution across the nodes by using podantiaffinity. this approach would take more effort to maintain since replicas must be adjusted manually but can be useful if you want to have more than just 1 pod on each node.
now for the second issue.
the easiest solution would be to let the client implement logic on his part and send requests to all the nodes in a round robin principle, however, that is not a very practical and/or realistic way of doing it.
usually when using nodeport there is still a load balancer of some kind in front of it to distribute the load (not taking about the kubernetes service type loadbalancer here). this may seem redundant since by default nodeport will distribute the traffic across all the pods anyways, however, the node that gets requested still gets the traffic and then another hop happens. furthermore if only the same node is addressed at all time, once that node goes down (for whatever reason) traffic will never reach any of the pods anyways. so for those (and many other reasons) a load balancer should always be used in combination with nodeport. to solve the issue simply configure the load balancer to preserve the source ip of the original client.
furthermore, depending on what cloud you are running on, there is a chance of you being able to configure a service type loadbalancer instead of nodeport (which basically is a nodeport service + a load balancer in front of it as described above) , configure it with externaltrafficpolicy: local and address the first issue as described earlier and you achieved what you wanted to do.
"
49189406,kubectl exec command to write contents to a file in the pod,"i am trying below command

kubectl exec -it sss-pod-four  echo ""hi"" &gt;&gt; /mnt/sss/testnew.txt


but it throws error

-bash: /mnt/sss/testnew.txt: no such file or directory


what is the best way to achieve this
",<kubernetes><exec><kubectl>,49189635,40,"found a similar question here   and below command works now

 kubectl exec -it sss-pod-four  -- bash -c ""echo hi &gt; /mnt/sss/testnew.txt"" 

"
34502022,exposing two ports in google container engine,"is it possible to create a pod in the google container engine where two ports are exposed: port 8080 is listening for incoming content and port 80 distributes this content to clients?

the following command to create a pod is given as example by google:

kubectl run hello-node --image=gcr.io/${project_id}/hello-node --port=8080


i can't seem to define a listening port, and when adding a second ""--port="" switch only one port is exposed. 
is there a way to expose a second port or am i limited to one port per container?
",<google-cloud-platform><kubernetes><gcloud><google-kubernetes-engine>,34503529,36,"no, you cannot specify multiple ports in kubectl run. but you can use kubectl create to create a replication controller, and specify multiple ports for the container.
https://github.com/kubernetes/examples/blob/master/cassandra/cassandra-statefulset.yaml has an example:
ports:
- containerport: 7000
  name: intra-node
- containerport: 7001
  name: tls-intra-node
- containerport: 7199
  name: jmx
- containerport: 9042
  name: cql

"
54228049,how to view logs for failure of kubernetes container,"my kubernetes yaml file is getting created successfully but container shows error ,here is yaml  file for reference,basically its a multi container with memory limits defined in yaml file

apiversion: batch/v1
kind: job
metadata:
name: command-demo
spec:
ttlsecondsafterfinished: 100
template:
spec:
  volumes:
    - name: docker-sock
      emptydir: {}
  restartpolicy: never
  containers:
    - name: command-demo-container
      image: tarunkumard/fromscratch6.0
      volumemounts:
        - mountpath: /opt/gatling-fundamentals/build/reports/gatling/
          name: docker-sock
      imagepullpolicy: never
      resources:
        requests:
          memory: ""950mi""
        limits:
          memory: ""1gi""
    - name: ubuntu
      image: ubuntu:16.04
      command: [ ""/bin/bash"", ""-c"", ""--"" ]
      args: [ ""while true; do sleep 10; done;"" ]
      volumemounts:
        - mountpath: /docker-sock
          name: docker-sock
      imagepullpolicy: never
      env:
      - name: jvm_opts
        value: ""-xms950m -xmx1g""


tried below commands

 vagrant@ubuntu-xenial:~/pods$ kubectl create -f gat.yaml
 job.batch/command-demo created
 vagrant@ubuntu-xenial:~/pods$ kubectl get pods
 name                 ready   status   restarts   age
 command-demo-bptqj   1/2     error    0          2m33s 


here is output of describe pod

vagrant@ubuntu-xenial:~/pods$ kubectl describe pods command-demo-bptqj
name:           command-demo-bptqj
namespace:      default
node:           ip-172-31-8-145/172.31.8.145
start time:     thu, 17 jan 2019 02:03:28 +0000
labels:         controller-uid=152e2655-19fc-11e9-b787-02d8b37d95a0
                job-name=command-demo
annotations:    kubernetes.io/limit-ranger: limitranger plugin set: memory request for container ubuntu; memory limit for container ubuntu
status:         running
ip:             10.1.40.91
controlled by:  job/command-demo
containers:
  command-demo-container:
    container id:   docker://108004b18788b8410a9ecd0ebb06242463b5e12b193ed3f9d54fe99d1fd1f6b1
    image:          tarunkumard/fromscratch6.0
    image id:       docker-pullable://tarunkumard/fromscratch6.0@sha256:94cc06dde5e242c23e03742365d48008a9a31ffd9d79593838ebb4d651d932c9
    port:           &lt;none&gt;
    host port:      &lt;none&gt;
    state:          terminated
      reason:       error
      exit code:    2
      started:      thu, 17 jan 2019 02:03:30 +0000
      finished:     thu, 17 jan 2019 02:03:30 +0000
    ready:          false
    restart count:  0
    limits:
      memory:  1gi
    requests:
      memory:     950mi
    environment:  &lt;none&gt;
    mounts:
      /opt/gatling-fundamentals/build/reports/gatling/ from docker-sock (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-w6jt6 (ro)
  ubuntu:
    container id:  docker://fdedb595698ae6697ee3ac9bbf01d25e073bc3d6342a0d14c54a427264f1175d
    image:         ubuntu:16.04
    image id:      docker-pullable://ubuntu@sha256:e547ecaba7d078800c358082088e6cc710c3affd1b975601792ec701c80cdd39
    port:          &lt;none&gt;
    host port:     &lt;none&gt;
    command:
      /bin/bash
      -c
      --
    args:
      while true; do sleep 10; done;
    state:          running
      started:      thu, 17 jan 2019 02:03:30 +0000
    ready:          true
    restart count:  0
    limits:
      memory:  1gi
    requests:
      memory:  1gi
    environment:
      jvm_opts:  -xms950m -xmx1g
    mounts:
      /docker-sock from docker-sock (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-w6jt6 (ro)
conditions:
  type              status
  initialized       true
  ready             false
  containersready   false
  podscheduled      true
volumes:
  docker-sock:
    type:    emptydir (a temporary directory that shares a pod's lifetime)
    medium:
  default-token-w6jt6:
    type:        secret (a volume populated by a secret)
    secretname:  default-token-w6jt6
    optional:    false
qos class:       burstable
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type    reason     age    from                      message
  ----    ------     ----   ----                      -------
  normal  scheduled  5m32s  default-scheduler         successfully assigned default/command-demo-bptqj to ip-172-31-8-145
  normal  pulled     5m31s  kubelet, ip-172-31-8-145  container image ""tarunkumard/fromscratch6.0"" already present on machine
  normal  created    5m30s  kubelet, ip-172-31-8-145  created container
  normal  started    5m30s  kubelet, ip-172-31-8-145  started container
  normal  pulled     5m30s  kubelet, ip-172-31-8-145  container image ""ubuntu:16.04"" already present on machine
  normal  created    5m30s  kubelet, ip-172-31-8-145  created container
  normal  started    5m30s  kubelet, ip-172-31-8-145  started container


how do i know what exact is issue with my container or how to see logs
",<kubernetes><kubectl>,54233031,2,"hey margaret as the rest described you can use kubectl.

as a added idea you can ssh into the worker node and do a docker inspect on the container to see some additional logs.

if all of that does not give you what you need you can kubectl exec -it {pod_name} which will give you an interactive terminal into the docker container where you can check the /var/logs/ or other related os logs.
"
74051882,retrieve status of triggered pipeline using an api in tekton,"when we perform tekton trigger api using an eventlistener, i am getting following response while in the background, pipeline runs for certain period of time.
is there any api to fetch the status of this pipelinerun using the given eventid or eventlisteneruid?
{
  &quot;eventlistener&quot;: &quot;listener&quot;,
  &quot;namespace&quot;: &quot;default&quot;,
  &quot;eventlisteneruid&quot;: &quot;ea71a6e4-9531-43a1-94fe-6136515d938c&quot;,
  &quot;eventid&quot;: &quot;14a657c3-6816-45bf-b214-4afdaefc4ebd&quot;
}

ref - https://github.com/tektoncd/triggers/blob/main/docs/eventlisteners.md#labels-in-eventlisteners
",<kubernetes><kubectl><cicd><tekton><tekton-pipelines>,74085839,2,"you can use that eventid resolving your pipelinerun:
kubectl -n &lt;your-namespace&gt; get pr -l triggers.tekton.dev/tekton-eventid=&lt;your-event-id&gt;

then, extract the status column, or use jsonpath to access status.conditions[0].type.
"
69309945,gcp kuberentes cloud deploy vs cloud build,"i am deploying a kubernetes app via github on gcp clusters. everything works fine  then.. i came across cloud deploy delivery pipeline..now i am stuck.
following the docs here
apiversion: skaffold/v2beta12
kind: config
build:
  artifacts:
  - image: skaffold-example
deploy:
  kubectl:
    manifests:
      - k8s-*

in the k8s folder i have my deployment files like so
apiversion: apps/v1
kind: deployment
metadata:
  name: ixh-auth-depl
  labels:
    app: ixh-auth
spec:
  replicas: 1
  selector:
    matchlabels:
      app: ixh-auth
  template:
    metadata:
      labels:
        app: ixh-auth
    spec:
      containers:
      - name: ixh-auth
        image: mb/ixh-auth:latest
        ports:
        - containerport: 3000
        resources:
          requests:
            cpu: 100m
            memory: 500mi

but it gives the error invalid kubernetes manifest. i cannot find anything to read on this and don't know how to proceed.
",<kubernetes><google-cloud-platform><google-kubernetes-engine><skaffold>,69310941,1,"the correct way to declare the manifests was this. the wildcard probably didn't work. the folder name here would be k8s-manifests.
deploy:
  kubectl:
    manifests:
      - k8s-manifests/redis-deployment.yml
      - k8s-manifests/node-depl.yml
      - k8s-manifests/node-service.yml
  

"
43588888,"`helm upgrade --name` results in ""error: unknown flag: --name""","when running helm upgrade --install --namespace $project_namespace --values values.yaml --name $some_name some/chart.

i get error: unknown flag: --name.

is there no way to set the name of a chart you are targeting with upgrade? is this only possible for install?
",<kubernetes><kubernetes-helm>,43592642,11,"the solution was that no --name was needed.

the syntax for a helm upgrade is ""helm upgrade [release] [chart]"", so the ""release"" is the same as what would be the --name in a helm install.
"
66994472,kubernetes nginx ingress controller - different route if query string exists,"is it possible with the nginx ingress controller for kubernetes to have an ingress rule that routes to different services based on if a query string exists? for example..
/foo/bar -&gt; route to servicea
/foo/bar?x=10 -&gt; route to serviceb
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: xxxx.com
    http:
      paths:
      - path: /foo/bar(/|$)(.*)
        pathtype: prefix
        backend:
          service:
            name: servicea
            port:
              number: 8001
      - path: /foo/bar(/|$)(.*)\?
        pathtype: prefix
        backend:
          service:
            name: serviceb
            port:
              number: 8002

",<nginx><kubernetes><kubernetes-ingress>,67087832,3,"i managed to find a working solution for what you described with two ingress objects. with the example that you provided ingress won't be able to direct you towards service-b since nginx does not match query string at all. this is very well explained here.
ingress selects the proper backed based on path. so i have prepared separate path for the second backend and put a conditional redirect to it to the first path so when request reach the /tmp path it uses service-b backend and trims the tmp part from the request.
so here's the ingress that matches /foo/bar for the backend-a
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-ingress
  annotations:
    nginx.ingress.kubernetes.io/configuration-snippet: |
            if ($args ~ .+){
                      rewrite ^ http://xxxx.com/foo/bar/tmp permanent;
                      }
spec:
  rules:
  - host: xxxx.com
    http:
      paths:
      - path: /foo/bar
        pathtype: prefix
        backend:
          servicename: service-a
          serviceport: 80

and here is the ingress that matches /foo/bar? and whatever comes after for the backend-b
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-ingress-rewrite
  annotations:
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /foo/bar$1
spec:
  rules:
  - host: xxxx.com
    http:
      paths:
      - path: /foo/bar/tmp(.*)
        backend:
          servicename: service-b
          serviceport: 80

please note, that previous configuration leftovers can prevent that solution from working well. clean up, redeploy and ingress controller restart should help in that situation.
here are some tests to prove the case. first i have added the xxxx.com to /etc/hosts:
➜  ~ cat /etc/hosts
127.0.0.1       localhost
192.168.59.2 xxxx.com

- here we are testing the firs path /foo/bar:
➜  ~ curl -l -v http://xxxx.com/foo/bar        
*   trying 192.168.59.2...
* tcp_nodelay set
* connected to xxxx.com (192.168.59.2) port 80 (#0)
&gt; get /foo/bar http/1.1 &lt;----- see path here! 
&gt; host: xxxx.com
&gt; user-agent: curl/7.52.1
&gt; accept: */*
&gt; 
&lt; http/1.1 200 ok
&lt; date: tue, 13 apr 2021 12:30:00 gmt
&lt; content-type: application/json; charset=utf-8
&lt; content-length: 644
&lt; connection: keep-alive
&lt; x-powered-by: express
&lt; etag: w/&quot;284-p+j4ozl3lklvyqdp6fegtpvw/vm&quot;
&lt; 
{
  &quot;path&quot;: &quot;/foo/bar&quot;,
  &quot;headers&quot;: {
    &quot;host&quot;: &quot;xxxx.com&quot;,
    &quot;x-request-id&quot;: &quot;1f7890a47ca1b27d2dfccff912d5d23d&quot;,
    &quot;x-real-ip&quot;: &quot;192.168.59.1&quot;,
    &quot;x-forwarded-for&quot;: &quot;192.168.59.1&quot;,
    &quot;x-forwarded-host&quot;: &quot;xxxx.com&quot;,
    &quot;x-forwarded-port&quot;: &quot;80&quot;,
    &quot;x-forwarded-proto&quot;: &quot;http&quot;,
    &quot;x-scheme&quot;: &quot;http&quot;,
    &quot;user-agent&quot;: &quot;curl/7.52.1&quot;,
    &quot;accept&quot;: &quot;*/*&quot;
  },
  &quot;method&quot;: &quot;get&quot;,
  &quot;body&quot;: &quot;&quot;,
  &quot;fresh&quot;: false,
  &quot;hostname&quot;: &quot;xxxx.com&quot;,
  &quot;ip&quot;: &quot;192.168.59.1&quot;,
  &quot;ips&quot;: [
    &quot;192.168.59.1&quot;
  ],
  &quot;protocol&quot;: &quot;http&quot;,
  &quot;query&quot;: {},
  &quot;subdomains&quot;: [],
  &quot;xhr&quot;: false,
  &quot;os&quot;: {
    &quot;hostname&quot;: &quot;service-a&quot; &lt;------ pod hostname that response came from.

- and here we are testing the firs path /foo/bar:
➜  ~ curl -l -v http://xxxx.com/foo/bar\?x\=10 
*   trying 192.168.59.2...
* tcp_nodelay set
* connected to xxxx.com (192.168.59.2) port 80 (#0)
&gt; get /foo/bar?x=10 http/1.1 &lt;--------- the requested path! 
&gt; host: xxxx.com
&gt; user-agent: curl/7.52.1
&gt; accept: */*
&gt; 
&lt; http/1.1 301 moved permanently
&lt; date: tue, 13 apr 2021 12:31:58 gmt
&lt; content-type: text/html
&lt; content-length: 162
&lt; connection: keep-alive
&lt; location: http://xxxx.com/foo/bar/tmp?x=10
&lt; 
* ignoring the response-body
* curl_http_done: called premature == 0
* connection #0 to host xxxx.com left intact
* issue another request to this url: 'http://xxxx.com/foo/bar/tmp?x=10'
* found bundle for host xxxx.com: 0x55d6673218a0 [can pipeline]
* re-using existing connection! (#0) with host xxxx.com
* connected to xxxx.com (192.168.59.2) port 80 (#0)
&gt; get /foo/bar/tmp?x=10 http/1.1
&gt; host: xxxx.com
&gt; user-agent: curl/7.52.1
&gt; accept: */*
&gt;  
{
  &quot;path&quot;: &quot;/foo/bar&quot;,
  &quot;headers&quot;: {
    &quot;host&quot;: &quot;xxxx.com&quot;,
    &quot;x-request-id&quot;: &quot;96a949a407dae653f739db01fefce7bf&quot;,
    &quot;x-real-ip&quot;: &quot;192.168.59.1&quot;,
    &quot;x-forwarded-for&quot;: &quot;192.168.59.1&quot;,
    &quot;x-forwarded-host&quot;: &quot;xxxx.com&quot;,
    &quot;x-forwarded-port&quot;: &quot;80&quot;,
    &quot;x-forwarded-proto&quot;: &quot;http&quot;,
    &quot;x-scheme&quot;: &quot;http&quot;,
    &quot;user-agent&quot;: &quot;curl/7.52.1&quot;,
    &quot;accept&quot;: &quot;*/*&quot;
  },
  &quot;method&quot;: &quot;get&quot;,
  &quot;body&quot;: &quot;&quot;,
  &quot;fresh&quot;: false,
  &quot;hostname&quot;: &quot;xxxx.com&quot;,
  &quot;ip&quot;: &quot;192.168.59.1&quot;,
  &quot;ips&quot;: [
    &quot;192.168.59.1&quot;
  ],
  &quot;protocol&quot;: &quot;http&quot;,
  &quot;query&quot;: {
    &quot;x&quot;: &quot;10&quot;
  },
  &quot;subdomains&quot;: [],
  &quot;xhr&quot;: false,
  &quot;os&quot;: {
    &quot;hostname&quot;: &quot;service-b&quot; &lt;-----service-b host name!
  },
  &quot;connection&quot;: {}

for the responses i've used the  mendhak/http-https-echo image:
apiversion: v1
kind: pod
metadata:
  name: service-b
  labels:
    app: echo2
spec:
  containers:
  - name: service-b #&lt;-------- service-b host name
    image: mendhak/http-https-echo
    ports:
    - containerport: 80

"
45720105,spring boot could not autowire field kubernetes service_host,"i am using minikube. i have a service named updatedaddress. i am calling updateaddress service from updatecustomer service using auto injection of kubernetes environment variables .

my java code looks like this 

    @value(""${updateaddress_service_host}"")
    private string updateaddresshost;

    @value(""${updateaddress_service_port}"")
    private string updateaddressport;
    ...
    greeting= resttemplate.getforentity(""http://""+updateaddresshost+"":""+updateaddressport+""/updateaddress"", greeting.class).getbody();


when i execute the following command 

kubectl --namespace=default-staging exec updatecustomer-4023824433-r5r19 env


i can see the environment variables updateaddress_service_host=10.0.0.180 and updateaddress_service_port=80 among many other variables.

when i try building the spring boot service i get the error 

 error creating bean with name 'updatecustomerinforesilient': injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.beancreationexception: could not autowire field: private java.lang.string com.amwater.updatecustomerinforesilient.updateaddresshost; nested exception is java.lang.illegalargumentexception: could not resolve placeholder 'updateaddress_service_host' in string value ""${updateaddress_service_host}""


any advice would be helpful. thank you .
",<spring><spring-boot><kubernetes><kubectl><minikube>,45722083,1,"instated of using server ip  and port number, try to use the service dns name and test the application.

it will be something like this my-svc.my-namespace.svc.cluster.local replace your servicename and namespace.

here is the documentation https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/
"
66451485,override default service account used by spring boot app deployed in kubernetes,"problem  statement :
i  have  deployed  a  spring  boot  app  which  when  on  starting  always  uses  default  compute  engine  service  account  credentials to  authenticate  the  app ,  i  have  a  created  a  seperate  service  account  and  key  but  not  able  to  replace  the  default  one.  i  tried  specifying  the  new  service  account  in deployement.yaml  by  using  &quot;serviceaccountname&quot;  field  but  still  got  the  error  saying  service  account eg :&quot;xyz&quot; not  found.
serviceaccountname: {{ .values.serviceaccountname }}
so  how  can  i  override  default  service  account of  compute  engine  with  a  specific  service  account  and  define  it  in  deployment.yaml.
if  i  add  the  credentials  of  new  service  account  in  app  code  base  it  will  work  but  that  is  not  a  best  practice  to  do  so ,  please  someone  help  me  on  resolving  this  issue
snippet  of  my  deployment.yaml  file:
apiversion: apps/v1
kind: deployment
metadata:
  labels:
    app: helloworld
    appversion: {{ .values.appversion }}
  name: helloworld
spec:
  replicas: 1
  selector:
    matchlabels:
      app: helloworld
  template:
    metadata:
      labels:
        app: helloworld
        environment: {{ .values.environment }}
    spec:
      containers:
        - name: helloworld
          image: {{ .values.imagesha }}
          imagepullpolicy: always
          securitycontext:
            allowprivilegeescalation: false
            runasuser: 1000
          ports:
            - containerport: 8080
          env:
          - name: spring_config_location
            value: &quot;/app/deployments/config/&quot;          
          volumemounts:
            - name: application-config
              mountpath: &quot;/app/deployments/config&quot;
              readonly: true
      volumes:
      - name: application-config
        configmap:
          name: {{ .values.configmapname }}
          items:
          - key: application.properties
            path: application.properties

",<spring-boot><kubernetes><google-cloud-platform><google-kubernetes-engine>,66583185,1,"i think you should use workload identity which allows to access google cloud from outside.

workload identity is the recommended way to access google cloud services from applications running within gke due to its improved security properties and manageability. for information about alternative ways to access google cloud apis from gke, refer to the alternatives section below.

above guide is well described and i think it should resolve your issue.
for additional example, you can check one of the community tutorial - using kubernetes workload identity for client-server authorization.

in gke, the workload identity feature allows these identities to also be associated with iam service accounts. this allows a pod running as a kubernetes service account to act as the associated service account for authorized access to google apis and to services that verify identity based on google cloud-specific oidc.

both docs have examples which should help you to adjust workload identity to your needs.
"
59321083,helm-charts: share env var in sibling charts' deployment/configmaps,"files structure (minimized)

there is a charts folder containing multiple charts.

charts/
  foo-chart/
    templates/
       deployment.yml
       secrets.yml
  bar-chart/
    templates/
      configmaps/
        script.yml


secrets.yml

defines a token:

apiversion: v1
kind: secret
metadata:
  name: {{ .release.name }}-secret
  labels:
    app: {{ include ""metrics.name"" . }}
    chart: {{ include ""metrics.chart"" . }}
    release: {{ .release.name }}
    heritage: {{ .release.service }}
type: opaque
data:
  # note: service token has to fit the nist requirement
  servicetoken: {{ randascii 40 | b64enc }}


deployment.yml

runs a command which uses an environmental variable which uses a secret:

containers:
  command:
  - fancy-binary
  - -token
  - $(auth_token)
  env:
  - name: auth_token
  valuefrom:
    secretkeyref:
    name: {{ .release.name }}-secret
    key: servicetoken


script.yml

is supposed to run bash command (django admin-command) and use environmental variable as well:

# create a service token
django-admin service_token_add $(auth_token)




issues


is the auth_token going to be visible in script.yml?
does the env valuefrom auto-set the value of auth_token (is deployment going to work)?

",<kubernetes><kubernetes-helm>,59353940,1,"answering to your first question, environment variables passed through env field of a container will be visible everywhere in your container
so also in the script you run unless you explicitly unset it.

you can check it by creating this (you should be able to copypaste the example):

apiversion: v1
kind: secret
metadata:
  name: test-secret
type: opaque
data:
  servicetoken: mtizndu2nzg5mao=     # base64 encoded string: ""1234567890""

---
apiversion: v1
kind: pod
metadata:
  name: test
spec:
  containers:
  - args:
    - echo
    - hello
    - $(auth_token)
    name: test
    env:
    - name: auth_token
      valuefrom:
          secretkeyref:
          name: test-secret
          key: servicetoken
    image: centos:7
  restartpolicy: never


and then when pod completes, check logs and you will see your token:

$ kubectl logs test
hello 1234567890


the same applies to scripts.

answering you second question; as you probably already saw in example above, using env valuefrom will indeed auto-set your env to the value from secret.

let me know if it was helpful.
"
66793426,go struct: multiple nested fields but only one field can be specified,"i wanted to know how to implement inheritance in go. after reading i understood that i must think about struct embedding. as i am a kubernetes developer, i jump into the kubernetes source code and start reading the podspec in which the volumes field is closer to what i am looking for.
when i thought i was starting to understand, something intrigued me.
by reading the snippet below, before the type volumesource struct you can read only one of its members may be specified
type volume struct {
    // volume's name.
    // must be a dns_label and unique within the pod.
    // more info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
    name string `json:&quot;name&quot; protobuf:&quot;bytes,1,opt,name=name&quot;`
    // volumesource represents the location and type of the mounted volume.
    // if not specified, the volume is implied to be an emptydir.
    // this implied behavior is deprecated and will be removed in a future version.
    volumesource `json:&quot;,inline&quot; protobuf:&quot;bytes,2,opt,name=volumesource&quot;`
}

// represents the source of a volume to mount.
// only one of its members may be specified.
type volumesource struct {
    // hostpath represents a pre-existing file or directory on the host
    // machine that is directly exposed to the container. this is generally
    // used for system agents or other privileged things that are allowed
    // to see the host machine. most containers will not need this.
    // more info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
    // ---
    // todo(jonesdl) we need to restrict who can use host directory mounts and who can/can not
    // mount host directories as read/write.
    // +optional
    hostpath *hostpathvolumesource `json:&quot;hostpath,omitempty&quot; protobuf:&quot;bytes,1,opt,name=hostpath&quot;`
    // emptydir represents a temporary directory that shares a pod's lifetime.
    // more info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
    // +optional
    emptydir *emptydirvolumesource `json:&quot;emptydir,omitempty&quot; protobuf:&quot;bytes,2,opt,name=emptydir&quot;`
    // gcepersistentdisk represents a gce disk resource that is attached to a
    // kubelet's host machine and then exposed to the pod.
    // more info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
    // +optional
    gcepersistentdisk *gcepersistentdiskvolumesource `json:&quot;gcepersistentdisk,omitempty&quot; protobuf:&quot;bytes,3,opt,name=gcepersistentdisk&quot;`
    // awselasticblockstore represents an aws disk resource that is attached to a
    // kubelet's host machine and then exposed to the pod.
    // more info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
    // +optional
    awselasticblockstore *awselasticblockstorevolumesource `json:&quot;awselasticblockstore,omitempty&quot; protobuf:&quot;bytes,4,opt,name=awselasticblockstore&quot;`
    // gitrepo represents a git repository at a particular revision.
    // deprecated: gitrepo is deprecated. to provision a container with a git repo, mount an
    // emptydir into an initcontainer that clones the repo using git, then mount the emptydir
    // into the pod's container.
    // +optional
    ....

how and where is this constraint satisfied?
is it in the struct definition as it's written or programmatically in the source code in another .go file? because i looked for it in the source code where it could be programmatically verified, but i didn't see.
please, can you help me to understand?
",<go><kubernetes><kubernetes-pod>,66793584,2,"there's no such thing to limit a structs field values in the language spec. however, i have a good feeling that since all fields are pointers, a method of volume source checks for all fields and expects only one field to be non-nil.
maybe something like this, i'm not sure of the usage of reflect though
func (v volumesource) checkfields() error {
    s := reflect.typeof(v)
    counter := 0
    for i:= s.numfield() - 1; i &gt;= 0 ; i-- {
        n := s.field(i).name()
        e := reflect.valueof(v).field(i)
        if !e.isvalid(){
            continue
        }
        if e != nil {
            counter++
        }
        if counter &gt; 1{
            return errors.new(&quot;more than 1 field initialized&quot;)
        }

    }
}


"
73014793,spring boot application can't find aws credentials from any credentials chain,"i'm trying to migrate several spring boot services to eks and they can't retrieve aws credentials from credentials chain and pods are failing with following error: unable to load credentials from any of the providers in the chain awscredentialsproviderchain
these are what i've tried so far:
i'm using web identity token from aws sts for credentials retrieval.
@bean
public awscredentialsprovider awscredentialsprovider() {
    if (system.getenv(&quot;aws_web_identity_token_file&quot;) != null) {
        return webidentitytokencredentialsprovider.builder().build();
    }
    return new defaultawscredentialsproviderchain();
}

@bean
public sqsclient sqsclient(awscredentialsprovider awscredentialsprovider) {
    return sqsclient
            .builder()
            .credentialsprovider(() -&gt; (awscredentials) awscredentialsprovider.getcredentials())
            .region(region.eu_west_1).build();
}

@bean
public snsclient snsclient(awscredentialsprovider awscredentialsprovider) {
    return snsclient
            .builder()
            .credentialsprovider(() -&gt; (awscredentials) awscredentialsprovider.getcredentials())
            .region(region.eu_west_1).build();
}

the services also have aws-java-sdk-sts maven dependency packaged.
iam role for the services is also fine and aws_web_identity_token_file is a also automatically created within pod after each jenkins build based on k8s manifest file.
from pod i can make get and post request to sns and sqs without any problem.
",<amazon-web-services><spring-boot><kubernetes><microservices><amazon-eks>,73035530,3,"problem was fixed.
main issue was conflicting aws sdk bom version with individual models. also previous version of bom i was using wasn't supporting aws sdk v2.x .
these are the main take aways from the issue:

aws sdk authenticate services using credentials provider chain . the default credential provider chain of the aws sdk for java 2.x searches for credentials in your environment using a predefined sequence.
1.1 as of aws sdk for java 2.x web identity token from aws sts is within default provider chain.
1.2 as long as using v2 of the sdk and having the sts dependency makes explicit configuration of web identity token redundant.
1.3 make sure candidate service is using aws sdk v2 as it’ll reduce the configuration code to minimum.


if a candidate service using aws sdk v1 following configuration should be added as web identity token isn’t in default provider chain for v1.
@bean
public awscredentialsprovider awscredentialsprovider() {
    if (system.getenv(&quot;aws_web_identity_token_file&quot;) != null) {
        return webidentitytokencredentialsprovider.builder().build();
    }    
    return new defaultawscredentialsproviderchain();
}

last but not least try to use try to use latest aws sdk bom dependency . (currently all modules have the same version, but this may not always be the case)
"
71353947,why am i getting a csrf 403 from oauth2 proxy when running on gke but not locally?,"i have a simple setup that is using oauth2 proxy to handle authentication. it works fine locally using minikube but when i try to use gke when the oauth callback happens i get a 403 status and the the following message...

login failed: unable to find a valid csrf token. please try again.

the offending url is http://ourdomain.co/oauth2/callback?code=j_6ao0axsbrn4bwr&amp;state=r_afqm9wssppvykyyze_naggnpnkup1plyzafoeo0go%3a%2fip
what should be configured differently to avoid the csrf error?
",<kubernetes><oauth><google-kubernetes-engine><openid-connect><oauth2-proxy>,71354934,3,"in my case it was because i needed to set the cookie to secure = false. apparently i could still have secure true no problem with http and an ip but once i uploaded with a domain it failed.
"
52765182,aws eks add user restricted to namespace,"i have created aws eks cluster since i have created using my aws userid has been added to system:masters group. but when checked configmap aws-auth i don't see my user id. why ?

i had to give access to another user, so i have to assign appropriate aws policies to the iam user, then i edited the configmap aws-auth with the following mapping 

mapusers:
----
- userarn: arn:aws:iam::573504862059:user/abc-user  
  username: abc-user
  groups:
    - system:masters


so far i have understood when a user is part of system:masters group, this user has admin privileges on the cluster.

how can i add a new user who will have restricted privileges to a specific namespace? do i have to do the same thing what i have done for the above user? if so then what group i should add the new user to?
",<amazon-web-services><kubernetes><kubectl><amazon-eks>,52765737,9,"i would familiarize with kubernetes rbac concepts
so you can create a role since these are limited to a specific namespace.
kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  namespace: my-namespace
  name: full-namespace
rules:
- apigroups: [&quot;*&quot;] 
  resources: [&quot;*&quot;]
  verbs: [&quot;*&quot;]

then create a rolebinding:
$ kubectl create rolebinding my-namespace-binding --role=full-namespace --group=namespacegroup --namespace=my-namespace

or kubectl create -f this:
apiversion: rbac.authorization.k8s.io/v1
kind: rolebinding
metadata:
  name: my-namespace-binding
  namespace: mynamespace
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: full-namespace
subjects:
- apigroup: rbac.authorization.k8s.io
  kind: group
  name: namespacegroup

then on your configmap:
mapusers:
----
- userarn: arn:aws:iam::573504862059:user/abc-user  
  username: abc-user
  groups:
    - namespacegroup

"
56759669,unreasonable not enough cpu for deployment scaling,"i am trying to understand deployment scaling with load balancer. i created kubernetes cluster on google cloud with 6 nodes: 2 cores and 13gb ram each (n1-highmem-2) and launch 5 pods and 1 load balancer service. each pod has a limit specified to 5.1gb and 1cpu. when i tried to scale my deployment to 10 pods i got an error that my cpu number is too low. how? i have cluster with 12 cores in total and 78gb of ram. here is my yaml file:

apiversion: v1
kind: namespace
metadata:
   name: production
   labels:
      name: production
---
apiversion: v1
kind: service
metadata:
   name: my-service
   namespace: production
   labels:
      run: mypod
spec:
   type: loadbalancer
   ports:
      - port: 8050
        targetport: 8050
        protocol: tcp
        name: http
   selector:
      run: mypod
---
apiversion: apps/v1
kind: deployment
metadata:
   name: test
   namespace: production
spec:
   selector:
      matchlabels:
         run: mypod
   replicas: 5
   template:
      metadata:
         namespace: production
         labels:
            run: mypod
      spec:
         containers:
            - name: test
              image: my-hello-world
              ports:
              - containerport: 8050
              resources:
                 limits:
                    cpu: ""1""
                    memory: ""5.1gi""
                 requests:
                    cpu: ""1""
                    memory: ""500mi""

",<kubernetes><google-kubernetes-engine>,56760125,2,"other containers may be requesting cpu from your cluster (including the kube-system ones).

you are requesting 1 cpu for each test container replica, but keep in mind that each container must be scheduled in one of the nodes (being that every single node only has 2 cpu available). that means: if a node has a single kube-system container that is requesting any amount of cpu, the node cannot afford more than one test container. e.g.:


  node 1:
  
  
  calico-node-rqcw7  -   250m
  test-83h1d         - 1000m
  test-kd93h         - 1000m  # &lt;----- this one cannot be scheduled because the node already is using 1250m
  


use kubectl describe nodes command and you should figure out what containers are being scheduled in which nodes, including their cpu requests.
"
44679343,docker how to use boolean value on spec.container.env.value,"is there a way to pass a boolean value for spec.container.env.value  ?
i want to override, with helm, a boolean env variables in a docker parent image (https://github.com/apsl/docker-thumbor) : upload_enabled

i made a simpler test

if you try the following yaml : 

apiversion: v1
kind: pod
metadata:
  name: envar-demo
  labels:
    purpose: demonstrate-envars
spec:
  containers:
  - name: envar-demo-container
    image: gcr.io/google-samples/node-hello:1.0
    env:
    - name: demo_greeting
      value: true


and try to create it with kubernetes, you got the following error : 

kubectl create -f envars.yaml


the error : 

error: error validating ""envars.yaml"": error validating data: expected type string, for field spec.containers[0].env[0].value, got bool; if you choose to ignore these errors, turn validation off with --validate=false


with validate=false 

error from server (badrequest): error when creating ""envars.yaml"": pod in version ""v1"" cannot be handled as a pod: [pos 192]: json: expect char '""' but got char 't'


it doesn't work with integer values too
",<docker><kubernetes><kubernetes-helm>,44692213,20,"spec.container.env.value is defined as string. see here:
https://kubernetes.io/docs/api-reference/v1.6/#envvar-v1-core

you'd have to cast/convert/coerse to boolean in your container when using this value
"
66216626,permission denied while reading file as root in azure aks container,"i have aks cluster deployed(version 1.19) on azure, part of the deployment in kube-system namespace there are 2 azure-cni-networkmonitor pods, when opening a bash in one of the pods using:
kubectl exec -t -i -n kube-system azure-cni-networkmonitor-th6pv -- bash

i've noticed that although i'm running as root in the container:

uid=0(root) gid=0(root) groups=0(root)

there are some files that i can't open for reading, read commands are resulting in permission denied error, for example:
cat: /run/containerd/io.containerd.runtime.v1.linux/k8s.io/c3bd2dfc2ad242e1a706eb3f42be67710630d314cfeb4b96ec35f35869264830/rootfs/sys/module/zswap/uevent: permission denied

file stat:
access: (0200/--w-------)  uid: (    0/    root)   gid: (    0/   root)

linux distribution running on container:

common base linux delridge

although the file is non-readable, i shouldn't have a problem to read it as root right?
any idea why would this happen? i don't see there any selinux enabled.
",<kubernetes><azure-devops><permissions><kubectl><azure-aks>,66226187,2,"/proc and /sys are special filesystems created and maintained by the kernel to provide interfaces into settings and events in the system. the uevent files are used to access information about the devices or send events.
if a given subsystem implements functionality to expose information via that interface, you can cat the file:
[root@home sys]# cat /sys/devices/system/cpu/cpu0/uevent
driver=processor
modalias=cpu:type:x86,ven0000fam0006mod003f:feature:,0000,0001,0002,0003,0004,0005,0006,0007,0008,0009,000b,000c,000d,000e,000f,0010,0011,0013,0017,0018,0019,001a,001b,001c,002b,0034,003a,003b,003d,0068,006f,0070,0072,0074,0075,0076,0079,0080,0081,0089,008c,008d,0091,0093,0094,0096,0097,0099,009a,009b,009c,009d,009e,009f,00c0,00c5,00e7,00eb,00ec,00f0,00f1,00f3,00f5,00f6,00f9,00fa,00fb,00fd,00ff,0120,0123,0125,0127,0128,0129,012a,012d,0140,0165,024a,025a,025b,025c,025d,025f

but if that subsystem doesn't expose that interface, you just get permission denied - even root can't call kernel code that's not there.
"
70202542,what happens when kubernetes readiness-probe return false? how long to wait?,"what happens when kubernetes readiness-probe returns false? does kubernetes restart that pod after timeout? how long kubernetes waits for readiness?
",<kubernetes><kubernetes-pod><readinessprobe>,70202732,5,"readiness probe doesn't restart the pod/container, readiness probe determines that the container is ready to serve traffic. if the container is probed and considered not &quot;ready&quot;, the container will be removed from the endpoints and traffic wont be sent to it, until it is ready again.
[1] https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes
[2] https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
[3] kubectl explain pod.spec.containers.readinessprobe
kind:     pod
version:  v1

resource: readinessprobe &lt;object&gt;

description:
     periodic probe of container service readiness. container will be removed
     from service endpoints if the probe fails. cannot be updated. more info:
     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes

     probe describes a health check to be performed against a container to
     determine whether it is alive or ready to receive traffic.

fields:
   exec &lt;object&gt;
     one and only one of the following should be specified. exec specifies the
     action to take.

   failurethreshold &lt;integer&gt;
     minimum consecutive failures for the probe to be considered failed after
     having succeeded. defaults to 3. minimum value is 1.

   httpget  &lt;object&gt;
     httpget specifies the http request to perform.

   initialdelayseconds  &lt;integer&gt;
     number of seconds after the container has started before liveness probes
     are initiated. more info:
     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes

   periodseconds    &lt;integer&gt;
     how often (in seconds) to perform the probe. default to 10 seconds. minimum
     value is 1.

   successthreshold &lt;integer&gt;
     minimum consecutive successes for the probe to be considered successful
     after having failed. defaults to 1. must be 1 for liveness and startup.
     minimum value is 1.

   tcpsocket    &lt;object&gt;
     tcpsocket specifies an action involving a tcp port. tcp hooks not yet
     supported

   timeoutseconds   &lt;integer&gt;
     number of seconds after which the probe times out. defaults to 1 second.
     minimum value is 1. more info:
     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes

let's use the default readiness probe from the documentation:
cat pod.yaml
apiversion: v1
kind: pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerport: 80
    readinessprobe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialdelayseconds: 5
      periodseconds: 5

to perform a probe, the kubelet executes the command cat /tmp/healthy in the target container. if the command succeeds, it returns 0, then the container is ready and can &quot;serve&quot;. if the command returns anything but 0, container is not healthy.
since this file doesn't exist in the container from the start, when the pod starts, it is going to be very unhealthy.
date &amp;&amp; k get pods nginx
thu  2 dec 2021 19:08:43 ast
name    ready   status    restarts   age
nginx   0/1     running   0          66s

now, lets exec into it and create the file, so that the command succeeds.
k exec -it nginx -- bash
root@nginx:/# touch /tmp/healthy
root@nginx:/# exit
exit

checking again:
date &amp;&amp; k get pods nginx
thu  2 dec 2021 19:09:26 ast
name    ready   status    restarts   age
nginx   1/1     running   0          110s

removing again:
k exec -it nginx -- bash
root@nginx:/# rm /tmp/healthy
root@nginx:/# exit
exit

checking:
date &amp;&amp; k get pods nginx
thu  2 dec 2021 19:09:53 ast
name    ready   status    restarts   age
nginx   0/1     running   0          2m17s

"
57104660,how to delete kubernetes job automatically after job completion,"i am running a kubernetes job on gke and want to delete the job automatically after the job is completed.

here is my configuration file for the job.
i set ttlsecondsafterfinished: 0 but the job was not deleted automatically.
am i missing something?


cluster / node version: 1.12.8-gke.10


apiversion: batch/v1
kind: job
metadata:
  name: myjob
spec:
  # automatically clean up finished job
  ttlsecondsafterfinished: 0
  template:
    metadata:
      name: myjob
    spec:
      containers:
        - name: myjob
          image: gcr.io/gcp_project/myimage:commit_sha
          command: [""bash""]
          args: [""deploy.sh""]
      # do not restart containers after they exit
      restartpolicy: never

",<kubernetes><google-kubernetes-engine>,57104795,1,"looks like this feature is still not available on gke now.

https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/
https://cloud.google.com/kubernetes-engine/docs/concepts/alpha-clusters#about_feature_stages

to ensure stability and production quality, normal gke clusters only enable features that
are beta or higher. alpha features are not enabled on normal clusters because they are not
production-ready or upgradeable.

"
53819668,pod not restarting automatically when crashing after reaching memory limit,"i am running my elixir app on gke

here is my deployment configuration:

apiversion: extensions/v1beta1
kind: deployment
metadata:
  name: myapp
  namespace: production
spec:
  replicas: 1
  revisionhistorylimit: 1
  strategy:
      type: rollingupdate
  template:
    metadata:
      labels:
        app: myapp
        tier: backend
    spec:
      securitycontext:
        runasuser: 0
        runasnonroot: false
      containers:
      - name: myapp
        image: myimage
        resources:
          limits:
            cpu: 3000m
            memory: 2000mi
          requests:
            cpu: 2500m
            memory: 1000mi
        ports:
        - containerport: 80
        args:
          - foreground


as you can see in the image, the pod reached its memory limit and crashed


these are my last logs:

erl_child_setup closed

crash dump is being written to: erl_crash.dump...done

shutting down..

node is not running!


and then my app is frozen, i get 502 when trying to request the app,

in order to restart i restart the pod (kubectl delete pod), and then it runs again,

my question is: why doesnt the pod restart automatically when reaches memory limit?
",<kubernetes><google-kubernetes-engine>,53820583,5,"you'll need to add probes that will check if your application is healthy.

since you mentioned a 502, i'm assuming this is a phoenix application and you can add a health-check endpoint:

livenessprobe:
  httpget:
    path: /healthz
    port: 8080
  initialdelayseconds: 3
  periodseconds: 3


when this request stops receiving a 200, then the kubernetes controller will restart your pod.
"
57970255,helm v3 - cannot find the official repo,"i have been trying to install nginx ingress using helm version 3

helm install my-ingress stable/nginx-ingress


but helm doesn't seem to be able to find it's official stable repo. it gives the message: 


  error: failed to download ""stable/nginx-ingress"" (hint: running helm
  repo update may help)




i tried helm repo update. but it doesn't help.

i tried listing the repos helm repo list but it is empty.



i tried to add the stable repo: 

helm repo add stable https://github.com/helm/charts/tree/master/stable


but it fails with: 


  error: looks like ""https://github.com/helm/charts/tree/master/stable""
  is not a valid chart repository or cannot be reached: failed to fetch
  https://github.com/helm/charts/tree/master/stable/index.yaml : 404 not
  found

",<kubernetes><kubernetes-helm><kubernetes-deployment>,57970816,193,"the stable repository is hosted on https://kubernetes-charts.storage.googleapis.com/. so, try the following:
helm repo add stable https://kubernetes-charts.storage.googleapis.com/

edit 2020-11-16: the above repository seems to have been deprecated. the following should now work instead:
helm repo add stable https://charts.helm.sh/stable

"
74086199,confused with pods and containers,"when we say a &quot;pod&quot; in kubernetes, is it just a name to denote the group of containers it has? or is pod itself a container(which has an os running inside), with other containers running inside it?
ie, like this ? :
i can ssh into a worker node

i see pods running there

i can exec into a pod

there i can see the containers

i can further exec into one of those containers to see the application logs

so the worker node has an os, pod has an os, and containers has an os aswell?

",<kubernetes><kubernetes-pod>,74087903,1,"in kubernetes, a pod is the smallest deployable unit and is a single running instance. a pod is not a container itself but it contains 1+ relatively coupled containers inside it that all run when the pod is launched (ex: say your container needs a logging container to be deployed alongside it, you'd deploy both containers within a pod). these containers within the pod share the same network and pod resources. in high-level kubernetes deployment, you'd probably never deploy a pod itself but rather declare and deploy a pod controller (deployment, replicaset, daemonset).
the general hierarchy is:
deployment manages replicasets manages pods manages containers.
in kubernetes, the 2 main components is the control plane (usually replicated 3x for ha) and then your worker nodes:
control plane (master node): api server (communication), scheduler, controllers, etcd (key-value store that defines desired state of cluster)
worker nodes: kubelet (to communicate with api server in control plane), kube-proxy (network), container runtime (ex: docker), and pods
there's a lot more to kubernetes but i hope this helps clear some initial questions.
"
70547587,using pod anti affinity to force only 1 pod per node,"i am trying to get my deployment to only deploy replicas to nodes that aren't running rabbitmq (this is working) and also doesn't already have the pod i am deploying (not working).
i can't seem to get this to work. for example, if i have 3 nodes (2 with label of app.kubernetes.io/part-of=rabbitmq) then all 2 replicas get deployed to the remaining node. it is like the deployments aren't taking into account their own pods it creates in determining anti-affinity. my desired state is for it to only deploy 1 pod and the other one should not get scheduled.
kind: deployment
metadata:
  name: test-scraper
  namespace: scrapers
  labels:
    k8s-app: test-scraper-deployment
spec:
  replicas: 2
  selector:
    matchlabels:
      app: testscraper
  template:
    metadata:
      labels:
        app: testscraper
    spec:
      affinity:
        podantiaffinity:
          requiredduringschedulingignoredduringexecution:
          - labelselector:
              matchexpressions:
              - key: app.kubernetes.io/part-of
                operator: in
                values:
                - rabbitmq
              - key: app
                operator: in
                values:
                - testscraper
            namespaces: [scrapers, rabbitmq]
            topologykey: &quot;kubernetes.io/hostname&quot;
      containers:
        - name: test-scraper
          image: #######:latest```

",<kubernetes><kubernetes-pod><kubernetes-deployment>,70548983,4,"i think thats because of the matchexpressions part of your manifest , where it requires pods need to have both the labels  app.kubernetes.io/part-of: rabbitmq and  app: testscraper to satisfy the antiaffinity rule.
based on deployment yaml you have provided , these pods will have only app: testscraper but not pp.kubernetes.io/part-of: rabbitmq hence both the replicas are getting scheduled on same node
from documentation (the requirements are anded.):
kubectl explain pod.spec.affinity.podantiaffinity.requiredduringschedulingignoredduringexecution.labelselector

...
fields:
   matchexpressions     &lt;[]object&gt;
     matchexpressions is a list of label selector requirements.
     **the requirements are anded.**

"
57330661,where are the possible metrics for kubernetes autoscaling defined,"i'm trying to play with autoscaling scenarios (currently with microk8s single node personal cluster).

basic cpu scaling works fine.

for the more complex scenarios, i'm trying to follow the guide at https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics but i can't figure out how / where the possible pod metrics / object metrics are defined / documented. for example, .. where is ""packets-per-second"" documented .

i can kind of navigate via kubectl or manually exercising the rest apis but there has to be a better way.

thanks

apiversion: autoscaling/v2beta1
kind: horizontalpodautoscaler
metadata:
  name: php-apache
  namespace: default
spec:
  scaletargetref:
    apiversion: apps/v1
    kind: deployment
    name: php-apache
  minreplicas: 1
  maxreplicas: 10
  metrics:
  - type: resource
    resource:
      name: cpu
      target:
        type: averageutilization
        averageutilization: 50
  - type: pods
    pods:
      metric:
        name: packets-per-second ====&gt; where is this name defined/documented ?
      targetaveragevalue: 1k
  - type: object
    object:
      metric:
        name: requests-per-second ====&gt; where is this name defined/documented ?
      describedobject:
        apiversion: networking.k8s.io/v1beta1
        kind: ingress
        name: main-route
      target:
        kind: value
        value: 10k

",<kubernetes><scalability><autoscaling><kubernetes-pod>,57335593,7,"cpu or memory usage in resourcemetric is provided by kubelet and collected by metric-server
but for packets-per-second and requests-per-second, there are no official provider, so this field can actually be any value, depend on the non-official custom metrics api you deployed.
some popular custom metrics api are listed at  https://github.com/kubernetes/metrics/blob/release-1.22/implementations.md
"
51363674,kubernetes eks ingress and tls,"i'm trying to accomplish a very common task for an application: 

assign a certificate and secure it with tls/https.

i've spent nearly a day scouring thru documentation and trying multiple different tactics to get this working but nothing is working for me.

initially i setup nginx-ingress on eks using helm by following the docs here: https://github.com/nginxinc/kubernetes-ingress. i tried to get the sample app working (cafe) using the following config:

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: cafe-ingress
spec:
  tls:
  - hosts:
    - cafe.example.com
    secretname: cafe-secret
  rules:
  - host: cafe.example.com
    http:
      paths:
      - path: /tea
        backend:
          servicename: tea-svc
          serviceport: 80
      - path: /coffee
        backend:
          servicename: coffee-svc
          serviceport: 80


the ingress and all supported services/deploys worked fine but there's one major thing missing: the ingress doesn't have an associated address/elb:

name           hosts                 address   ports     age
cafe-ingress   cafe.example.com                80, 443   12h


service loadbalancers create elb resources, i.e.:

testnodeapp    loadbalancer   172.20.4.161     a64b46f3588fe...   80:32107/tcp     13h


however, the ingress is not creating an address. how do i get an ingress controller exposed externally on eks to handle tls/https? 
",<kubernetes><amazon-eks>,51410623,15,"i've replicated every step necessary to get up and running on eks with a secure ingress. i hope this helps anybody else that wants to get their application on eks quickly and securely.

to get up and running on eks:


deploy eks using the cloudformation template here: keep in mind that i've restricted access with the cidrip: 193.22.12.32/32. change this to suit your needs.
install client tools. follow the guide here.
configure the client. follow the guide here.
enable the worker nodes. follow the guide here.


you can verify that the cluster is up and running and you are pointing to it by running:

kubectl get svc

now you launch a test application with the nginx ingress.

note: everything is placed under the ingress-nginx namespace. ideally this would be templated to build under different namespaces, but for the purposes of this example it works.

deploy nginx-ingress:

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/cloud-generic.yaml


fetch rbac.yml from here. run:

kubectl apply -f rbac.yml

have a certificate and key ready for testing. create the necessary secret like so:

kubectl create secret tls cafe-secret --key mycert.key --cert mycert.crt -n ingress-nginx

copy coffee.yml from here. copy coffee-ingress.yml from here. update the domain you want to run this under. run them like so

kubectl apply -f coffee.yaml
kubectl apply -f coffee-ingress.yaml


update the cname for your domain to point to the address for:

kubectl get ing -n ingress-nginx -o wide

refresh dns cache and test the domain. you should get a secure page with request stats. i've replicated this multiple times so if it fails to work for you check the steps, config, and certificate. also, check the logs on the nginx-ingress-controller* pod. 

kubectl logs pod/nginx-ingress-controller-*********** -n ingress-nginx

that should give you some indication of what's wrong.
"
63412552,why readwriteonce is working on different nodes?,"our platform which runs on k8s has different components. we need to share the storage between two of these components (comp-a and comp-b) but by mistake, we defined the pv and pvc for that as readwriteonce and even when those two components were running on different nodes everything was working and we were able to read and write to the storage from both components.
based on the k8s docs the readwriteonce can be mounted to one node and we have to use readwritemany:

readwriteonce -- the volume can be mounted as read-write by a single node
readonlymany -- the volume can be mounted read-only by many nodes
readwritemany -- the volume can be mounted as read-write by many nodes&quot;

so i am wondering why everything was working fine while it shouldn't?
more info:
we use nfs for storage and we are not using dynamic provisioning and below is how we defined our pv and pvc (we use helm):
- apiversion: v1
  kind: persistentvolume
  metadata:
    name: gstreamer-{{ .release.namespace }}
  spec:
    capacity:
      storage: 10gi
    accessmodes:
      - readwriteonce
    persistentvolumereclaimpolicy: recycle
    mountoptions:
      - hard
      - nfsvers=4.1
    nfs:
      server: {{ .values.global.nfsserver }}
      path: /var/nfs/general/gstreamer-{{ .release.namespace }}

- apiversion: v1
  kind: persistentvolumeclaim
  metadata:
    name: gstreamer-claim
    namespace: {{ .release.namespace }}
  spec:
    volumename: gstreamer-{{ .release.namespace }}
    accessmodes:
      - readwriteonce
    resources:
      requests:
        storage: 10gi

update
the output of some kubectl commands:
$ kubectl get -n 149 pvc
name              status   volume                                     capacity   access modes   storageclass   age
gstreamer-claim   bound    gstreamer-149                              10gi       rwo                           177d


$ kubectl get -n 149 pv
name                                       capacity   access modes   reclaim policy   status   claim                                       storageclass   reason   age
gstreamer-149                              10gi       rwo            recycle          bound    149/gstreamer-claim                                                 177d


i think somehow it takes care of it because the only thing the pods need to do is connecting to that ip.
",<kubernetes><kubernetes-pod><persistent-volumes><kubernetes-pvc>,63524679,15,"it's quite misleading concept regarding accessmode, especially in nfs.
in kubernetes persistent volume docs it's mentioned that nfs supports all types of access. rwo, rxx and rwx.
however accessmode is something like matching criteria, same as storage size. it's described better in openshift access mode documentation

a persistentvolume can be mounted on a host in any way supported by the resource provider. providers have different capabilities and each pv’s access modes are set to the specific modes supported by that particular volume. for example, nfs can support multiple read-write clients, but a specific nfs pv might be exported on the server as read-only. each pv gets its own set of access modes describing that specific pv’s capabilities.


claims are matched to volumes with similar access modes. the only two matching criteria are access modes and size. a claim’s access modes represent a request. therefore, you might be granted more, but never less. for example, if a claim requests rwo, but the only volume available is an nfs pv (rwo+rox+rwx), the claim would then match nfs because it supports rwo.


direct matches are always attempted first. the volume’s modes must match or contain more modes than you requested. the size must be greater than or equal to what is expected. if two types of volumes, such as nfs and iscsi, have the same set of access modes, either of them can match a claim with those modes. there is no ordering between types of volumes and no way to choose one type over another.


all volumes with the same modes are grouped, and then sorted by size, smallest to largest. the binder gets the group with matching modes and iterates over each, in size order, until one size matches.

in the next paragraph:

a volume’s accessmodes are descriptors of the volume’s capabilities. they are not enforced constraints. the storage provider is responsible for runtime errors resulting from invalid use of the resource.


for example, nfs offers readwriteonce access mode. you must mark the claims as read-only if you want to use the volume’s rox capability. errors in the provider show up at runtime as mount errors.

another example is that you can choose a few accessmodes as it is not constraint but a matching criteria.
$ cat &lt;&lt;eof | kubectl create -f -
&gt; apiversion: v1
&gt; kind: persistentvolumeclaim
&gt; metadata:
&gt;   name: exmaple-pvc
&gt; spec:
&gt;   accessmodes:
&gt;     - readonlymany
&gt;     - readwritemany
&gt;     - readwriteonce
&gt;   resources:
&gt;     requests:
&gt;       storage: 1gi
&gt; eof

or as per gke example:
$ cat &lt;&lt;eof | kubectl create -f -
apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: exmaple-pvc-rwo-rom
spec:
  accessmodes:
    - readonlymany
    - readwriteonce
  resources:
    requests:
      storage: 1gi
eof               
persistentvolumeclaim/exmaple-pvc-rwo-rom created

pvc output
$ kubectl get pvc
name                  status    volume                                     capacity   access modes   storageclass   age
exmaple-pvc           pending                                                                        standard       2m18s
exmaple-pvc-rwo-rom   bound     pvc-d704d346-42b3-4090-af96-aebeee3053f5   1gi        rwo,rox        standard       6s
persistentvolumeclaim/exmaple-pvc created

exmaple-pvc is in pending state as default gke gcepersistentdisk its not supporting rreadwritemany.
warning  provisioningfailed  10s (x5 over 69s)  persistentvolume-controller  failed to provision volume with storageclass &quot;standard&quot;: invalid accessmodes [readonlymany readwritemany readwr
iteonce]: only accessmodes [readwriteonce readonlymany] are supported

however second pvc exmaple-pvc-rwo-rom were created and you can see it have 2 access mode rwo, rox.
in short accessmode is more like requirement for pvc/pv to bind. if nfs which is providing all access modes binds with rwo it fulfill requirement, however it will work as rwm as nfs providing that capability.
hope it answered cleared a bit.
in addition you can check other stackoverflow threads regarding accessmode
"
58256778,minikube ingress insisting on https despite tls not configured,"i want to test my (helm packaged) kubernetes application locally using minikube, with a kubernetes ingress to proxy http to the http services my application provides. but this is not working because the ingress (or ingress controller) is insisting that connections are https, despite me not requesting tls. how do i ensure the ingress allows http?

kubectl get --output=yaml ingress shows that there is an ingress resource, for http, without tls:

apiversion: v1
items:
- apiversion: extensions/v1beta1
  kind: ingress
  metadata:
    creationtimestamp: ""2019-10-06t10:54:38z""
    generation: 1
    labels:
      app.kubernetes.io/instance: quarreling-shrimp
      app.kubernetes.io/managed-by: tiller
      app.kubernetes.io/name: mc
      app.kubernetes.io/version: 2.3.1-snapshot
      helm.sh/chart: mc-2.3.1
    name: quarreling-shrimp-mc
    namespace: default
    resourceversion: ""126597""
    selflink: /apis/extensions/v1beta1/namespaces/default/ingresses/quarreling-shrimp-mc
    uid: 296f8d69-8f40-49c5-b352-acbc6ec1cc19
  spec:
    rules:
    - http:
        paths:
        - backend:
            servicename: quarreling-shrimp-mc-be-svc
            serviceport: 8080
          path: /api
        - backend:
            servicename: quarreling-shrimp-mc-fe
            serviceport: 80
          path: /
  status:
    loadbalancer:
      ingress:
      - ip: 192.168.122.66
kind: list
metadata:
  resourceversion: """"
  selflink: """"


but when i try to access the application using http, the response tries to redirect to use https. this is the output of curl -i 192.168.122.66:

http/1.1 308 permanent redirect
server: openresty/1.15.8.1
date: sun, 06 oct 2019 11:22:40 gmt
content-type: text/html
content-length: 177
connection: keep-alive
location: https://192.168.122.66/

&lt;html&gt;
&lt;head&gt;&lt;title&gt;308 permanent redirect&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;center&gt;&lt;h1&gt;308 permanent redirect&lt;/h1&gt;&lt;/center&gt;
&lt;hr&gt;&lt;center&gt;openresty/1.15.8.1&lt;/center&gt;
&lt;/body&gt;
&lt;/html&gt;

",<kubernetes><https><minikube><kubernetes-ingress>,58264928,1,"minikube uses an nginx ingress controller. that controller does a permanent redirect (http status code 308) from initial http to https:


  by default the controller redirects (308) to https if tls is enabled for that ingress


but, as you point out, the documentation suggests it should not do a redirect in your case because you have not enabled tls.

i've observed that once i add host: field to the particular ingress resource without tls enabled, the resulting curl command returns http/1.1 200 with no redirect action:

  rules:
  - host: example.com
    http:
      paths:
      - backend:
          servicename: some-svc
          serviceport: 80
        path: /


$ curl -v http://$(kubectl get svc -l component=controller -o jsonpath='{.items[0].status.loadbalancer.ingress[0].ip}') -h 'host: example.com'

&gt; get / http/1.1
&gt; host: example.com
&gt; user-agent: curl/7.47.0
&gt; accept: */*
&gt; 
&lt; http/1.1 200


but an http get without a matching host causes a redirect:

$ curl -v http://$(kubectl get svc -l component=controller -o jsonpath='{.items[0].status.loadbalancer.ingress[0].ip}')

&gt; get / http/1.1
&gt; host: xx.xx.xx.xx
&gt; user-agent: curl/7.47.0
&gt; accept: */*
&gt; 
&lt; http/1.1 308 permanent redirect


therefore, i suppose that although the host: field is optional, if you don't specify it in the target ingress resource, the ingress controller will not properly recognize tls related settings.
"
54155534,kubernetes eviction manager evicting control plane pods to reclaim ephemeral storage,"i am using kubernetes v1.13.0. my master is also functioning as a worker-node, so it has workload pods running on it, apart from control plane pods.

the kubelet logs on my master show the following lines:


eviction_manager.go:340] eviction manager: must evict pod(s) to reclaim ephemeral-storage
eviction_manager.go:358] eviction manager: pods ranked for eviction: kube-controller-manager-vm2_kube-system(1631c2c238e0c5117acac446b26d9f8c), kube-apiserver-vm2_kube-system(ce43eba098d219e13901c4a0b829f43b), etcd-vm2_kube-system(91ab2b0ddf4484a5ac6ee9661dbd0b1c)


once the kube-apiserver pod is evicted, the cluster becomes unusable.

what can i do to fix this? should i add more ephemeral storage? how would i go about doing that? that means adding more space to the root partition on my host?

my understanding is that ephemeral storage consists of /var/log and /var/lib/kubelet folders, which both come under the root partition.

a df -h on my host shows:


filesystem                               size  used avail use% mounted on
/dev/vda1                                 39g   33g  6.2g  85% /


so it looks like the root partition has lot of memory left, and there is no disk pressure. so what is causing this issue? some of my worker pods must be doing something crazy with storage, but it's still 6g seems like plenty of room.

will adding more space to the root partition fix this issue temporarily?

kubectl describe vm2 gives the following info:


conditions:
  type             status  lastheartbeattime                 lasttransitiontime                reason                       message
  ----             ------  -----------------                 ------------------                ------                       -------
  memorypressure   false   fri, 11 jan 2019 21:25:43 +0000   wed, 05 dec 2018 19:16:41 +0000   kubelethassufficientmemory   kubelet has sufficient memory available
  diskpressure     false   fri, 11 jan 2019 21:25:43 +0000   fri, 11 jan 2019 20:58:07 +0000   kubelethasnodiskpressure     kubelet has no disk pressure
  pidpressure      false   fri, 11 jan 2019 21:25:43 +0000   wed, 05 dec 2018 19:16:41 +0000   kubelethassufficientpid      kubelet has sufficient pid available
  ready            true    fri, 11 jan 2019 21:25:43 +0000   thu, 06 dec 2018 17:00:02 +0000   kubeletready                 kubelet is posting ready status. apparmor enabled
capacity:
 cpu:                8
 ephemeral-storage:  40593708ki
 hugepages-1gi:      0
 hugepages-2mi:      0
 memory:             32946816ki
 pods:               110
allocatable:
 cpu:                8
 ephemeral-storage:  37411161231
 hugepages-1gi:      0
 hugepages-2mi:      0
 memory:             32844416ki
 pods:               110


it seems to me that there was pressure on ephemeral-storage, and the eviction manager is trying to reclaim some storage by evicting least recently used pods. but it should not evict the control plane pods, otherwise cluster is unusable.

currently, the kubelet evicts the control plane pods. then i try to manually start the apiserver and other control plane pods by adding and removing a space in the /etc/kubernetes/manifests files. this does start the apiserver, but then it again gets evicted. ideally, the kubelet should ensure that the static pods in /etc/kubernetes/manifests are always on and properly managed.

i am trying to understand what is going on here, and how to fix this issue, so that my kubernetes cluster becomes more robust, and i don't have to keep manually restarting the apiserver.
",<kubernetes><kubernetes-apiserver>,54443743,11,"i had this same problem and solved it by changing the threshold for evictionhard.

looking at /etc/systemd/system/kubelet.service.d/10-kubeadm.conf i have:

[service]
environment=""kubelet_kubeconfig_args=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf""
environment=""kubelet_config_args=--config=/var/lib/kubelet/config.yaml""
# this is a file that ""kubeadm init"" and ""kubeadm join"" generates at runtime, populating the kubelet_kubeadm_args variable dynamically
environmentfile=-/var/lib/kubelet/kubeadm-flags.env
# this is a file that the user can use for overrides of the kubelet args as a last resort. preferably, the user should use
# the .noderegistration.kubeletextraargs object in the configuration files instead. kubelet_extra_args should be sourced from this file.
environmentfile=-/etc/default/kubelet
execstart=
execstart=/usr/bin/kubelet $kubelet_kubeconfig_args $kubelet_config_args $kubelet_kubeadm_args $kubelet_extra_args


so i see my config file for kubelet is /var/lib/kubelet/config.yaml 

opening that i changed evitionhard settings to be (i think they were 10 or 15% before): 

...
evictionhard:
  imagefs.available: 1%
  memory.available: 100mi
  nodefs.available: 1%
  nodefs.inodesfree: 1%
...




there is also the --experimental-allocatable-ignore-eviction (https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/) setting which should completely disable eviction.
"
70007478,kubernetes multi-container pod termination process,"i have a multi-container pod in k8s, let's call them a and b. when stopping the pod, a must stop before b because a needs b until it's off.
to do that, i registered a prestop hook on a so a can gracefully stop before b.
however i'm not sure this is a good solution, because i miss some information i can't find in k8s documentation:
what happens when a multi-container pod is stopped?

all containers prestop hooks are called, then when they are all over all containers receive sigterm, or
in parallel, all containers receive prestop if they have one or directly sigterm if they don't?

in the second case, prestop is useless for what i want to do as b will be instantly killed.
",<kubernetes><kubernetes-pod><termination>,70027149,4,"typically, during pod deletion, the container runtime sends a term signal to the main process in each container.
according to the official documentation:


if one of the pod's containers has defined a  prestop  hook,
the kubelet runs that hook inside of the container.

the kubelet triggers the container runtime to send a term signal to process 1 inside each container.



this numeration can confuse - looks like term signal will be sent only after prestop  hook will be finished.
i decided to check the order of work with a simple example below.
apiversion: v1
kind: pod
metadata:
  name: lifecycle-demo
spec:
  restartpolicy: never
  volumes:
  - name: config
    configmap:
      name: nginx-conf
  containers:
  - name: container-1
    image: nginx
    lifecycle:
      prestop:
        exec:
          command: [&quot;/bin/sleep&quot;,&quot;15&quot;]
    ports:
    - containerport: 80
  - name: container-2
    image: nginx
    ports:
    - containerport: 81
    volumemounts:
    - name: config
      mountpath: /etc/nginx/conf.d
  terminationgraceperiodseconds: 30

container-1 has prestop  hook for 15 seconds delay.
i've connected to both containers to see behavior during pod deletion.
result
after pod deletion:

container-1 worked for 15 seconds, before the connection was lost

container-2 immediately lost connection


conclusion
if the container has a prestop  hook, it will try to execute it. only then it will receive term signal. the main condition in this case: the grace period has not expired.
if the container doesn't have a  prestop  hook, it will receive term signal immediately after the command to remove the pod. thus, it will not wait whileprestop  hook will be executed for another container.

note: the containers in the pod receive the term signal at different times and in an arbitrary order. if the order of shutdowns
matters, consider using a prestop hook to synchronize.

"
66531779,kubernetes clean way to define environment variables for multiple environments,"i'm working with a web app and there are multiple environments that we deploy this to; prod, staging, multiple qa environments, and even some developer environments when necessary. we're migrating to kubernetes from elastic beanstalk and trying to set up the config/yaml files in as clean a way as we can. the issue is, we've defined a yaml file for each environment that has some secrets in it, and this is getting a little bit hard to maintain with lots of copy/paste. below is an example of the files/contents:
disclaimer - this work was mostly done by the devops team and i'm a web engineer trying to assist them, so i will try to answer any questions as best as i can, but i may not have all the right answers
folder structure:
- k8s // root folder
 - deployment.yaml
 - production
   - production-params.yaml
 - staging
   - staging-1-params.yaml
   - staging-2-params.yaml
   - qa-1-params.yaml
 - developers
   - some-dev-params.yaml

the contents of each one of these *-params.yaml files is almost identical, let's look at a couple examples.
production-params.yaml
apiversion: 'kubernetes-client.io/v1'
kind: externalsecret
metadata:
  name: prod-params
spec:
  backendtype: systemmanager
  data:
    - key:  /xxx/production/env_var_1
      name: env_var_1
    - key:  /xxx/production/env_var_2
      name: env_var_2
    - key:  /xxx/production/env_var_3
      name: env_var_3
    - key:  /xxx/production/env_var_4
      name: env_var_4

staging-1-params.yaml
apiversion: 'kubernetes-client.io/v1'
kind: externalsecret
metadata:
  name: prod-params
spec:
  backendtype: systemmanager
  data:
    - key:  /xxx/staging1/env_var_1
      name: env_var_1
    - key:  /xxx/staging1/env_var_2
      name: env_var_2
    - key:  /xxx/staging1/env_var_3
      name: env_var_3
    - key:  /xxx/staging1/env_var_4
      name: env_var_4

and every other params file is like this, with only the file paths in the 'key' changing, but its almost identical. is there a way we can make these somewhat dynamic or cleaner? i'm not a devops/k8s pro and did some research, seems like helm can be helpful here but not sure how to use it to solve this problem. i read a tutorial that was a little helpful but i'm still confused. if anyone knows of any resources or has solved this problem in the past, i'd really appreciate the help
",<kubernetes><kubernetes-helm>,66575531,3,"this is the sort of replacement helm is good at.  if you write a helm chart, you can use its templating syntax to fill in a specific part of the yaml:
# templates/external-secret.yaml
apiversion: 'kubernetes-client.io/v1'
kind: externalsecret
metadata:
  name: prod-params
spec:
  backendtype: systemmanager
  data:
    - key:  /xxx/{{ .values.environment }}/env_var_1
      name: env_var_1
    - key:  /xxx/{{ .values.environment }}/env_var_2
      name: env_var_2
{{/* etc. */}}

you can then provide a yaml file of settings per environment:
# production.yaml
environment: production

# staging-1.yaml
environment: staging-1

when you go to deploy the application, you can provide one of these files as a command-line option, and the contents of the file will be visible to the templating engine as .values.
helm install the-app . -f staging-1.yaml

that approach would let you put all of the things that are &quot;the same&quot; in the templates directory, and all of the things that are different per environment in the per-environment yaml values files.
"
75802247,why is nginx's $request_uri empty?,"i'm using nginx (v4.5.2) on a kubernetes cluster, and i'm trying to configure it to redirect non-www urls to the www equivalent. for example...

https://example.com  -&gt;  https://www.example.com
https://example.com/about  -&gt;  http://www.example.com/about

so this is what i've added to the annotations (i'll carry on using example.com as the url host)...
annotations:
  ...
  nginx.ingress.kubernetes.io/from-to-www-redirect: 'true'
  nginx.ingress.kubernetes.io/configuration-snippet: |
    if ($host = 'example.com' ) {
      rewrite ^ https://www.$request_uri permanent;
    }

however, if i now navigate to https://example.com i get redirected to https://www..
the docs say $request_uri contains ...

full original request uri (with arguments)

... so why is $request_uri apparently empty in my case?
",<kubernetes><nginx><kubernetes-ingress>,75802491,2,"$request_uri will contain the path with arguments. to get your desired redirect you probably want to use $host$request_uri.
for some examples of usage of $request_uri you can search it on https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/ to see examples or https://www.webhosting24.com/understanding-nginx-request_uri/ also explains it quite well.
"
65716901,kubectl command to find a particular pod status as ready,"i wanted to hit a command which searches pod with the service name and identify its pod's status as &quot;ready&quot;
i tried some of the commands but it does not work and it does not search with service-name.
kubectl get svc | grep my-service | --output=&quot;jsonpath={.status.containerstatuses[*].ready}&quot; | cut -d' ' -f2

i tried to use the loop also, but the script does not give the desired output.
can you please help me figure out the exact command?
",<kubernetes><containers><kubernetes-helm><kubectl><kubernetes-pod>,65717627,1,"every service create a endpoints which contain the podip and other info for service. you can just use that endpoints to get you pods.  . it will show you the ready pod for your my-service.
use this command:
kubectl get endpoints -n &lt;name_space&gt; &lt;service_name&gt; -o json | jq -r 'select(.subsets != null) | select(.subsets[].addresses != null) | .subsets[].addresses[].targetref.name'

for you the command will be:
kubectl get endpoints my-service -o json | jq -r 'select(.subsets != null) | select(.subsets[].addresses != null) | .subsets[].addresses[].targetref.name'

you can run the script for getting the pod status
#!/usr/bin/env bash
for podname in $(kubectl get endpoints my-service -o json | jq -r 'select(.subsets != null) | .subsets[].addresses[].targetref.name')
do
kubectl get pods -n demo  $podname  -o json | jq -r ' select(.status.conditions[].type == &quot;ready&quot;) | .status.conditions[].type ' | grep -x ready

done

"
72809498,enable tab auto completion for kubectl in bash function,"given a bash function in .bashrc such as
kgp () {
  kubectl get po -n $1 $2
}

is it possible to have kubectl auto complete work for k8s resources such as namespaces/pods? as an example if i use
kubectl get po -n nsprefix podprefix

i can tab auto complete the prefix. whereas with the positional parameters when i call
kgp nsprefix podprefix

i have to type out the entire resource name.
",<bash><kubernetes><kubectl><bash-completion>,72809792,1,"yes, that's because bash-completion only understands known commands, not aliases or new functions that you have made up. you will experience the same thing with a trivial example of alias whee=/bin/ls and then whee &lt;tab&gt; will do nothing because it doesn't &quot;recurse&quot; into that alias, and for sure does not attempt to call your function in order to find out what arguments it could possibly accept. that could potentially be catastrophic
you're welcome to create a new complete handler for your custom kgp, but that's the only way you'll get the desired behavior
_kgp_completer() {
    local cur prev words cword

    compreply=()
    _get_comp_words_by_ref -n : cur prev words cword
    if [[ $cword == 1 ]] &amp;&amp; [[ -z &quot;$cur&quot; ]]; then
        compreply=( $(echo ns1 ns2 ns3) )
    elif [[ $cword == 2 ]] &amp;&amp; [[ -z &quot;$cur&quot; ]]; then
        compreply=( $(echo pod1 pod2 pod3) )
    fi
    echo &quot;debug: cur=$cur prev=$prev words=$words cword=$cword compreply=${compreply[@]}&quot; &gt;&amp;2
}
complete -f _kgp_completer kgp

"
69516047,unable to view docker images on google kubernetes node v1.21.4-gke.2300,"i created a new kubernetes cluster (gke) and installed an application using helm.
i was able to locate the gke-node on which my pod was deployed using the command,
kubectl get pod -n namespace -o wide
post that i logged on to the kubernetes-node, however on this node i am unable to view the docker images. this is the case on v1.21.4-gke.2300
in the older-version v1.19.13-gke.1200, i was able to observe the docker-images on nodes when they were pulled from repository
i can view the list of docker-images on v1.21.4-gke.2300 with the command
kubectl get pods -n geo-test -o jsonpath=&quot;{.items[*].spec.containers[*].image}&quot; | tr -s '[[:space:]]' '\n' |  sort |  uniq -c
but i would like to know where in the cluster are these images getting stored and why i am not able to observe them in the node like i did in the older version
my reason for asking is, because in version v1.19.13-gke.1200, i was able to perform minor changes in the docker-image, build a custom-image and use that for installation instead of storing the images in the gcr and pulling it from there
any suggestion on how to go about it in the new

",<docker><kubernetes><google-kubernetes-engine>,69516458,5,"starting with gke node version 1.19, the default node image for linux nodes is the container-optimized os with containerd (cos_containerd) variant instead of the container-optimized os with docker (cos) variant.
now instead of docker commands you can use crictl. refer to the crictl user guide for the complete set of supported features and usage information.
specifically, you can run crictl images to list the images, available on the node.
"
71760171,how to kubectl re-apply deployment,"i want to update my pod because there is a new image uploaded to docker registry with latest tag.
i am currently doing this:
kubectl delete -f deployment.yaml
kubectl apply -f deployment.yaml

if i do:
kubectl apply -f deployment.yaml

it says my deployment is unchanged.
however, i want make my service alive even for a second. isn't there a way i could do something like the following?
kubectl re-apply -f deployment.yaml

",<kubernetes><kubectl>,71760634,14,"you can just delete the pod once and restart the pod so it will change the image and pull new version from docker registry.
however, make sure imagepullpolicy set to always in your deployment.yaml
or else you need to update one minor field into deployment.yaml and keep imagepullpolicy to always in that case apply will change the deployment.
example :
spec:
  containers:
  - name: test
    image: image:latest
    ports:
    - containerport: 80
    imagepullpolicy: always
  imagepullsecrets:
    - name: docker-secret

option 2
kubectl rollout restart deployment/&lt;deployment-name&gt;

read more at : how do i force kubernetes to re-pull an image?
"
62601666,why my gke node pool does not auto-scale down?,"i've got a preemptible node pool which is clearly under-utilized:

the node pool hosts a deployment with hpa with the following setup:
apiversion: apps/v1
kind: deployment
metadata:
  name: backend
  labels:
    app: backend
spec:
  replicas: 1
  selector:
    matchlabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      initcontainers:
      - name: wait-for-database
        image: ### image ###
        command: ['bash', 'init.sh']
      containers:
      - name: backend
        image: ### image ###
        command: [&quot;bash&quot;, &quot;entrypoint.sh&quot;]
        imagepullpolicy: always
        resources:
          requests:
            memory: &quot;200m&quot;
            cpu: &quot;50m&quot;
        ports:
        - name: probe-port
          containerport: 8080
          hostport: 8080
        volumemounts:
          - name: static-shared-data
            mountpath: /static
        readinessprobe:
          httpget:
            path: /readiness/
            port: probe-port
          failurethreshold: 5
          initialdelayseconds: 10
          periodseconds: 10
          timeoutseconds: 5
      - name: nginx
        image: nginx:alpine
        resources:
          requests:
            memory: &quot;400m&quot;
            cpu: &quot;20m&quot;
        ports:
        - containerport: 80
        volumemounts:
        - name: nginx-proxy-config
          mountpath: /etc/nginx/conf.d/default.conf
          subpath: app.conf
        - name: static-shared-data
          mountpath: /static
      volumes:
      - name: nginx-proxy-config
        configmap:
          name: backend-nginx
      - name: static-shared-data
        emptydir: {}
      nodeselector:
        cloud.google.com/gke-nodepool: app-dev
      tolerations:
      - effect: noschedule
        key: workload
        operator: equal
        value: dev
---
apiversion: autoscaling/v2beta1
kind: horizontalpodautoscaler
metadata:
  name: backend
  namespace: default
spec:
  maxreplicas: 12
  minreplicas: 8
  scaletargetref:
    apiversion: extensions/v1beta1
    kind: deployment
    name: backend
  metrics:
  - resource:
      name: cpu
      targetaverageutilization: 50
    type: resource
---

the node pool also has the toleration label.
the hpa utilization shows this:
name              reference                    targets   minpods   maxpods   replicas   age
backend-develop   deployment/backend-develop   10%/50%   8         12        8          38d

but the node pool does not scale down for about a day. no heavy load on this deployment:
name                             status   roles    age     version
gke-dev-app-dev-fee1a901-fvw9    ready    &lt;none&gt;   22h     v1.14.10-gke.36
gke-dev-app-dev-fee1a901-gls7    ready    &lt;none&gt;   22h     v1.14.10-gke.36
gke-dev-app-dev-fee1a901-lf3f    ready    &lt;none&gt;   24h     v1.14.10-gke.36
gke-dev-app-dev-fee1a901-lgw9    ready    &lt;none&gt;   3d10h   v1.14.10-gke.36
gke-dev-app-dev-fee1a901-qxkz    ready    &lt;none&gt;   3h35m   v1.14.10-gke.36
gke-dev-app-dev-fee1a901-s10l    ready    &lt;none&gt;   22h     v1.14.10-gke.36
gke-dev-app-dev-fee1a901-sj4d    ready    &lt;none&gt;   22h     v1.14.10-gke.36
gke-dev-app-dev-fee1a901-vdnw    ready    &lt;none&gt;   27h     v1.14.10-gke.36

there's no affinity settings for this deployment and node pool. some of the nodes easily pack several same pods, but others just hold one pod for hours, no scale down happens.
what could be wrong?
",<kubernetes><google-kubernetes-engine><gcloud><autoscaling><hpa>,62614390,1,"the issue was:
hostport: 8080

this lead to failedscheduling didn't have free ports.
that's why the nodes were kept online.
"
71260800,"how to update this configmap with kubectl patch command, without kubectl edit command","below is a k8s configmap configuration, i need to use the kubectl patch command to update it, but don't know how to do it
# kubectl get configmap myconfig -o yaml 
apiversion: v1
kind: configmap
metadata:
  name: debug-config
data:
  config.json: |-
    {
        &quot;portservicedms&quot;: 500,
        &quot;buggdse&quot;: {
            &quot;enable&quot;: false
        },
        &quot;ghinterval&quot;: {
            &quot;start&quot;: 5062,
            &quot;end&quot;: 6000
        },
        &quot;lopfdfhd&quot;: false,
        &quot;chf&quot;: {
            &quot;drivername&quot;: &quot;mysql&quot;
        },
        &quot;paralbac&quot;: {
            &quot;loginurl&quot;: &quot;https://127.0.0.1:7788&quot;,
            &quot;sources&quot;: [
                {
                    &quot;servicename&quot;: &quot;hopyyu&quot;,
                    &quot;status&quot;: false,
                    &quot;serviceurl&quot;: &quot;https://127.0.0.1:9090/ft/test&quot;
                },
                {
                    &quot;sourcename&quot;: &quot;bgudreg&quot;,
                    &quot;status&quot;: false, # need to patch here to true
                    &quot;serviceurl&quot;: &quot;https://127.0.0.1:9090&quot;  # need to patch here to  &quot;https://192.168.123.177:45663&quot;
                }
            ]
        }
    }


i searched on google site to find a similar way to deal with it, but it doesn't work
i tried this command and it doesn't work：
kubectl get cm myconfig -o json | jq -r '.data.&quot;config.json&quot;.paralbac.sources[1]={&quot;sourcename&quot;: &quot;bgudreg&quot;, &quot;status&quot;: true, &quot;serviceurl&quot;: &quot;https://192.168.123.177:45663&quot;}' | kubectl apply -f -


i reduced the command to here：
kubectl get cm myconfig -o json | jq -r '.data.&quot;config.json&quot; # it works (the double quotes are for escaping the dot)

kubectl get cm myconfig -o json | jq -r '.data.&quot;config.json&quot;.paralbac # it can't work：   jq: error (at &lt;stdin&gt;:18): cannot index string with string &quot;paralbac&quot;



so, i think my current problem is in how to keep working after escaped symbols in jq
",<kubernetes><kubectl>,71262466,1,"here's how you can update the configmap in the question:
myconfig=$(mktemp) \
  &amp;&amp; kubectl get configmap debug-config -o jsonpath='{.data.config\.json}' \
  | jq '.paralbac.sources[1].status = true' \
  | jq '.paralbac.sources[1].serviceurl = &quot;https://192.168.123.177:45663&quot;' &gt; myconfig \
  &amp;&amp; kubectl create configmap debug-config --from-file=config.json=myconfig --dry-run=client -o yaml | kubectl replace -f - \
  &amp;&amp; rm myconfig

now do kubectl get configmap debug-config -o jsonpath='{.data.config\.json}' | jq will show you the updated config.json in the configmap.
"
71502398,what is the expected behavior of running multiple `kubectl rollout restart` commands simultaneously?,"context: we have multiple processes that are watching the same feature flag to determine whether a restart is required, and trying to determine if we need to ensure that exactly one process calls kubectl rollout restart.
suppose n processes simultaneously call kubectl rollout restart on the same deployment, for n &gt; 3.
which of the following behaviors is expected to happen?

the deployment goes down entirely as the overlapping restarts cause different pods to be deleted.
all the restarts eventually run, but they run serially.
some number of restarts m, where m &lt; n will run serially.
something else.

i have searched around but haven't found documentation about this behavior, so a pointer would be greatly appreciated.
",<kubernetes><kubectl>,71507012,4,"i didn't find the official documentation explaining how kubernetes will behave as presented in your question.
however, i wrote a script that will spawn the 5 rollout restart command in parallel and used the deployment.yaml below for testing, with rollingupdate as strategy and maxsurge = maxunavailable = 1.
deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: webapp1
spec:
  strategy:
    rollingupdate:
      maxsurge: 1
      maxunavailable: 1
    type: rollingupdate
  replicas: 10
  selector:
    matchlabels:
      app: webapp1
  template:
    metadata:
      labels:
        app: webapp1
    spec:
      containers:
      - name: webapp1
        image: katacoda/docker-http-server:latest
        ports:
        - containerport: 80

script.sh
for var in 1..5; do
        kubectl rollout restart deployment webapp1 &gt; /dev/null 2&gt;&amp;1 &amp;
done

then executed the script and watched the behavior
    . script.sh; watch -n .5 kubectl get po

the watch command revealed that the kubernetes maintained the desired state as commanded by the deployment.yaml. at no time, fewer than 9 pods were in the running state. screenshots were taken few seconds apart


so, from this experiment, i deduce that no matter how many parallel rollout-restarts occur, kubernetes controller manager is smart enough to still maintain the desired state.
hence, the expected behavior will be as described in your manifest.
"
54125760,unable to fetch broker id using kubectl command,"i want to fetch the list of broker ids in a cluster using kubectl exec command.

i am able to run the commands from inside the pod and fetch the list of broker ids, however i need to find the list without having to go inside.

i am using kafka helm charts from incubator and kubernetes distribution which comes along with docker for mac.

kubectl exec hissing-warthog-kafka-1 -- /usr/bin/zookeeper-shell hissing-warthog-zookeeper:2181 &lt;&lt;&lt; ""ls /brokers/ids""


expected result:
welcome to zookeeper!
jline support is enabled

watcher::

watchedevent state:syncconnected type:none path:null
[zk: hissing-warthog-zookeeper:2181(connected) 0] ls /brokers/ids
[0, 1, 2]

actual result:
connecting to hissing-warthog-zookeeper:2181
welcome to zookeeper!
jline support is enabled

watcher::

watchedevent state:syncconnected type:none path:null
[zk: hissing-warthog-zookeeper:2181(connected) 0]
",<kubernetes><apache-kafka><apache-zookeeper><kubectl><kubernetes-helm>,54126780,2,"it should work in following way:

kubectl exec hissing-warthog-kafka-1 -- /usr/bin/zookeeper-shell hissing-warthog-zookeeper:2181 -c ls /brokers/ids


hope this helps.
"
68379689,kubenetes accsess api web,"im new to kub and i converted my envirement from docker-compose,
i have a pod that have python code  - if i use my docker on the same host i can accsess
but when its on pod no traffic goes inside,
kubectl config view
apiversion: v1
clusters:
- cluster:
    certificate-authority-data: data+omitted
    server: https://10.10.10.130:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: redacted
    client-key-data: redacted

api-service.yaml:
apiversion: v1
kind: service
metadata:
  annotations:
    kompose.cmd: /snap/kompose/19/kompose-linux-amd64 convert --volumes hostpath
    kompose.version: 1.21.0 (992df58d8)
  creationtimestamp: null
  labels:
    io.kompose.service: api
  name: api
spec:
  ports:
  - name: &quot;5001&quot;
    port: 5001
    targetport: 5001
  selector:
    io.kompose.service: api
status:
  loadbalancer: {}

api-deployment.yaml:
apiversion: apps/v1
kind: deployment
metadata:
  annotations:
    kompose.cmd: /snap/kompose/19/kompose-linux-amd64 convert --volumes hostpath
    kompose.version: 1.21.0 (992df58d8)
  creationtimestamp: null
  labels:
    io.kompose.service: api
  name: api
spec:
  replicas: 1
  selector:
    matchlabels:
      io.kompose.service: api
  strategy:
    type: recreate
  template:
    metadata:
      annotations:
        kompose.cmd: /snap/kompose/19/kompose-linux-amd64 convert --volumes hostpath
        kompose.version: 1.21.0 (992df58d8)
      creationtimestamp: null
      labels:
        io.kompose.service: api
    spec:
      containers:
      - image: 127.0.0.1:5000/api:latest
        imagepullpolicy: &quot;never&quot;
        name: api
        ports:
        - containerport: 5001
        resources: {}
        volumemounts:
        - mountpath: /base
          name: api-hostpath0
      restartpolicy: always
      serviceaccountname: &quot;&quot;
      volumes:
      - hostpath:
          path: /root/ansible/api/base
        name: api-hostpath0
status: {}

pod log:
 * serving flask app 'server' (lazy loading)
 * environment: production
   warning: this is a development server. do not use it in a production deployment.
   use a production wsgi server instead.
 * debug mode: on
 * running on all addresses.
   warning: this is a development server. do not use it in a production deployment.
 * running on http://10.244.0.17:5001/ (press ctrl+c to quit)
 * restarting with stat
 * debugger is active!
 * debugger pin: 553-272-086

i tried reaching what the config view shows and i get this :
https://10.10.10.130:6443/
{
  &quot;kind&quot;: &quot;status&quot;,
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    
  },
  &quot;status&quot;: &quot;failure&quot;,
  &quot;message&quot;: &quot;forbidden: user \&quot;system:anonymous\&quot; cannot get path \&quot;/\&quot;&quot;,
  &quot;reason&quot;: &quot;forbidden&quot;,
  &quot;details&quot;: {
    
  },
  &quot;code&quot;: 403
}

the path to reach through container is :
https://10.10.10.130:5001/
it does not reach container and says like site does not exists -
again this works on docker container so what am i missing ?
thanks
--edit--
if i curl http://10.244.0.17:5001/ (the address the api pod) from host i get in, why i cannot get in from outside?
also tried adding nginx + api pod deployment
  template:
    spec:
      hostnetwork: true

still cannot reach please help
",<kubernetes><kubectl>,68396033,1,"found the solution!
i needed to add  externalips to my pods service.yaml (api and nginx)
spec:
  ports:
  - name: &quot;8443&quot;
    port: 8443
    targetport: 80
  externalips:
      - 10.10.10.130

"
60190036,bazel kubernetes object error: no objects passed to apply (google container registry),"i have a k8s_object rule to apply a deployment to my google kubernetes cluster. here is my setup:

load(""@io_bazel_rules_docker//nodejs:image.bzl"", ""nodejs_image"")
nodejs_image(
    name = ""image"",
    data = ["":lib"", ""//:package.json""],
    entry_point = "":index.ts"",
)

load(""@io_bazel_rules_k8s//k8s:object.bzl"", ""k8s_object"")
k8s_object(
  name = ""k8s_deployment"",
  template = "":gateway.deployment.yaml"",
  kind = ""deployment"",
  cluster = ""gke_cents-ideas_europe-west3-b_cents-ideas"",
  images = {
    ""gcr.io/cents-ideas/gateway:latest"": "":image""
  },
)


but when i run bazel run //services/gateway:k8s_deployment.apply, i get the following error

info: analyzed target //services/gateway:k8s_deployment.apply (0 packages loaded, 0 targets configured).
info: found 1 target...
target //services/gateway:k8s_deployment.apply up-to-date:
  bazel-bin/services/gateway/k8s_deployment.apply
info: elapsed time: 0.113s, critical path: 0.00s
info: 0 processes.
info: build completed successfully, 1 total action
info: build completed successfully, 1 total action
$ /snap/bin/kubectl --kubeconfig= --cluster=gke_cents-ideas_europe-west3-b_cents-ideas --context= --user= apply -f -
2020/02/12 14:52:44 unable to publish images: unable to publish image gcr.io/cents-ideas/gateway:latest
error: no objects passed to apply


error: no objects passed to apply
it doesn't push the new image to the google container registry.

strangely, this worked a few days ago. but i didn't change anything.

here is the full code if you need to take a closer look: https://github.com/flolude/cents-ideas/blob/069c773ade88dfa8aff492f024a1ade1f8ed282e/services/gateway/build

update

i don't know if this has something to do with this issue but when i run

gcloud auth configure-docker


i get some warnings:

warning: `docker-credential-gcloud` not in system path.
gcloud's docker credential helper can be configured but it will not work until this is corrected.
warning: your config file at [/home/flolu/.docker/config.json] contains these credential helper entries:

{
  ""credhelpers"": {
    ""asia.gcr.io"": ""gcloud"", 
    ""staging-k8s.gcr.io"": ""gcloud"", 
    ""us.gcr.io"": ""gcloud"", 
    ""gcr.io"": ""gcloud"", 
    ""marketplace.gcr.io"": ""gcloud"", 
    ""eu.gcr.io"": ""gcloud""
  }
}
adding credentials for all gcr repositories.
warning: a long list of credential helpers may cause delays running 'docker build'. we recommend passing the registry name to configure only the registry you are using.
gcloud credential helpers already registered correctly.

",<kubernetes><google-kubernetes-engine><bazel><kubectl><google-container-registry>,60193061,1,"i had google-cloud-sdk installed via snap install. what i did to make it work is to remove google-cloud-sdk via

snap remove google-cloud-sdk


and then followed those instructions to install it via

sudo apt install google-cloud-sdk


now it works fine
"
45879498,how can i update a secret on kubernetes when it is generated from a file?,"i've created a secret using
kubectl create secret generic production-tls \
  --from-file=./tls.key \
  --from-file=./tls.crt

if i'd like to update the values - how can i do this?
",<kubernetes><kubectl><kubernetes-secrets>,45881259,417,"this should work:
kubectl create secret generic production-tls \
--save-config \
--dry-run=client \
--from-file=./tls.key --from-file=./tls.crt \
-o yaml | \
kubectl apply -f -

"
73614025,"unable to create secret in kubernetes: ""secret is invalid: data[.dockerconfigjson]: invalid value: ""<secret contents redacted>"": invalid character 'e'","does anyone know what am i doing wrong with my kubernetes secret yaml and why its not able to successfully create one programatically?
i am trying to programmatically create a secret in kubernetes cluster with credentials to pull an image from a private registry but it is failing with the following:
&quot;secret &quot;secrettest&quot; is invalid: data[.dockerconfigjson]: invalid value: &quot;&lt;secret contents redacted&gt;&quot;: invalid character 'e' looking for beginning of value&quot;

this is the yaml i tried to use to create the secret with. it is yaml output from a secret previously created in my kubernetes cluster using the command line except without a few unnecessary properties. so i know this is valid yaml:
apiversion: v1
data:
  .dockerconfigjson: eyjhdxrocyi6eyjozwxsb3dvcmxklmf6dxjly3iuaw8ionsidxnlcm5hbwuioijozwxsbyisinbhc3n3b3jkijoid29ybgqilcjhdxroijoiyudwc2jhodzkmjl5ykdrpsj9fx0=
kind: secret
metadata:
  name: secrettest
  namespace: default
type: kubernetes.io/dockerconfigjson

this is the decoded value of the &quot;.dockerconfigjson&quot; property which seems to be throwing the error but not sure why if the value is supposed to be encoded per documentation:
{&quot;auths&quot;:{&quot;helloworld.azurecr.io&quot;:{&quot;username&quot;:&quot;hello&quot;,&quot;password&quot;:&quot;world&quot;,&quot;auth&quot;:&quot;agvsbg86d29ybgq=&quot;}}}

according to the documentation, my yaml is valid so im not sure whats the issue:
customize secret yaml
note: i tried creating the secret using the kubernetes client and &quot;patchnamespacedsecretwithhttpmessagesasync&quot; in c#
referenced documentaion: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
",<kubernetes><kubernetes-secrets>,73615781,1,"i found my issue. i was trying to create the secret object using
yaml.loadallfromstring()

which was double encoding my .dockerconfigjson value. the weird part was the if the value wasnt encoded, it would fail. so i had to just manually create the secret object instead of reading from a yaml file.
"
71641614,why is this annotation of ewma are different?,"i have one service with 10 pods inside of my cluster and it sends multiple requests to the master node for more than an hour.
i put an annotation in my ingress resource and modified it with some annotation, the first annotation i used is only to change the load balancer method to ewma load balancing.
annotations:       nginx.ingress.kubernetes.io/load-balance: ewma

during the time when the client requested the service from the master node, it received the request perfectly, which means the client received different responses from different pods and from different agent nodes inside of the cluster.
but when i changed the annotation to this annotation
nginx.ingress.kubernetes.io/upstream-hash-by: &quot;ewma&quot;

the client received the same answer every time from the same pod and from the same node, even i send requests for the service 5 times in a second for more than 30 minutes. are they implemented correctly? and why are they different?
",<nginx><kubernetes><kubernetes-ingress><nginx-ingress><internal-load-balancer>,71800803,1,"this is a community wiki answer posted for better visibility. feel free to expand it.
root cause:
the nodes should receive equal requests from clients (load balancing) and at the same time saving machine resources.
due to this, need to find the best solution between annotations below (based on the question):
nginx.ingress.kubernetes.io/load-balance: ewma

and
nginx.ingress.kubernetes.io/upstream-hash-by: ewma

solution:
usage of nginx.ingress.kubernetes.io/load-balance: ewma annotation is preferable solution for the mentioned purpose.
based on the documents: load-balance use the peak ewma method for routing. in contrast, of upstream-hash-by, which is load balance using consistent hashing of ip or other variables and provides connection to the same pod.
for more information, see this article kubernetes nginx ingress: consistent hash subset load balancer.
"
52535811,can not install nginx by using helm over kubernetes,"i have kubernetes cluster v1.10 over centos 7 , bare-metal 

helm version
client: &amp;version.version{semver:""v2.11.0-rc.3"", gitcommit:""28d295be2a94115b786ee277dffcc2b5483bde47"", gittreestate:""clean""}
server: &amp;version.version{semver:""v2.11.0-rc.3"", gitcommit:""28d295be2a94115b786ee277dffcc2b5483bde47"", gittreestate:""clean""}


i am trying to install nginx using helm 

helm install stable/nginx-ingress --name nginx


it returns 

error: release nginx failed: 
clusterroles.rbac.authorization.k8s.io ""nginx-nginx-ingress"" is 
forbidden: attempt to grant extra privileges: 
[policyrule{apigroups:[""""], resources:[""configmaps""], verbs: 
[""list""]} policyrule{apigroups:[""""], resources:[""configmaps""], 
verbs:[""watch""]} policyrule{apigroups:[""""], resources: 
[""endpoints""], verbs:[""list""]} policyrule{apigroups:[""""], 
resources:[""endpoints""], verbs:[""watch""]} policyrule{apigroups: 
[""""], resources:[""nodes""], verbs:[""list""]} policyrule{apigroups: 
[""""], resources:[""nodes""], verbs:[""watch""]} policyrule{apigroups: 
[""""], resources:[""pods""], verbs:[""list""]} policyrule{apigroups: 
[""""], resources:[""pods""], verbs:[""watch""]} policyrule{apigroups: 
[""""], resources:[""secrets""], verbs:[""list""]} policyrule{apigroups: 
[""""], resources:[""secrets""], verbs:[""watch""]} 
policyrule{apigroups:[""""], resources:[""nodes""], verbs:[""get""]} 
policyrule{apigroups:[""""], resources:[""services""], verbs:[""get""]} 
policyrule{apigroups:[""""], resources:[""services""], verbs:[""list""]} 
policyrule{apigroups:[""""], resources:[""services""], verbs: 
[""update""]} policyrule{apigroups:[""""], resources:[""services""], 
verbs:[""watch""]} policyrule{apigroups:[""extensions""], resources: 
[""ingresses""], verbs:[""get""]} policyrule{apigroups:[""extensions""], 
resources:[""ingresses""], verbs:[""list""]} policyrule{apigroups: 
[""extensions""], resources:[""ingresses""], verbs:[""watch""]} 
policyrule{apigroups:[""""], resources:[""events""], verbs:[""create""]} 
policyrule{apigroups:[""""], resources:[""events""], verbs:[""patch""]} 
policyrule{apigroups:[""extensions""], resources: 
[""ingresses/status""], verbs:[""update""]}] user=&amp; 
{system:serviceaccount:kube-system:default 8f248058-b684-11e8- 
b781-daf0a0c10949 [system:serviceaccounts 
system:serviceaccounts:kube-system system:authenticated] map[]} 
ownerrules=[] ruleresolutionerrors=[]


how can i solve this issue ? 

thank you :d 
",<kubernetes><nginx-ingress><kubernetes-helm>,52539348,1,"after search i think this is the solution 

helm install stable/nginx-ingress --name ingress --namespace kube-system --set rbac.create=false --set rbac.createrole=false --set rbac.createclusterrole=false


or

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/cloud-generic.yaml

"
75373670,how to get the full name of a pod by both its creation date and part of its name?,"in my namespace, i have several pods named with the same prefix, followed by the random string. there are also other pods, named differently. the result of kubectl get pods would look something like this:
service-job-12345abc
service-job-abc54321
other-job-54321cba

i need to find the nameof the most recently created pod starting with &quot;service-job-&quot;.
i found this thread, which helps getting the name of the most recent pod in general. this one gets me the complete names of pods starting with a specific prefix.
what i struggle with is combining these two methods. with each one, i seem to lose the information i need to perform the other one.
note: i am not an administrator of the cluster, so i cannot change anything about the naming etc. of the pods. the pods could also be in any possible state.
",<kubernetes><kubectl>,75374831,1,"this works as you expect:
kubectl get pods --sort-by=.metadata.creationtimestamp --template '{{range .items}}{{.metadata.name}}{{&quot;\n&quot;}}{{end}}' | grep service-job- | head -1 

"
40574651,go-mysql connection refused when connecting to kubernetes mysql service,"i have a problem when connecting  to a mysql instance with a go app using standard package.
this is my connection string/log

    [13 nov 16 13:53 +0000] [info] connecting to mysql.. root:awsomepass@tcp(a-mysql-0:3340)/db?charset=utf8&amp;parsetime=true&amp;loc=local
    2016/11/13 13:53:25 dial tcp 10.108.1.35:3340: getsockopt: connection refused


i tried 

grant all privileges on *.* to 'root'@'%' with grant option;


here is how i make connection, just basic, with string concatenation only

db, err := sql.open(""mysql"", ""root:awsomepass@tcp(a-mysql-0:3340)/db?charset=utf8&amp;parsetime=true&amp;loc=local"")
if err != nil {
    log.fatal(err)
}


i can ping the service, connect to it with mysql-client from a different pod. 

    # can connect without port for service
    / # mysql -u root -h a-mysql-0 -p
    enter password:
    welcome to the mariadb monitor.  commands end with ; or \g.
    your mysql connection id is 11
    server version: 5.7.16 mysql community server (gpl)

    copyright (c) 2000, 2016, oracle, mariadb corporation ab and others.

    type 'help;' or '\h' for help. type '\c' to clear the current input statement.

    mysql [(none)]&gt; ctrl-c -- exit!
    aborted

    # can't' connect with port for service
    / # mysql -u root -h a-mysql-0:3340 -p
    enter password:
    error 2005 (hy000): unknown mysql server host 'a-mysql-0:3340' (-3)


and the mysql-service 

    ➜  stg git:(develop) ✗ kubectl describe svc a-mysql-0
    name:            a-mysql-0
    namespace:        default
    labels:            name=a-mysql-0
                tier=database
                type=mysql
    selector:        name=a-mysql-0,tier=database
    type:            clusterip
    ip:            none
    port:            a-mysql-0    3340/tcp
    endpoints:        10.108.1.35:3340
    session affinity:    none
    no events.


is there anything i have missed or permission?
",<mysql><go><kubernetes><google-kubernetes-engine>,40583114,2,"got a response from kubernetes-slack, from mav. i am accessing the mysql-service to a wrong container-port. default mysql port was 3306. i thought i was using a custom container that exposes 3340.
"
53861258,error in minikube installation on windows 7 enterprise,"i am trying to follow instructions on 
https://kubernetes.io/docs/setup/minikube/ 

but i am getting an error on the command:

curl $(minikube service hello-minikube --url)


details below:



as you might have guessed i am a beginner, will appreciate if someone can guide me on what i am doing wrong.
",<kubernetes><kubectl><minikube>,53861672,2,"basically:

curl $(minikube service hello-minikube --url)


is a bash command and when use on a bash prompt it executes minikube service hello-minikube --url and the output is passed to curl

since you are using a windows command prompt, you can run this first:

minikube service hello-minikube --url


copy the output and then run:

curl &lt;output&gt;

"
64720327,gke rpc health check with multiple ports and different protocols under the same backend service,"i am trying to spin up a third-party service that accepts connections in 4 different ports:
x-deployment.yaml
apiversion: apps/v1
kind: deployment
metadata:
  name: x-deployment
  labels:
    app: x
...
ports:
  - containerport: 8000 # httpgraphqlserver
  - containerport: 8001 # websocketserver
  - containerport: 8020 # jsonrpcserver
  - containerport: 8030 # httpindexingserver
livenessprobe:
  tcpsocket:
    port: 8020

x-service.yaml
apiversion: cloud.google.com/v1
kind: backendconfig
metadata:
  name: x-rpc-config
spec:
  healthcheck:
    checkintervalsec: 7
    timeoutsec: 3
    healthythreshold: 2
    unhealthythreshold: 2
    type: http2
    port: 8020
---
apiversion: v1
kind: service
metadata:
  name: x-service
  annotations:
    beta.cloud.google.com/backend-config: '{&quot;default&quot;: &quot;x-rpc-config&quot;}'
spec:
  selector:
    app: x
  ports:
    - name: graphql
      port: 8000
      targetport: 8000
    - name: subscription
      port: 8001
      targetport: 8001
    - name: indexing
      port: 8030
      targetport: 8030
    - name: jrpc
      port: 8020
      targetport: 8020
  type: nodeport

ingress.yaml
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: backend-ingress
  annotations:
    kubernetes.io/ingress.global-static-ip-name: backend-dev-ip-address
    networking.gke.io/managed-certificates: backend-certificate
spec:
  rules:
    - host: x.dev.domain.io
      http:
        paths:
          - path: /rpc
            backend:
              servicename: x-service
              serviceport: 8020
          - path: /idx
            backend:
              servicename: x-service
              serviceport: 8030
          - path: /ws
            backend:
              servicename: x-service
              serviceport: 8001
          - path: /*
            backend:
              servicename: x-service
              serviceport: 8000

by default the gke loadbalancer runs the health check on http:80, if i spin up the backend-service (x-service.yaml) without the backendconfig (x-rpc-config), it is able to detect only 2 healthy backend-services, both with http ports: 8000 and 8030). however the backend-services listen to ports: 8020 (rpc) and 8030 (ws) are not considered healthy. i believe it happens because of the protocol type, so i've created the backendconfig (x-rpc-config) to run a tpc health check instead, using http2 protocol for port 8020 - which is where the livenessprobe is pointing to.
the pods and services are created properly, but the load balancer still fails to detect them as healthy services. the console simply shows the following warning:

some backend services are in unhealthy state

the goal is to open up the port 8020 (rpc) but also keep the 8000 (http) working. is it possible? do i need another type of load balancer or it is just a config issue?
i could not find any example of healthcheck config for multiple ports with different protocols under the same service. it is probably an anti-pattern?
thanks in advance.
",<kubernetes><load-balancing><google-kubernetes-engine><rpc><kubernetes-health-check>,65005581,2,"solution
instead of using an ingress, which will launch a http/https load balancer on gcp by default, i've changed the service to work as a loadbalancer with a custom http2 health check config. by default this configuration will spin up a tcp load balancer on gcp. for instance:
apiversion: cloud.google.com/v1
kind: backendconfig
metadata:
  name: rpc-config
spec:
  healthcheck:
    checkintervalsec: 10
    timeoutsec: 3
    healthythreshold: 2
    unhealthythreshold: 2
    type: http2
    port: 8020
---
apiversion: v1
kind: service
metadata:
  name: x-service
  annotations:
    cloud.google.com/app-protocols: '{&quot;rpc-a&quot;:&quot;http2&quot;, &quot;rpc-b&quot;:&quot;http2&quot;, &quot;rpc-c&quot;:&quot;http2&quot;}'
    beta.cloud.google.com/backend-config: '{&quot;default&quot;: &quot;rpc-config&quot;}'
spec:
  selector:
    app: x-node
  ports:
    - name: rpc-a
      port: 5001
      protocol: tcp
      targetport: 5001
    - name: rpc-b
      port: 8020
      protocol: tcp
      targetport: 8020
    - name: rpc-c
      port: 8000
      protocol: tcp
      targetport: 8000
  type: loadbalancer

the next step is to enable the ssl for the tcp lb. i saw gcp has the ssl proxy lb, that might solve it. just need to figure out the proper configuration for that, i could not find it in their docs.
"
59011273,kubenetes ingress api routing,"i have a react web application listening on the default path and i'm looking to include my api backend on the same url.

a snippet of my ingress is below: 

    http:
      paths:
      - backend:
          servicename: atsweb
          serviceport: 80
        path: /(.*)
      - backend:
          servicename: atsapi
          serviceport: 80
        path: /api(/|$)(.*)


my api has a bunch of functions which are routed after /api/ and i have a test page at mydomain.io/api/values which i cannot get to. my frontend service works fine. 

is it just the pathing which is incorrect?

i've deployed a standalone api just to check the container port/service ports are correct. 
",<kubernetes><kubernetes-ingress><azure-aks>,59011909,2,"looks like you copied the example from . what are your ingress annotations? check the rewrite as it looks like is making a redirect. nonetheless, the ingress that would work for looks like this:

---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: your-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: ""false""
spec:
  rules:
  - http:
      paths:
      - path: /
        backend:
          servicename: atsweb
          serviceport: 80
      - path: /api/
        backend:
          servicename: atsapi
          serviceport: 80


check there is no rewrite annotation. this makes your uri be appended fully to the next proxy. thus, making mydomain.io/api/values go to atsapi:80/api/values 
"
58412311,traefik configuration to watch a particular kubernetes namespace doesn't works,"i deployed the same chart (contains traefik as sub-chart) to different namespaces of a cluster. both traefik dashboards were showing that every frontend has 2 corresponding backends.


this could be because traefik was watching ingress objects of all namespaces. so i decided to restrict it to one namespace.

traefik chart: https://github.com/helm/charts/tree/master/stable/traefik

values.yaml :

## default values for traefik
image: traefik
imagetag: 1.7.14
imagepullpolicy: always
imagepullsecret: """"

nameoverride: """"
fullnameoverride: """"
dependson: rest 

restart: always

## can switch the service type to nodeport if required
servicetype: loadbalancer
# set static ip for service
loadbalancerip: """"
# loadbalancersourceranges: []
whitelistsourcerange: []
externaltrafficpolicy: cluster
replicas: 1

startuparguments:
  - ""--api""
  - ""--kubernetes""

poddisruptionbudget: {}
  # maxunavailable: 1
  # minavailable: 2

# priorityclassname: """"

# rootcas: []

resources: {}

debug:
  enabled: false

deploymentstrategy:
  type: recreate
  # rollingupdate:
  #   maxsurge: 1
  #   maxunavailable: 0


securitycontext: {}
env: {}

nodeselector: {}
  # key: value
affinity: {}
  # key: value
tolerations: []
# - key: ""key""
#   operator: ""equal|exists""
#   value: ""value""
#   effect: ""noschedule|prefernoschedule|noexecute(1.6 only)""


## kubernetes ingress filters
kubernetes:
  namespaces:
  - default
  - kube-system
  # endpoint:
  # labelselector:
  # ingressclass:
  # ingressendpoint:
  #   hostname: ""localhost""
  #   ip: ""127.0.0.1""
  #   publishedservice: ""namespace/servicename""
  #   usedefaultpublishedservice: false

proxyprotocol:
  enabled: false
  # trustedips is required when enabled
  trustedips: []
  # - 10.0.0.0/8
forwardedheaders:
  enabled: false
  # trustedips is required when enabled
  trustedips: []
  # - 10.0.0.0/8

## add arbitrary configmaps to deployment
## will be mounted to /configs/, i.e. myconfig.json would
## be mounted to /configs/myconfig.json.
configfiles: {}
  # myconfig.json: |
  #   filecontents...

## add arbitrary secrets to deployment
## will be mounted to /secrets/, i.e. file.name would
## be mounted to /secrets/mysecret.txt.
## the contents will be base64 encoded when added
secretfiles: {}
  # mysecret.txt: |
  #   filecontents...

ssl:
  enabled: false
  enforced: false
  permanentredirect: false
  upstream: false
  insecureskipverify: false
  generatetls: false
  # defaultcn: ""example.com""
    # or *.example.com
  defaultsanlist: []
    # - example.com
    # - test1.example.com
  defaultiplist: []
    # - 1.2.3.4
  # ciphersuites: []
  # https://docs.traefik.io/configuration/entrypoints/#specify-minimum-tls-version
  # tlsminversion: versiontls12
  # https://docs.traefik.io/configuration/entrypoints/#strict-sni-checking
  # snistrict: false
  defaultcert: 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
  defaultkey: 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
  # basic auth to protect all the routes. can use htpasswd to generate passwords
  # &gt; htpasswd -n -b testuser testpass
  # &gt; testuser:$apr1$jxra7j2s$lpvns9vsme8fhn0r.ast11
  auth: {}
    # basic:
    #   testuser: $apr1$jxra7j2s$lpvns9vsme8fhn0r.ast11

kvprovider:
  ## if you want to run traefik in ha mode, you will need to setup a kv provider. therefore you can choose one of
  ## * etcd
  ## * consul
  ## * boltdb
  ## * zookeeper
  ##
  ## ref: https://docs.traefik.io/user-guide/cluster/

  ## storeacme has to be enabled to support ha support using acme, but at least one kvprovider is needed
  storeacme: false
  importacme: false

  # etcd:
    # endpoint: etcd-service:2379
    # useapiv3: false
    # watch: true
    # prefix: traefik

    ## override default configuration template.
    ## for advanced users :)
    ##
    ## optional
    # filename: consul.tmpl
    # username: foo
    # password: bar
    # tls:
    #   ca: ""/etc/ssl/ca.crt""
    #   cert: ""/etc/ssl/consul.crt""
    #   key: ""/etc/ssl/consul.key""
    #   insecureskipverify: true
    #
  # consul:
    # endpoint: consul-service:8500
    # watch: true
    # prefix: traefik

    ## override default configuration template.
    ## for advanced users :)
    ##
    ## optional
    # filename: consul.tmpl
    # username: foo
    # password: bar
    # tls:
    #   ca: ""/etc/ssl/ca.crt""
    #   cert: ""/etc/ssl/consul.crt""
    #   key: ""/etc/ssl/consul.key""
    #   insecureskipverify: true

    ## only relevant for etcd


acme:
  enabled: false
  email: admin@example.com
  onhostrule: true
  staging: true
  logging: false
  # configure a let's encrypt certificate to be managed by default.
  # this is the only way to request wildcard certificates (works only with dns challenge).
  domains:
    enabled: false
    # list of sets of main and (optional) sans to generate for
    # for wildcard certificates see https://docs.traefik.io/configuration/acme/#wildcard-domains
    domainslist:
      # - main: ""*.example.com""
      # - sans:
      #   - ""example.com""
      # - main: ""*.example2.com""
      # - sans:
      #   - ""test1.example2.com""
      #   - ""test2.example2.com""
  ## acme challenge type: ""tls-sni-01"", ""tls-alpn-01"", ""http-01"" or ""dns-01""
  ## note the chart's default of tls-sni-01 has been deprecated and (except in
  ## certain circumstances) disabled by let's encrypt. it remains as a default
  ## value in this chart to preserve legacy behavior and avoid a breaking
  ## change. users of this chart should strongly consider making the switch to
  ## the recommended ""tls-alpn-01"" (avaialbe since v1.7), dns-01 or http-01
  ## (available since v1.5) challenge.
  challengetype: tls-sni-01
  ## configure dnsprovider to perform domain verification using dns challenge
  ## applicable only if using the dns-01 challenge type
  delaybeforecheck: 0
  resolvers: []
    # - 1.1.1.1:53
    # - 8.8.8.8:53
  dnsprovider:
    name: nil
    existingsecretname: """"
    auroradns:
      aurora_user_id: """"
      aurora_key: """"
      aurora_endpoint: """"
    azure:
      azure_client_id: """"
      azure_client_secret: """"
      azure_subscription_id: """"
      azure_tenant_id: """"
      azure_resource_group: """"
    cloudflare:
      cloudflare_email: """"
      cloudflare_api_key: """"
    digitalocean:
      do_auth_token: """"
    dnsimple:
      dnsimple_oauth_token: """"
      dnsimple_base_url: """"
    dnsmadeeasy:
      dnsmadeeasy_api_key: """"
      dnsmadeeasy_api_secret: """"
      dnsmadeeasy_sandbox: """"
    dnspod:
      dnspod_api_key: """"
    dreamhost:
      dreamhost_api_key: """"
    dyn:
      dyn_customer_name: """"
      dyn_user_name: """"
      dyn_password: """"
    exoscale:
      exoscale_api_key: """"
      exoscale_api_secret: """"
      exoscale_endpoint: """"
    gandi:
      gandi_api_key: """"
    godaddy:
      godaddy_api_key: """"
      godaddy_api_secret: """"
    gcloud:
      gce_project: """"
      gce_service_account_file: """"
    linode:
      linode_api_key: """"
    namecheap:
      namecheap_api_user: """"
      namecheap_api_key: """"
    ns1:
      ns1_api_key: """"
    otc:
      otc_domain_name: """"
      otc_user_name: """"
      otc_password: """"
      otc_project_name: """"
      otc_identity_endpoint: """"
    ovh:
      ovh_endpoint: """"
      ovh_application_key: """"
      ovh_application_secret: """"
      ovh_consumer_key: """"
    pdns:
      pdns_api_url: """"
    rackspace:
      rackspace_user: """"
      rackspace_api_key: """"
    rfc2136:
      rfc2136_nameserver: """"
      rfc2136_tsig_algorithm: """"
      rfc2136_tsig_key: """"
      rfc2136_tsig_secret: """"
      rfc2136_timeout: """"
    route53:
      aws_region: """"
      aws_access_key_id: """"
      aws_secret_access_key: """"
    vultr:
      vultr_api_key: """"
  ## save acme certs to a persistent volume.
  ## warning: if you do not do this and you did not have configured
  ## a kvprovider, you will re-request certs every time a pod (re-)starts
  ## and you will be rate limited!
  persistence:
    enabled: true
    annotations: {}
    ## acme data persistent volume storage class
    ## if defined, storageclassname: &lt;storageclass&gt;
    ## if set to ""-"", storageclassname: """", which disables dynamic provisioning
    ## if undefined (the default) or set to null, no storageclassname spec is
    ##   set, choosing the default provisioner.  (gp2 on aws, standard on
    ##   gke, aws &amp; openstack)
    ##
    # storageclass: ""-""
    accessmode: readwriteonce
    size: 1gi
    ## a manually managed persistent volume claim
    ## requires persistence.enabled: true
    ## if defined, pvc must be created manually before volume will be bound
    ##
    # existingclaim:

dashboard:
  enabled: true
  domain: localhost
  servicetype: clusterip
  service: {}
    # annotations:
    #   key: value
  ingress: {}
    # annotations:
    #   key: value
    # labels:
    #   key: value
    # tls:
      # - hosts:
      #   - traefik.example.com
      #   secretname: traefik-default-cert
  auth: {}
    # basic:
    #   username: password
  statistics: {}
    ## number of recent errors to show in the ‘health’ tab
    # recenterrors:
service:
  # annotations:
  #   key: value
  # labels:
  #   key: value
  ## further config for service of type nodeport
  ## default config with empty string """" will assign a dynamic
  ## nodeport to http and https ports
  nodeports:
    http: """"
    https: """"
  ## if static nodeport configuration is required it can be enabled as below
  ## configure ports in allowable range (eg. 30000 - 32767 on minikube)
  # nodeports:
  #   http: 30080
  #   https: 30443
gzip:
  enabled: true
traefiklogformat: json
accesslogs:
  enabled: false
  ## path to the access logs file. if not provided, traefik defaults it to stdout.
  # filepath: """"
  format: common  # choices are: common, json
  ## for json logging, finer-grained control over what is logged. fields can be
  ## retained or dropped, and request headers can be retained, dropped or redacted
  fields:
    # choices are keep, drop
    defaultmode: keep
    names: {}
      # clientusername: drop
    headers:
      # choices are keep, drop, redact
      defaultmode: keep
      names: {}
        # authorization: redact

rbac:
  enabled: true

## enable the /metrics endpoint, for now only supports prometheus
## set to true to enable metric collection by prometheus
metrics:
  prometheus:
    enabled: false
    ## if true, prevents exposing port 8080 on the main traefik service, reserving
    ## it to the dashboard service only
    restrictaccess: false
    # buckets: [0.1,0.3,1.2,5]
  datadog:
    enabled: false
    # address: localhost:8125
    # pushinterval: 10s
  statsd:
    enabled: false
    # address: localhost:8125
    # pushinterval: 10s
deployment:
  # labels to add to the pod container metadata
  # podlabels:
  #   key: value
  # podannotations:
  #   key: value
  hostport:
    httpenabled: false
    httpsenabled: false
    dashboardenabled: false
    # httpport: 80
    # httpsport: 443
    # dashboardport: 8080
sendanonymoususage: false
tracing:
  enabled: false
  servicename: traefik
  # backend: choices are jaeger, zipkin, datadog
  # jaeger:
  #   localagenthostport: ""127.0.0.1:6831""
  #   samplingserverurl: http://localhost:5778/sampling
  #   samplingtype: const
  #   samplingparam: 1.0
  # zipkin:
  #   httpendpoint: http://localhost:9411/api/v1/spans
  #   debug: false
  #   samespan: false
  #   id128bit: true
  # datadog:
  #   localagenthostport: ""127.0.0.1:8126""
  #   debug: false
  #   globaltag: """"

## create horizontalpodautoscaler object.
##
# autoscaling:
#   minreplicas: 1
#   maxreplicas: 10
#   metrics:
#   - type: resource
#     resource:
#       name: cpu
#       targetaverageutilization: 60
#   - type: resource
#     resource:
#       name: memory
#       targetaverageutilization: 60

## timeouts
##
# timeouts:
#   ## responding are timeouts for incoming requests to the traefik instance
#   responding:
#     readtimeout: 0s
#     writetimeout: 0s
#     idletimeout: 180s
#   ## forwarding are timeouts for requests forwarded to the backend servers
#   forwarding:
#     dialtimeout: 30s
#     responseheadertimeout: 0s


even after setting kubernetes.namespaces value, the traefik was watching all the namespaces.

how can i resolve this?
",<kubernetes><namespaces><traefik><kubernetes-ingress>,58412527,2,"i got the answer.

as described here: https://docs.traefik.io/getting-started/configuration-overview/#the-static-configuration


  you can use only one type of static configuration method at the same
  time.


while setting kubernetes.namespaces value, i was setting the entry of the traefik config file.

i was directly setting the following command-line argument also:

startuparguments:
  - ""--api""
  - ""--kubernetes""


this --kubernetes command overrides/disables the values set with kubernetes.namespaces values.
the default setting of watching all namespaces is applied.

when i commented-out the startuparguments section from the values file, everything started working correctly.
"
72279424,nested templating helm,"i am working on a problem to implement a helm chart with customize configmap and trying to populate the configmap based on the environment mode.
values.yaml
externalipservice:
 ip: 1.1.1.1
 port:  80 

emsconfig: &quot;receivers:
 otlp:
   protocols:
     http:
processors:
 batch:
exporters:
 otlp/ems:
   endpoint: {{ .values.externalipservice.ip }}:{{ .values.externalipservice.port }}
service:
 pipelines:
   traces:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
   metrics:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
   logs:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
&quot;

configmap.yaml
apiversion: v1
kind: configmap
metadata:
  name: simple-demo
data:
  message: &quot;{{ tpl .values.emsconfig .}}&quot;

the helm template output is a plain string and not a yaml content. i have tried toyaml as well but it did not help either. could someone please help to find a way to do nested rendering and to be able to use the final output in the confimap
apiversion: v1
kind: configmap
metadata:
  name: simple-demo
data:
  message: &quot;receivers: otlp: protocols: http: processors: batch: exporters: otlp/ems: endpoint: {{ .values.externalipservice.ip }}:{{ .values.externalipservice.port }} service: pipelines: traces: receivers: [otlp] processors: [batch] exporters: [otlp/ems] metrics: receivers: [otlp] processors: [batch] exporters: [otlp/ems] logs: receivers: [otlp] processors: [batch] exporters: [otlp/ems] &quot;

",<kubernetes><kubernetes-helm>,72280009,1,"in this situation, you need to use _halpers.tpl file.
first, add this to the _halpers.tpl file:
{{- define &quot;appname.emsconfig&quot; -}}
receivers:
 otlp:
   protocols:
     http:
processors:
 batch:
exporters:
 otlp/ems:
   endpoint: {{ .values.externalipservice.ip }}:{{ .values.externalipservice.port }}
service:
 pipelines:
   traces:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
   metrics:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
   logs:
     receivers: [otlp]
     processors: [batch]
     exporters: [otlp/ems]
{{- end }}

the values.yaml file will look like this:
externalipservice:
 ip: 1.1.1.1
 port:  80 


and the configmap.yaml file, will need to look like this:
apiversion: v1
kind: configmap
metadata:
  name: simple-demo
data:
  message: |-
  {{ include &quot;appname.emsconfig&quot; . | nindent 4}}

"
57696087,how to generate yaml template with kubectl command?,"is it possible to generate yaml with kubernetes' kubectl command? to clarify - i'm not talking about generating yaml from existing deployments like kubectl get xxxx -o yaml, but about generating yaml files to create a pod, service, ingress, etc. for the first time.
ps: there is a way to get yaml files from kubernetes.io site (1, 2) but i am looking if there is a way to generate yaml templates with kubectl only.
",<docker><kubernetes><yaml><kubectl>,57697773,61,"there's the command create in kubectl that does the trick and replaced the run used in the past: let's image you want to create a deployment running a nginx:latest docker image.
# kubectl create deployment my_deployment --image=busybox --dry-run=client --output=yaml

apiversion: apps/v1
kind: deployment
metadata:
  creationtimestamp: null
  labels:
    app: my_deployment
  name: my_deployment
spec:
  replicas: 1
  selector:
    matchlabels:
      app: my_deployment
  strategy: {}
  template:
    metadata:
      creationtimestamp: null
      labels:
        app: my_deployment
    spec:
      containers:
      - image: busybox
        name: busybox
        resources: {}
status: {}

let's analyze each parameter:

my_deployment is the deployment name you chose
--image is the docker image you want to deploy
--dry-run=client won't execute the resource creation, used mainly for validation.  replace 'client' with 'true' for older versions of kubernetes. neither client nor server will actually create the resource, though server will return an error if the resource cannot be created without a dry run (ie: resource already exists). the difference is very subtle.
--output=yaml prints to standard output the yaml definition of the deployment resource.

obviously, you can perform this options just with few kubernetes default resources:
# kubectl create 
  clusterrole         create a clusterrole.
  clusterrolebinding  create a clusterrolebinding for a particular clusterrole
  configmap           create a configmap from a local file, directory or literal value
  deployment          create a deployment with the specified name.
  job                 create a job with the specified name.
  namespace           create a namespace with the specified name
  poddisruptionbudget create a pod disruption budget with the specified name.
  priorityclass       create a priorityclass with the specified name.
  quota               create a quota with the specified name.
  role                create a role with single rule.
  rolebinding         create a rolebinding for a particular role or clusterrole
  secret              create a secret using specified subcommand
  service             create a service using specified subcommand.
  serviceaccount      create a service account with the specified name

according to this, you can render the template without the prior need of deploying your resource.
"
59906051,what prevents the 'instance-groups' annotation from being set when creating a multi-cluster ingress on google kubernetes engine?,"i'm trying to create a multi-cluster ingress on google kubernetes engine using kubemci, however when running the following command the program waits indefinitely for the ingress service to get the ingress.gcp.kubernetes.io/instance-groups annotation (as illustrated in the output below).

what is preventing this annotation from being set?

input

./kubemci create app-mci \
    --ingress=ingress.yaml \
    --gcp-project=app-prod \
    --kubeconfig=mcikubeconfig


output

% ./kubemci create app-mci --ingress=ingress.yaml --gcp-project=app-prod --kubeconfig=clusters.yaml        
created ingress in cluster: gke_app-prod_europe-west4-a_app-europe-west4
created ingress in cluster: gke_app-prod_us-east4-a_app-us-east4
ensuring health checks
pod app-deployment-c99578769-xdmql matching service selectors app=app (targetport ): lacks a matching http probe for use in health checks.
pod app-deployment-c99578769-xgq2m matching service selectors app=app (targetport ): lacks a matching http probe for use in health checks.
pod app-deployment-c99578769-qms7r matching service selectors app=app (targetport ): lacks a matching http probe for use in health checks.
pod app-deployment-c99578769-tsrsw matching service selectors app=app (targetport ): lacks a matching http probe for use in health checks.
path for healthcheck is /
ensuring health check for port: {svcname:default/app-service svcport:{type:0 intval:80 strval:} nodeport:30061 protocol:http svctargetport: negenabled:false}
health check mci1-hc-30061--app-mci exists already. checking if it matches our desired health check
desired health check exists already
determining instance groups for cluster gke_app-prod_europe-west4-a_app-europe-west4
waiting for ingress ( default : app-ingress ) to get ingress.gcp.kubernetes.io/instance-groups annotation.....
waiting for ingress ( default : app-ingress ) to get ingress.gcp.kubernetes.io/instance-groups annotation.....
waiting for ingress ( default : app-ingress ) to get ingress.gcp.kubernetes.io/instance-groups annotation.....
⋮


as you can see my configuration is identical (aside from resource names) to that in the multi-cluster ingress guide:

deployment.yaml

apiversion: apps/v1
kind: deployment
metadata:
  name: app-deployment
spec:
  selector:
    matchlabels:
      app: app
  replicas: 2
  template:
    metadata:
      labels:
        app: app
    spec:
      containers:
        - name: app
          image: gcr.io/app-prod/app:tag
          ports:
            - containerport: 8080


service.yaml

apiversion: v1
kind: service
metadata:
  labels:
    app: app
  name: app-service
spec:
  ports:
    - port: 80
      protocol: tcp
      targetport: 8080
      name: http
      nodeport: 30061
  selector:
    app: app
  type: nodeport


ingress.yaml

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: app-ingress
  annotations:
    kubernetes.io/ingress.global-static-ip-name: app-ip
    kubernetes.io/ingress.class: gce-multi-cluster
spec:
  backend:
    servicename: app-service
    serviceport: 80

",<kubernetes><google-kubernetes-engine><kubernetes-ingress>,59906052,1,"enable http load balancing

enable the http load balancing add-on to allow the load balancer controller to set the ingress.gcp.kubernetes.io/instance-groups annotation.

console


edit a cluster.
expand add-ons.
enable http load balancing:




command line

% gcloud container clusters update [cluster_name] --update-addons httploadbalancing=enabled

updating ***...done.                                                                                                                                                              
updated [https://container.googleapis.com/v1/projects/***/zones/us-east4-a/clusters/***].
to inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east4-a/***?project=***


view the cluster configuration:

% gcloud container clusters describe [cluster_name]

# enabled
addonsconfig:
  httploadbalancing: {}

# disabled
addonsconfig:
  httploadbalancing:
    disabled: true




configure services

ensure that the backend services used in the multi-cluster ingress are configured correctly.

services must:


  
  have the same name in all of the clusters.
  be in the same namespace in all of the clusters.
  be of type nodeport.
  use the same port number for all of the clusters.
  
  &mdash; setting up a multi-cluster ingress, google
  




credit


nikhil jindal for his insight.
ivan for raising this issue.

"
57004419,how to pass variables from parent to child in helm?,"i am new to helm and i want to know how i can pass variables from the parent package to children.
i have a multi microservices application which consists of different helm packages as below:

$ tree parent/
parent/
├── charts/
│   ├── child-a-0.0.1.tgz
│   ├── child-b-0.0.1.tgz
│   └── child-c-0.0.1.tgz
├── chart.yaml
├── templates/
│   ├── notes.txt
│   └── secret.yaml
└── values.yaml


and for example, i want to set public-ip in the parent values.yaml and when i install the parent that public-ip passed and set in the children as well.
",<kubernetes><kubernetes-helm>,57004543,12,"overriding values of a child chart is described in the helm documentation.
in the parent chart's values.yaml file (or an external file you pass to helm install -f) you can explicitly override values for a subchart:
childa:
  publicip: 10.10.10.10

the top-level values key global is also always passed to child charts, but the chart needs to know to look for it.
global:
  publicip: 10.10.10.10

env:
  - name: public_ip
    value: {{ .values.global.publicip }}

this resolution happens fairly early in the helm setup phase, so there's no way to pass a computed value to a subchart, or to pass the same value from the parent chart's top-level config into subcharts without restructuring things into global.
"
60029288,"cloud build bazel error: ""kubectl toolchain was not properly configured so apply cannot be executed""","i am trying to use rules_k8s for bazel to deploy to my kubernetes cluster.

thus i have this cloudbuild.yaml file, which is executed by google cloud build:

steps:
  - name: gcr.io/cloud-builders/bazel
    args: ['run', '//:kubernetes.apply']


(//:kubernetes is just a k8s_objects)



on my local machine running bazel run //:kubernetes.apply works fine, but
although the google cloud build succeeds, it logs those errors. so the configuration is not applied to my kubernetes cluster:

target //:kubernetes.apply up-to-date:
  bazel-bin/kubernetes.apply
info: elapsed time: 29.863s, critical path: 0.14s
info: 0 processes.
info: build completed successfully, 1 total action
info: running command line: bazel-bin/kubernetes.apply
info: build event protocol files produced successfully.
info: build completed successfully, 1 total action
kubectl toolchain was not properly configured so k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so projection_database_k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so projection_database_k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so k8s_service.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_deployment.apply cannot be executed.
kubectl toolchain was not properly configured so event_store_k8s_service.apply cannot be executed.


i also get a warning from the bazel cache:

debug: /builder/home/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/io_bazel_rules_k8s/toolchains/kubectl/kubectl_toolchain.bzl:28:9: no kubectl tool was found or built, executing run for rules_k8s targets might not work.


p.s.: i get the same errors when using //:kubernetes.create

my setup

deployments

load(""@io_bazel_rules_k8s//k8s:object.bzl"", ""k8s_object"")
k8s_object(
  name = ""k8s_deployment"",
  kind = ""deployment"",
  cluster = ""gke_cents-ideas_europe-west3-a_cents-ideas"",
  template = "":ideas.deployment.yaml"",
  images = {
    ""gcr.io/cents-ideas/ideas:latest"": "":image""
  },
)


services

k8s_object(
  name = ""k8s_service"",
  kind = ""service"",
  cluster = ""gke_cents-ideas_europe-west3-a_cents-ideas"",
  template = "":ideas.service.yaml"",
)


aggregations

load(""@io_bazel_rules_k8s//k8s:objects.bzl"", ""k8s_objects"")
k8s_objects(
    name = ""k8s"",
    objects = [
      "":k8s_deployment"",
      "":k8s_service"",
    ]
)


final composition

k8s_objects(
    name = ""kubernetes"",
    objects = [
        ""//services/ideas:k8s"",
        # ...
    ]
)


update

i've now tried to make my own docker image with bazel and kubectl:

from gcr.io/cloud-builders/bazel

run curl -lo https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
run chmod +x ./kubectl
run mv ./kubectl /usr/local/bin/kubectl


i pushed it to gcr and changed my cloudbuild.yaml to:

steps:
  - name: eu.gcr.io/cents-ideas/bazel-kubectl
    args: [""run"", ""//:kubernetes.apply""]


i firstly noticed, that the step took way longer than before. however at the end it throws an error:

$ /usr/local/bin/kubectl --kubeconfig= --cluster=gke_cents-ideas_europe-west3-a_cents-ideas --context= --user= apply -f -
error: cluster ""gke_cents-ideas_europe-west3-a_cents-ideas"" does not exist


here is the full log.
",<kubernetes><bazel><kubectl><google-cloud-build>,60054216,3,"as for the updated question, now you need to authenticate somehow to gke inside the container.

first thing, i recommend installing gcloud tool to your container.
btw, as for the huge container size 1.2 gb, that's because cloud-builders/bazel is huge :)

have a look at our example on slim bazel container version:
https://github.com/aspect-development/bazel-k8s-example/blob/master/tools/dockerfile.dazel

and here is dockerfile for installing gcloud and kubectl, so you can grab needed parts from both files:
https://github.com/googlecloudplatform/cloud-builders/blob/master/gcloud/dockerfile

the second thing is authenticating, after gcloud is installed it should be easy.
overall cloudbuild step should look similar to this:

- name: &lt;link to your container&gt;
  entrypoint: /bin/sh
  args:
  - -c
  - |
    gcloud container clusters get-credentials cents-ideas --zone europe-west3-a --project cents-ideas
    bazel run //:kubernetes.apply

"
70336210,tekton pipelines: enable alpha features using released pipelines yaml without the need to store (& maintain) feature-flags configmap,"we'd like to use tekton experimental features such as the pipelines in pipelines feature. we already installed the feature as described in the readme via kubectl apply but end up in an error like this:
pipeline default/buildpacks-test-pipeline can't be run; it contains tasks that don't exist: couldn't retrieve task &quot;generic-gitlab-set-status&quot;: tasks.tekton.dev &quot;generic-gitlab-set-status&quot; not found

in this issue it is stated, that we need to enable tekton alpha features in our deployment. in the tekton docs at customizing the pipelines controller behavior all feature flags are described - including the alpha features. the docs state we should change the enable-api-fields: field from stable to alpha if we want to use those features.
the recommended way of installing tekton pipelines is to use kubectl apply leveraging a remotely served yaml file:
kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml

inside we see the configmap feature-flags (shortened):
apiversion: v1
kind: configmap
metadata:
  name: feature-flags
  namespace: tekton-pipelines
  labels:
    app.kubernetes.io/instance: default
    app.kubernetes.io/part-of: tekton-pipelines
data:
  ...
  # setting this flag will determine which gated features are enabled.
  # acceptable values are &quot;stable&quot; or &quot;alpha&quot;.
  enable-api-fields: &quot;stable&quot;
  ...

is there a way to change the enable-api-fields field to alpha somehow on-the-fly without the need to store (and in the long run maintain) the official tekton pipeline yaml file?
",<kubernetes><kubectl><tekton><tekton-pipelines><openshift-pipelines>,70336211,1,"a simple combination of curl which downloads the file and pipes it into sed, which substitutes the stable to alpha works like a charm - especially since this flag is the only line including stable (except of the commentary line directly above). sed is a common tool to set dynamic values with kubernetes yaml file.
you may test-drive it adding a grep at the end to see the lines changed with:
curl https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml | sed &quot;s#stable#alpha#g&quot; | grep enable-api-fields

now combining the command with a final kubectl apply -f - (instead of grep) will do what was asked for:
curl https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml | sed &quot;s#stable#alpha#g&quot; | kubectl apply -f -

now the officially released tekton pipelines yaml is configured to use alpha features on-the-fly - without the need to store and maintain the configmap in a custom git repository for example.
"
65571673,skipping kubernetes service creation if it already exists with github actions,"i set the following github action job to automatically deploy a &quot;nginx&quot; app on eks and create a &quot;nginx-service&quot; service on push.
i'm trying to configure a skip in the service creation step when the service already exists.
my job:
name: cd_eks

on:
  - push

jobs:
  eks_nginx_deployment_service:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.aws_access_key_id }}
          aws-secret-access-key: ${{ secrets.aws_secret_access_key }}
          aws-region: eu-central-1

      - name: trigger deploy
        uses: consensys/kubernetes-action@master
        env:
          kube_config_data: ${{ secrets.kube_config_data }}
        with:
          args: apply -f nginx_deployment.yaml

      - name: get service list
        id: get_service_list
        uses: consensys/kubernetes-action@master
        env:
          kube_config_data: ${{ secrets.kube_config_data }}
        with:
          args: get services/nginx-service -o name

      - name: create elb service
        if: &lt;service doesn't exist&gt; # &lt;- that's my point
        uses: consensys/kubernetes-action@master
        env:
          kube_config_data: ${{ secrets.kube_config_data }}
        with:
          args: create -f nginx_loadbalancer.yaml

i tried to refer to the previous step (get_service_list) output, unsuccessfully.
thank you
",<kubernetes><kubectl><github-actions><amazon-eks>,65571981,1,"if you want to skip a step based off of the output of a previous step, try out the following:
step 1 - determine the name of the output you want to use
if you want to access the output of the consensys/kubernetes-action, we first need to determine what the output's name is. thankfully, consensys documents this output via the yaml definition of the action:
./.action.yml
outputs:
  result:
    description: &quot;output of the kubectl command run&quot;

to access the output of a step, github actions support the following expression: ${{ steps.step_id.outputs.output_name }}
since we know the id of the step you want to use, and consensys documents this action's output, we then know the final expression is as follows: ${{ steps.get_service_list.outputs.result }}
step 2 - determine appropriate 'if' statement
from step 1, we were able to determine that the output of get_service_list is the output of the kubectl command. this means that one will have to have a little knowledge about kubectl (experimenting locally can help with this). since you are passing get services/nginx-service -o name, i am assuming that you are checking for the existence of an item named services/nginx-service. if it exists, kubectl get services/nginx-service -o name will output services/nginx-service. if it doesn't exist, kubectl will return an error. in other words, we can say that if the output does not equal &quot;services/nginx-service&quot;, run the step named &quot;create elb service&quot;.
step 3 - putting it all together
the above two steps gave us:

the proper name of the get_service_list step's output
the conditional we want to use for the step named &quot;create elb service&quot;

putting those pieces of information together, the &quot;create elb service&quot; step could take on the following form:
- name: create elb service
  if: steps.get_service_list.outputs.result != 'services/nginx-service'
  uses: consensys/kubernetes-action@master
  env:
    kube_config_data: ${{ secrets.kube_config_data }}
  with:
    args: create -f nginx_loadbalancer.yaml

note github actions automatically assumes that the value of a conditional if keyword is an expression, so you do not have to surround the expression in ${{ }}.
helpful links/notes

supported operators in github action expressions
about contexts and expressions

"
74481168,"do kubernetes prestop hooks prevent all containers in a pod from stopping, or only the container it's set on?","the kubernetes documentation about prestop hooks claims the following:

prestop hooks are not executed asynchronously from the signal to stop
the container; the hook must complete its execution before the term
signal can be sent.

however, it does not say anything about other containers in the pod.
suppose terminationgraceperiodseconds has not yet passed.
are all containers in a pod protected from termination until the prestop hook for each container finishes? or does each prestop hook only protect its own container?
",<kubernetes><kubernetes-pod>,74484188,2,"i believe prestop hook only protects the container for which it's declared.
for example, in the following set up:
apiversion: v1
kind: pod
metadata:
  name: lifecycle-demo
spec:
  containers:
  - name: lifecycle-demo-container
    image: nginx
    lifecycle:
      prestop:
        exec:
          command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;sleep 15&quot;]
  - name: other-container
    image: mysql
    env:
    - name: mysql_allow_empty_password
      value: &quot;true&quot;

if i terminate the pod, the mysql receives sigterm and shuts down immediately while the nginx container stays alive for extra 15 seconds due to its prestop hook
"
69042024,possible to modify generated helm template?,"i'm using a static yaml file to install gitlab. therefore i run
helm template gitlab gitlab/gitlab -f &quot;config.yaml&quot; &gt; gitlab.yaml

but in this generated yaml file i always have to modify these three values:
apiversion: v1
kind: service
metadata:
  name: gitlab-gitlab-shell
  namespace: gitlab # &lt;--- change
  labels:
    app: gitlab-shell
    chart: gitlab-shell-4.4.2
    release: gitlab
    heritage: helm
  annotations:
    environment: prod
spec:
  type: nodeport # &lt;--- change
  ports:
    - port: 30022
      targetport: 2222
      protocol: tcp
      nodeport: 30022 # &lt;-- add
      name: ssh
  selector:
    app: gitlab-shell
    release: gitlab

is it possible to 'automate' this? maybe directly in the config file?
this is how my config.yaml looks like:
global:
  edition: ce
  hosts:
    domain: domain.com

  shell:
    port: 30022

  pod:
    labels:
      environment: prod

  deployment:
    annotations:
      environment: prod

  service:
    annotations:
      environment: prod

  ingress:
    class: nginx
    configurecertmanager: false
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      acme.cert-manager.io/http01-edit-in-place: 'true'

certmanager:
  install: false

nginx-ingress:
  enabled: false

gitlab:
  webservice:
    ingress:
      tls:
        secretname: gitlab-webservice-tls
  gitaly:
    persistence:
      size: 2gi

gitlab-runner:
  runners:
    privileged: true

registry:
  ingress:
    tls:
      secretname: gitlab-registry-tls

postgresql:
  persistence:
    size: 2gi
minio:
  ingress:
    tls:
      secretname: gitlab-minio-tls
  persistence:
    size: 2gi
redis:
  persistence:
    size: 2gi

prometheus:
  alertmanager:
    enabled: false
    persistentvolume:
      enabled: false
      size: 2gi
  pushgateway:
    enabled: false
    persistentvolume:
      enabled: false
      size: 2gi
  server:
    persistentvolume:
      enabled: true
      size: 2gi

",<kubernetes><gitlab><kubernetes-helm>,69044338,3,"in general, it's hard to modify the output of a helm chart.  you can configure things the chart author has specifically allowed using helm template syntax but not make arbitrary changes.
typically i would expect a chart to not include an explicit namespace: at all, and to honor the helm install --namespace option (helm template has a similar option).  configuring a service is extremely common and i would expect the chart to have settings for that.
if you're using the official gitlab cloud native helm chart then it has a lot of settings, including specifically for the gitlab shell chart.  in your values.yaml file you should be able to specify
gitlab-shell:
  service:
    type: nodeport
    nodeport: 30022

(these are specific configuration options specific to this chart because the chart author has made them configurable, not a generic way to edit the generated object.)
generally all of the related objects in a larger-scale deployment need to be in the same namespace.  i don't see an option to manually configure the gitlab shell subchart namespace, and indeed it'd be a little unusual; if it needs to access a global gitlab configmap, for example, those would have to be in the same namespace.  in your specific example the service and the pods bound to it need to be in the same namespace.  i'd expect you can use the helm install -n option to move everything to a different namespace, but not on a per-component basis.
"
63411049,kubernetes cronjob: reset missed start times after cluster recovery,"i have a cluster that includes a cronjob scheduled to run every 5 minutes.
we recently experienced an issue that incurred downtime and required manual recovery of the cluster. although now healthy again, this particular cronjob is failing to run with the following error:
cannot determine if job needs to be started: too many missed start time (&gt; 100). set or decrease .spec.startingdeadlineseconds or check clock skew.

i understand that the cronjob has 'missed' a number of scheduled jobs while the cluster was down, and this has past a threshold at which no further jobs will be scheduled.
how can i reset the number of missed start times and have these jobs scheduled again (without scheduling all the missed jobs to suddenly run?)
",<kubernetes><cron><kubernetes-cronjob><k8s-cronjobber>,63412024,13,"per the kubernetes cronjob docs, there does not seem to be a way to cleanly resolve this. setting the .spec.startingdeadlineseconds value to a large number will re-schedule all missed occurrences that fall within the increased window.
my solution was just to kubectl delete cronjob x-y-z and recreate it, which worked as desired.
"
72548534,how to add curr timestamp to while loop in container in pod in kubernetes?,"apiversion: v1
kind: pod
metadata:
  name: pv-pod
  namespace: auth
spec:
  containers:
  - name: busybox
    image: busybox
    #************** here is the command!
    command: ['sh', '-c', 'while true; do echo date &gt; /output/output.log; sleep 5; done']
    volumemounts:
    - name: pv-storage
      mountpath: /output
  volumes:
  - name: pv-storage
    persistentvolumeclaim:
      claimname: host-storage-pvc

this command is where i need to insert into a file &quot;success! wed jun  8 20:28:01 wast 2022&quot;,i.e. current timestamp.
command: ['sh', '-c', 'while true; do echo success! $date &gt;&gt; /output/output.log; sleep 5; done']

but it keeps writing 'success date'
",<linux><kubernetes><kubernetes-pod>,72549917,2,"you could use command substitution for this. that would be in shell or bash, the same.
additionally, you may need to escape the dollar sign, since $() has a special meaning in kubernetes manifests.
echo &quot;success $$(date)&quot; &gt;&gt; ...

"
53290615,k8s secret composition,"i am using helm/k8s to deploy a third party (prisma) container. the container expects a environment variable in the shape of yaml similar to 

port: 4466                           
managementapisecret: $prisma_secret
databases:                           
  default:                           
    connector: postgres              
    host: postgresql                 
    port: 5432                       
    user: postgres                   
    password: $pg_secret             
    migrations: true                 


i have access to the postgres password and managementapisecret as values in a separate secret. i am trying to create pod that fetches the two secrets and uses them to create a environment variable. my currently attempt at a solution looks like this. 

containers:                                    
  - name: prisma                               
    image: 'prismagraphql/prisma:1.14'         
    ports:                                     
      - name: prisma-4466                      
        containerport: 4466                    
    env:                                       
      - name: pg_secret                        
        valuefrom:                             
          secretkeyref:                        
            name: postgresql                   
            key: postgres-password             
      - name: prisma_config                    
        value: |                               
          port: 4466                           
          managementapisecret: $prisma_secret
          databases:                           
            default:                           
              connector: postgres              
              host: postgresql                 
              port: 5432                       
              user: postgres                   
              password: $pg_secret             
              migrations: true    


this does not seem to work (because the secret is evaluated at kubectl apply time?). is there an alternative way of creating env variables with secret information?
",<kubernetes><kubernetes-helm><prisma>,53291136,2,"from the envvar doc: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#envvar-v1-core


  variable references $(var_name) are expanded using the previous defined environment variables in the container and any service environment variables.


your second envvar can use the value of the earlier envvar as $(pg_secret)
"
57868848,problems configuring ingress with cookie affinity,"i was looking for how to use cookie affinity in gke, using ingress for that.

i've found the following link to do it: https://cloud.google.com/kubernetes-engine/docs/how-to/configure-backend-service

i've created a yaml with the following:

---
apiversion: apps/v1
kind: deployment
metadata:
  name: my-bsc-deployment
spec:
  selector:
    matchlabels:
      purpose: bsc-config-demo
  replicas: 3
  template:
    metadata:
      labels:
        purpose: bsc-config-demo
    spec:
      containers:
      - name: hello-app-container
        image: gcr.io/google-samples/hello-app:1.0
---
apiversion: cloud.google.com/v1beta1
kind: backendconfig
metadata:
  name: my-bsc-backendconfig
spec:
  timeoutsec: 40
  connectiondraining:
    drainingtimeoutsec: 60
  sessionaffinity:
    affinitytype: ""generated_cookie""
    affinitycookiettlsec: 50
---
apiversion: v1
kind: service
metadata:
  name: my-bsc-service
  labels:
    purpose: bsc-config-demo
  annotations:
    beta.cloud.google.com/backend-config: '{""ports"": {""80"":""my-bsc-backendconfig""}}'
spec:
  type: nodeport
  selector:
    purpose: bsc-config-demo
  ports:
  - port: 80
    protocol: tcp
    targetport: 8080
---
apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-bsc-ingress
spec:
  rules:
  - http:
      paths:
      - path: /*
        backend:
          servicename: my-bsc-service
          serviceport: 80
---


everything seems to go well. when i inspect the created ingress i see 2 backend services. one of them has the cookie configured, but the other doesn't.

if i create the deployment, and from gcp's console, create the service and ingress, only one backend service appears.

somebody knows why using a yaml i get 2, but doing it from console i only get one?

thanks in advance 

oscar
",<cookies><kubernetes><google-kubernetes-engine><kubernetes-ingress><affinity>,57907695,1,"your definition is good.

the reason you have two backend's is because your ingress does not define a default backend. gce lb require a default backend so during lb creation, a second backend is added to the lb to act as the default (this backend does nothing but serve 404 responses). the default backend does not use the backendconfig.

this shouldn't be a problem, but if you want to ensure only your backend is used, define a default backend value in your ingress definition by adding the spec.backend:


apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: my-bsc-ingress
spec:
  backend:
    servicename: my-bsc-service
    serviceport: 80
  rules:
  - http:
      paths:
      - path: /*
        backend:
          servicename: my-bsc-service
          serviceport: 80


but, like i said, you don't need to define this, the additional backend won't really come into play and no sessions affinity is required (there is only a single pod anyway). if you are curious, the default backend pod in question is called l7-default-backend-[replicaset_hash]-[pod_hash] in the kube-system namespace
"
60754598,"can't upgrade deployment from apiversion extensions/v1beta1 to apps/v1, it uses extensions/v1beta1 automatically","i currently have a gke kubernetes 1.15 cluster and i'm planning to upgrade to 1.16. since 1.16 doesn't support certain apis i have to change my deployments from extensions/v1beta1 to apps/v1.

using this simple deployment.yml:

apiversion: apps/v1
kind: deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchlabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerport: 80


when i apply it into my 1.15 cluster: kubectl -n mynamespace deployment.yml, what is actually see is the following (kubectl -n mynamespace get deployments nginx-deployment):

apiversion: extensions/v1beta1
kind: deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: ""1""
    kubectl.kubernetes.io/last-applied-configuration: |
...


as you can see the actual apiversion is extensions/v1beta1 instead of apps/v1. why isn't it applying the version i specified?

update:

this is my kubectl version:

client version: version.info{major:""1"", minor:""17"", gitversion:""v1.17.4"", gitcommit:""8d8aa39598534325ad77120c120a22b3a990b5ea"", gittreestate:""clean"", builddate:""2020-03-12t23:41:24z"", goversion:""go1.14"", compiler:""gc"", platform:""darwin/amd64""}
server version: version.info{major:""1"", minor:""15+"", gitversion:""v1.15.9-gke.24"", gitcommit:""39e41a8d6b7221b901a95d3af358dea6994b4a40"", gittreestate:""clean"", builddate:""2020-02-29t01:24:35z"", goversion:""go1.12.12b4"", compiler:""gc"", platform:""linux/amd64""}

",<kubernetes><google-kubernetes-engine><kubectl><kubernetes-deployment>,61034945,4,"the apiversion returned from kubectl get won't necessarily match up with the actual apiversion of your current configuration.

see here: https://github.com/kubernetes/kubernetes/issues/62283#issuecomment-380968868

quote:


  kubectl get uses server-preferred order, which will prefer the extensions api group for backward compatibility, until extensions is removed. that is to say, kubectl get deployment uses extenions/v1beta1 endpoint by default.
  
  to get deployments under apps api group, you can use kubectl get deployment.apps, which returns you apps/v1 deployments.

"
64576277,using a variable within a path in kubernetes,"i have a simple statefulset with two containers. i just want to share a path by an emptydir volume:
volumes:
 - name: shared-folder
 emptydir: {}

the first container is a busybox:
  - image: busybox
    name: test
    command:
      - sleep
      - &quot;3600&quot;
    volumemounts:
    - mountpath: /cache
      name: shared-folder

the second container creates a file on /cache/&lt;pod_name&gt;. i want to mount both paths within the emptydir volume to be able to share files between containers.
  volumemounts:
    - name: shared-folder
      mountpath: /cache/$(hostname)

problem. the second container doesn't resolve /cache/$(hostname) so instead of mounting /cache/pod-0 it mounts /cache/$(hostname). i have also tried getting the pod_name and setting as env variable but it doesn't resolve it neither.
dows anybody knows if it is possible to use a path like this (with env variables) in the mountpath attribute?
",<kubernetes><kubernetes-statefulset>,64588527,3,"to use mountpath with env variable you can use subpath with expanded environment variables (k8s v1.17+).
in your case it would look like following:
containers:
- env:
  - name: my_pod_name
    valuefrom:
      fieldref:
        fieldpath: metadata.name
  volumemounts:
  - mountpath: /cache
    name: shared-folder
    subpathexpr: $(my_pod_name)

"
60572620,helm override common template values,"first day helm user here. trying to understand how to build common templates for k8s resources.
let's say i have 10 cron jobs within single chart, all of them different by args and names only. today 10 full job manifests exists and 95% of manifest content is equal. i want to move common part in template and create 10 manifests where i will provide specific values for args and names.

so i defined template _cron-job.yaml

    {{- define ""common.cron-job""}}
apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: {{ include ""costing-report.name"" . }}-bom-{{ .values.env }}
  labels:
{{ include ""costing-report.labels"" . | indent 4 }}
spec:
  schedule: ""{{ .values.cronjob.schedulebom }}""
  suspend: {{ .values.cronjob.suspendbom }}
  {{- with .values.cronjob.concurrencypolicy }}
  concurrencypolicy: {{ . }}
  {{- end }}
  {{- with .values.cronjob.failedjobshistorylimit }}
  failedjobshistorylimit: {{ . }}
  {{- end }}
  {{- with .values.cronjob.successfuljobshistorylimit }}
  successfuljobshistorylimit: {{ . }}
  {{- end }}
  jobtemplate:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include ""costing-report.name"" . }}
        app.kubernetes.io/instance: {{ .release.name }}
    spec:
      template:
        spec:
          containers:
            - name: {{ .chart.name }}
              image: ""{{ .values.image.repository }}:{{ .values.image.tag }}""
              imagepullpolicy: {{ .values.image.pullpolicy }}
              args: [""--report=bom"",""--email={{ .values.configmap.service.email_bom }}""]
              env:
                - name: spring_profiles_active
                  value: ""{{ .values.env }}""
              envfrom:
                - configmapref:
                    name: {{ include ""costing-report.fullname"" . }}
                - secretref:
                    name: {{ .values.secrets.properties }}
          restartpolicy: never
          {{- with .values.imagepullsecrets }}
          imagepullsecrets:
            {{- toyaml . | nindent 8 }}
          {{- end }}    
{{- end -}}


and now i need to create job manifest that override name and args job1.yaml

{{- template ""common.cron-job"" . -}}
??? override ???
name: {{ include ""cost-report.name"" . }}-job1-{{ .values.env }}
jobtemplate:
spec:
  template:
    spec:
      containers:
        args: [""--report=bom"",""--email={{ .values.configmap.service.email_bom }}""]


is there any way to do this? i didn't find this in helm docs. i did find this https://github.com/helm/charts/tree/master/incubator/common but it didn't work as well and gave me error.

thanks.
",<templates><kubernetes><charts><overriding><kubernetes-helm>,60607991,1,"solution found

option 1
use example from helm github https://github.com/helm/charts/tree/master/incubator/common 
solution based on yaml merging and values override. pretty flexible, allow you to define common templates and the use them to compose final k8s manifest. 

option 2
define common template and pass parameters with desired values.
in my case it looks smth like this.

_common.cronjob.yaml

{{- define ""common.cronjob"" -}}
{{- $root := .root -}} 
{{- $name := .name -}} 
{{- $schedule := .schedule -}} 
{{- $suspend := .suspend -}} 
{{- $args := .args -}} 

apiversion: batch/v1beta1
kind: cronjob
metadata:
  name: {{ $name }}
  labels:
{{ include ""costing-report.labels"" $root | indent 4 }}
spec:
  schedule: {{ $schedule }}
  suspend: {{ $suspend }}
  {{- with $root.values.cronjob.concurrencypolicy }}
  concurrencypolicy: {{ . }}
  {{- end }}
  {{- with $root.values.cronjob.failedjobshistorylimit }}
  failedjobshistorylimit: {{ . }}
  {{- end }}
  {{- with $root.values.cronjob.successfuljobshistorylimit }}
  successfuljobshistorylimit: {{ . }}
  {{- end }}
  jobtemplate:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include ""costing-report.name"" $root }}
        app.kubernetes.io/instance: {{ $root.release.name }}
    spec:
      template:
        spec:
          containers:
            - name: {{ $root.chart.name }}
              image: ""{{ $root.values.image.repository }}:{{ $root.values.image.tag }}""
              imagepullpolicy: {{ $root.values.image.pullpolicy }}
              args: {{ $args }}
              env:
                - name: spring_profiles_active
                  value: ""{{ $root.values.env }}""
              envfrom:
                - configmapref:
                    name: {{ include ""costing-report.fullname"" $root }}
                - secretref:
                    name: {{ $root.values.secrets.properties }}
          restartpolicy: never
          {{- with $root.values.imagepullsecrets }}
          imagepullsecrets:
            {{- toyaml . | nindent 8 }}
          {{- end }}
{{- end -}}


then create job manifest(s), define values to pass to common template

bom-cronjob.yaml

{{ $bucket := (printf ""%s%s%s"" ""\""--bucket=ll-costing-report-"" .values.env ""\"","" )}}
{{ $email := (printf ""%s%s%s"" ""\""--email="" .values.configmap.service.email_bom ""\"""") }}
{{ $args := (list ""\""--report=bom\"","" ""\""--reporttype=load\"","" ""\""--source=bamboorose\"","" $bucket ""\""--table=costing_bom\"","" ""\""--ignorelines=1\"","" ""\""--truncate=true\"","" $email )}}
{{ $name := (printf ""%s%s"" ""costing-report.name-bom-"" .values.env )}}
{{- template ""common.cronjob"" (dict ""root"" . ""name"" $name ""schedule"" .values.cronjob.schedulebom ""suspend"" .values.cronjob.suspendbom ""args"" $args) -}}


last line do the trick. trick is that you can pass only single argument to template, in my case it's dictionary with all values that i need on template side. you can omit defining template variables and use dict values right away. please note that i pass root context (scope) as ""root"" and prefix . with ""root"" in template.
"
63510597,using generatename for yaml file to be installed by helm,"i have upload.yaml file which is uploads a script to mongo, i package with helm.
apiversion: batch/v1
kind: job
metadata:
  generatename: upload-strategy-to-mongo-v2
spec:
  parallelism: 1
  completions: 1
  template:
    metadata:
      name: upload-strategy-to-mongo
    spec:
      volumes:
      - name: upload-strategy-to-mongo-scripts-volume
        configmap:
          name: upload-strategy-to-mongo-scripts-v3
      containers:
      - name: upload-strategy-to-mongo
        image: mongo
        env:
        - name: mongodb_uri
          value: @@@@
        - name: mongodb_username
          valuefrom:
            secretkeyref:
              name: mongodb-user
              key: @@@@
        - name: mongodb_password
          valuefrom:
            secretkeyref:
              name: mongodb-user
              key: @@@@@
        volumemounts:
          - mountpath: /scripts
            name: upload-strategy-to-mongo-scripts-volume
        command: [&quot;mongo&quot;]
        args:
          - $(mongodb_uri)/ravnml
          - --username
          - $(mongodb_username)
          - --password
          - $(mongodb_password)
          - --authenticationdatabase
          - admin
          - /scripts/upload.js
      restartpolicy: never
---
apiversion: v1
kind: configmap
metadata:
  creationtimestamp: null
  name:  upload-strategy-to-mongo-scripts-v3
data:
  upload.js: |
    // read the object from file and parse it
    var data = cat('/scripts/strategy.json');
    var obj = json.parse(data);

    // upsert strategy
    print(db.strategy.find());
    db.strategy.replaceone(
        { name : obj.name },
          obj,
        { upsert: true }
    )
    print(db.strategy.find());
  strategy.json: {{ .files.get &quot;strategy.json&quot; | quote }}

now i am using generatename to generate a custom name every time i install it. i require to have multiple packages been installed and i require the name to be dynamic.
error
when i install this script with helm install &lt;name&gt; &lt;tar.gz file&gt; -n &lt;namespace&gt; i get the following error
error: rendered manifests contain a resource that already exists. unable to continue with install: could not get information about the resource: resource name may not be empty

but i am able to install if i don't use generatename. any ideas?
i looked at various resources but they don't seem to answer how to install via helm.
references looked:
add random string on kubernetes pod deployment name https://github.com/kubernetes/kubernetes/issues/44501 ;
https://zknill.io/posts/kubernetes-generated-names/
",<kubernetes><kubernetes-helm><kubectl><kubernetes-pod>,63511647,5,"this seems to be a known issue. helm doesn't work with generatename. for unique names, you can use the helm's build in properties like revision or name. see the following link for reference:

https://github.com/helm/helm/issues/3348#issuecomment-482369133

"
72547695,duplicate an existing k8s pod,"in a namespace foo there is an existing pod running
$ kubectl get pods -n foo

name                      ready     status    restarts   age
hello-1816639685-xejyk    1/1       running   0          6d3h

how can we duplicate the hello pod so that we can try out things in this duplicated pod without affecting the original pod?
",<ubuntu><kubernetes><kubectl><kubernetes-pod>,72547757,3,"you can get the pod manifest using yaml output from kubectl and create a new pod based on that specification.
for example
kubectl get pod hello-1816639685-xejyk -n foo -o yaml
you need to use a different name or namespace, since the name must be unique.
"
59107069,how to enable a feature gate in google kubernetes engine?,"i'm create gke clusters for end-to-end tests programmatically with

gcloud container clusters create mereet-e2e-$ci_commit_short_sha-$ci_pipeline_iid --machine-type=n1-standard-1 --no-enable-stackdriver-kubernetes --no-enable-autoupgrade --preemptible --enable-kubernetes-alpha --quiet


afaik feature flags are enabled with kubeadm init which is run by gke. i searched carefully through options of gcloud, gcloud container, gcloud container clusters and gcloud container clusters create as well as their gcloud alpha and gcloud beta equivalents with no clue how to control feature gates.

i would like to activate the feature gate startupprobe.

i tried beta and alpha clusters in the hope that my feature gate is already active in these versions. it's not a problem that the feature will be only available in beta or alpha.
",<kubernetes><google-kubernetes-engine><gcloud>,59107250,2,"accroding to the docs, startupprobe is a 1.16 alpha feature, while on gke you can create clusters up to 1.14.



so, it won't even be documented in gcp docs. besides, note that you don't have access to k8s master on gke. only to some features.

with kubeadm you can do whatever you want.
"
54190531,helm prevent from adding the default chart repo on helm init,"i want to use helm with gitlab to deploy my services to openshift.

i have a gitlab runner deployed in openshift. 

i already have tiller installed in openshift under the tiller namespace and am using the docker image docker.greater.com.au/platform/images/dtzar/helm-kubectl:latest

my system is also behind a proxy which i won't be able to get past.

as part of one of my gitlab ci build steps i have the following:

$ helm init --client-only
creating /root/.helm 
creating /root/.helm/repository 
creating /root/.helm/repository/cache 
creating /root/.helm/repository/local 
creating /root/.helm/plugins 
creating /root/.helm/starters 
creating /root/.helm/cache/archive 
creating /root/.helm/repository/repositories.yaml 
adding stable repo with url: https://kubernetes-charts.storage.googleapis.com 
error: looks like ""https://kubernetes-charts.storage.googleapis.com"" is not a valid chart repository or cannot be reached: get https://kubernetes-charts.storage.googleapis.com/index.yaml: proxy authorization required


my main question is i am wondering if it's possible to disable helm from trying to add https://kubernetes-charts.storage.googleapis.com as a repostiory as part of helm init?

it might be worth noting that i do not know if helm init --client-only is a required step in using helm with this setup.

i have also tried a simple helm version and the server is responding with a proxy authorization required error.

client: &amp;version.version{semver:""v2.12.1"", 
gitcommit:""02a47c7249b1fc6d8fd3b94e6b4babf9d818144e"", gittreestate:""clean""}
error: get https://---.---.---.---:---/api/v1/namespaces/tiller/pods?labelselector=app%3dhelm%2cname%3dtiller: proxy authorization required


i've removed the ip address but it's trying to resolve the tiller server from the wrong ip address when running this helm version command.
",<kubernetes><gitlab><openshift><kubernetes-helm>,54331487,6,"you can define which stable repository you would like to use with option -o --stable-repo-url url.

example: helm init --client-only --stable-repo-url https://path.to.my.repo

you could found more info here
"
67058841,nginx returning incorrect content-type,"i have a vue.js application, and my deployment setup is very standard,

pod -&gt; service -&gt; ingress

here's the related code,
dockerfile:
from node:lts-alpine as build
workdir /app
copy . .

# default build mode
arg mode=production

# build the dist folder
run npm ci
run npm run build ${mode}

# serve from nginx
from nginx:alpine
copy ./nginx.conf /etc/nginx/nginx.conf
copy --from=build /app/dist /usr/share/nginx/html

nginx.conf:
user  nginx;
worker_processes  1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;
events {
  worker_connections  1024;
}
http {
  include       /etc/nginx/mime.types;
  default_type  application/octet-stream;
  log_format  main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
                    '$status $body_bytes_sent &quot;$http_referer&quot; '
                    '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';
  access_log  /var/log/nginx/access.log  main;
  sendfile        on;
  keepalive_timeout  65;
  server {
    listen       8080;
    location / {
      root   /usr/share/nginx/html;
      index  index.html;
      try_files $uri $uri/ /index.html;
    }
  }
}

ingress prod: (kept only the necessary bits for brevity sakes),
apiversion: extensions/v1beta1
kind: ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
  labels:
    app: &lt;my-app&gt;
    app.kubernetes.io/instance: &lt;my-instance&gt;
  name: &lt;my-name&gt;
  namespace: &lt;my-namespace&gt;
spec:
  rules:
    - host: &lt;my-host&gt;
      http:
        paths:
          - backend:
              servicename: livspace-hub
              serviceport: 80
            path: /


ingress local:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: &lt;my-app-name&gt;
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: &lt;my-host&gt;
    http:
      paths:
      - path: /
        pathtype: prefix
        backend:
          service:
            name: hub-service
            port:
              number: 9090

the error i get is,

uncaught syntaxerror: unexpected token '&lt;' chunk-vendors.a727ce10.js:1
uncaught syntaxerror: unexpected token '&lt;' app.a68a0468.js:1

and the content-type for both these resources in the network tab is text/html.
edit 1:
this is what my folder looks like after deployment,
/usr/share/nginx/html # ls
50x.html assets css  favicon.ico fonts index.html  js  styles

the path for my js file is,
https://&lt;my-domain&gt;/js/app.a68a0468.js
edit 2:
here are the logs from my local vs deployed application.
local:

 - - [12/apr/2021:10:38:18 +0000] &quot;get / http/1.1&quot; 200 3213 &quot;-&quot; &quot;mozilla/5.0 (macintosh; intel mac os x 11_2_3) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.114 safari/537.36 edg/89.0.774.75&quot;
 - - [12/apr/2021:10:38:18 +0000] &quot;get /css/milestone.1c126aff.css http/1.1&quot; 200 1139 &quot;http:///&quot; &quot;mozilla/5.0 (macintosh; intel mac os x 11_2_3) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.114 safari/537.36 edg/89.0.774.75&quot;
 - - [12/apr/2021:10:38:18 +0000] &quot;get /css/catalogue.5794c500.css http/1.1&quot; 200 156 &quot;http:///&quot; &quot;mozilla/5.0 (macintosh; intel mac os x 11_2_3) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.114 safari/537.36 edg/89.0.774.75&quot;

deployed:

 - - [12/apr/2021:12:46:28 +0000] &quot;get / http/1.1&quot; 200 3213 &quot;https:///&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.90 safari/537.36 edg/89.0.774.54&quot;
 - - [12/apr/2021:12:46:28 +0000] &quot;get / http/1.1&quot; 200 3213 &quot;https:///&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.90 safari/537.36 edg/89.0.774.54&quot;
 - - [12/apr/2021:12:46:28 +0000] &quot;get / http/1.1&quot; 200 3213 &quot;https:///&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.90 safari/537.36 edg/89.0.774.54&quot;
 - - [12/apr/2021:12:46:28 +0000] &quot;get / http/1.1&quot; 200 3213 &quot;https:///&quot; &quot;mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/89.0.4389.90 safari/537.36 edg/89.0.774.54&quot;

my local instance is also run via docker/docker-compose, so the setup is essentially the same.
as you can see, my local setup logs show requests for specific files - get /&lt;filename&gt; - whereas the deployed instance shows only logs for get /.
",<docker><nginx><kubernetes><kubernetes-ingress><nginx-ingress>,67077601,3,"tl;dr
remove/modify the following annotation from ingress prod:

nginx.ingress.kubernetes.io/rewrite-target: /$2


explanation:
the annotation that you are using (rewrite-target: /$2) is targeting a capture group that does not exist.
each request that is sent to your application through your ingress resource is getting rewritten to /.
to fix that you can either:

entirely remove this annotation.
modify the annotation that would support your rewrite, for example: /.

you can read more about rewrites, capture groups and how nginx-ingress handles them by following this documentation:

kubernetes.github.io: ingress nginx: examples: rewrite


example:
i've used your exact ingress manifest with slight tweaks and stumbled upon the same issue as you've described:

curl ip
curl ip/hello.html

to show the request that came to the pod i've used nginx pod as a backend:
/docker-entrypoint.sh: configuration complete; ready for start up
10.88.0.20 - - [13/apr/2021:15:01:37 +0000] &quot;get / http/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.64.1&quot; &quot;source_ip_of_mine&quot;
10.88.0.20 - - [13/apr/2021:15:01:40 +0000] &quot;get / http/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.64.1&quot; &quot;source_ip_of_mine&quot;


additional resources:

kubernetes.io: docs: concepts: services networking: ingress

"
67662353,four different errors when using kubectl apply command,"my docker-compose file is as below:
version: '3'

services:
    nginx:
        build: .
        container_name: nginx
        ports:
            - '80:80'

and my dockerfile:
from nginx:alpine

i used kompose konvert and it created two files called nginx-deployment.yml and nginx-service.yml with the below contents.
nginx-deployment.yml:
apiversion: apps/v1
kind: deployment
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.22.0 (955b78124)
  creationtimestamp: null
  labels:
    io.kompose.service: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchlabels:
      io.kompose.service: nginx
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert
        kompose.version: 1.22.0 (955b78124)
      creationtimestamp: null
      labels:
        io.kompose.service: nginx
    spec:
      containers:
        - image: nginx:alpine
          name: nginx
          ports:
            - containerport: 80
          resources: {}
      restartpolicy: always
status: {}

and nginx-service.yml:
apiversion: v1
kind: service
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.22.0 (955b78124)
  creationtimestamp: null
  labels:
    io.kompose.service: nginx
  name: nginx
spec:
  ports:
    - name: &quot;80&quot;
      port: 80
      targetport: 80
  selector:
    io.kompose.service: nginx
status:
  loadbalancer: {}

my kustomization.yml:
resources:
        - nginx-deployment.yml
        - nginx-service.yml

all files are in the same path /home.
i run these three commands but for each of them i got a different error:

kubectl apply -f kustomization.yml:

error: error validating &quot;kustomization.yml&quot;: error validating data: [apiversion not set, kind not set]; if you choose to ignore these errors, turn validation off with --validate=false


kubectl apply -k .:

error: accumulating resources: accumulation err='accumulating resources from 'nginx-deployment.yml': evalsymlink failure on '/home/nginx-deployment.yml' : lstat /home/nginx-deployment.yml: no such file or directory': evalsymlink failure on '/home/nginx-deployment.yml' : lstat /home/nginx-deployment.yml: no such file or directory


kubectl apply -f kustomization.yml --validate=false:

error: unable to decode &quot;kustomization.yml&quot;: object 'kind' is missing in '{&quot;resources&quot;:[&quot;nginx-deployment.yml&quot;,&quot;nginx-service.yml&quot;]}'


kubectl apply -k . --validate=false:

error: accumulating resources: accumulation err='accumulating resources from 'nginx-deployment.yml': evalsymlink failure on '/home/nginx-deployment.yml' : lstat /home/nginx-deployment.yml: no such file or directory': evalsymlink failure on '/home/nginx-deployment.yml' : lstat /home/nginx-deployment.yml: no such file or directory

the kubernetes is a single node.
why i'm getting these errors and how may i run my container in this environment?
",<kubernetes><kubectl><kustomize>,67662695,4,"your kustomization.yml file has two errors. the files generated by kompose have .yaml extensions but you are referring to .yml and you are missing the kind and apiversion lines.
apiversion: kustomize.config.k8s.io/v1beta1
kind: kustomization

resources:
  - nginx-deployment.yaml
  - nginx-service.yaml

kubectl apply -k .

"
73382225,kubeconfig - oidc based authentication,"below is my kubeconfig file for accessing kubernetes clusters:
kind: clientconfig
apiversion: authentication.gke.io/v2alpha1
spec:
  name: dev-corp
  server: https://10.x.x.x:443
  certificateauthoritydata: ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc
  authentication:
  - name: oidc
    oidc:
      clientid: aaaaad3-9aa1-33c8-dd0-ddddd6b5bf5
      clientsecret: ccccccccccccccccc-
      issueruri: https://login.microsoftonline.com/aaaa92-aab7-bbfa-cccf-ddaaaaaaaa/v2.0
      kubectlredirecturi: http://localhost:12345/callback
      cloudconsoleredirecturi: http://console.cloud.google.com/kubernetes/oidc
      scopes: offline_access,profile
      userclaim: upn
      userprefix: '-'
      groupsclaim: groups
  preferredauthentication: oidc


there are different oauth grant types.
my understanding is, above oauth grant type is client credential grant type, that requires client_id, client_secret, token url(issueruri), scope


what is the significance of fields kubectlredirecturi, cloudconsoleredirecturi, userclaim, userprefix?

how oidc different from oauth2?

oauth2.config does not store userclaim &amp; userprefix, groupsclaim information
, as shown here.... https://github.com/golang/oauth2/blob/master/oauth2.go#l41
how to store kind:clientconfig with oidc based authentication into cache? for example api.config can be  stored with an api from client-go to write api.config as shown here.


",<kubernetes><oauth-2.0><openid-connect><kubectl>,73382406,2,"kubectl_redirect_url: the redirect url that kubectl oidc login uses for authorization. this is typically of the format http://localhost:port/callback, where port is any port above 1024 that will be available on developer workstations, for example http://localhost:10000/callback. you must register the url with your oidc provider as an authorized redirect url for the client application.
user_prefix: prefix prepended to user claims to prevent conflicts with existing names. by default, an issuer prefix is appended to the userid given to the kubernetes api server (unless the user claim is email). the resulting user identifier is issuer_uri#user. we recommend using a prefix, but you can disable the prefix by setting user_prefix to -.
userclaim: the user identifier in the token under the claim name configured in spec.authentication.oidc.userclaim in the client configuration file.
cloudconsoleredirecturi the name tell the story, the cloud redirect url for oidc, for example in case of google https://console.cloud.google.com/kubernetes/oidc
oidc vs oauth2
what&#39;s the difference between openid and oauth?
the file in the question from oidc and you are comparing the value with oauth, both handling at different way, better to update the question again with oauth config file.
api-server-authentication
you can check kubeconfig builder
kubernetes-engine-oidc

how to store kind:clientconfig with oidc based authentication into cache?

you can write to a file and then read, or somewhere in the cloud storage as well
"
59664244,how to generate a random string / password in kubernetes secrets,"for now, i deploy my application pods using static files and one of them is app-secrets.yaml with all secrets to deploy an application

---
apiversion: v1
kind: secret
metadata:
  name: app-secrets
type: opaque
data:
  root: xxxxxx
  user1: xxxxxx
  user2: xxxxxx


but this is not neither secure nor convenient (if i need another app instance, i have to create another file with human-generated password).

i'm looking to generate random passwords at application creation but i don't know if it's possible.
i've already looked to the topic secret and especially secretgenerator but this is not directly what i want as i understand it, because it does not create a random string but a random secret name like secret/app-secrets-ssdsdfmfh4k but i have to provide still the passwords.
",<kubernetes><kubernetes-secrets>,59666255,7,"you may want to use kubernetes-secret-generator. i've tested it and it's doing exactly what you need.
to accomplish it you have to have helm in your cluster and follow these instructions:
clone repository
$ git clone https://github.com/mittwald/kubernetes-secret-generator

create helm deployment
$ helm upgrade --install secret-generator ./deploy/chart

now you to use it, you just have to

add annotation secret-generator.v1.mittwald.de/autogenerate to any
kubernetes secret object .the value of the annotation can be a field
name (or comma separated list of field names) within the secret; the
secretgeneratorcontroller will pick up this annotation and add a field
[or fields] (password in the example below) to the secret with a
randomly generated string value. from here.

$ kubectl apply -f mysecret.yaml
apiversion: v1
kind: secret
metadata:
  name: mysecret
  annotations:
    secret-generator.v1.mittwald.de/autogenerate: password
data:
  username: ugxlyxnlqwnjzxb0cg==

after applying this secret you can take a look at it to check if the passward was generated as expected:
$ kubectl get secrets mysecret -o yaml
apiversion: v1
data:
  password: dnvktdbjz0tfs1bacmttmnbuc3d2yws2ylzsz0xptufkdstda3dwuq==
  username: ugxlyxnlqwnjzxb0cg==
kind: secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiversion&quot;:&quot;v1&quot;,&quot;data&quot;:{&quot;username&quot;:&quot;ugxlyxnlqwnjzxb0cg==&quot;},&quot;kind&quot;:&quot;secret&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;secret-generator.v1.mittwald.de/autogenerate&quot;:&quot;password&quot;},&quot;name&quot;:&quot;mysecret&quot;,&quot;namespace&quot;:&quot;default&quot;}}
    secret-generator.v1.mittwald.de/autogenerate: password
    secret-generator.v1.mittwald.de/autogenerate-generated-at: 2020-01-09 14:29:44.397648062
      +0000 utc m=+664.011602557
    secret-generator.v1.mittwald.de/secure: &quot;yes&quot;
  creationtimestamp: &quot;2020-01-09t14:29:44z&quot;
  name: mysecret
  namespace: default
  resourceversion: &quot;297425&quot;
  selflink: /api/v1/namespaces/default/secrets/mysecret
  uid: 7ae42d71-32ec-11ea-92b3-42010a800009
type: opaque

as we can see, the password was generated.
"
71221736,how to change docker default storage size,"i've been having loads of issues with kubectl not having enough space. how can i increase the default storage size allocated to docker?
none of minikube recommendations worked.
1. run &quot;docker system prune&quot; to remove unused docker data (optionally with &quot;-a&quot;)
2. increase the storage allocated to docker for desktop by clicking on:
   docker icon &gt; preferences &gt; resources &gt; disk image size
3. run &quot;minikube ssh -- docker system prune&quot; if using the docker container runtime

and the second is not possible from command line...
",<docker><kubernetes><kubectl><minikube>,71222086,3,"taking your comment into consideration

i get imagepullbackoff when i try to deploy nginx on the cluster –
caterina

you can specify minikube's disk allocations separately:
minikube start --memory=8192 --cpus=4 --disk-size=50g
which can help you to work around the disk space issues as the default is significantly smaller:  --disk-size string disk size allocated to the minikube vm (format: &lt;number&gt;[&lt;unit&gt;], where unit = b, k, m or g). (default &quot;20000mb&quot;)
"
55673385,"helm upgrade fails with ""function ""x"" not defined""","i'm trying to upgrade a helm chart,

i get the error function ""pod"" not defined which make sense because i really have no such function.

the ""pod"" is coming from a json file which i convert into a configmap and helm is reading this value as a function and not as a straight string which is part of the json file.

this is a snippet of my configmap:

# generated from 'pods' from https://raw.githubusercontent.com/coreos/prometheus-operator/master/contrib/kube-prometheus/manifests/grafana-dashboarddefinitions.yaml
# do not change in-place! in order to change this file first read following link:
# https://github.com/helm/charts/tree/master/stable/prometheus-operator/hack
{{- if and .values.grafana.enabled .values.grafana.defaultdashboardsenabled }}
apiversion: v1
kind: configmap
metadata:
  name: {{ printf ""%s-%s"" (include ""prometheus-operator.fullname"" $) ""services-health"" | trunc 63 | trimsuffix ""-"" }}
  labels:
    {{- if $.values.grafana.sidecar.dashboards.label }}
    {{ $.values.grafana.sidecar.dashboards.label }}: ""1""
    {{- end }}
    app: {{ template ""prometheus-operator.name"" $ }}-grafana
{{ include ""prometheus-operator.labels"" $ | indent 4 }}
data:
  services-health.json: |-
    {
      ""annotations"": {
        ""list"": [
          {
            ""builtin"": 1,
            ""datasource"": ""-- grafana --"",
            ""enable"": true,
            ""hide"": true,
            ""iconcolor"": ""rgba(0, 211, 255, 1)"",
            ""name"": ""annotations &amp; alerts"",
            ""type"": ""dashboard""
          }
        ]
      },
      ""targets"": [
        {
          ""expr"": ""{__name__=~\""kube_pod_container_status_ready\"", container=\""aggregation\"",kubernetes_namespace=\""default\"",chart=\""\""}"",
          ""format"": ""time_series"",
          ""instant"": false,
          ""intervalfactor"": 2,
          ""legendformat"": ""{{pod}}"",
          ""refid"": ""a""
        }
}
{{- end }}


the error i get is coming from this line: ""legendformat"": ""{{pod}}"",

and this is the error i get:


  helm upgrade --dry-run prometheus-operator-chart
  /home/ubuntu/infra-devops/helm/vector-chart/prometheus-operator-chart/
      error: upgrade failed: parse error in ""prometheus-operator/templates/grafana/dashboards/services-health.yaml"":
  template:
  prometheus-operator/templates/grafana/dashboards/services-health.yaml:1213:
  function ""pod"" not defined


i tried to escape it but nothing worked.
anyone get idea about how i can work around this issue?
",<kubernetes><kubernetes-helm><configmap>,55673990,15,"escaping gotpl placeholders is possible using backticks. for example, in your scenario, instead of using {{ pod }} you could write {{` {{ pod }} `}}.
"
72490855,clusterip service not accessible from within the cluster pods,"i have got 2 deployments in my cluster ui and user. both of these are exposed by cluster ip service. there is an ingress which makes both the services publicly accessible.
now when i do  &quot;kubectl exec -it ui-pod -- /bin/sh&quot; and then try to &quot;ping user-service-cluster-ip:port&quot; it doesn't work.
all i get is no packet returned i.e. a failure message.
attaching my .yml file
apiversion: apps/v1
kind: deployment
metadata:
  name: user-service-app
  labels:
    app: user-service-app
spec:
  replicas: 1
  selector:
    matchlabels:
      app: user-service-app
  template:
    metadata:
      labels:
        app: user-service-app
    spec:
      containers:
      - name: user-service-app
        image: &lt;my-image-url&gt;
        imagepullpolicy: always
        ports:
        - containerport: 3000
        livenessprobe:
          httpget:
            path: /ping
            port: 3000
        readinessprobe:
          httpget:
            path: /ping
            port: 3000
          
          

---
apiversion: &quot;v1&quot;
kind: &quot;service&quot;
metadata:
  name: &quot;user-service-svc&quot;
  namespace: &quot;default&quot;
  labels:
    app: &quot;user-service-app&quot;
spec:
  type: &quot;clusterip&quot;
  selector:
    app: &quot;user-service-app&quot;
  ports:
  - protocol: &quot;tcp&quot;
    port: 80
    targetport: 3000

---
apiversion: apps/v1
kind: deployment
metadata:
  name: ui-service-app
  labels:
    app: ui-service-app
spec:
  replicas: 1
  selector:
    matchlabels:
      app: ui-service-app
  template:
    metadata:
      labels:
        app: ui-service-app
    spec:
      containers:
      - name: ui-service-app
        image: &lt;my-image-url&gt;
        imagepullpolicy: always
        ports:
        - containerport: 3000

---
apiversion: &quot;v1&quot;
kind: &quot;service&quot;
metadata:
  name: &quot;ui-service-svc&quot;
  namespace: &quot;default&quot;
  labels:
    app: &quot;ui-service-app&quot;
spec:
  type: &quot;clusterip&quot;
  selector:
    app: &quot;ui-service-app&quot;
  ports:
  - protocol: &quot;tcp&quot;
    port: 80
    targetport: 3000
  


---
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: awesome-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  ingressclassname: nginx
  defaultbackend:
    service:
      name: ui-service-svc
      port:
        number: 80
  rules:
  - http:
      paths:      
      - path: /login
        pathtype: prefix
        backend:
          service:
            name: ui-service-svc
            port:
              number: 80
      - path: /user(/|$)(.*)
        pathtype: prefix
        backend:
          service:
            name: user-service-svc
            port:
              number: 80

",<kubernetes><devops><kubernetes-ingress><kubernetes-service>,72491684,1,"ping operates by means of internet control message protocol (icmp) packets. this is not what your service is serving. you can try curl user-service-cluster-ip/ping or curl http://user-service-svc/ping within your ui pod.
"
59550564,kubelet does not have clusterdns ip configured in microk8s,"i'm using microk8s in ubuntu.
i'm trying to run a simple &quot;hello world&quot; program but i got the error when a pod is created.

kubelet does not have clusterdns ip configured and cannot create pod using &quot;clusterfirst&quot; policy. falling back to &quot;default&quot; policy

here is my deployment.yaml file which i'm trying to apply:
apiversion: v1
kind: service
metadata:
  name: grpc-hello
spec:
  ports:
  - port: 80
    targetport: 9000
    protocol: tcp
    name: http
  selector:
    app: grpc-hello
  type: nodeport
---
apiversion: apps/v1
kind: deployment
metadata:
  name: grpc-hello
spec:
  replicas: 1
  selector:
    matchlabels:
      app: grpc-hello
  template:
    metadata:
      labels:
        app: grpc-hello
    spec:
      containers:
      - name: esp
        image: gcr.io/endpoints-release/endpoints-runtime:1
        args: [
          &quot;--http2_port=9000&quot;,
          &quot;--backend=grpc://127.0.0.1:50051&quot;,
          &quot;--service=hellogrpc.endpoints.octa-test-123.cloud.goog&quot;,
          &quot;--rollout_strategy=managed&quot;,
        ]
        ports:
          - containerport: 9000
      - name: python-grpc-hello
        image: gcr.io/octa-test-123/python-grpc-hello:1.0
        ports:
          - containerport: 50051

here is what i got when i try to describe the pod:
events:
  type     reason             age                from                   message
  ----     ------             ----               ----                   -------
  normal   scheduled          31s                default-scheduler      successfully assigned default/grpc-hello-66869cf9fb-kpr69 to azeem-ubuntu
  normal   started            30s                kubelet, azeem-ubuntu  started container python-grpc-hello
  normal   pulled             30s                kubelet, azeem-ubuntu  container image &quot;gcr.io/octa-test-123/python-grpc-hello:1.0&quot; already present on machine
  normal   created            30s                kubelet, azeem-ubuntu  created container python-grpc-hello
  normal   pulled             12s (x3 over 31s)  kubelet, azeem-ubuntu  container image &quot;gcr.io/endpoints-release/endpoints-runtime:1&quot; already present on machine
  normal   created            12s (x3 over 31s)  kubelet, azeem-ubuntu  created container esp
  normal   started            12s (x3 over 30s)  kubelet, azeem-ubuntu  started container esp
  warning  missingclusterdns  8s (x10 over 31s)  kubelet, azeem-ubuntu  pod: &quot;grpc-hello-66869cf9fb-kpr69_default(19c5a870-fcf5-415c-bcb6-dedfc11f936c)&quot;. kubelet does not have clusterdns ip configured and cannot create pod using &quot;clusterfirst&quot; policy. falling back to &quot;default&quot; policy.
  warning  backoff            8s (x2 over 23s)   kubelet, azeem-ubuntu  back-off restarting failed container
events:
  type     reason             age                from                   message
  ----     ------             ----               ----                   -------
  normal   scheduled          31s                default-scheduler      successfully assigned default/grpc-hello-66869cf9fb-kpr69 to azeem-ubuntu
  normal   started            30s                kubelet, azeem-ubuntu  started container python-grpc-hello
  normal   pulled             30s                kubelet, azeem-ubuntu  container image &quot;gcr.io/octa-test-123/python-grpc-hello:1.0&quot; already present on machine
  normal   created            30s                kubelet, azeem-ubuntu  created container python-grpc-hello
  normal   pulled             12s (x3 over 31s)  kubelet, azeem-ubuntu  container image &quot;gcr.io/endpoints-release/endpoints-runtime:1&quot; already present on machine
  normal   created            12s (x3 over 31s)  kubelet, azeem-ubuntu  created container esp
  normal   started            12s (x3 over 30s)  kubelet, azeem-ubuntu  started container esp
  warning  missingclusterdns  8s (x10 over 31s)  kubelet, azeem-ubuntu  pod: &quot;grpc-hello-66869cf9fb-kpr69_default(19c5a870-fcf5-415c-bcb6-dedfc11f936c)&quot;. kubelet does not have clusterdns ip configured and cannot create pod using &quot;clusterfirst&quot; policy. falling back to &quot;default&quot; policy.
  warning  backoff            8s (x2 over 23s)   kubelet, azeem-ubuntu  back-off restarting failed container

i researched this and i found some answers, but none are working for me. i also create the kube-dns for this but don't know why this still is not working. these kube-dns are running. kube-dns are in kube-system namespace.
name                       ready   status    restarts   age
kube-dns-6dbd676f7-dfbjq   3/3     running   0          22m

and here is what i apply to create the kube-dns:
apiversion: v1
kind: service
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: reconcile
    kubernetes.io/name: &quot;kubedns&quot;
spec:
  selector:
    k8s-app: kube-dns
  clusterip: 10.152.183.10
  ports:
  - name: dns
    port: 53
    protocol: udp
  - name: dns-tcp
    port: 53
    protocol: tcp
---
apiversion: v1
kind: serviceaccount
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: reconcile
---
apiversion: v1
kind: configmap
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: ensureexists
data:
  upstreamnameservers: |-
    [&quot;8.8.8.8&quot;, &quot;8.8.4.4&quot;]
# why set upstream ns: https://github.com/kubernetes/minikube/issues/2027
---
apiversion: apps/v1
kind: deployment
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: reconcile
spec:
  # replicas: not specified here:
  # 1. in order to make addon manager do not reconcile this replicas parameter.
  # 2. default is 1.
  # 3. will be tuned in real time if dns horizontal auto-scaling is turned on.
  strategy:
    rollingupdate:
      maxsurge: 10%
      maxunavailable: 0
  selector:
    matchlabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
      - key: &quot;criticaladdonsonly&quot;
        operator: &quot;exists&quot;
      volumes:
      - name: kube-dns-config
        configmap:
          name: kube-dns
          optional: true
      containers:
      - name: kubedns
        image: gcr.io/google-containers/k8s-dns-kube-dns:1.15.8
        resources:
          # todo: set memory limits when we've profiled the container for large
          # clusters, then set request = limit to keep this container in
          # guaranteed class. currently, this container falls into the
          # &quot;burstable&quot; category so the kubelet doesn't backoff from restarting it.
          limits:
            memory: 170mi
          requests:
            cpu: 100m
            memory: 70mi
        livenessprobe:
          httpget:
            path: /healthcheck/kubedns
            port: 10054
            scheme: http
          initialdelayseconds: 60
          timeoutseconds: 5
          successthreshold: 1
          failurethreshold: 5
        readinessprobe:
          httpget:
            path: /readiness
            port: 8081
            scheme: http
          # we poll on pod startup for the kubernetes master service and
          # only setup the /readiness http server once that's available.
          initialdelayseconds: 3
          timeoutseconds: 5
        args:
        - --domain=cluster.local.
        - --dns-port=10053
        - --config-dir=/kube-dns-config
        - --v=2
        env:
        - name: prometheus_port
          value: &quot;10055&quot;
        ports:
        - containerport: 10053
          name: dns-local
          protocol: udp
        - containerport: 10053
          name: dns-tcp-local
          protocol: tcp
        - containerport: 10055
          name: metrics
          protocol: tcp
        volumemounts:
        - name: kube-dns-config
          mountpath: /kube-dns-config
      - name: dnsmasq
        image: gcr.io/google-containers/k8s-dns-dnsmasq-nanny:1.15.8
        livenessprobe:
          httpget:
            path: /healthcheck/dnsmasq
            port: 10054
            scheme: http
          initialdelayseconds: 60
          timeoutseconds: 5
          successthreshold: 1
          failurethreshold: 5
        args:
        - -v=2
        - -logtostderr
        - -configdir=/etc/k8s/dns/dnsmasq-nanny
        - -restartdnsmasq=true
        - --
        - -k
        - --cache-size=1000
        - --no-negcache
        - --log-facility=-
        - --server=/cluster.local/127.0.0.1#10053
        - --server=/in-addr.arpa/127.0.0.1#10053
        - --server=/ip6.arpa/127.0.0.1#10053
        ports:
        - containerport: 53
          name: dns
          protocol: udp
        - containerport: 53
          name: dns-tcp
          protocol: tcp
        # see: https://github.com/kubernetes/kubernetes/issues/29055 for details
        resources:
          requests:
            cpu: 150m
            memory: 20mi
        volumemounts:
        - name: kube-dns-config
          mountpath: /etc/k8s/dns/dnsmasq-nanny
      - name: sidecar
        image: gcr.io/google-containers/k8s-dns-sidecar:1.15.8
        livenessprobe:
          httpget:
            path: /metrics
            port: 10054
            scheme: http
          initialdelayseconds: 60
          timeoutseconds: 5
          successthreshold: 1
          failurethreshold: 5
        args:
        - --v=2
        - --logtostderr
        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,srv
        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,srv
        ports:
        - containerport: 10054
          name: metrics
          protocol: tcp
        resources:
          requests:
            memory: 20mi
            cpu: 10m
      dnspolicy: default  # don't use cluster dns.
      serviceaccountname: kube-dns

what am i missing?
",<kubernetes><kubectl><kubelet><microk8s>,59550723,49,"you have not specified how you deployed kube dns but with microk8s it's recommended to use core dns.
you should not deploy kube dns or core dns on your own; rather you need to enable dns using this command microk8s enable dns which would deploy core dns and set up dns.
"
56663201,how do i customize postgresql configurations using helm chart?,"i'm trying to deploy an application that uses postgresql as a database to my minikube. i'm using helm as a package manager, and add have added postgresql dependency to my requirements.yaml. now the question is, how do i set postgres user, db and password for that deployment? here's my templates/applicaion.yaml

apiversion: v1
kind: service
metadata:
  name: {{ template ""sgm.fullname"" . }}-service
spec:
  type: nodeport
  selector:
    app: {{ template ""sgm.fullname"" . }}
  ports:
  - port: 80
    targetport: 8080
---
apiversion: apps/v1
kind: deployment
metadata:
  name: {{ template ""sgm.fullname"" . }}-deployment
spec:
  replicas: 2
  selector:
    matchlabels:
      app: {{ template ""sgm.fullname"" . }}
  template:
    metadata:
      labels:
        app: {{ template ""sgm.fullname"" . }}
    spec:
      containers:
      - name: sgm
        image: mainserver/sgm
        env:
        - name: postgres_host
          value: {{ template ""postgres.fullname"" . }}.default.svc.cluster.local


i've tried adding a configmap as it is stated in the postgres helm chart github readme, but seems like i'm doing something wrong
",<kubernetes><kubernetes-helm>,56665165,3,"this is lightly discussed in the helm documentation: your chart's values.yaml file contains configuration blocks for the charts it includes.  the github page for the helm stable/postgresql chart lists out all of the options.

either in your chart's values.yaml file, or in a separate yaml file you pass to the helm install -f option, you can set parameters like

postgresql:
  postgresqldatabase: stackoverflow
  postgresqlpassword: enterimagedescriptionhere


note that the chart doesn't create a non-admin user (unlike its sibling mysql chart).  if you're okay with the ""normal"" database user having admin-level privileges (like creating and deleting databases) then you can set postgresqluser here too.

in your own chart you can reference these values like any other

- name: pguser
  value: {{ .values.postgresql.postgresqluser }}

"
76360582,pods is forbidden: user tote-admin cannot list resource pods in api group at the cluster scope,"i am creating a new user in my kubeadm kubernetes cluster named tote. so first i created a key:
openssl genrsa -out tote.key 2048

then i created a csr:
openssl req -new -key tote.key -subj &quot;/cn=tote-admin&quot; -out tote.csr

finally, i am following kubernetes docs in here so:
a) i create a certificate signing request manifest:
apiversion: certificates.k8s.io/v1
kind: certificatesigningrequest
metadata:
  name: tote
spec:
  request: xxxxxx (based64 of the generated csr)
  signername: kubernetes.io/kube-apiserver-client
  usages:
  - client auth

b) approve the csr using kubectl:
kubectl certificate approve tote

c) produce the crt certificate for tote user:
kubectl get csr tote -o jsonpath='{.status.certificate}'| base64 -d &gt; tote.crt

finally, when trying to list pods using apiserver url using tote user, it gives me error as the following:
curl https://172.31.127.100:6443/api/v1/pods --key tote.key --cert tote.crt --cacert /etc/kubernetes/pki/ca.crt

and the response:
{
  &quot;kind&quot;: &quot;status&quot;,
  &quot;apiversion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {},
  &quot;status&quot;: &quot;failure&quot;,
  &quot;message&quot;: &quot;pods is forbidden: user \&quot;tote-admin\&quot; cannot list resource \&quot;pods\&quot; in api group \&quot;\&quot; at the cluster scope&quot;,
  &quot;reason&quot;: &quot;forbidden&quot;,
  &quot;details&quot;: {
    &quot;kind&quot;: &quot;pods&quot;
  },
  &quot;code&quot;: 403

any help how to resolve this issue and allow user tote to access pods?
",<kubernetes><kubernetes-security>,76361427,1,"
looks your auth working, but user doesn't have the necessary permissions. you need to create rbac permissions for the user you use. refer to using rbac authorization

and also try capturing certs from the .kube/config file.
like client-key data :
echo -n &quot;ls0....cg==&quot; | base64 -d &gt; admin.key


client-certificate-data :
echo -n &quot;ls0...c==&quot; | base64 -d &gt; admin.crt 

certificate authority-data :
echo -n &quot;ls0...g==&quot; | base64 -d &gt;ca.crt 

then use, curl https://172.31.127.100:6443 \  --key admin.key \ --cert admin.crt  --cacert can.crt
"
57093039,multiple subcharts with differents .values properties,"i'm trying to create a chart with multiple subcharts ( 2 instances of ibm-db2oltp-dev). is there a way to define in the same values.yaml file, different configuration for each instance?
i need two databases:
db2inst.instname: user1
db2inst.password: password1
options.databasename: dbname1

db2inst.instname: user2
db2inst.password: password2
options.databasename: dbname2

i saw it could be done via alias but i didn't find an example explaining how to do it. is it possible?
",<kubernetes><kubernetes-helm>,57093447,20,"yes, it is possible:
in chart.yaml for helm 3 or in requirements.yaml for helm 2:
dependencies:
  - name: ibm-db2oltp-dev                *(full chart name here)*
    repository: http://localhost:10191   *(actual repository url here)*
    version: 0.1.0                       *(required version)*
    alias: db1inst                       *(the name of the chart locally)*
  - name: ibm-db2oltp-dev
    repository: http://localhost:10191
    version: 0.1.0
    alias: db2inst

parentchart/values.yaml:
someparentchartvaluex: x
someparentchartvaluey: y

db1inst:
  instname: user1
  db2inst: password1

db2inst:
  instname: user2
  db2inst: password2

"
65137134,azure pipelines environments and helm,"i have an azure pipeline that i am using to generate and push helm charts in. within this pipeline i have a deployment stage that uses the helmdeploy0 task. this task requires a kubernetesserviceendpoint. consequentially, i have also opted to use pipeline environments and have configured my dev kubernetes cluster as my dev environment for use in the pipeline. i am unsure ohow this task is going to use this environment as i have to assume that azure devops, upon using the environment, must be authenticating with the cluster, thus, the helm chart should simply install. unfortunately the helmdeploy0 task requires this serviceendpoint key. any insight would be appreciated. below is a snippet of the pipeline stage.
- stage: dev
  displayname: deploy to dev
  dependson: build
  condition: and(succeeded(), eq(variables['build.sourcebranch'], 'refs/heads/master'))
  jobs: 
  - deployment:
    
    displayname: deploy $(projname)
    environment: 'dev'
    strategy:
      runonce:
        predeploy:
          steps:
            - task: helminstaller@1
              inputs:
                helmversiontoinstall: latest
        deploy:
          steps:
            - task: helmdeploy@0
              displayname: install helm chart
              inputs: 
                command: install
                chartname: $(registry_name)/helm/$(projname)
                arguments: --version $(tag)
                releasename: $(projname)

note: yes i know variables cannot be used as the display name, it's there to protect any ip right now.
",<azure><kubernetes><azure-devops><azure-pipelines><kubernetes-helm>,65137742,1,"you probably need to explicitly specify your kubernetes cluster resource name in the environment section. see below:
- deployment: 
  environment:               
    name: dev   # name of the environment to run this job on.
    resourcename: cluster-resource-name # name of the resource in the environment to record the deployments against
    resourcetype: kubernetes
  strategy:
    ...

you can also try using the shorten syntax: environment: environmentname.resourcename. if the shorten syntax failed to find the resource, you need to use above syntax to provide the resourcetype. see document here.
the steps of the deployment job automatically inherit the service connection details from resource targeted by the deployment job.

you can scope the target of deployment to a particular resource within the environment. this allows you to record deployment history on a specific resource within the environment. the steps of the deployment job automatically inherit the service connection details from resource targeted by the deployment job.

check here for information.
"
60815906,helm prometheus operator - set email notifications/edit secrets,"i have installed prometheus-operator via helm and now want to set email notifications for alertmanager:
i edited prometheus operator secret:
    kubectl get secret alertmanager-prometheus-prometheus-oper-alertmanager -n monitoring -o yaml
    apiversion: v1
    data:
      alertmanager.yaml: z2xvymfsogogihjlc29sdmvfdgltzw91ddognw0kcmvjzwl2zxjzogotig5hbwu6icjudwxsigpyb3v0ztokicbncm91cf9ietokicatigpvygogigdyb3vwx2ludgvydmfsoia1bqogigdyb3vwx3dhaxq6idmwcwogihjly2vpdmvyoiaibnvsbcikicbyzxblyxrfaw50zxj2yww6ideyaaogihjvdxrlczokicatig1hdgnoogogicagicbhbgvydg5hbwu6ifdhdgnozg9nciagicbyzwnlaxzlcjogim51bgwi
    kind: secret
    metadata:
      creationtimestamp: &quot;2020-03-23t09:19:57z&quot;
      labels:
        app: prometheus-operator-alertmanager
        chart: prometheus-operator-8.12.2
        heritage: helm
        release: prometheus
      name: alertmanager-prometheus-prometheus-oper-alertmanager
      namespace: monitoring
      resourceversion: &quot;1853097&quot;
      selflink: /api/v1/namespaces/monitoring/secrets/alertmanager-prometheus-prometheus-oper-alertmanager
      uid: eb7f514e-6bf4-4791-9c1a-e45590ba2a36
    type: opaque



 echo 'z2xvymfsogogihjlc29sdmvfdgltzw91ddognw0kcmvjzwl2zxjzogotig5hbwu6icjudwxsigpyb3v0ztokicbncm91cf9ietokicatigpvygogigdyb3vwx2ludgvydmfsoia1bqogigdyb3vwx3dhaxq6idmwcwogihjly2vpdmvyoiaibnvsbcikicbyzxblyxrfaw50zxj2yww6ideyaaogihjvdxrlczokicatig1hdgnoogogicagicbhbgvydg5hbwu6ifdhdgnozg9nciagicbyzwnlaxzlcjogim51bgwi' | base64 --decode

created a new alertmanager.yaml file:
global:
  resolve_timeout: 5m
route:
  group_by: [alertname]
  # send all notifications to me.
  receiver: email-alert

  group_by: ['job', 'alertname', 'service', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: email-alert
  routes:
  - match:
      severity: critical
    receiver: email-alert

receivers:
- name: email-alert
  email_configs:
  - to: email@example.com
    from: email@example.com
    # your smtp server address
    smarthost: smtp.office365.com:587
    auth_username: email@example.com
    auth_identity: email@example.com
    auth_password: pass

created template:
apiversion: v1
data:
  alertmanager.yaml: alertmanager_config
kind: secret
metadata:
  name: alertmanager-main
  namespace: monitoring
type: opaque

encoded it and applied:
sed &quot;s/alertmanager_config/$(cat alertmanager.yaml | base64 -w0)/g&quot; alertmanager-secret-k8s.yaml | kubectl apply -f -

i exposed alertmanager as nodeport via port 30700.
so when i access it (http://ip:30700/#/status), i see this alertmanager.yaml is not applied, i.e., secret is not changed.
what needs to be done so i can edit this prometheus alertmanager secret?
tried with
helm upgrade prometheus stable/prometheus-operator --namespace monitoring -f alertmanager.yaml 

without help

",<kubernetes><kubernetes-helm><prometheus-alertmanager><prometheus-operator>,60827309,1,"figured it out thanks to this reference

delete current secret:
kubectl delete secret alertmanager-prometheus-prometheus-oper-alertmanager -n monitoring


create file alertmanager.yaml:
  global:
    resolve_timeout: 5m
  route:
    receiver: 'email-alert'
    group_by: ['job']


    routes:
    - receiver: 'email-alert'
      match:
        alertname: etcdinsufficientmembers
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h  

  receivers:
  - name: email-alert
    email_configs:
    - to: receiver@example.com
      from: sender@example.com
      # your smtp server address
      smarthost: smtp.office365.com:587
      auth_username: sender@example.com
      auth_identity: sender@example.com
      auth_password: pass


create new secret with same name as old one:
kubectl create secret generic alertmanager-prometheus-prometheus-oper-alertmanager -n monitoring --from-file=alertmanager.yaml



"
58321337,how to include default value with tpl function call,"i have top level chart and one of the subcharts. in subchart i want to use variables that defined in level chart, and if it is not found - use default value.

i have code like this in one of deployment definitions in my subchart

name: {{tpl .values.global.my.globalvalue .}}


where values.global.my.globalvalue - is parameter from top level chart. 

problem is when i try to install only subchart - i am failing, i need some defaults. 

i tried to puth like below and it is not working

name: {{default defaultname tpl .values.global.my.globalvalue .}}
name: {{tpl .values.global.my.globalvalue . | defaultname}}


could you please advise the correct way to do that.
",<kubernetes><deployment><kubernetes-helm>,58322807,1,"as per using the default function:


  one function frequently used in templates is the default function:
  default default_value given_value. this function allows you to specify
  a default value inside of the template, in case the value is omitted.


you should use:

name: {{ .values.global.my.globalvalue | default ""defaultname"" | quote }}
"
56340598,how to find cpu and ram usage in kubernetes deployment,"my kubernetes cluster is failing to deploy new applications with insufficient cpu on the cluster

after digging around rancher and kubectl i have found that i am using 5% of cpu, but reserved 96% cpu. 

this is due to wrongly configured values in my micro-services values.yaml

if there a way to find out how much the micro-services are using when idle and when at load

resources:
  requests:
    memory: {{ .values.resources.requests.memory | quote}}
    cpu: {{ .values.resources.requests.cpu | quote}}

  limits:
    memory: {{ .values.resources.limits.memory | quote}}
    cpu: {{ .values.resources.requests.cpu | quote}}


i have tried using kubectl to describe the node 
i am monitoring netdata, but that is real time and hard to gauge limits from that.

if anyone had suggestions, that would be great
",<kubernetes><kubernetes-helm><kubectl>,56340818,1,"the built in tool is kubectl top but this requires you have metrics-server running, which you probably do if you are using a hosted kube option but might not if running it yourself. beyond that, prometheus and tools like node-exporter and cadvisor can get you the data
"
51223937,ingress is not getting address on gke and gce,"when creating ingress, no address is generated and when viewed from gke dashboard it is always in the creating ingress status.
describing the ingress does not show any events and i can not see any clues on gke dashboard.

has anyone has a similar issue or any suggestions on how to debug?

my deployment.yaml

apiversion: extensions/v1beta1
kind: ingress
metadata:
  name: mobile-gateway-ingress    
spec:
  backend:
    servicename: mobile-gateway-service
    serviceport: 80
---
apiversion: v1
kind: service
metadata:
  name: mobile-gateway-service
spec:
  ports:
  - protocol: tcp
    port: 80
    targetport: 8080
  selector:
    app: mobile-gateway
  type: nodeport
---
apiversion: apps/v1 
kind: deployment
metadata:
  name: mobile-gateway-deployment
  labels:
    app: mobile-gateway
spec:
  selector:
    matchlabels:
      app: mobile-gateway
  replicas: 2
  template:
    metadata:
      labels:
        app: mobile-gateway
    spec:
      containers:
      - name: mobile-gateway
        image: eu.gcr.io/my-project/mobile-gateway:latest
        ports:
          - containerport: 8080


describing ingress shows no events:

mobile-gateway ➤ kubectl describe ingress mobile-gateway-ingress                                                                                                                         git:master*
name:             mobile-gateway-ingress
namespace:        default
address:
default backend:  mobile-gateway-service:80 (10.4.1.3:8080,10.4.2.3:8080)
rules:
  host  path  backends
  ----  ----  --------
  *     *     mobile-gateway-service:80 (10.4.1.3:8080,10.4.2.3:8080)
annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {""apiversion"":""extensions/v1beta1"",""kind"":""ingress"",""metadata"":{""annotations"":{},""name"":""mobile-gateway-ingress"",""namespace"":""default""},""spec"":{""backend"":{""servicename"":""mobile-gateway-service"",""serviceport"":80}}}

events:  &lt;none&gt;
hello ➤


with a simple loadbalancer service, an ip address is given. the problem is only with the ingress resource.
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,51251806,10,"the problem in this case was i had did not include the addon httploadbalancing when creating the cluster!
my fault but was would have been noice to have an event informing me of this mistake in the ingress resource.

strange that when i created a new cluster to follow the tutorial cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer using default addons including httploadbalancing that i observed the same issue. maybe i didn't wait long enough? anyway, working now that i have included the addon.
"
54882727,kubectl using command to get cluster status,"i need to create a shell-script which examine the cluster
status.**

i saw that the kubectl describe-nodes provides lots of data
i can output it to json and then parse it but maybe it’s just overkill.
is there a simple way to with kubectl command to get the status of the cluster ? just if its up / down
",<kubernetes><google-cloud-platform><kubectl>,54882812,16,"the least expensive way to check if you can reach the api server is kubectl version. in addition kubectl cluster-info gives you some more info.
"
53008125,what's the minimal permissions i need to configure for a gke node pool to pull from a private gcr repo in the same project?,"i am trying to configure my gke cluster to pull from a private gcr repo in the same project. i am not using oauth scopes but have associated a least privilege service account with the default node pool and provided it with the roles/storage.objectviewer permission.

however, i am still receiving the following when trying to access this image:

failed to pull image ""eu.gcr.io/&lt;project&gt;/&lt;image&gt;"": rpc error: code = unknown desc = error response from daemon: unauthorized: you don't have the needed permissions to perform this operation, and you may have invalid credentials. to authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication


do i also need to configure imagepullsecrets or should the roles/storage.objectviewer permission be sufficient?
",<kubernetes><google-cloud-platform><google-kubernetes-engine>,53021926,14,"the root cause of this issue was not setting access (oauth) scopes on the cluster instances preventing the service account from working as intended.
from the gcp docs about compute service accounts :

you must set access scopes on the instance to authorize access.
you cannot set only iam roles on the service account and omit access scopes when creating the virtual machine instance. the level of access a service account has is determined by a combination of access scopes and iam roles so you must configure both access scopes and iam roles for the service account to work properly.

the minimal scopes required when accessing private images in gcr can be found here with the meaning of these scopes found here. a least privilege service account for the cluster nodes can then be created following the instructions here.
as described here an alternative would be to only grant the https://www.googleapis.com/auth/cloud-platform scope to the cluster nodes which authorises access to all cloud platform services and then limit access through iam roles on node service accounts.
by configuring the cluster nodes as above, imagepullsecrets are not required for pulling private images from gcr in the same project.
"
60558494,relation between redis/postgres volume claim and application configuration,"i would run redis for caching with separate pod in k8s using https://github.com/helm/charts/tree/master/stable/redis chart.

so redis is managing pvc and using for persistence and in my opinion my application's pod should ideally only need to connect to redis as a service. so, this host:port should be enough as far as i can think..this situation is same as any database.

so my doubt is, should i make any extra configuration in application's yaml for volume which is relates with redis or postgresql? i mean, should application's pod mount it as well? what is the common usage for following best practices to connect redis or database from application's pod?

i.e parts of configuration in redis for volume

   enabled: true
    path: /data
    subpath: """"
    accessmodes:
    - readwriteonce
    size: 8gi
    matchlabels: {}
    matchexpressions: {}


application's deployment.yaml

env:     
      - name: redis_host
        value: redis-master
      - name: redis_port
        value: ""6379""




- name: postgres_host
              valuefrom:
                configmapkeyref:
                  name: {{ .release.name }}-config
                  key: postgres_host
            - name: postgres_port
              valuefrom:
                configmapkeyref:
                  name: {{ .release.name }}-config
                  key: postgres_port
            - name: postgres_db
              valuefrom:
                configmapkeyref:
                  name: {{ .release.name }}-config
                  key: postgres_db

",<kubernetes><kubernetes-helm>,60561027,1,"as far as i understand, i think in your case you have to configure pvc/pv. it is properly to setup pvc directly in deployment definition:

example for redis, creating pvc (only if you have enabled dynamic provisioning): 

apiversion: v1
kind: persistentvolumeclaim
metadata:
  name: your-mysql-pv-claim
  labels:
    app: redis
spec:
  storageclassname: your-storage-class
  accessmodes:
    - readwriteonce
  resources:
    requests:
      storage: 8gi


in redis deployment configuration file in specification section add following lines:

  volumes:
  - name: your-mysql-persistent-storage
    persistentvolumeclaim:
      claimname: your-mysql-pv-claim


same steps you have to fill for postgress. 
remember ito check if you have storageclass. otherwise you will have to do it manually. also remember to define path where specific volume should be mounted. 

storage provisioning in cloud:


  static
  
  a cluster administrator creates a number of pvs. they carry the
  details of the real storage, which is available for use by cluster
  users. they exist in the kubernetes api and are available for
  consumption.
  
  dynamic
  
  when none of the static pvs the administrator created match a
  user’s persistentvolumeclaim, the cluster may try to dynamically
  provision a volume specially for the pvc. this provisioning is based
  on storageclasses: the pvc must request a storage class and the
  administrator must have created and configured that class for dynamic
  provisioning to occur. claims that request the class """" effectively
  disable dynamic provisioning for themselves.
  
  to enable dynamic storage provisioning based on storage class, the
  cluster administrator needs to enable the defaultstorageclass
  admission controller on the api server. this can be done, for example,
  by ensuring that defaultstorageclass is among the comma-delimited,
  ordered list of values for the --enable-admission-plugins flag of the
  api server component. for more information on api server command-line
  flags, check kube-apiserver documentation.


you can also have shared volumes then two containers can use these volumes to communicate.

more information you can find here: pvc, pvc-kubernetes, pvc-kubernetes-pod.
"
53693030,how can i access to services outside the cluster using kubectl proxy?,"when we spin up a cluster with kubeadm in kubernetes, and the service's .yaml file looks like this :

apiversion: v1
kind: service
metadata:
  name: neo4j
  labels:
    app: neo4j
    component: core
spec:
  clusterip: none
  ports:
    - port: 7474
      targetport: 7474
      name: browser
    - port: 6362
      targetport: 6362
      name: backup
  selector:
    app: neo4j
    component: core


after all pods and services run, i do kubectl proxy and it says :

starting to serve on 127.0.0.1:8001


so when i want to access to this service like :

curl localhost:8001/api/


it's just reachable inside the cluster! how can i reach to services outside the cluster?
",<kubernetes><kubectl><kubeadm><kube-apiserver>,53694256,2,"you should expose your service using nodeport:

apiversion: v1
kind: service
metadata:
  name: neo4j
  labels:
    app: neo4j
    component: core
spec:
  externaltrafficpolicy: local
  type: nodeport
  ports:
    - port: 7474
      targetport: 7474
      name: browser
    - port: 6362
      targetport: 6362
      name: backup
  selector:
    app: neo4j
    component: core


now if you describe your service using 

 kubectl describe svc neo4j


you will get a nodeport value which will be in between 30000-32767 and you can access your service from outside the cluster using

curl http://&lt;node_ip&gt;:&lt;node_port&gt;


hope this helps.

edit: yes you can't directly use clusterip: none in case of exposing service through nodeport. now clusterip: none means there is no internal load balancing done by kubernetes and for that we can also use externaltrafficpolicy=local in service definition. 

alternatively, you might be able to use an ingress to route traffic to the correct service.
"
68979336,kubectl port-forwarding not working for ipv6 binding with socat,"i'm trying to understand why this particular socat command isn't working in my case where i run it in a ipv6 only kubernetes cluster.
cluster is build on top of aws with calico cni &amp; containerd. provisioned using kubeadm and kubernetes 1.21.
i have run the following socat command which binds to loopback interface ::1,
kubectl --context=$cluster1 run --image=alpine/socat socat -- tcp6-listen:15000,bind=\[::1\],fork,reuseaddr /dev/null

and then i try to port-forward and curl to 15000 port,
kubectl --context=$cluster1 port-forward pod/socat 35000:15000 --address=::1
curl -ivg http://localhost:35000

i get the error,
forwarding from [::1]:35000 -&gt; 15000
handling connection for 35000
e0830 17:09:59.604799   79802 portforward.go:400] an error occurred forwarding 35000 -&gt; 15000: error forwarding port 15000 to pod a8ba619774234e73f4c1b4fe4ff47193af835cffc56cb6ad1a8f91e745ac74e9, uid : failed to execute portforward in network namespace &quot;/var/run/netns/cni-8bade2c1-28c9-6776-5326-f10d55fd0ff9&quot;: failed to dial 15000: dial tcp4 127.0.0.1:15000: connect: connection refused

its listening to 15000 as,
active internet connections (servers and established)
proto recv-q send-q local address           foreign address         state       pid/program name
tcp        0      0 ::1:15000               :::*                    listen      1/socat

however if i run the following it works fine,
kubectl --context=$cluster1 run --image=alpine/socat socat -- tcp6-listen:15000,bind=\[::\],fork,reuseaddr /dev/null

not sure i understand why port-forward would fail for the loopback interface binding ::1 but not for catch all ::. can someone please shed some light on this ?
",<kubernetes><kubectl><portforwarding><socat>,69276774,2,"for those of you running into a similar issue with your ipv6 only kubernetes clusters heres what i have investigated found so far.
background: it seems that this is a generic issue relating to ipv6 and cri.
i was running containerd in my setup and containerd versions 1.5.0-1.5.2 added two prs (don't use socat for port forwarding and use happy-eyeballs for port-forwarding) which fixed a number of issues in ipv6 port-forwarding.
potential fix: further to pulling in containerd version 1.5.2 (as part of ubuntu 20.04 lts) i was also getting the error ipv4: dial tcp4 127.0.0.1:15021: connect: connection refused ipv6 dial tcp6: address localhost: no suitable address found when port-forwarding. this is caused by a dns issue when resolving localhost. hence i added localhost to resolve as ::1 in the host machine with the following command.
sed -i 's/::1 ip6-localhost ip6-loopback/::1 localhost ip6-localhost ip6-loopback/' /etc/hosts

i think the important point here is that check your container runtimes to make sure ipv6 (tcp6 binding) is supported.
"
71196230,kubernetes statefulsets: restart all pods concurrently (instead of in sequence),"i have a use-case for concurrent restart of all pods in a statefulset.
does kubernetes statefulset support concurrent  restart of all pods?
according to the statefulset documentation, this can be accomplished by setting the pod update policy to parallel as in this example:
apiversion: apps/v1
kind: statefulset
metadata:
  name: mysql-db
spec:
  podmanagementpolicy: parallel
  replicas: 3

however this does not seem to work in practice, as demonstrated on this statefulset running on eks:

apply this:

---
apiversion: apps/v1
kind: statefulset
metadata:
  name: producer
  namespace: ragnarok
spec:
  selector:
    matchlabels:
      app: producer
  replicas: 10
  podmanagementpolicy: &quot;parallel&quot;
  servicename: producer-service
  template:
    metadata:
      labels:
        app: producer
    spec:
      containers:
      - name: producer
        image: archbungle/load-tester:pulsar-0.0.49
        imagepullpolicy: ifnotpresent

rollout restart happens in sequence as if disregarding the rollout policy setting:

(base) welcome@traianos-macbook-pro eks-deploy % kubectl get pods -n ragnarok | egrep producer
producer-0                               1/1     running             0          3m58s
producer-1                               1/1     running             0          3m56s
producer-2                               1/1     running             0          3m53s
producer-3                               1/1     running             0          3m47s
producer-4                               1/1     running             0          3m45s
producer-5                               1/1     running             0          3m43s
producer-6                               1/1     running             1          3m34s
producer-7                               0/1     containercreating   0          1s
producer-8                               1/1     running             0          16s
producer-9                               1/1     running             0          19s

(base) welcome@traianos-macbook-pro eks-deploy % kubectl get pods -n ragnarok | egrep producer
producer-0                               1/1     running       0          4m2s
producer-1                               1/1     running       0          4m
producer-2                               1/1     running       0          3m57s
producer-3                               1/1     running       0          3m51s
producer-4                               1/1     running       0          3m49s
producer-5                               1/1     running       0          3m47s
producer-6                               0/1     terminating   1          3m38s
producer-7                               1/1     running       0          5s
producer-8                               1/1     running       0          20s
producer-9                               1/1     running       0          23s

(base) welcome@traianos-macbook-pro eks-deploy % kubectl get pods -n ragnarok | egrep producer
producer-0                               1/1     running       0          4m8s
producer-1                               1/1     running       0          4m6s
producer-2                               1/1     running       0          4m3s
producer-3                               1/1     running       0          3m57s
producer-4                               1/1     running       0          3m55s
producer-5                               0/1     terminating   0          3m53s
producer-6                               1/1     running       0          4s
producer-7                               1/1     running       0          11s
producer-8                               1/1     running       0          26s
producer-9                               1/1     running       0          29s




",<kubernetes><kubernetes-statefulset>,71199975,5,"as the document pointed, parallel pod management will effective only in the scaling operations. this option only affects the behavior for scaling operations. updates are not affected.
maybe you can try something like
kubectl scale statefulset producer --replicas=0 -n ragnarok
and
kubectl scale statefulset producer --replicas=10 -n ragnarok
according to documentation, all pods should be deleted and created together by scaling them with the parallel policy.
reference : https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#parallel-pod-management
"
63515014,gke resourcequota incorrectly shows pod limit reached and prevents new pod creation,"i can't create new pods in my default namespace in gke. i checked the error on deployments and replicasets using kubectl -n default get replicaset xxxx --&gt; the error is:
  warning  failedcreate  6m54s replicaset-controller  error creating: pods &quot;dummy-deployment-54b6f555b7-ms5sb&quot; is forbidden: exceeded quota: gke-resource-quotas, requested: pods=1, used: pods=5k, limited: pods=5k

so i ran this command kubectl get resourcequota gke-resource-quotas -o yaml -n default to look at what's going on with gke-resource-quotas
i get this result:
apiversion: v1
kind: resourcequota
metadata:
  creationtimestamp: &quot;2020-02-04t13:06:27z&quot;
  name: gke-resource-quotas
  namespace: default
  resourceversion: &quot;109072xxxx&quot;
  selflink: /api/v1/namespaces/default/resourcequotas/gke-resource-quotas
  uid: 2727d85b-474f-11ea-a2f2-xxxxxxxxxx
spec:
  hard:
    count/ingresses.extensions: 5k
    count/jobs.batch: 10k
    pods: 5k
    services: &quot;1500&quot;
status:
  hard:
    count/ingresses.extensions: 5k
    count/jobs.batch: 10k
    pods: 5k
    services: &quot;1500&quot;
  used:
    count/ingresses.extensions: &quot;7&quot;
    count/jobs.batch: &quot;4540&quot;
    pods: 5k
    services: &quot;20&quot;

but i checked using kubectl -n default get pods | wc -l i do not have 5k pods running.
this is preventing me from creating new pods in my default namespace in gke.
this seems like an error on part of gke/k8s. does anyone know how i can resolve this? thanks!
",<kubernetes><google-kubernetes-engine>,63516629,3,"it totally looks like a gke issue with their pre-built quotas. you might have at one point hit the 5k limit perhaps not being updated for terminated pods and it thinks it has reached the limit.
someone else found a workaround so i would just try that for now:
kubectl delete resourcequota gke-resource-quotas -n default

if you are running at that scale and this is an important recurring issue i would strongly recommend hitting gke/gcp support. or seek alternatives like running outside of gke.
✌️
"
64762763,cpu based horizontal pod autoscaling doesn't work in kubernetes cluster,"i am trying to test the horizontal pod autoscale feature for my kubernetes cluster deployed in aws(using eks).
i have set resource as 'cpu' and target type as 'utilization' and set 'averageutilization' to 15 in the yaml file.
so technically when the cpu utilization percentage meets the 15% set percentage, kubernetes cluster should auto-scale horizontally(add pods automatically). this is an important part of the yaml file:
    maxreplicas: 11
    metrics:
    - type: resource
      resource:
        name: cpu
        target:
          type: utilization
          averageutilization: 15

i am pumping a lot of http traffic into the kubernetes cluster, but all pods stabilize at 35% - 36% cpu with 5 or 6 pods and they do not create additional pods to bring down average cpu utilization to 15% (which i set in yaml file as 'averageutilization').
no matter how much i debug and run tests many times, it's the same case. what am i doing wrong here, am i missing something else?
",<kubernetes><kubectl><kubernetes-pod><amazon-eks>,64763754,3,"did you check that metrics-server is enabled? it is required in order to enable hpa: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis.
here's metrics-server doc: https://github.com/kubernetes-sigs/metrics-server. in order to test it quickly and check it solves your issue, you can disable tls: --kubelet-insecure-tls. in production, you'll need to enable tls again.
to check that metrics-server is enabled, you can run the kubectl top command. it requires a few seconds to start, because it needs to collect some metrics first.
"
76014084,how to fill in the deployment values from the list?,"values.yaml
s3catalogs:
  catalogs:
    - catalogname: botvoice
      url: &quot;http://sandbox5.*.com&quot;
    - catalogname: wrongvoice
      url: &quot;http://sandbox5.*.com&quot;

the structure specified above needs to be filled in somehow in deployment.yaml
tried different variants, with brackets [0] does not accept.
        - name: s3catalogs__catalogs
          value: &quot;{{ .values.s3catalogs.catalogs  }}&quot;
        - name: s3catalogs__catalogs__url
          value: &quot;{{ .values.s3catalogs.catalogs.url}}&quot;

that's not how it works
",<kubernetes><kubernetes-helm>,76014310,1,"i think you were on the right path using 0 (and presumably 1) to access elements of the s3catalogs array in your values.yaml file.
the following syntax works for me:
deployment.yaml:
  - name: s3catalogs__catalogs__catalogname_0
    value: &quot;{{ index .values.s3catalogs.catalogs 0 &quot;catalogname&quot; }}&quot;
  - name: s3catalogs__catalogs__url_0
    value: &quot;{{ index .values.s3catalogs.catalogs 0 &quot;url&quot; }}&quot;
  - name: s3catalogs__catalogs__catalogname_1
    value: &quot;{{ index .values.s3catalogs.catalogs 1 &quot;catalogname&quot; }}&quot;
  - name: s3catalogs__catalogs__url_1
    value: &quot;{{ index .values.s3catalogs.catalogs 1 &quot;url&quot; }}&quot;

values.yaml:
s3catalogs:
  catalogs:
    - catalogname: botvoice
      url: &quot;http://sandbox5.foo.com&quot;
    - catalogname: wrongvoice
      url: &quot;http://sandbox5.bar.com&quot;

when i do a helm template, following is the result:
- name: s3catalogs__catalogs__catalogname_0
  value: &quot;botvoice&quot;
- name: s3catalogs__catalogs__url_0
  value: &quot;http://sandbox5.foo.com&quot;
- name: s3catalogs__catalogs__catalogname_1
  value: &quot;wrongvoice&quot;
- name: s3catalogs__catalogs__url_1
  value: &quot;http://sandbox5.bar.com&quot;

is this something that'll work out for you?
"
65892505,override deployd helm-chart values on gke with values from a file in the local machine?,"i would like to change my deployed(gke) helm chart values file with the ones that are inside my local file, basically to do this:
helm upgrade -f new-values.yml {release name} {package name or path}

so i've make all the changes inside my local file, but the deployment is inside the gke cluster.
i've connected to my cluster via ssh, but how can i run the above command in order to perform  the update if the file with the new values is on my local machine and the deployment is inside gke cluster?
maybe somehow via the scp command?
",<kubernetes><kubernetes-helm>,65907612,1,"solution by setting up required tools locally (you need a while or two for that)
you just need to reconfigure your kubectl client, which can be done pretty straighforward. when you log in to gcp console -&gt; go to kubernetes engine -&gt; clusters -&gt; click on actions (3 vertical dots to the right of the cluster name) -&gt; select connect -&gt; copy the command, which may resemble the following one:
gcloud container clusters get-credentials my-gke-cluster --zone europe-west4-c --project my-project

it assumes you have your cloud sdk and kubectl already installed on your local machine. if you have not, here you have step-by-step description how to do that:

installing google cloud sdk [debian/ubuntu] (if you use a different os, simply choose another tab)
installing kubectl tool [debian/ubuntu] (choose your os if it is something different)

once you run the above command on your local machine, your kubectl context will be automatically set to your gke cluster even if it was set before e.g. to your local minikube instance. you can check it by running:
kubectl config current-context

ok, almost done. did i also mention helm ? well, you will also need it. so if you have not installed it on your local machine previously, please do it now:

install helm [debian/ubuntu]

alternative slution using cloud shell (much quicker)
if installing and configuring it locally seems to you too much hassle, you can simply use a cloud shell (i bet you've used it before). in case you didn't, once logged in to your gcp console click on the following icon:

once logged into cloud shell, you can choose to upload your local files there:
simply click on more (3 dots again):

and choose upload a file:

"
67095994,"minikube: will deleting the service ""service/kubernetes"" break my kubernetes cluster?","i accidentally did: k delete service/kubernetes. it sounds like an essential service... so i would think deleting would break the kubernetes cluster but somehow the service just came back.
will deleting the service &quot;service/kubernetes&quot; break my kubernetes cluster? if no why?
related question: what causes the service service/kubernetes to come back automatically?
",<kubernetes><minikube><kubernetes-service>,67096249,3,"
what causes the service service/kubernetes to come back automatically?

a part of the control plane run controllers, and there is a controller that is responsible for the kubernetes service. see controlplane controller
"
33069736,how do i get logs from all pods of a kubernetes replication controller?,"running kubectl logs shows me the stderr/stdout of one kubernetes container.  

how can i get the aggregated stderr/stdout of a set of pods, preferably those created by a certain replication controller?
",<logging><kubernetes><google-kubernetes-engine>,44448420,470,"you can use labels
kubectl logs -l app=elasticsearch

and you'd probably want to specify --max-log-requests --all-containers --ignore-errors in order to:

specify the number of concurrent log streams (default is 5)
include logs from pods with multiple containers
continue to next pod on fatal error (e.g. logs could not be retrieved)

"
53239081,how does minreadyseconds affect readiness probe?,"let's say i have a deployment template like this

spec:
  minreadyseconds: 15
  readinessprobe:
    failurethreshold: 3
    httpget:
      path: /
      port: 80
      scheme: http
    initialdelayseconds: 20
    periodseconds: 20
    successthreshold: 1
    timeoutseconds: 5


how will this affect the newly versions of my app? will the minreadyseconds and initialdelayseconds count at the same time? will the initialdelayseconds come first then minreadyseconds?
",<kubernetes><google-kubernetes-engine>,53239388,42,"from kubernetes deployment documentation:


  .spec.minreadyseconds is an optional field that specifies the minimum number of seconds for which a newly created pod should be ready without any of its containers crashing, for it to be considered available. this defaults to 0 (the pod will be considered available as soon as it is ready). to learn more about when a pod is considered ready, see container probes


so your newly created app pod have to be ready for .spec.minreadyseconds seconds to be considered as available.


  initialdelayseconds: number of seconds after the container has started before liveness or readiness probes are initiated.


so initialdelayseconds comes before minreadyseconds.

lets say, container in the pod has started at t seconds. readiness probe will be initiated at t+initialdelayseconds seconds. assume pod become ready at t1 seconds(t1 &gt; t+initialdelayseconds). so this pod will be available after t1+minreadyseconds seconds.
"
64389575,how to run kubectl commands in a cron,"i created a schedule configuration inside my gcloud project to create snapshots of a bunch of virtual disks.
now i want to add my schedule configuration to my disks, but i dont know how to do it in a automated way, because i have more than 1200 disks.
i tryed to use a pod with a cron inside, but i cannot execute the kubectl command to list all my persistent volumes:
kubectl describe pv | grep &quot;name&quot; | awk 'nr % 2 == 1' | awk '{print $2}'

i want to use this list with the next command in a loop to add automatically my programmed schedule to my disks:
gcloud compute disks add-resource-policies [disk_name] --resource-policies [schedule_name] --zone [zone]

thanks in advance for your help.
edit 1: after some comments i changed my code to add a kubernetes cronjob, but the result is the same, the code doesn't work (the pod is created, but it gives me an error: imagepullbackoff):
resource &quot;kubernetes_cron_job&quot; &quot;schedulerdemo&quot; {
  metadata {
    name = &quot;schedulerdemo&quot;
  }
  spec {
    concurrency_policy            = &quot;replace&quot;
    failed_jobs_history_limit     = 5
    schedule                      = &quot;*/5 * * * *&quot;
    starting_deadline_seconds     = 10
    successful_jobs_history_limit = 10
    job_template {
      metadata {}
      spec {
        backoff_limit = 2
        ttl_seconds_after_finished    = 10
        template {
          metadata {}
          spec {
            container {
              name    = &quot;scheduler&quot;
              image   = &quot;imgscheduler&quot;
              command = [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;date; kubectl describe pv | grep 'name' | awk 'nr % 2 == 1' | awk '{print $2}'&quot;]
            }
          }
        }
      }
    }
  }
}

",<kubernetes><cron><google-kubernetes-engine><persistent-volumes>,64535094,1,"answering the comment:

ok, shame on me, wrong image name. now i have an error in the container log: /bin/sh: kubectl: not found

it means that the image that you are using doesn't have kubectl installed (or it's not in the path). you can use image: google/cloud-sdk:latest. this image already have cloud-sdk installed which includes:

gcloud
kubectl


to run a cronjob that will get the information about pv's and change the configuration of gcp storage  you will need following accesses:

kubernetes/gke api(kubectl) - serviceaccount with a role and rolebinding.
gcp api (gcloud) - google service account with iam permissions for storage operations.

i found this links helpful when assigning permissions to list pv's:

kubernetes.io: rbac
success.mirantis.com: article: user unable to list persistent volumes

the recommended way to assign specific permissions for gcp access:

workload identity is the recommended way to access google cloud services from applications running within gke due to its improved security properties and manageability.
-- cloud.google.com: kubernetes engine: workload identity: how to

i encourage you to read documentation i linked above and check other alternatives.

as for the script used inside of a cronjob. you should look for pdname instead of name as the pdname is representation of the gce-pd disk in gcp (assuming that we are talking about in-tree plugin).
you will have multiple options to retrieve the disk name from the api to use it in the gcloud command.
one of the options:
kubectl get pv -o yaml | grep &quot;pdname&quot; | cut -d &quot; &quot; -f 8 | xargs -n 1 gcloud compute disks add-resource-policies --zone=zone --resource-policies=policy


disclaimer!
please treat above command only as an example.

above command will get the pdname attribute from the pv's and iterate with each of them in the command after xargs.
some of the things to take into consideration when creating a script/program:

running this command more than once on a single disk will issue an error that you cannot assign multiple policies. you  could have a list of already configured disks that do not require assigning a policy.
consider using .spec.concurrencypolicy: forbid instead of replace. replaced cronjob will start from the beginning iterating over all of those disks. command could not complete in the desired time and cronjob will be replaced.
you will need to check for the correct kubectl version as the official support allows +1/-1 version difference between client and a server (cloud-sdk:latest uses v1.19.3).


i highly encourage you to look on other methods to backup your pvc's (like for example volumesnapshots).
take a look on below links for more reference/ideas:

stackoverflow.com: answer: periodic database backup in kubernetes
stash.run: guides: latest: volumesnapshot: pvc
velero.io

it's worth to mention that:

csi drivers are the future of storage extension in kubernetes. kubernetes has announced that the in-tree volume plugins are expected to be removed from kubernetes in version 1.21. for details, see kubernetes in-tree to csi volume migration moves to beta. after this change happens, existing volumes using in-tree volume plugins will communicate through csi drivers instead.
-- cloud.google.com: kubernetes engine: persistent volumes: gce pd csi driver: benefits of using

switching to csi plugin for your storageclass will allow you to use volume snapshots inside of gke:

volume snapshots let you create a copy of your volume at a specific point in time. you can use this copy to bring a volume back to a prior state or to provision a new volume.
-- cloud.google.com: kubernetes engine: persistent volumes: volume snaphosts: how to


additional resources:

cloud.google.com: kubernetes engine: persistent volumes
cloud.google.com: kubernetes engine: cronjobs: how to
terraform.io: kubernetes: cronjob
cloud.google.com: compute: disks: create snapshot

"
54883258,helm install or upgrade release failed on kubernetes cluster: the server could not find the requested resource or upgrade failed: no deployed releases,"using helm for deploying chart on my kubernetes cluster, since one day, i can't deploy a new one or upgrading one existed.

indeed, each time i am using helm i have an error message telling me that it is not possible to install or upgrade ressources.

if i run helm install --name foo . -f values.yaml --namespace foo-namespace i have this output:


  error: release foo failed: the server could not find the requested
  resource


if i run helm upgrade --install foo . -f values.yaml --namespace foo-namespace or helm upgrade foo . -f values.yaml --namespace foo-namespace i have this error:


  error: upgrade failed: ""foo"" has no deployed releases


i don't really understand why.

this is my helm version:

client: &amp;version.version{semver:""v2.12.3"", gitcommit:""eecf22f77df5f65c823aacd2dbd30ae6c65f186e"", gittreestate:""clean""}
server: &amp;version.version{semver:""v2.12.3"", gitcommit:""eecf22f77df5f65c823aacd2dbd30ae6c65f186e"", gittreestate:""clean""}


on my kubernetes cluster i have tiller deployed with the same version, when i run kubectl describe pods tiller-deploy-84b... -n kube-system:

name:               tiller-deploy-84b8...
namespace:          kube-system
priority:           0
priorityclassname:  &lt;none&gt;
node:               k8s-worker-1/167.114.249.216
start time:         tue, 26 feb 2019 10:50:21 +0100
labels:             app=helm
                    name=tiller
                    pod-template-hash=84b...
annotations:        &lt;none&gt;
status:             running
ip:                 &lt;ip_number&gt;
controlled by:      replicaset/tiller-deploy-84b8...
containers:
  tiller:
    container id:   docker://0302f9957d5d83db22...
    image:          gcr.io/kubernetes-helm/tiller:v2.12.3
    image id:       docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:cab750b402d24d...
    ports:          44134/tcp, 44135/tcp
    host ports:     0/tcp, 0/tcp
    state:          running
      started:      tue, 26 feb 2019 10:50:28 +0100
    ready:          true
    restart count:  0
    liveness:       http-get http://:44135/liveness delay=1s timeout=1s period=10s #success=1 #failure=3
    readiness:      http-get http://:44135/readiness delay=1s timeout=1s period=10s #success=1 #failure=3
    environment:
      tiller_namespace:    kube-system
      tiller_history_max:  0
    mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from helm-token-... (ro)
conditions:
  type              status
  initialized       true 
  ready             true 
  containersready   true 
  podscheduled      true 
volumes:
  helm-token-...:
    type:        secret (a volume populated by a secret)
    secretname:  helm-token-...
    optional:    false
qos class:       besteffort
node-selectors:  &lt;none&gt;
tolerations:     node.kubernetes.io/not-ready:noexecute for 300s
                 node.kubernetes.io/unreachable:noexecute for 300s
events:
  type    reason     age   from                   message
  ----    ------     ----  ----                   -------
  normal  scheduled  26m   default-scheduler      successfully assigned kube-system/tiller-deploy-84b86cbc59-kxjqv to worker-1
  normal  pulling    26m   kubelet, k8s-worker-1  pulling image ""gcr.io/kubernetes-helm/tiller:v2.12.3""
  normal  pulled     26m   kubelet, k8s-worker-1  successfully pulled image ""gcr.io/kubernetes-helm/tiller:v2.12.3""
  normal  created    26m   kubelet, k8s-worker-1  created container
  normal  started    26m   kubelet, k8s-worker-1  started container


is someone have faced the same issue ?



update:

this the folder structure of my actual chart named foo:
structure folder of the chart:

&gt; templates/
  &gt; deployment.yaml 
  &gt; ingress.yaml
  &gt; service.yaml
&gt; .helmignore
&gt; chart.yaml 
&gt; values.yaml


i have already tried to delete the chart in failure using the delete command helm del --purge foo but the same errors occurred.

just to be more precise, the chart foo is in fact a custom chart using my own private registry. imagepullsecret are normally setting up.

i have run these two commands helm upgrade foo . -f values.yaml --namespace foo-namespace --force | helm upgrade --install foo . -f values.yaml --namespace foo-namespace --force and i still get an error:

upgrade failed
rolling back
error: failed to create resource: the server could not find the requested resource
error: upgrade failed: failed to create resource: the server could not find the requested resource


notice that foo-namespace already exist. so the error don't come from the namespace name or the namespace itself. indeed, if i run helm list, i can see that the foo chart is in a failed status.
",<kubernetes><devops><kubernetes-helm>,55363025,9,"tiller stores all releases as configmaps in tiller's namespace(kube-system in your case). try to find broken release and delete it's configmap using commands:

$ kubectl get cm --all-namespaces -l owner=tiller
namespace     name               data   age
kube-system   nginx-ingress.v1   1      22h

$ kubectl delete cm  nginx-ingress.v1 -n kube-system


next, delete all release objects (deployment,services,ingress, etc) manually and reinstall release using helm again.

if it didn't help, you may try to download newer release of helm (v2.14.3 at the moment) and update/reinstall tiller.
"
68179293,kubectl doesn't load the new endpoint to connect,"when i run kubectl get svc i have the error unable to connect to the server: dial tcp: lookup db3e0792b37be7363d42af594f4c72ab.gr7.eu-centrale-1.xx.
i update my ~/.kube/config to add the new endpoint  https://6af7819922f51e229c9b408fe5dxxxxxxx.gr7.eu-central-1.
however it seems kubectl doesn't load the new endpoint.
because if i run again kubectl get svc he try to connect to same previous endpoint
",<amazon-web-services><kubernetes><amazon-ec2><kubectl><amazon-eks>,68179472,1,"if you have multiple cluster contexts. use kubectl to edit this and target the context you wish to edit.
$ kubectl config view
apiversion: v1
clusters:
- cluster:
  certificate-authority-data: data+omitted
  server: https://10.0.0.10:6443
name: default
.....

to update the endpoint to from 10.0.0.10 to 192.168.0.1:
$ kubectl config set-cluster default --server=https://192.168.0.1
cluster &quot;default&quot; set.

validate the update is correct:
$ kubectl config view
apiversion: v1
clusters:
- cluster:
  certificate-authority-data: data+omitted
  server: https://192.168.0.1
name: default
....

also ensure you have switched to the correct context by (in this case &quot;default&quot;) context:
$ kubectl config use-context default
switched to context &quot;default&quot;.

"
52730629,pulling from private registry fails - unsupported docker v1 repository request,"i am trying to run a container on my kubernetes cluster (1.9.7-gke.6), using a private registry (artifactory). 

failed to pull image ""myrepo.myartifactory.mycompany.com/org/image:latest"": rpc error: code = unknown desc = error: status 400 trying to pull repository org/image: ""{
\""errors\"" :[ {
    \""status\"" : 400,
    \""message\"" : \""unsupported docker v1 repository request for 'myrepo'\""\n  } ]
}""


i assume this means that the docker client tries to perform a v1 registry request, which seems to be not supported by our artifactory installation.

i checked the docker version of my cluster nodes:

$ kubectl describe nodes | grep docker
 container runtime version:  docker://17.3.2
 container runtime version:  docker://17.3.2
 container runtime version:  docker://17.3.2


i found the docker flag --disable-legacy-registry=true but i am not sure how to best configure my gke cluster this way.
",<docker><kubernetes><artifactory><google-kubernetes-engine>,52747531,4,"the actual issue was that our credentials of the registry changed. updating the pull credentials on our cluster fixed the issue.

i assume that the issue can occur under certain circumstances where the registry api returns an error such as an authentication or authorization error. if that is the case, the docker client tries to downgrade to an older api version - which is not available on artifactory.

this would cause artifactory to return the mentioned unsupported docker v1 repository request for 'myrepo' error, which unfortunately masks the actual error.
"
64349602,kubernetes ingress controller,"i'm working with microk8s using kubernetes 1.19. the provided ingress.yaml does not work. given my troubleshooting below, it seems like ngnix cannot connect to the default-http-backend. microk8s was installed on a ubuntu 20.04 using snap. i know that there exists a ingress addon. but nonetheless, i would like it to work with this setup.
microk8s kubectl get pods --all-namespaces
kube-ingress           default-http-backend-7744d88f46-45vp7        1/1     running            0          53m
kube-ingress           nginx-74dd8dd664-7cn67                       0/1     crashloopbackoff   15         53m

microk8s kubectl logs -n kube-ingress nginx-74dd8dd664-7cn67
w1014 08:28:14.903056       6 flags.go:249] ssl certificate chain completion is disabled (--enable-ssl-chain-completion=false)
w1014 08:28:14.903143       6 client_config.go:543] neither --kubeconfig nor --master was specified.  using the inclusterconfig.  this might not work.
i1014 08:28:14.903398       6 main.go:220] creating api client for https://10.152.183.1:443
i1014 08:28:14.910869       6 main.go:264] running in kubernetes cluster version v1.19+ (v1.19.2-34+1b3fa60b402c1c) - git (clean) commit 1b3fa60b402c1c4cb0df8a99b733ad41141a2eb7 - platform linux/amd64
f1014 08:28:14.913646       6 main.go:91] no service with name kube-ingress/default-http-backend found: services &quot;default-http-backend&quot; not found

ingress.yml
apiversion: v1
kind: namespace
metadata:
  name: kube-ingress
---
kind: configmap
metadata:
  namespace: kube-ingress
  name: nginx
apiversion: v1
data:
  proxy-connect-timeout: &quot;15&quot;
  proxy-read-timeout: &quot;600&quot;
  proxy-send-timeout: &quot;600&quot;
  hsts-include-subdomains: &quot;false&quot;
  body-size: &quot;200m&quot;
  server-name-hash-bucket-size: &quot;256&quot;
---
apiversion: apps/v1
kind: deployment
metadata:
  name: default-http-backend
  namespace: kube-ingress
spec:
  replicas: 1
  selector:
    matchlabels:
      app: default-http-backend
  template:
    metadata:
      labels:
        app: default-http-backend
    spec:
      containers:
      - name: default-http-backend
        # any image is permissable as long as:
        # 1. it serves a 404 page at /
        # 2. it serves 200 on a /healthz endpoint
        image: gcr.io/google_containers/defaultbackend:1.0
        livenessprobe:
          httpget:
            path: /healthz
            port: 8080
            scheme: http
          initialdelayseconds: 30
          timeoutseconds: 5
        ports:
        - containerport: 8080
        resources:
          limits:
            cpu: 10m
            memory: 20mi
          requests:
            cpu: 10m
            memory: 20mi
---
apiversion: apps/v1
kind: deployment
metadata:
  name: nginx
  namespace: kube-ingress
spec:
  replicas: 1
  selector:
    matchlabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      serviceaccountname: nginx
      containers:
      - image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.31.0
        name: nginx
        imagepullpolicy: always
        env:
          - name: pod_name
            valuefrom:
              fieldref:
                fieldpath: metadata.name
          - name: pod_namespace
            valuefrom:
              fieldref:
                fieldpath: metadata.namespace
        livenessprobe:
          httpget:
            path: /healthz
            port: 10254
            scheme: http
          initialdelayseconds: 30
          timeoutseconds: 5
        ports:
        - containerport: 80
        - containerport: 443
        args:
        - /nginx-ingress-controller
        - --default-backend-service=kube-ingress/default-http-backend
        - --configmap=kube-ingress/nginx
---
kind: serviceaccount
apiversion: v1
metadata:
  name: nginx
  namespace: kube-ingress
---
kind: role
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress-newrole
rules:
  - apigroups:
      - &quot;&quot;
    resources:
      - services
    verbs:
      - get
      - list
      - watch
---
kind: rolebinding
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress-newrole
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: nginx-ingress-newrole
subjects:
- kind: serviceaccount
  name: nginx
  namespace: kube-ingress
---
kind: clusterrole
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress-clusterole
rules:
  - apigroups:
      - &quot;&quot;
    resources:
      - services
    verbs:
      - get
      - list
      - watch
---
kind: rolebinding
apiversion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress-clusterole
roleref:
  apigroup: rbac.authorization.k8s.io
  kind: role
  name: nginx-ingress-clusterole
subjects:
- kind: serviceaccount
  name: nginx
  namespace: kube-ingress

",<nginx><kubernetes><kubernetes-ingress><nginx-ingress><microk8s>,64439632,1,"issue
as mentioned in the logs
no service with name kube-ingress/default-http-backend found: services &quot;default-http-backend&quot; not found

the main issue here was the lack of default-http-backend service in kube-ingress namespace.
solution
the solution here is to simply add the default-http-backend service.
you can create it with kubectl expose or yaml file.
"
69842518,multiple ingress-nginx in kubernetes not validating webhook not working,"as stated in the title, i currently have a configuration with 2 ingress-nginx v1.0.0 on gke v1.20.10.
when i deploy one alone the configuration is working and i have no issue, but when i deploy the second one the validatingwebhook and then try to deploy an ingress the 2 validatingwebhook try to evaluate the newly created ingress.
this result in this error:
**error from server (internalerror): error when creating &quot;ingress-example.yaml&quot;: internal error occurred: failed calling webhook &quot;validate.nginx-public.ingress.kubernetes.io&quot;: post &quot;https://ingress-nginx-controller-admission-public.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s&quot;: x509: certificate is valid for ingress-nginx-controller-admission-private, ingress-nginx-controller-admission-private.ingress-nginx.svc, not ingress-nginx-controller-admission-public.ingress-nginx.svc**

i checked and everything seems to be correctly separated, my validatingwebhook is deployed like that, the {{ ingress_type }} is a placeholder for -public or -private:
---
apiversion: admissionregistration.k8s.io/v1
kind: validatingwebhookconfiguration
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.0.0
    app.kubernetes.io/component: admission-webhook
  name: ingress-nginx-admission{{ ingress_type }}
webhooks:
  - name: validate.nginx{{ ingress_type }}.ingress.kubernetes.io
    matchpolicy: equivalent
    objectselector:
      matchlabels:
        ingress-nginx : nginx{{ ingress_type }}
    rules:
      - apigroups:
          - networking.k8s.io
        apiversions:
          - v1
        operations:
          - create
          - update
        resources:
          - ingresses
    failurepolicy: fail
    sideeffects: none
    admissionreviewversions:
      - v1
    clientconfig:
      service:
        namespace: ingress-nginx
        name: ingress-nginx-controller-admission{{ ingress_type }}
        path: /networking/v1/ingresses
---
apiversion: v1
kind: service
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.0.0
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller-admission{{ ingress_type }}
spec:
  type: clusterip
  ports:
    - name: https-webhook
      port: 443
      targetport: webhook
      appprotocol: https
  selector:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}

i can't seem to find a solution, there is an old github issue on that with no answer, maybe i'm doing something wrong but i just can't see it.
as asked in comment, here is the ingress-example i'm trying to deploy, this works perfectly fine with only one ingress, not with two:
apiversion: networking.k8s.io/v1
kind: ingress
metadata:
  name: example-ingress
  annotations:
    kubernetes.io/ingress.class: nginx-private
#    external-dns.alpha.kubernetes.io/target: &quot;ip&quot;
  labels:
    ingress-nginx : nginx-public
spec:
  rules:
    - host: hello.mydomainhere
      http:
        paths:
          - path: /
            pathtype: prefix
            backend:
              service:
                name: web
                port:
                  number: 8080

",<kubernetes><google-kubernetes-engine><ingress-nginx>,69855781,1,"so for those that may encounter this error.
i tried different things before finding what was wrong. you have to rename all the labels but the version of the ingress-nginx, i did not think that it would break for so little, but it does. in the end i'm using something like this:
---
apiversion: admissionregistration.k8s.io/v1
kind: validatingwebhookconfiguration
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/instance: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/version: 1.0.0
    app.kubernetes.io/component: admission-webhook{{ ingress_type }}
  name: ingress-nginx-admission{{ ingress_type }}
webhooks:
  - name: validate.nginx{{ ingress_type }}.ingress.kubernetes.io
    matchpolicy: equivalent
    objectselector:
      matchlabels:
        ingress-nginx : nginx{{ ingress_type }}
    rules:
      - apigroups:
          - networking.k8s.io
        apiversions:
          - v1
        operations:
          - create
          - update
        resources:
          - ingresses
    failurepolicy: fail
    sideeffects: none
    admissionreviewversions:
      - v1
    clientconfig:
      service:
        namespace: ingress-nginx
        name: ingress-nginx-controller-admission{{ ingress_type }}
        path: /networking/v1/ingresses
---
apiversion: v1
kind: service
metadata:
  labels:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/instance: ingress-nginx{{ ingress_type }}
    app.kubernetes.io/version: 1.0.0
    app.kubernetes.io/component: controller{{ ingress_type }}
  name: ingress-nginx-controller-admission{{ ingress_type }}
spec:
  type: clusterip
  ports:
    - name: https-webhook
      port: 443
      targetport: webhook
      appprotocol: https
  selector:
    app.kubernetes.io/name: ingress-nginx{{ ingress_type }}

i think in this case it's really important to do the same on all the resources.
"
60400224,kubernetes network plugin,"i have installed a kubernetes cluster of 3 nodes with the calico network plugin.
for some reason i decided to remove totally kubernetes and reisntall it with a different network plugin: flannel.

all seemed fine until i tried to deploy my first container.

kubectl describe pod/cassandra return the following error:

unknown desc = [failed to set up sandbox container ""957f68c3cbe9b230b0e2bd6729a12c340f903de568622e28e335f7b48563a445"" network for pod ""cassandra-d7db46b86-dz7ck"": networkplugin cni failed to set up pod ""cassandra-d7db46b86-dz7ck_default"" network: error getting clusterinformation: get https://[10.96.0.1]:443/apis/crd.projectcalico.org/v1/clusterinformations/default: x509: certificate signed by unknown authority (possibly because of ""crypto/rsa: verification error"" while trying to verify candidate authority certificate ""kubernetes""), failed to clean up sandbox container ""957f68c3cbe9b230b0e2bd6729a12c340f903de568622e28e335f7b48563a445"" network for pod ""cassandra-d7db46b86-dz7ck"": networkplugin cni failed to teardown pod ""cassandra-d7db46b86-dz7ck_default"" network: error getting clusterinformation: get https://[10.96.0.1]:443/apis/crd.projectcalico.org/v1/clusterinformations/default: x509: certificate signed by unknown authority (possibly because of ""crypto/rsa: verification error"" while trying to verify candidate authority certificate ""kubernetes"")]
  normal   sandboxchanged          3s (x3 over 18s)  kubelet, &lt;node name&gt;  pod sandbox changed, it will be killed and re-created.


by reading at the errors it seems that the calico plugin is still used by kubernetes, although i removed it and installed the flannel plugin.

how can i clean this mess ?
",<kubernetes><kubernetes-networking>,60405775,5,"
clear ip route: ip route flush proto bird
remove all calico links in all nodes

ip link list | grep cali | awk '{print $2}' | cut -c 1-15 | xargs -i {} ip link delete {}


remove ipip module modprobe -r ipip
remove calico configs

rm /etc/cni/net.d/10-calico.conflist &amp;&amp; rm /etc/cni/net.d/calico-kubeconfig


restart kubelet service

after this you install flannel.
"
63467220,kubectl delete but ignore ones with error,"i have a list of namespaces and i want to delete them but some of them are giving error and i want to skip that ones and continue other deletions. how can i do that?
kubectl delete services,deployments -n ${namespace} --all  --grace-period=10

",<jenkins><kubernetes><kubectl>,63467323,46,"you can try using --ignore-not-found=true flag in command
kubectl delete deployments --ignore-not-found=true -n ${namespace} --all  --grace-period=10

"
52202159,jenkins + kubenetes: how to use kubectl in kubernetes-plugin,"i am configuring jenkins on kubernetes system. it works fine to build. but in order to deploy, we need to call kubectl or helm. currently, i am using


lachlanevenson/k8s-kubectl:v1.8.8
lachlanevenson/k8s-helm:latest


it is fail and throw exception: ""error from server (forbidden): pods is forbidden: user ""system:serviceaccount:jenkins:default"" cannot list pods in the namespace ""jenkins""""

the jenkins script is simple:

def label = ""worker-${uuid.randomuuid().tostring()}""

podtemplate(label: label,containers: [
  containertemplate(name: 'kubectl', image: 'lachlanevenson/k8s-kubectl:v1.8.8', command: 'cat', ttyenabled: true)
],
volumes: [
  hostpathvolume(mountpath: '/var/run/docker.sock', hostpath: '/var/run/docker.sock')
]){
  node(label) {
    stage('run kubectl') {
        container('kubectl') {
            sh ""kubectl get pods""
        }    
    }
  }
}


could you please let me know what is wrong?

thanks,
",<jenkins><kubernetes><jenkins-plugins><kubectl><kubernetes-helm>,52204104,3,"the kubernetes (k8s) master, as of kubernetes v1.8, by default implements role-based access control (rbac) security controls on accesses to its api. the rbac controls limit access to the k8s api by your workloads to only those resources and methods which you have explicitly permitted.

you should create a role which permits access to the pod resource's list verb (and any other resources you require1), create a service account object, and finally create a role binding which assigns the role to the service account.

finally, provide the service account to your jenkins deployment by supplying its name in the serviceaccountname property of the pod template. ensure automountserviceaccounttoken is true to have k8s install an api key into your pod. attempts to access the k8s api using the native k8s api wrappers and libraries should find this key and automatically authenticate your requests.

1if you are planning to make deployments from jenkins, you will certainly require more than the ability to list pods, as you will be required to mutate objects in the system. however, if you use helm, it is helm's tiller pod which influences the downstream k8s objects for your deployments, so the set of permissions you require for the helm tiller and for jenkins to communicate with the tiller will vary.
"
58498972,why i get some strange chars when i deploy with helm via the command line?,"i am trying to deploy the nginx-ingress helm chart and i want to provide some extraargs.

the thing is that, when i try to pass the arguments from the console

helm upgrade --install ${release_name} \
--set controller.extraargs={udp-services-configmap=default/cm-udp-services} \
stable/nginx-ingress


i get this when i describe the deployment.

    args:
      /nginx-ingress-controller
      --default-backend-service=default/tcp-udp-ic-nginx-ingress-default-backend
      --election-id=ingress-controller-leader
      --ingress-class=nginx
      --configmap=default/tcp-udp-ic-nginx-ingress-controller
      --0=udp-services-configmap:default/cm-udp-services


i just don't understand why i get this 0=.

however, when i add the extra argument via the values.yml file, 

  ## additional command line arguments to pass to nginx-ingress-controller
  ## e.g. to specify the default ssl certificate you can use
  ## extraargs:
  ##   default-ssl-certificate: ""&lt;namespace&gt;/&lt;secret_name&gt;""
  extraargs: {
               udp-services-configmap=default/cm-udp-services
  }


everything is ok.

has anyone else encounter this?

edit

even though weibeld's answer solved the problem, i observe that when i deploy the ic, the service unfortunately does not have the ports that are stated in the config-map open. 
",<kubernetes><kubernetes-helm><nginx-ingress>,58499253,2,"remove the curly braces and delimit the udp-services-configmap argument with a period:

helm upgrade --install ${release_name} \
--set controller.extraargs.udp-services-configmap=default/cm-udp-services \
stable/nginx-ingress


and if you use a values.yaml file, the usual way to write it is:

controller:
  extraargs:
    udp-services-configmap: default/cm-udp-services


you don't need curly braces in yaml, except for denoting an empty object (extraargs: {}).
"
35537834,debugging a container in a crash loop on kubernetes,"in gke, i have a pod with two containers. they use the same image, and the only difference is that i am passing them slightly different flags. one runs fine, the other goes in a crash loop. how can i debug the reason for the failure?

my pod definition is

apiversion: v1
kind: replicationcontroller
metadata:
  name: doorman-client
spec:
  replicas: 10
  selector:
    app: doorman-client
  template:
    metadata:
      name: doorman-client
      labels:
        app: doorman-client
    spec:
      containers:
        - name: doorman-client-proportional
          resources:
            limits:
              cpu: 10m
          image: gcr.io/google.com/doorman/doorman-client:v0.1.1
          command: 
            - client
            - -port=80
            - -count=50
            - -initial_capacity=15
            - -min_capacity=5
            - -max_capacity=2000
            - -increase_chance=0.1
            - -decrease_chance=0.05
            - -step=5
            - -resource=proportional
            - -addr=$(doorman_service_host):$(doorman_service_port_grpc)
            - -vmodule=doorman_client=2
            - --logtostderr
          ports:
            - containerport: 80
              name: http

        - name: doorman-client-fair
          resources:
            limits:
              cpu: 10m
          image: gcr.io/google.com/doorman/doorman-client:v0.1.1
          command: 
            - client
            - -port=80
            - -count=50
            - -initial_capacity=15
            - -min_capacity=5
            - -max_capacity=2000
            - -increase_chance=0.1
            - -decrease_chance=0.05
            - -step=5
            - -resource=fair
            - -addr=$(doorman_service_host):$(doorman_service_port_grpc)
            - -vmodule=doorman_client=2
            - --logtostderr
          ports:
            - containerport: 80
              name: http


kubectl describe gives me the following:

6:06 [0] (szopa szopa-macbookpro):~/gopath/src/github.com/youtube/doorman$ kubectl describe pod doorman-client-tylba
name:               doorman-client-tylba
namespace:          default
image(s):           gcr.io/google.com/doorman/doorman-client:v0.1.1,gcr.io/google.com/doorman/doorman-client:v0.1.1
node:               gke-doorman-loadtest-d75f7d0f-node-k9g6/10.240.0.4
start time:         sun, 21 feb 2016 16:05:42 +0100
labels:             app=doorman-client
status:             running
reason:
message:
ip:             10.128.4.182
replication controllers:    doorman-client (10/10 replicas created)
containers:
  doorman-client-proportional:
    container id:   docker://0bdcb8269c5d15a4f99ccc0b0ee04bf3e9fd0db9fd23e9c0661e06564e9105f7
    image:      gcr.io/google.com/doorman/doorman-client:v0.1.1
    image id:       docker://a603248608898591c84216dd3172aaa7c335af66a57fe50fd37a42394d5631dc
    qos tier:
      cpu:  guaranteed
    limits:
      cpu:  10m
    requests:
      cpu:      10m
    state:      running
      started:      sun, 21 feb 2016 16:05:42 +0100
    ready:      true
    restart count:  0
    environment variables:
  doorman-client-fair:
    container id:   docker://92fea92f1307b943d0ea714441417d4186c5ac6a17798650952ea726d18dba68
    image:      gcr.io/google.com/doorman/doorman-client:v0.1.1
    image id:       docker://a603248608898591c84216dd3172aaa7c335af66a57fe50fd37a42394d5631dc
    qos tier:
      cpu:  guaranteed
    limits:
      cpu:  10m
    requests:
      cpu:          10m
    state:          running
      started:          sun, 21 feb 2016 16:06:03 +0100
    last termination state: terminated
      reason:           error
      exit code:        0
      started:          sun, 21 feb 2016 16:05:43 +0100
      finished:         sun, 21 feb 2016 16:05:44 +0100
    ready:          false
    restart count:      2
    environment variables:
conditions:
  type      status
  ready     false
volumes:
  default-token-ihani:
    type:   secret (a secret that should populate this volume)
    secretname: default-token-ihani
events:
  firstseen lastseen    count   from                            subobjectpath                   reason      message
  ───────── ────────    ─────   ────                            ─────────────                   ──────      ───────
  29s       29s     1   {scheduler }                                                scheduled   successfully assigned doorman-client-tylba to gke-doorman-loadtest-d75f7d0f-node-k9g6
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   implicitly required container pod       pulled      container image ""gcr.io/google_containers/pause:0.8.0"" already present on machine
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   implicitly required container pod       created     created with docker id 5013851c67d9
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   implicitly required container pod       started     started with docker id 5013851c67d9
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-proportional}    created     created with docker id 0bdcb8269c5d
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-proportional}    started     started with docker id 0bdcb8269c5d
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        created     created with docker id ed0928176958
  29s       29s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        started     started with docker id ed0928176958
  28s       28s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        created     created with docker id 0a73290085b6
  28s       28s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        started     started with docker id 0a73290085b6
  18s       18s     1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        backoff     back-off restarting failed docker container
  8s        8s      1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        started     started with docker id 92fea92f1307
  29s       8s      4   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        pulled      container image ""gcr.io/google.com/doorman/doorman-client:v0.1.1"" already present on machine
  8s        8s      1   {kubelet gke-doorman-loadtest-d75f7d0f-node-k9g6}   spec.containers{doorman-client-fair}        created     created with docker id 92fea92f1307


as you can see, the exit code is zero, with the message being ""error"", which is not super helpful.

i tried:


changing the order of the definitions (firs one always runs, second one always fails).
changing the used ports to be different (no effect)
changing the name of the ports to be different (no effect).

",<kubernetes><google-kubernetes-engine>,35538884,3,"it's tough to say exactly without knowing more about your app, but the two containers definitely can't use the same port if they're part of the same pod. in kubernetes, each pod gets its own ip address, but each container in the pod shares that same ip address. that's why you can't have more than one of them using the same port unless you split them into separate pods.

to get more info, i'd recommend using the kubectl logs [pod] [optional container name] command, which can be used to get the stdout/stderr from a container. the -p flag can be used to get the logs from the most recently failed container.
"
66344949,kubectl not communicating with minikube,"learning kubernetes with kubectl and minikube locally. i can see this via kubectl:
&gt; kubectl get all -o wide

name                                     ready   status    restarts   age   ip           node       nominated node   readiness gates
pod/mongodb-deployment-8f6675bc5-tjwsb   1/1     running   0          20s   10.1.43.14   chris-x1   &lt;none&gt;           &lt;none&gt;
pod/mongo-express-78fcf796b8-9gbsd       1/1     running   0          20s   10.1.43.15   chris-x1   &lt;none&gt;           &lt;none&gt;

name                            type           cluster-ip       external-ip   port(s)          age   selector
service/kubernetes              clusterip      10.152.183.1     &lt;none&gt;        443/tcp          29m   &lt;none&gt;
service/mongo-express-service   loadbalancer   10.152.183.254   &lt;pending&gt;     8081:30000/tcp   20s   app=mongo-express
service/mongodb-service         clusterip      10.152.183.115   &lt;none&gt;        27017/tcp        20s   app=mongodb

name                                 ready   up-to-date   available   age   containers      images          selector
deployment.apps/mongodb-deployment   1/1     1            1           20s   mongodb         mongo           app=mongodb
deployment.apps/mongo-express        1/1     1            1           21s   mongo-express   mongo-express   app=mongo-express

name                                           desired   current   ready   age   containers      images          selector
replicaset.apps/mongodb-deployment-8f6675bc5   1         1         1       20s   mongodb         mongo           app=mongodb,pod-template-hash=8f6675bc5
replicaset.apps/mongo-express-78fcf796b8       1         1         1       21s   mongo-express   mongo-express   app=mongo-express,pod-template-hash=78fcf796b8

but when i lanuch minikube dashboard i don't see any pods, deployments, services etc...? its like they are running off of different clusters. if i paste the yaml configs directly into minikube dashboard, then i can see everything. so strange... why?
i can use the minikube kubectl command, but that doesn't seem like thats how this should work.
running ubuntu 20, kubectl 1.20, and minikube 1.17.
",<kubernetes><kubectl><minikube>,66345375,1,"turns out i was set to run off of microk8s-cluster instead of minikube.
chris@chris-x1 /v/w/p/k8s&gt; kubectl config view

apiversion: v1
clusters:
- cluster:
    certificate-authority-data: data+omitted
    server: https://127.0.0.1:16443
  name: microk8s-cluster
contexts:
- context:
    cluster: microk8s-cluster
    user: admin
  name: microk8s
current-context: microk8s
kind: config
preferences: {}
users:
- name: admin
  user:
    token: redacted

so i needed to follow these steps to access a dashboard: https://microk8s.io/docs/addon-dashboard
"
36283660,creating image pull secret for google container registry that doesn't expire?,"i'm trying to get kubernetes to download images from a google container registry from another project. according to the docs you should create an image pull secret using: 

$ kubectl create secret docker-registry myregistrykey --docker-server=docker_registry_server --docker-username=docker_user --docker-password=docker_password --docker-email=docker_email


but i wonder what docker_user and docker_password i should use for authenticating with google container registry? looking at the gcr docs it says that the password is the access token that you can get by running:

$ gcloud auth print-access-token


this actually works... for a while. the problem seems to be that this access token expires after (what i believe to be) one hour. i need a password (or something) that doesn't expire when creating my image pull secret. otherwise the kubernetes cluster can't download the new images after an hour or so. what's the correct way to do this?
",<google-cloud-platform><kubernetes><google-kubernetes-engine><google-container-registry>,36286707,23,"this is really tricky but after a lot of trail and error i think i've got it working.

go to the google developer console &gt; api manager &gt; credentials and click &quot;create credentials&quot; and create a &quot;service account key&quot;

under &quot;service account&quot; select new and name the new key &quot;gcr&quot; (let the key type be json)

create the key and store the file on disk (from here on we assume that it was stored under ~/secret.json)

now login to gcr using docker from command-line:
$ docker login -e your@email.se -u _json_key -p &quot;$(cat ~/secret.json)&quot; https://eu.gcr.io


this will generate an entry for &quot;https://eu.gcr.io&quot; in your ~/.docker/config.json file.
6. copy the json structure under &quot;https://eu.gcr.io&quot; into a new file called &quot;~/docker-config.json&quot;, remove newlines! for example:


base64 encode this file:
$ cat ~/docker-config.json | base64

this will print a long base64 encoded string, copy this string and paste it into an image pull secret definition (called ~/pullsecret.yaml):



apiversion: v1
  kind: secret
  metadata:
    name: mykey
  data:
    .dockercfg: &lt;paste base64 encoded string here&gt;
  type: kubernetes.io/dockercfg



now create the secret:

$ kubectl create -f ~/pullsecret.yaml
10. now you can use this pull secret from a pod, for example:

apiversion: v1
kind: pod
metadata: 
  name: foo
  namespace: awesomeapps
spec: 
  containers: 
    - image: &quot;janedoe/awesomeapp:v1&quot;
      name: foo
  imagepullsecrets: 
    - name: mykey


or add it to a service account.
"
47079714,kubernetes dns lookup of microservice,"i have a question on the kubernetes dns lookup, if i am using in my services deployment ""dns"" instead of ""env"", 

can my microservice using another microservices in the cluster get the dns names of all the microservices?

i get this piece of code, if i use env then i get the the info of host from env. but if i am using dns what format and how do i get the dns names, is there a dns object i can query on the client side?

if (isset($_get['cmd']) === true) {
  $host = 'redis-master';
if (getenv('get_hosts_from') == 'env') {
  $host = getenv('redis_master_service_host');
}


ref: https://github.com/googlecloudplatform/container-engine-samples/blob/master/guestbook/php-redis/guestbook.php

if someone has examples (preferably nodejs), i can dig into that. 
",<dns><kubernetes><google-kubernetes-engine>,47083280,7,"first off this is documented throughly. in any case if you want to query dns to find out where things are running you can do so if you know the service name by pointing at:

my-svc.my-namespace.svc.cluster.local


additionally, if you also want to abstract port numbers and are ok with knowing a port name you can query srv records and get both port numbers as well as cname:

_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local


for your specific example this would be something like (assuming default namespace):

_redis-client._tcp.redis-service.default.svc.cluster.local


querying srv records is more reliable than depending on environment variables because if during the lifetime of the pod, an external service changes location, environment variables can't be re-injected, but re-querying dns records will yield updated results.
"
64955491,"how is the ""cluster creator"" user of an aws eks cluster mapped to the ""system:masters"" rbac group?","i'm trying to understand how are managed rbac authorizations for the first user that create an eks cluster within aws.
or in other words : how is the cluster creator mapped to the &quot;system:masters&quot; group within rbac ?
i know this doc states : &quot;when you create an amazon eks cluster, the iam entity user or role, such as a federated user that creates the cluster, is automatically granted system:masters permissions in the cluster's rbac configuration.&quot;
and i understand how clusterrole cluster-admin and clusterrolebinding cluster-admin grants full admin rights to any members of the &quot;system:masters&quot; group.
what i can't figure out is how/where is the cluster creator user mapped to this group ? (the &quot;automatically granted&quot; part of the doc)
ps: i know that to add additionnal user/roles i'm supposed to use the aws-auth configmap, but this first user is not defined here and still has access to cluster.
if anyone can enlighten me please ?
thanks in advance!
for the record i'm using a kubernetes 1.18 eks cluster that was built with terraform via the community module here :
module &quot;cluster&quot; {
  source  = &quot;terraform-aws-modules/eks/aws&quot;
  version = &quot;13.2.1&quot;

  cluster_version = &quot;1.18&quot;
  cluster_name    = &quot;memorandom-${local.id}&quot;
  vpc_id          = module.vpc.vpc_id
  subnets         = module.vpc.private_subnets

  write_kubeconfig = false
  manage_aws_auth  = true

  worker_groups = [
    {
      instance_type = &quot;t3.medium&quot;
      asg_max_size  = 3
      key_name      = &quot;pbenefice&quot;
    }
  ]

  tags = local.tags
}

",<kubernetes><amazon-iam><amazon-eks><kubernetes-rbac>,65060804,8,"so i reached for aws support on this topic. and to summarize the answer was : &quot;most of what you are asking about is confidential information and cannot be disclosed.&quot;.
i paste the full reply here :

thanks for reaching out to aws premium support. my name is * and i understand you're curious about the implementation details of the cluster creator's being part of the system:masters group.
most of what you are asking about is confidential information and cannot be disclosed.
however, i can tell you that the eks control plane has an authenticator component. you can enable logs for this as described here [1].
personally, i like to think of that &quot;automatically granted&quot; part of the docs as an imaginary, read-only permanent object under the mapusers: section of the aws-auth configmap. imaginary because it's not implemented in the aws-auth configmap, but the permissions it is granted are the same as if it were there.  i've created an imaginary cluster-creator user object in the example below [2] that shows the effective implementation
[1]: amazon eks control plane logging - https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html
[2]: example aws-auth configmap
apiversion: v1
data:
  maproles: |
    - rolearn: arn:aws:iam::111122223333:role/eksctl-my-cluster-nodegroup-standard-wo-nodeinstancerole-1wp3nue3o6ucf
      username: system:node:{{ec2privatednsname}}
      groups:
        - system:bootstrappers
        - system:nodes
  mapusers: |
    # the way eks currently bootstraps your cluster permissions, you can think of the cluster-creator having a
    # read-only permanent entry here - the effective permissions are the same
    - userarn: arn:aws:iam::111122223333:user/cluster-creator
      username: cluster-creator
      groups:
        - system:masters
    # in an actual aws-auth configmap, the cluster-creator entry above isn't there and
    # only the mapusers below would be shown
    - userarn: arn:aws:iam::111122223333:user/admin
      username: admin
      groups:
        - system:masters
    - userarn: arn:aws:iam::111122223333:user/ops-user
      username: ops-user
      groups:
        - system:masters

the most important practical considerations regarding the cluster creator rbac permissions are:

the iam entity (user or role) that created the cluster is always going to have admin privileges (system:masters permissions)
if iam entity is deleted without other iam entities being added with the necessary permissions to the aws-auth configmap - you have two options:

you must either recreate the iam entity with the same name to regain access to your cluster, or
delete the cluster and create a new cluster using a new iam entity



i know this probably wasn't all the information you'd hoped for, but i hope it helps satisfy part of your curiosity.
as i can't go into any real depth to answer your questions, i'll go ahead and resolve your case.
i hope you have a wonderful day and please feel free to reach out to us anytime.
"
73760555,why does kubectl annotate does work and kubectl patch does not?,"i am trying to use ‘kubectl patch’ to provide an annotation to a default service account in a namespace. this is because the javascript client does not seem to have a kubectl annotate function. so now i wonder:
why does the following patch command not work?
kubectl patch sa default -n somenamespace -v8 --type=json -p='[{&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;annotations/http://eks.amazonaws.com~1role-arn&quot;, &quot;value&quot;: &quot;ueah&quot;}]'


while the following statement using annotate does work?

kubectl annotate --overwrite -v8 sa default -n t-werwww2 http://eks.amazonaws.com/role-arn=&quot;ueah&quot;

what would be the correct kubectl patch command?
",<kubernetes><kubectl><patch><annotate>,73767670,2,"@hiroyukik seems to have partially answered your question by pointing out that you have the path wrong and it should be &quot;/metadata/annotations&quot;.
you used the json merge patch strategy in your comment. i don't think you need to find a json patch alternative as you suggested, as the javascript kubernetes client supports json merge patch.
my understanding is that you just add a header in the options to set the strategy you want, like so:
const options = { &quot;headers&quot;: { &quot;content-type&quot;: patchutils.patch_format_json_merge_patch } }

see the docs for how to add this to the function call:
https://kubernetes-client.github.io/javascript/classes/corev1api.corev1api-1.html#patchnamespacedserviceaccount
however, if you do really need to use the json patch strategy, you'll need to check whether the service account has annotations first as that strategy has no way of creating and adding a field in a single operation. see this github comment for an explanation:
https://github.com/kubernetes/kubernetes/issues/90623#issuecomment-621584160
so a complete shell script example using the json patch strategy would look like this:
kubectl get sa default -n somenamespace -o json \
  | jq -e '.metadata | has(&quot;annotations&quot;)' &amp;&amp; \
kubectl patch sa default -n somenamespace --type=json \
    -p='[{&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/metadata/annotations/eks.amazonaws.com~1role-arn&quot;, &quot;value&quot;: &quot;ueah&quot;}]' || \
kubectl patch sa default -n somenamespace --type=json \
    -p='[{&quot;op&quot;:&quot;add&quot;,&quot;path&quot;:&quot;/metadata/annotations&quot;,&quot;value&quot;:{}},{&quot;op&quot;:&quot;add&quot;,&quot;path&quot;:&quot;/metadata/annotations/eks.amazonaws.com~1role-arn&quot;,&quot;value&quot;: &quot;ueah&quot;}]'

"
